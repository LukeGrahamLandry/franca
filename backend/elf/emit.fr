EmitElf :: @struct {
    m: *Qbe.Module;
    header: *Elf.Header;
    program_headers: []Elf.ProgramHeader;
    commands: List(u8); // only contains (elf, program, section) headers
    payload: List(u8);  // everything else
    // these are the final bytes that will be emitted
    // (commands, payload, segments)
    chunks: List([]u8);  
    // These don't do anything i think? but you always at least an empty one. 
    section_names: List(Str);
    section_index := zeroed EnumMap(SegmentType, u16);
};

SymbolTableInfo :: @struct {  
    fixups: []FixP = empty();
    symbols: []*SymbolInfo = empty();
    local_count := 0;  // NOT counting exports
};

max_program_headers :: 9;
prot_read_write :: bit_or(Elf.PF_R, Elf.PF_W);
prot_read :: Elf.PF_R;

align_segments :: fn(m: *Qbe.Module) i64 = {
    patch_pending_symbols(m);
    
    code := m.segments&[.Code]&;
    code_size := code.len() - m.goal.commands_size_guess;

    // who fucking knows
    if m.segments&[.ZeroInitData]&.len() > 0 && m.segments&[.MutableData]&.len() == 0 {
        m.segments&.index(.MutableData).reserve(u8);
    };
    
    @if(m.goal.type != .Relocatable)
    for_enum SegmentType { s | 
        m.align_to(s, 4096);
        // blink (https://github.com/jart/blink) wants 65k pages to let you turn on linear memory optimisation. 
        // which makes it a lot faster (they claim 400%, i get 20%, but still). 
        // (this is what `-Wl,-z,common-page-size=65536,-z,max-page-size=65536` i guess)
        if m.goal.arch == .x86_64 {
            m.align_to(s, 1.shift_left(16));
        };
    };
    m.fixups_locked = true; // we're going to stomp the data section with relocation info so you can run it jitted anymore after this. 
    code_size
};

finalize_symbols :: fn(m: *Qbe.Module) SymbolTableInfo = {
    @debug_assert(m.goal.type != .Relocatable); // TODO: does this really need a different code path?
    fixups, symbols := collect_aot_fixups(m);
    
    // TODO: would it be nicer to have multiple symbol tables (put exports elsewhere?)
    //       if not, still have collect_aot_fixups return the list so you keep the extra capacity. :SLOW
    if m.goal.type == .Dynamic {
        ::List(@type symbols[0]);
        s := symbols.assume_owned(temp());
        for m.exports { id | 
            it := m.get_symbol_info(id);
            if it.fixups.len == 0 {
                s&.push(it);
            }
        };
        symbols = s.items();
    };
    
    // local symbols are kept seperate from imports. 
    // dynsym.sh_info is the index of the first global symbol. 
    // exports are also global (same as imports)
    partition_unordered(*SymbolInfo, symbols, fn(it) => it.kind == .Local && (!it.export || !@is(m.goal.type, .Relocatable, .Dynamic)));
    
    local_count := 0;
    enumerate symbols { i, s |
        local_count += int(s.kind == .Local);
    };
    if !m.goal.link_libc {
        symbols.len = local_count;
        // :SLOW
        local_fix := FixP.list(temp());
        for fixups { it |
            ::enum(@type it.symbol.kind);
            if it.symbol.kind == .Local {
                local_fix&.push(it);
            } else {
                @assert(!it.symbol.strong, "importing non-weak symbol '%' in static binary", it.symbol.name);
                @match(it.fix.type&) {
                    fn DataAbsolute() => {
                        i64.ptr_from_raw(it.fix.patch_at)[] = 0;
                    };
                    fn InReg(info) => @match(m.goal.arch) {
                        fn aarch64() => {
                            // i use adr when in range but i don't want to deal with another relocation type rn
                            reg := @as(u5) info.r;
                            inst: []u32 = (ptr = u32.ptr_from_raw(it.fix.patch_at), len = 2);
                            inst[0] = movz(.X64, reg, 0, .Left0);
                            inst[1] = Arm.arm_nop;
                        };
                        fn rv64() => todo();
                        @default => unreachable();
                    };
                    @default => ();
                };
            }
        };
        fixups = local_fix.items();
    };
    (fixups = fixups, symbols = symbols, local_count = local_count)
};

start_elf :: fn(m: *Qbe.Module) EmitElf #inline = {
    commands: List(u8) = fixed_list(ptr = u8.ptr_from_raw(m.segment_address(.Code, 0)), len = m.goal.commands_size_guess);
    h := commands&.reserve_type(Elf.Header); h[] = zeroed(Elf.Header);
    program_headers_size := max_program_headers * size_of(Elf.ProgramHeader);
    @debug_assert_gt(commands.maybe_uninit.len, program_headers_size);
    ph: []Elf.ProgramHeader = (
        ptr = ptr_cast_unchecked(u8, Elf.ProgramHeader, commands.maybe_uninit.index_unchecked(commands.len)), 
        len = max_program_headers,
    );
    h.program_header_off = commands.len;
    commands.len += program_headers_size;
    h.section_header_off = commands.len;
    
    h.magic = Elf.MAGIC;
    h.class = 2; // 64-bit
    h.data = 1; // little endian
    h.header_version = 1;  // "current version"... as of 1997 (?)
    h.version = 1;
    h.program_header_entsize = size_of(Elf.ProgramHeader);
    h.section_header_entsize = size_of(Elf.SectionHeader);
    h.ehsize = size_of(Elf.Header);  // qemu-user cares about this field but the real linux kernel doesn't
    
    h.type = @match(m.goal.type) {
        fn Exe() => .Executable;
        fn Relocatable() => .Relocatable;
        fn Dynamic() => .Dynamic;
        @default => unreachable();
    };
    if m.goal.arch == .rv64 {
        // this fixes `ld.lld: error: a.o: cannot link object files with different floating-point ABI from [...]/crt1.o`
        h.flags = h.flags.bit_or(Elf.EF_RISCV_FLOAT_ABI_DOUBLE);
    };
    
    h.machine = @match(m.goal.arch) {
        fn aarch64() => .arm64;
        fn x86_64()  => .amd64;
        fn rv64()    => .rv64;
        @default     => unreachable();
    };
    if m.goal.have_entry_point {
        h.entry = main_entry_point_vaddr(m) + Elf.MYSTERY_SPICE;
    };
    (
        m = m,
        chunks = list([]u8, 10, temp()),
        commands = commands,
        header = h,
        program_headers = ph,
        payload = u8.list(m.goal.chained_size_guess, temp()),
        section_names = Str.list(10, temp()),
    )
};

PayloadBase :: @struct(virtual: i64, file: i64);

create_the_segments :: fn(e: *EmitElf) PayloadBase = {
    virtual_offset := Elf.MYSTERY_SPICE; 
    file_offset    := 0;
    make_segment :: fn(e: *EmitElf, seg: SegmentType, prot: u32, name: Str) => {
        break :: local_return;
        segment := e.m.segments&[seg]&;

        // without this skip you get `rosetta error: bss_size overflow`
        // yes, even tho this isn't for the bss segment; i don't make the rules; i just work here.
        @if(segment.len() == 0) break();  
        
        e.chunks&.push(live_segment_part(e.m, seg)); // :waste :commandsispartofcodenow
    
        e.program_header()[] = (
            type = .Load,
            prot = prot,
            offset = file_offset,
            vaddr = virtual_offset, 
            paddr = virtual_offset,
            file_size = segment.len(),
            mem_size = segment.len(),
            align = 4096,
        );
        
        // TODO: this comment doesn't make any sense. exe stills works without this
        // for static linking, local symbols are defined relative to a section so we need them even for Exe
        if e.m.goal.type == .Relocatable || e.m.goal.exe_debug_symbol_table {
            e.section_index&[seg] = e.header.section_header_num;
            flag := int(prot.bit_and(Elf.PF_X) != 0).shift_left(@as(i64) Elf.SectionFlag.Exec)
                .bit_or(int(prot.bit_and(Elf.PF_W) != 0).shift_left(@as(i64) Elf.SectionFlag.Write))
                .bit_or(1.shift_left(@as(i64) Elf.SectionFlag.Alloc));
            
            h := e.section_header(name);
            h[] = (
                name = 0, // TODO
                type = .ProgramBits, 
                flags = flag,
                addr = virtual_offset,  // this is required for exe_debug_symbol_table, nothing else cares
                offset = file_offset, 
                size = segment.len(),
                addr_align = 0,
            );
            
            if e.m.goal.type != .Relocatable {
                // help disassembler not show junk
                if seg == .Code {
                    pad := e.m.text_padding();
                    h.offset += pad;
                    h.addr += pad;
                    h.size -= pad;
                }
            }
        };
        
        virtual_offset += segment.mmapped.len;
        file_offset += segment.len();
    };
   
    // the LOAD headers are required to be in order. 
    
    RW :: prot_read_write;
    e.make_segment(.Code, RX, ".text"); RX :: bit_or(Elf.PF_R, Elf.PF_X);// :waste :commandsispartofcodenow
    e.make_segment(.ConstantData, RW, ".rodata");  // TODO: how the fuck do i do relocations in a non-writable segment?
    e.make_segment(.MutableData, RW, ".data");
    
    bss := e.m.segments&[.ZeroInitData]&;
    if bss.len() > 0 {
        // idk why this doesn't work for me without its own program header. 
        // shouldn't i just be able to do .mem_size += bss.len(); on the MutableData's program header? 
        // that was the reasoning behind always making sure there's at least one byte in taht segment when theres bss.
        // but booting doesn't work without this.... and undef.ssa doesn't work without that^ (which would make sense except that im giving it its own here so wtf)
        e.program_header()[] = (
            type = .Load,
            prot = RW,
            offset = file_offset,
            vaddr = virtual_offset, 
            paddr = virtual_offset,
            file_size = 0,
            mem_size = bss.len(),
            align = 4096,
        );
        // for linker
        e.section_index&[.ZeroInitData] = e.header.section_header_num;
        e.section_header(".bss")[] = (
            name = 0, // TODO
            type = .Bss, 
            // doesn't do anything...
            flags = 1.shift_left(@as(i64) Elf.SectionFlag.Write)
                .bit_or(1.shift_left(@as(i64) Elf.SectionFlag.Alloc)),
            addr = virtual_offset,  
            offset = file_offset, 
            size = bss.len(),
            addr_align = 4096,
        );
        
        virtual_offset += bss.len();
    };
    (virtual = virtual_offset, file = file_offset)
};

// results are in temp()
fn output_elf(m: *QbeModule) [][]u8 = {
    if m.goal.wrap_entry_for_linux_libc {
        start := "start";
        m.emit_linux_start(m.intern(m.goal.entry_point), m.intern(start));
        m.goal.entry_point = start;
    };
    
    debug_log_byte_size(m);
    code_size := align_segments(m);
    
    e: EmitElf = start_elf(m); e := e&;
    
    e.section_header("")[] = Elf.SectionHeader.zeroed();
    p_header := e.program_header();

    base := create_the_segments(e);
    
    if m.goal.type != .Relocatable {
        T := finalize_symbols(m);
        have_any_imports := T.local_count != T.symbols.len;
        if T.symbols.len > 0 {
            if have_any_imports {
                e.request_interp(e.program_header(), base);
            };
            
            dynamics := e.for_dynamic_loader(base, T);
            e.seal_dynamic(e.program_header(), e.program_header(), base, dynamics);
        };
        
        e.program_header()[] = (
            type = .Stack,
            prot = prot_read_write,
            offset = 0,
            vaddr = 0, 
            paddr = 0,
            file_size = 0,
            mem_size = 16777216,
            align = 0,
        );
        
        program_headers_size := e.program_headers.len * Elf.ProgramHeader.size_of();
        p_header[] = (
            type = .Phdr,
            prot = prot_read,
            offset = size_of(Elf.Header),
            vaddr = size_of(Elf.Header) + Elf.MYSTERY_SPICE, 
            paddr = size_of(Elf.Header) + Elf.MYSTERY_SPICE,
            file_size = program_headers_size,
            mem_size = program_headers_size,
            align = 8,
        );
    } else {
        e.emit_linker_relocations(base);
        section_names(e, base);
    };
    
    // program headers are only for the os loader, not a static linker, 
    // but it's easier to just always output them and pretend we didn't instead of checking in the above code. 
    if m.goal.type == .Relocatable {
        e.header.program_header_num = 0;
        e.header.program_header_off = 0;
        e.header.program_header_entsize = 0;
    };
    
    end := e.commands.len;
    @assert_le(end, m.goal.commands_size_guess, "we guessed wrong so the array resized and all the pointers are junk");
    e.commands.len = m.goal.commands_size_guess;
    e.commands.items().rest(end).set_zeroed();
    @assert_le(e.payload.len, m.goal.chained_size_guess, "resized and now the pointers are junk");  // TODO: don't think i need this here, just mach-o did
    if e.payload.len != 0 {
        e.chunks&.push(e.payload.items());
    };
    
    e.chunks.items()
}

// TODO: I think it really doesn't need the names so maybe i can take this out. 
section_names :: fn(e: *EmitElf, base: PayloadBase) void = {
    e.header.section_header_names_index = e.header.section_header_num;
    header := e.section_header(".shstrtab");
    
    offsets := u32.list(temp());
    string_table_start := e.payload.len;
    for e.section_names { n |
        offsets&.push(trunc(e.payload.len - string_table_start));
        e.payload&.push_all(n);
        e.payload&.push(0);
    };
    header[] = (
        name = 0,
        type = .StringTable, 
        flags = 0,
        addr = 0,
        offset = base.file + string_table_start, 
        size = e.payload.len - string_table_start,
        addr_align = 1,
    );
    
    ptr := ptr_cast_unchecked(u8, Elf.SectionHeader, e.commands.maybe_uninit.ptr.offset(e.header.section_header_off));
    s_headers: []Elf.SectionHeader = (ptr = ptr, len = e.header.section_header_num.zext());
    enumerate s_headers { i, h |
        h.name = offsets[i];
    };
};

request_interp :: fn(e: *EmitElf, interp_header: *Elf.ProgramHeader, base: PayloadBase) void = {
    loader_path := @match(e.m.goal.arch) {
        fn x86_64() => "/lib64/ld-linux-x86-64.so.2\0";
        fn aarch64() => "/lib/ld-linux-aarch64.so.1\0";
        fn rv64()   => "/usr/riscv64-linux-gnu/lib/ld-linux-riscv64-lp64d.so.1\0";
        @default    => @panic("unknown arch");
    };
    size := loader_path.len;
    addr := base.virtual + e.payload.len;
    interp_header[] = (
        type = .Interp,
        prot = prot_read,
        offset = base.file + e.payload.len,
        vaddr = addr, 
        paddr = addr,
        file_size = size,
        mem_size = size,
        align = 1,
    );
    e.payload&.push_all(loader_path);
    e.payload&.zero_pad_to_align(8);
};

// This is needed even for static executables: data relocations of local symbols are applied in franca_runtime_init. 
for_dynamic_loader :: fn(
    e: *EmitElf, 
    base: PayloadBase, 
    T: SymbolTableInfo,
) List(Elf.Dyn) = {
    m := e.m;
    // SectionHeader.link: Relocations -> DynSymbolTable -> StringTable
    // This is conceptually the same, it's just that the section headers don't do anything (?)
    dynamics := Elf.Dyn.list(10, temp());
    
    dynamics&.push(tag = .Flags, val = 8);  // DF_BIND_NOW // TODO: does this do anything?
    dynamics&.push(tag = .Flags_1, val = 1);  // ?     // TODO: does this do anything?
    dynamics&.push(tag = .Debug, val = 0);  // ?     // TODO: does this do anything?
   
    extra_strings := @if(m.goal.link_libc, glibc_dylib_paths, empty());
    table := e.create_symbol_table(T.symbols, .DynSymbolTable, extra_strings, base, false);
    for table.extra_strings { off |
        dynamics&.push(tag = .Needed, val = off);
    };
    
    if e.m.goal.type == .Dynamic {
        @debug_assert_eq(e.payload.len.mod(4), 0);
        start := e.payload.len;
        emit_dynamic_exports_hash(e, T);
        dynamics&.push(tag = .Hash, val = base.virtual + start);
        e.section_header(".hash")[] = (
            name = 0,
            type = .Hash, 
            flags = 1.shift_left(@as(i64) Elf.SectionFlag.Alloc),
            addr = 0,
            offset = base.file + start, 
            size = e.payload.len - start,
            addr_align = 4,
            ent_size = 4,
            link = table.symbol_table_index.zext(),
            info = 0,
        );
    };
    
    dynamics&.push(tag = .StrTab, val = table.strtab);
    dynamics&.push(tag = .StrSz, val = table.strsz);
    dynamics&.push(tag = .SymTab, val = table.symtab);
    dynamics&.push(tag = .SymEnt, val = size_of(Elf.Symbol));
    
    r_table := e.create_rela_table(T.fixups, base, table.symbol_table_index, 0, u8.ptr_from_int(0));
    dynamics&.push(tag = .RelA, val = r_table.rela);
    dynamics&.push(tag = .RelASz, val = r_table.relasz);
    dynamics&.push(tag = .RelAEnt, val = size_of(Elf.RelA));
    
    if m.goal.exe_debug_symbol_table {
        symbols := temp().alloc_init(*SymbolInfo, m.local_needs_reloc.len, 
            fn(i) => m.get_symbol_info(m.local_needs_reloc[i]));
        table := e.create_symbol_table(symbols, .SymbolTable, empty(), base, true);
    };
    
    dynamics
};

fn emit_dynamic_exports_hash(e: *EmitElf, T: SymbolTableInfo) void = {
    // TODO: more buckets, actually do the hash table properly instead of just a linked list :SLOW
    nbucket := 1;
    nchain  := T.symbols.len + 1;
    e.payload&.reserve((1 + 1 + nbucket + nchain) * size_of(u32));
    e.payload&.reserve_type(u32)[] = nbucket.trunc();
    e.payload&.reserve_type(u32)[] = nchain.trunc();
    bucket := e.payload&.reserve_type(u32, nbucket);
    chain  := e.payload&.reserve_type(u32, nchain);
    
    prev := 0;
    range(0, e.m.exports.len) { i |
        idx := e.m.get_symbol_info(e.m.exports[i])[].got_lookup_offset + 1;  // in symbol table
        @debug_assert(idx != 0);
        chain[idx] = prev.trunc();
        prev = idx;
    };
    bucket[0] = prev.trunc();
}

SymbolTableResults :: @struct {
    string_table_index: u16;
    symbol_table_index: u16;
    strtab: i64;
    strsz: i64;
    symtab: i64;
    extra_strings: []i64;
    first_global: i64;  // counting exports
};

// This sets symbol.got_lookup_offset to it's index in the table. 
create_symbol_table :: fn(
    e: *EmitElf, 
    symbols: []*SymbolInfo, 
    table_type: Elf.SectionType, 
    extra_strings: []Str,
    base: PayloadBase, 
    for_debug: bool,
) SymbolTableResults = {
    out := zeroed SymbolTableResults;
    
    // this is painful. for dynamic, it wants one strings blob with both the needed 
    // dylib names and the symbol names and offsets that point to strings are relative to 
    // the start of that one table
    string_table_start := e.payload.len;
    e.payload&.push(0);  // null
    extra_strings_out := i64.list(temp());
    for extra_strings { name |
        extra_strings_out&.push(e.payload.len - string_table_start);
        e.payload&.push_all(name);
        e.payload&.push(0);
    };
    out.extra_strings = extra_strings_out.items();
    
    imported_symbol_name_offsets := u32.list(symbols.len, temp());
    is_local :: fn(info) => info.kind == .Local && (!info.export || !@is(e.m.goal.type, .Relocatable, .Dynamic));
    
    local_count := 0;
    for symbols { info |
        imported_symbol_name_offsets&.push(trunc(e.payload.len - string_table_start));
        @debug_assert(info.name.len > 0 && info.name[info.name.len - 1] != 0, "empty symbol name or extra null terminator will not go well");
        e.payload&.push_all(info.name);
        e.payload&.push(0);
        local_count += int(info.is_local());
    };

    // ugh
    string_table_index := e.header.section_header_num;
    e.section_header(".dynstr")[] = (
        name = 0,
        type = .StringTable, 
        flags = 1.shift_left(@as(i64) Elf.SectionFlag.Strings),
        addr = 0,
        offset = base.file + string_table_start, 
        size = e.payload.len - string_table_start,
        addr_align = 1,
    );
    out.strtab = base.virtual + string_table_start;
    out.strsz = e.payload.len - string_table_start;
    
    e.payload&.zero_pad_to_align(8);
    symbol_table_start := e.payload.len;
    e.payload&.reserve_type(Elf.Symbol)[] = Elf.Symbol.zeroed();  // null
    symbol_index := 0;
    
    for symbols { symbol |
        xx := e.payload&.reserve_type(Elf.Symbol);
        local := symbol.kind == .Local;

        segment_base := Elf.MYSTERY_SPICE + ptr_diff(e.m.segments&[.Code].mmapped.ptr, e.m.segments&[symbol.segment].mmapped.ptr);
        section: u16 = 0;
        if e.m.goal.type == .Relocatable {
            // for linker, it's relative to start of the section instead of virtual base address. 
            segment_base = 0;
        };
        // section index is required for linker, and for exe_debug_symbol_table 
        // (even tho the latter still does addresses relative to base address not section). 
        if local {
            section = e.section_index&[symbol.segment];
        };

        // note: you can have a weak+export symbol, means it will be replaced if you link against something that has a strong definition.  
        // TODO: rn only import_c sets all its own symbols to strong. other frontends should do that too.
        bind := @if(is_local(symbol), 
            Elf.STB_LOCAL, 
                @if(symbol.strong, 
                    Elf.STB_GLOBAL, 
                    Elf.STB_WEAK));
                    
        if for_debug && symbol.segment == .Code && !local {
            section = e.section_index&[symbol.segment];
            @debug_assert(e.m.goal.exe_debug_symbol_table);
            local = true;  // the import **stub** is actually local
            bind = Elf.STB_LOCAL;
            local_count += 1;
        };
        if !local {
            symbol.size = 0;  // don't show the stub's size. just makes readelf less confusing to look at
        };
        
        STT_OBJECT :: 1; STT_FUNC :: 2;
        type := @if(symbol.segment == .Code, STT_FUNC, STT_OBJECT);   // TODO: does anyone care about this? 
        
        xx[] = (
            name = imported_symbol_name_offsets[symbol_index],
            info = bind.shift_left(4).bit_or(type).trunc(),
            value = @if(local, segment_base + symbol.offset, 0),
            section_header_index = section,
            size = symbol.size.zext(),  // TODO: does anyone care about this? maybe debugger disassemble? 
        );
        
        symbol.got_lookup_offset = symbol_index;
        symbol_index += 1;
    };
    
    // ugh
    out.symbol_table_index = e.header.section_header_num;
    e.section_header(".dynsym")[] = (
        name = 0, // TODO
        type = table_type, 
        flags = 2, // TODO: what does this mean? 
        addr = 0,  // TODO: clang has some virtual place here
        offset = base.file + symbol_table_start, 
        size = e.payload.len - symbol_table_start,
        addr_align = 8,
        ent_size = size_of(Elf.Symbol),
        link = string_table_index.zext(),
        info = local_count.trunc() + 1, 
    );
    out.symtab = base.virtual + symbol_table_start;
    out.first_global = local_count + 1;  // not the same as T.local_count
    
    out
};

RelaResults :: @struct {
    rela: i64;
    relasz: i64;
};

create_rela_table :: fn(
    e: *EmitElf, 
    fixups: []FixP, 
    base: PayloadBase, 
    symbol_table_index: u16, 
    target_section_index: u16,
    section_base_address: *u8,
) RelaResults = {
    m := e.m;
    relocation_table_start := e.payload.len;
    // TODO: do they have to be ordered by memory location like mach-o?
    // TODO: store increment in consistant place instead of on each guy
    
    reloc := m.goal.type == .Relocatable;
    each fixups { fix |
        // got_lookup_offset is set by create_symbol_table()
        sym: u32 = trunc(fix.symbol.got_lookup_offset + 1);
        
        // the target offset is relative to 
        // - exe: the virtual base address of the executable
        // - linker: the start of the segment
        off := @if(reloc, 
            ptr_diff(section_base_address, fix.fix.patch_at),
            ptr_diff(m.segments&[.Code].mmapped.ptr, fix.fix.patch_at) + Elf.MYSTERY_SPICE, 
        );
        
        type, increment := @match(fix.fix.type&) {
            fn DataAbsolute(it) => {
                i64.ptr_from_raw(fix.fix.patch_at)[] = 0;
                (@match(m.goal.arch) {
                    fn x86_64()  => Elf.R_AMD64_64;
                    fn aarch64() => Elf.R_AARCH64_ABS64;
                    fn rv64()    => Elf.R_RISCV_64;
                    @default     => todo();
                }, it.increment)
            }
            fn RipDisp32(it) => {
                @debug_assert(reloc);
                @debug_assert(m.goal.arch == .x86_64);
                
                // TODO: probably don't need this and it shouldn't be at risc of having aslr 
                //       bytes like the DataAbsolute case so don't bother. 
                u32.ptr_from_raw(fix.fix.patch_at)[] = 0;
                
                extern := fix.symbol.kind == .DynamicPatched;
                (@if_else {
                    @if(extern && it.call) => Elf.R_AMD64_PLT32;
                    @if(extern && it.got_load) => Elf.R_AMD64_REX_GOTPCRELX;
                    @else            => Elf.R_AMD64_PC32;
                }, it.increment - 4 /* :IncOffByFour */)
            };
            fn Call(it) => {
                @debug_assert(m.goal.arch != .x86_64);
                bl := @match(m.goal.arch) {
                    fn aarch64() => Elf.R_AARCH64_CALL26;
                    @default => todo();
                };
                (bl, 0)
            }
            fn InReg(it) => {
                @debug_assert(m.goal.arch != .x86_64);
                it.got_load = it.got_load && fix.symbol.kind != .Local;
                
                if m.goal.arch == .aarch64 {
                    // i use adr when in range but i don't want to deal with another relocation type rn
                    reg := @as(u5) it.r;
                    inst: []u32 = (ptr = u32.ptr_from_raw(fix.fix.patch_at), len = 2);
                    inst[0] = adrp(0, 0, reg);
                    inst[1] = if(it.got_load, => ldr_uo(.X64, reg, reg, 0), => add_im(.X64, reg, reg, 0, 0));
                };
                
                adrp_local, add_local, adrp_got, ldr_got := @match(m.goal.arch) {
                    fn aarch64() => (
                        Elf.R_AARCH64_ADR_PREL_PG_HI21, Elf.R_AARCH64_ADD_ABS_LO12_NC,
                        Elf.R_AARCH64_ADR_GOT_PAGE, Elf.R_AARCH64_LD64_GOT_LO12_NC,
                    );
                    fn rv64() => (
                        Elf.R_RISCV_PCREL_HI20, Elf.R_RISCV_PCREL_LO12_I,
                        Elf.R_RISCV_GOT_HI20, Elf.R_RISCV_PCREL_LO12_I,
                    );
                    @default => todo();
                };
                
                fst, snd := @if(it.got_load, 
                    (adrp_got, ldr_got),
                    (adrp_local, add_local));
                
                inc := it.increment;
                e.payload&.reserve_type(Elf.RelA)[] = (
                    sym = sym,  
                    offset = off,
                    addend = inc,
                    type = fst.trunc(),
                );
                
                if e.m.goal.type == .Relocatable && e.m.goal.arch == .rv64 {
                    // :StupidEncodingsWinStupidRelocations
                    anon := e.m.intern(@tfmt(".auipc%", off));
                    use_symbol(e.m, anon) { s |
                        @debug_assert(s.got_lookup_offset != -1);
                        sym = s.got_lookup_offset.trunc() + 1;
                    };
                    inc = 0;
                };
                
                off += 4;
                (snd, inc)
            }
            @default => @panic("TODO: elf fixup: %", fix.fix.type&.tag());
        };
        e.payload&.reserve_type(Elf.RelA)[] = (
            sym = sym,  
            offset = off,
            addend = increment,
            type = type.trunc(),
        );
    };
    
    name := @if(!reloc, ".rela.dyn", @tfmt(".rela%", e.section_names[target_section_index.zext()]));
    // ugh
    e.section_header(name)[] = (
        name = 0,
        type = .RelocAddend, 
        flags = 1.shift_left(@if(!reloc, @as(i64) Elf.SectionFlag.Alloc, @as(i64) Elf.SectionFlag.InfoLink)),
        addr = 0,  // TODO: clang has some virtual place here
        offset = base.file + relocation_table_start, 
        size = e.payload.len - relocation_table_start,
        addr_align = 8,
        ent_size = size_of(Elf.RelA),
        link = symbol_table_index.zext(),
        // only matters for static. 
        info = target_section_index.zext(),  // index of the section the relocation applies to
    );
    (rela = base.virtual + relocation_table_start, relasz = e.payload.len - relocation_table_start)
};

seal_dynamic :: fn(
    e: *EmitElf, 
    load_payload_header: *Elf.ProgramHeader, 
    dynamic_header: *Elf.ProgramHeader, 
    base: PayloadBase, 
    dynamics: List(Elf.Dyn), 
) void = {
    m := e.m;
    dynamics&.push(tag = .Null, val = 0);
    
    dynamics := dynamics.items().interpret_as_bytes();
    addr := base.virtual + e.payload.len;
    
    // ugh
    e.section_header(".dynamic")[] = (
        name = 0,
        type = .Dynamic, 
        flags = 2,
        addr = addr, 
        offset = base.file + e.payload.len, 
        size = dynamics.len,
        ent_size = size_of(Elf.Dyn),
        addr_align = 8,
    );
    
    RW :: prot_read_write;
    dynamic_header[] = (
        type = .Dynamic,
        prot = RW,
        offset = base.file + e.payload.len,
        vaddr = addr, 
        paddr = addr,
        file_size = dynamics.len,
        mem_size = dynamics.len,
        align = 8,
    );
    e.payload&.push_all(dynamics);
    
    section_names(e, base);
    size := e.payload.len();
    load_payload_header[] = (
        type = .Load,
        prot = RW,
        offset = base.file,
        vaddr = base.virtual, 
        paddr = base.virtual,
        file_size = size,
        mem_size = size,
        align = 4096,
    );
};

// For linker, targets are relative to a section, and the index of that section goes in the `info` field of the RELA header. 
// so each section that contains relocations needs a seperate section to describe them.
emit_linker_relocations :: fn(e: *EmitElf, base: PayloadBase) void = {
    m := e.m;
    
    for m.exports { id |
        use_symbol(m, id) { s |
            @debug_assert(s.export);
            if !s.local_but_marked_for_relocation && s.kind == .Local {
                m.local_needs_reloc&.push(id);
                s.local_but_marked_for_relocation = true;
            }
        };
    };
    for m.local_needs_reloc { id |
        s := m.get_symbol_info(id);
        @debug_assert_eq(s.kind, .Local, "nonlocal %", s.name);
    };
    
    cases: EnumMap(SegmentType, List(FixP)) = init(list(temp()));
    // TODO: just pass around lists of Sym instead of *SymbolInfo, fix in collect_aot_fixups and machO as well
    symbols := temp().alloc_uninit(*SymbolInfo, m.local_needs_reloc.len + m.imports.len);
    
    i := 0;
    collect :: fn(ids) => for ids { id |
        s := m.get_symbol_info(id);
        symbols[i] = s; i += 1;
        each s.fixups& { it |
            seg, _ := compiler_address_to_segment_offset(m, it.patch_at);
            case := cases&.index(seg);
            case.push(symbol = s, fix = it);
        };
    };
    
    collect(m.local_needs_reloc&);
    partition_unordered(*SymbolInfo, symbols.slice(0, i), fn(it) => !it.export);  // :SLOW
    collect(m.imports&);
    @debug_assert_eq(symbols.len, i);
   
    table := e.create_symbol_table(symbols, .SymbolTable, empty(), base, false);
    each cases& { seg, fixups | 
        if fixups.len > 0 {
            _ := e.create_rela_table(fixups.items(), base, table.symbol_table_index, e.section_index&[seg], m.segments&[seg].mmapped.ptr);
        }
    };
};

program_header :: fn(e: *EmitElf) *Elf.ProgramHeader = {
    e.header.program_header_num += 1;
    e.program_headers&.index(e.header.program_header_num.zext() - 1)
};

section_header :: fn(e: *EmitElf, name: Str) *Elf.SectionHeader = {
    e.section_names&.push(name);
    h := e.commands&.reserve_type(Elf.SectionHeader);
    e.header.section_header_num += 1;
    h
};

fn emit_linux_start(m: *Qbe.Module, main: Qbe.Sym, start: Qbe.Sym) void = {
    @if(IS_BOOTSTRAPPING) unreachable();  // :UpdateBoot
    
    // HACK: since i got rid of ExprLevelAsm and it's annoying to make another layer of
    // wrapper function that calls the ir part, this asm function doesn't have a return 
    // instruction so it falls through to the ir part. 
    // TODO: will that work for relocatable library? 
    //       im outputting relocations for local calls as though linker is allowed to move 
    //       functions around, so maybe i need to make sure the size of the symbol covers the whole function. 

    // (experimentally) I think only amd64 needs me to align sp myself 
    // but it doesn't hurt to do it for the others as well just for good luck. 
    // TODO: set fp/lr to zero so backtraces can stop safely?
    code: MultiArchAsm = (data = ({
        #use(Arm);
        imm :: encode_bitmask(-16, true).unwrap();
        (@const_slice(
            add_im(.X64, x0, sp, 0, 0), 
            // TODO: shouldn't need the @as(u5), the constants have a type annotation :CompilerBug
            @bits(Bits.X64, 0b00, 0b100100, @as(u13) imm, @as(u5) x0, @as(u5) sp),  // :SpEncoding
        )).interpret_as_bytes()
    }, { 
        #use(Amd);
        b := u8.list(temp());
        b&.encode_bin(.MovReg, .rdi, .rsp);
        b&.encode_extended_op(.Direct, 0x83, 4, .rsp);  // r/m64 AND imm8 (sign-extended)
        b&.push(@as(u8) 0 - 16);
        b.items()
    }, { 
        #use("@/backend/rv64/bits.fr");
        (@const_slice(
            I(0, RvReg.SP.bits(), @as(u3) OpI.add, RvReg.A0.bits(), .op_imm),
            I(-16, RvReg.SP.bits(), @as(u3) OpI.and, RvReg.SP.bits(), .op_imm),
        )).interpret_as_bytes()
    },
        empty()  // wasm; unreachable
    ));
    m.add_code_bytes(start, code&);  
    m.maybe_add_export(start, true);
    
    f := temp().box_uninit(Qbe.Fn);
    default_init(f, m);
    f.lnk = (id = m.intern("__start_middle"), no_inline = true);
    f.start = temp().box_zeroed(Qbe.Blk);
    f.nblk = 1;
    f.start.jmp.type = .hlt;
    
    @emit_instructions((f = f), (f.symcon(main)),  """
    @start
        %sp =l par
        %argc =l load %sp
        %argv =l add %sp, 8
        call $__libc_start_main(l %0, l %argc, l %argv, l 0, l 0, l 0, l 0)
    """);
    f.copy_instructions_from_scratch(f.start);
    run_qbe_passes(f);
    
    use_symbol(m, m.intern("__libc_start_main")) { s |
        s.strong = true;
    };
}

Elf :: import("@/backend/elf/bits.fr");
#use("@/backend/lib.fr");
