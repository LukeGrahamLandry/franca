// TODO:
// - rem for shifts that may overflow because thats a poison value on llvm. 
// - emit bitcode like zig does
// - this way of handling env parameters with inline asm is super fragile (i think it only works on -O0)
// - byval() doesn't do what i want. need to run part of the abi pass somehow? this sucks.
// - syscall, asm, add_asm_bytes, bss
// - run_tests.fr

LlvmEmit :: @struct(
    f: *Qbe.Fn,
    out: List(u8),
);

// I think they don't need to know the signeture for the same reason I don't need to know the signeture. 
fn finish_llvm(m: *QbeModule) [][]u8 = {
    o := m.llvm_global_code_buf&;
    for_symbols m { _, symbol |
        need_decl := false;
        if symbol.kind == .Pending && !symbol.name.starts_with("llvm.") {  // HACK what if you just happened to name your function that. bad news bears.  
            need_decl = true;
        };
        if symbol.kind == .Local && symbol.size > 0 {
            // must have been add_code_bytes; translate to module level assembly. 
            need_decl = true;
            prefix := if(m.goal.os == .linux, => "", => "_");
            bytes := m.segments&[.Code].mmapped.slice(symbol.offset, symbol.offset + symbol.size);
            
            @fmt(o, "module asm \"%%:\"\n", prefix, symbol.name);
            for bytes { inst |
                @fmt(o, "module asm \".byte %\"\n", @as(i64) inst.zext());
            };
        };
        if symbol.name == "__franca_code_segment" {
            // HACK HACK HACK
            @fmt(o, "@% = private unnamed_addr global { i8 } { i8 0 }\n", symbol.name);
            
        };
        if need_decl {
            @fmt(o, "declare ccc void @%();\n", symbol.name);
        };
    };
    chunks := list([]u8, temp());
    chunks&.push(m.llvm_global_code_buf.items());
    chunks.items()
}

fn emit_llvm(f: *Qbe.Fn) void = emit_llvm(f.globals, f);
fn emit_llvm(m: *QbeModule, f: *Qbe.Fn) void = {
    self: LlvmEmit = (f = f, out = list(temp()));
    
    n := f.lnk.id;
    symbol := m.get_symbol_info(n);  // :ThreadSafety
    symbol.kind = .Local;
    
    private := if(f.lnk.export, => "", => "private ");
    @fmt(self.out&, "define %ccc ", private);
    // TODO: correct return type
    if f.retty == -1 {
        if f.find_scalar_return_type() { k |
            self&.write_type(k);
            @fmt(self.out&, " "); 
        } else {
            @fmt(self.out&, "void "); 
        };
    } else {
        self&.write_aggragate_type(f.retty.zext());
    };
    @fmt(self.out&, "@%(", f.name()); 
    self&.write_params();
    @fmt(self.out&, ") \"frame-pointer\"=\"all\" {\n");
    for_blocks f { b | 
        self&.emit_block(b);
    };
    @fmt(self.out&, "}\n"); 
    push_all(m.llvm_global_code_buf&, self.out.items());
}

fn emit_block(self: *LlvmEmit, b: *Qbe.Blk) void = {
    @fmt(self.out&, "B%:\n", b.id);
    
    for_phi b { p |
        @fmt(self.out&, "\t%% = phi ", "%", self.f.get_temporary(p.to).name());
        self.write_type(p.cls);
        comma := "";
        range(0, p.narg.zext()) { a | 
            @fmt(self.out&, "% [ ", comma);
            self.write_ref(p.arg[a], p.cls);
            @fmt(self.out&, ", %B% ]", "%", p.blk[a].id);
            comma = ",";
        };
        @fmt(self.out&, "\n");
    };
    
    arg_count := 0;
    has_va := false;
    n_ins := 0;
    for_insts_forward b { i |   
        n_ins += 1;
        @match(i.op()) {
            fn dbgloc() => ();  // TODO
            fn sel0() => (); // part of sel1
            fn blit0() => (); // part of blit1
            fn par() => ();  // part of function definition
            fn parc() => ();  // part of function definition
            fn arg()  => { arg_count += 1; };  // part of call
            fn argc()  => { arg_count += 1; };  // part of call
            fn argv() => { arg_count += 1; has_va = true; };  // this means following args are variadic. 
            fn arge() => {
                if self.f.globals.goal.arch == .aarch64 {
                    @fmt(self.out&, "\tcall void asm sideeffect \"mov x9, $0\", \"r,~{r9}\"(i64 ");
                    self.write_ref(i.arg&[0], .Kl);
                    @fmt(self.out&, ")\n");
                } else {
                    panic("TODO: arge llvm arch");
                };
            }
            fn nop() => ();  // just added to avoid shuffling instructions around
            fn call() => {
                if i.to != QbeNull  {
                    if i.arg&[1] == QbeNull {
                        @fmt(self.out&, "\t%% = call ", "%", self.f.get_temporary(i.to).name());
                        self.write_type(i.cls());
                        self.out&.push_all(" ");
                    } else {
                        @fmt(self.out&, "\t%call.%_% = call ", "%", b.id, n_ins);
                        @debug_assert(rtype(i.arg&[1]) == .RType, "call second arg should be type (not yet abi lowered)");
                        self.write_aggragate_type(i.arg&[1].val());
                        self.out&.push_all(" ");
                    };
                } else {
                    @fmt(self.out&, "\tcall void");
                };
                if has_va {
                    self.write_non_va_types(i, arg_count);
                };
                callee := i.arg&[0];
                self.write_ref(callee, .Kl);
                @fmt(self.out&, "(");
                self.write_args(i, arg_count);
                arg_count = 0;
                has_va = false;
                @fmt(self.out&, ")\n");
                if rtype(i.arg&[1]) == .RType {
                    @fmt(self.out&, "\t%% = alloca ", "%", self.f.get_temporary(i.to).name());
                    self.write_aggragate_type(i.arg&[1].val());
                    @fmt(self.out&, ", i64 1\n");
                    @fmt(self.out&, "\tstore ");
                    self.write_aggragate_type(i.arg&[1].val());
                    @fmt(self.out&, " %call.%_%", "%", b.id, n_ins);
                    @fmt(self.out&, ", ptr");
                    self.write_ref(i.to, .Kl);
                    @fmt(self.out&, "\n");
                };
            };
            @default => self.emit_ins(i);
        };
    };
    
    j := b.jmp.type;
    @match(j) {
        fn jnz() => {
            @fmt(self.out&, "\tbr i1 ");
            self.write_ref(b.jmp.arg, .Kw);
            @fmt(self.out&, ", label %B%, label %B%\n", "%", b.s1.id, "%", b.s2.id);
        }
        fn jmp() => {
            @fmt(self.out&, "\tbr label %B%\n", "%", b.s1.id);
        }
        fn hlt() => self.out&.push_all("\tunreachable\n");
        fn ret0() => self.out&.push_all("\tret void\n");
        fn retc() => {
            assert(self.f.retty != -1, "can't retc in non-agg function");
            @fmt(self.out&, "\t%ret.% = load ", "%", b.id);      
            self.write_aggragate_type(self.f.retty.zext());
            @fmt(self.out&, ", ptr ");      
            self.write_ref(b.jmp.arg, .Kl);
            @fmt(self.out&, "\n\tret ");
            self.write_aggragate_type(self.f.retty.zext());
            @fmt(self.out&, " %ret.%\n", "%", b.id);        
        };
        @default => {
            assert(is_ret(j), "cannot convert to jumps on flags before emitting llvm");
            jump_offset := j.raw() - Qbe.J.retw.raw();
            @fmt(self.out&, "\tret ");
            
            if jump_offset < 4 {
                k := @as(Qbe.Cls) jump_offset;
                self.write_type(k);
            } else {
                self.out&.push_all("i8 ");
            };
            self.out&.push_all(" ");
            self.write_ref(b.jmp.arg, .Kw);
            @fmt(self.out&, "\n");
        };
    };
}

fn llvm_ty(i: *Qbe.Ins) Str = i.cls().llvm_ty();
fn llvm_ty(k: Qbe.Cls) Str = {
    types :: @const_slice("i32", "i64", "float", "double");
    types[k.raw().intcast()]
}

fn emit_ins(self: *LlvmEmit, i: *Qbe.Ins) void = {
    o := self.out&;
    @fmt(o, "\t");
    
    bin :: fn(int: Str, float: Str) => {
        name := if(i.cls().is_int(), => int, => float);
        @fmt(o, "% ", name);
        self.write_type(i.cls());
        o.push_all(" ");
        self.write_ref(i.arg&[0], argcls(i, 0));
        o.push_all(", ");
        self.write_ref(i.arg&[1], argcls(i, 1));
        o.push_all("\n");
    };
    int_bin :: fn(name: Str) => bin(name, "");
    if i.to != QbeNull {
        @fmt(self.out&, "%% = ", "%", self.f.get_temporary(i.to).name());
    };
    toT := i.llvm_ty();
    
    cast :: fn(name: Str) => {
        cast2(name, argcls(i, 0).llvm_ty(), toT);
    };
    cast2 :: fn(name: Str, in: Str, out: Str) => {
        @fmt(o, "% % ", name, in);
        self.write_ref(i.arg&[0], .Kl);
        @fmt(o, " to %\n", out);
    };
    @match(i.op()) {
        fn add()  => bin("add", "fadd");
        fn sub()  => bin("sub", "fsub");
        fn mul()  => bin("mul", "fmul");
        fn div()  => bin("sdiv", "fdiv");
        fn udiv() => int_bin("udiv");
        fn rem()  => int_bin("srem");
        fn urem() => int_bin("urem");
        fn and()  => int_bin("and");
        fn xor()  => int_bin("xor");
        fn or()   => int_bin("or");
        // TODO: these are wrong because llvm makes a poison value if you shift by too much instead of mod by the size. 
        fn sar()   => int_bin("ashr");
        fn shr()   => int_bin("lshr");
        fn shl()   => int_bin("shl");
        fn extsw() => cast("sext");
        fn extuw() => cast("zext");
        fn extub() => cast2("zext", "i8", toT);
        fn extsb() => cast2("sext", "i8", toT);
        fn extuh() => cast2("zext", "i16", toT);
        fn dtosi() => cast("fptosi");
        fn stosi() => cast("fptosi");
        fn swtof() => cast("sitofp");
        fn uwtof() => cast("uitofp");
        fn ultof() => cast("uitofp");
        fn stoui() => cast("fptoui");
        fn dtoui() => cast("fptoui");
        fn sltof() => cast("sitofp");
        fn cast()  => cast("bitcast");
        fn load() => {
            @fmt(o, "load %, ptr ", toT);
            self.write_ref(i.arg&[0], .Kl);
            o.push_all("\n");
        }
        fn neg() => {
            @fmt(o, "fneg % ", toT);
            self.write_ref(i.arg&[0], .Kl);
            o.push_all("\n");
        }
        fn llcast() => {
            @debug_assert(rtype(i.arg&[1]) == .RInt, "llcast second arg must be cast index");
            c := @as(LlvmCast) i.arg&[1].val();
            @match(c) {
                fn None() => panic("no cast");
                fn IntToPtr() => cast2("inttoptr", "i64", "ptr");
                fn PtrToInt() => cast2("ptrtoint", "ptr", "i64");
                fn PtrToIntW() => cast2("ptrtoint", "ptr", "i32");
                fn TruncLtoW() => cast2("trunc", "i64", "i32");
                fn TruncWtoB() => cast2("trunc", "i32", "i8");
                fn TruncLtoB() => cast2("trunc", "i64", "i8");
                fn TruncWtoH() => cast2("trunc", "i32", "i16");
                fn TruncLtoH() => cast2("trunc", "i64", "i16");
                fn ExtendI1ToW() => cast2("zext", "i1", "i32");
                fn ExtendI1ToH() => cast2("zext", "i1", "i16");
                fn ExtendI1ToL() => cast2("zext", "i1", "i64");
                fn CmpZero() => {   
                    int_type := "i64";
                    if rtype(i.arg&[0]) == .RTmp && self.f.tmp[i.arg&[0].val()].cls == .Kw {
                        int_type = "i32";
                    };
                    @fmt(o, "icmp ne % ", int_type);
                    self.write_ref(i.arg&[0], .Kl);
                    @fmt(o, ", 0\n");
                }
            };
        }
        fn vastart() => panic("isel lowers vastart");
        fn vaarg() => {
            push_all(o, "va_arg ptr ");
            self.write_ref(i.arg&[0], .Kl);
            push_all(o, ", ");
            self.write_type(i.cls());
            push_all(o, "\n");
        }
        fn sel1() => {
            sel1 := i;
            sel0 := i;
            while => sel0.op() != .sel0 {
                sel0 = sel0.offset(-1);
            };
            push_all(o, "select i1 ");
            self.write_ref(sel0.arg&[0], .Kl);
            @fmt(o, ", % ", toT);
            self.write_ref(sel1.arg&[0], sel1.cls());
            @fmt(o, ", % ", toT);
            self.write_ref(sel1.arg&[1], sel1.cls());
            @fmt(o, "\n");
        }
        fn blit1() => {
            i1 := i;
            i0 := i;
            while => i0.op() != .blit0 {
                i0 = i0.offset(-1);
            };
            
            @fmt(o, "call void @llvm.memmove.p0.p0.i32(ptr ");
            self.write_ref(i0.arg&[1], .Kl);
            @fmt(o, ", ptr ");
            self.write_ref(i0.arg&[0], .Kl);
            @fmt(o, ", i32 %, i1 false)\n", i1.arg&[0].rsval().abs()); 
        }
        fn pare() => {
            if self.f.globals.goal.arch == .aarch64 {
                @fmt(o, "call i64 asm \"mov $0, x9\", \"=r\"()\n");
            } else {
                panic("TODO: pare llvm arch");
            };
        }
        @default => {
            ck := Qbe.Cls.zeroed();
            cc: i32 = 0;
            if iscmp(i.op(), ck&, cc&) {
                @fmt(o, "%cmp % ", if(ck.is_int(), => "i", => "f"), llvm_condition_codes[cc.zext()]);
                self.write_type(ck);
                o.push_all(" ");
                self.write_ref(i.arg&[0], argcls(i, 0));
                o.push_all(", ");
                self.write_ref(i.arg&[1], argcls(i, 1));
                o.push_all("\n");
                return();
            };
            
            if i.op().is_store() {
                store_offset := i.op().raw() - Qbe.O.storeb.raw();
                types :: items(@list("i8", "i16", "i32", "i64", "float", "double") ast_alloc());
                @fmt(o, "store % ", types[store_offset.zext()]);
                self.write_ref(i.arg&[0], argcls(i, 0));
                o.push_all(", ptr ");
                self.write_ref(i.arg&[1], .Kl);
                o.push_all("\n");
                return();
            };
            if i.op().is_load() {
                store_offset := i.op().raw() - Qbe.O.storeb.raw();
                types :: items(@list("i8", "i16", "i32") ast_alloc());
                size := size_of_load(i).intcast().trailing_zeros();
                @fmt(o, "load %, ptr ", types[size]);
                self.write_ref(i.arg&[0], argcls(i, 0));
                o.push_all("\n");
                return();
            };
            
            if i.op().between(.alloc4, .alloc16) {
                align_log2 := i.op().raw() - Qbe.O.alloc4.raw();
                align := 1.shift_left(align_log2.intcast());
                @fmt(self.out&, "alloca i8, i64 ");
                self.write_ref(i.arg&[0], .Kl);
                @fmt(self.out&, ", align %\n", align);
                return();
            };
            
            names :: Qbe.O.get_enum_names();
            @fmt(o, "TODO:% ", names.index(@as(i64) intcast(@as(i32) i.op().raw())));
            self.write_ref(i.arg&[0], .Kl);
            self.write_ref(i.arg&[1], .Kl);
            o.push_all("\n");
            
        };
    }
} 

// TODO: we need to include abi information in attributes so we need to run some subset of the abi passes before getting here. 
fn write_params(e: *LlvmEmit) void = {
    comma := "";
    for_insts_forward e.f.start { i |
        continue :: local_return;
        if(@is(i.op(), .pare, .llcast), => continue());  // HACK. we don't bother inserting llcast at the end
        if(i.op() != .par && i.op() != .parc, => return());
        e.out&.push_all(comma);
        if i.op() == .parc {
            e.out&.push_all("ptr byval(");
            e.write_aggragate_type(i.arg&[0].val());
            e.out&.push_all(") ");
            e.write_ref(i.to, .Kl);
        } else {
            e.write_type(i.cls());
            e.out&.push_all(" ");
            e.write_ref(i.to, i.cls());
        };
        comma = ", ";
    };
}

fn write_args(e: *LlvmEmit, call: *Qbe.Ins, arg_count: i64) void = {
    comma := "";
    start := call.offset(-arg_count);
    for(start, call) { i |
        if i.op() != .argv {
            e.out&.push_all(comma);
            if i.op() == .argc {
                @debug_assert(rtype(i.arg&[0]) == .RType, "expected type for argc");
                e.out&.push_all("ptr byval(");
                e.write_aggragate_type(i.arg&[0].val());
                e.out&.push_all(") ");
                e.write_ref(i.arg&[1], .Kl);
            } else {
                e.write_type(i.cls());
                e.out&.push_all(" ");
                e.write_ref(i.arg&[0], i.cls());
            };
            comma = ", ";
        }
    };
}

fn write_non_va_types(e: *LlvmEmit, call: *Qbe.Ins, arg_count: i64) void = {
    comma := "";
    start := call.offset(-arg_count);
    e.out&.push_all("(");
    for(start, call) { i |
        e.out&.push_all(comma);
        comma = ", ";
        if i.op() == .argv {
            e.out&.push_all("...) ");
            return();
        };
        e.write_type(i.cls());
    };
    panic("write_non_va_types for non-va call");
}

fn write_ref(self: *LlvmEmit, r: Qbe.Ref, k: Qbe.Cls) void = {
    @match(rtype(r)) {
        fn RTmp() => {
            @fmt(self.out&, "%%", "%", self.f.get_temporary(r).name());
        }
        fn RCon() => {
            c := self.f.get_constant(r);
            @match(c.type) {
                fn CUndef() => @fmt(self.out&, "TODO:undef");
                fn CAddr() => {
                    name := self.f.globals.str(c.sym.id);
                    if c.bits.i == 0 {
                        @fmt(self.out&, " @%", name);
                    } else {
                        @fmt(self.out&, " getelementptr (i8, ptr @%, i32 %)", name, c.bits.i);
                    };
                };
                fn CBits() => {
                    i := c.bits.i;
                    if k == .Ks || k == .Kd {
                        // for f64, it wants the bits as hex. 
                        // for f32, it wants an f64 as hex that happens to be exactly representable as f32. 
                        if k == .Ks {
                            x: f32 = c.bits.s.s;
                            x: f64 = x.cast();
                            x: i64 = x.bitcast();
                            i = x;
                        };
                        h := fmt_hex(i);
                        @fmt(self.out&, "%", h); 
                    } else {
                        @fmt(self.out&, "%", i);
                    };
                }
            };
        }
        @default => {
            printfn(self.f, self.f.globals.debug_out);
            @fmt(self.out&, "TODO:reftype %", r);
        };
    };
}

fn write_type(self: *LlvmEmit, k: Qbe.Cls) void = {
    name := @match(k) {  
        fn Kw() => "i32";
        fn Kl() => "i64";
        fn Ks() => "float";
        fn Kd() => "double";
        @default => @panic("ICE: bad instruction class");
    };
    self.out&.push_all(name);
}

fn write_aggragate_type(self: *LlvmEmit, type: i64) void = {
    type := self.f.globals.types[][type]&;
    if type.is_union || type.nunion > 1 {
        // TODO: alignment
        @fmt(self.out&, "[% x i8]", type.size);
        return();
    };
    
    @fmt(self.out&, "{ ");
    i := 0;
    loop {
        f := type.fields[i]&;
        i += 1;
        scalar :: fn(name: Str) => {
            @fmt(self.out&, "%,", name);
        };
        @match(f.type) {
            fn FEnd() => {
                if self.out.items().ends_with(",") {
                    self.out.len -= 1;
                };
                
                @fmt(self.out&, " }");
                return();
            }
            fn FTyp() => {
                self.write_aggragate_type(f.len.zext());
                @fmt(self.out&, ",");
            }
            fn Fb() => scalar("i8");
            fn Fh() => scalar("i16");
            fn Fw() => scalar("i32");
            fn Fl() => scalar("i64");
            fn Fs() => scalar("float");
            fn Fd() => scalar("double");
            fn FPad() => {
                @fmt(self.out&, "[% x i8],", f.len);
            }
        };
    }
}

llvm_condition_codes :: items(@list( // :CmpOrder
     // Cieq Cine  Cisge  Cisgt  Cisle  Cislt  Ciuge  Ciugt  Ciule  Ciult
        "eq", "ne", "sge", "sgt", "sle", "slt", "uge", "ugt", "ule", "ult",
    // Cfeq   Cfge   Cfgt   Cfle   Cflt   Cfne    Cfo   Cfuo
       "oeq", "oge", "ogt", "ole", "olt", "une", "ord", "uno",
                                    // ne unordered because nan!=nan 
) ast_alloc());

fn find_scalar_return_type(f: *Qbe.Fn) ?Qbe.Cls = {
    for_blocks f { b |
        j := b.jmp.type;
        if j == .ret0 {
            return(.None);
        };
        if is_ret(j) {
            jump_offset := j.raw() - Qbe.J.retw.raw();
            k := @as(Qbe.Cls) jump_offset;
            return(Some = k);
        };
    };
    .None // i guess its fine if all paths hlt. 
}

fn emit_llvm(m: *QbeModule, dat: *Qbe.Dat) void = {
    ::enum(@type dat.type);
    type := m.llvm_global_type_buf&;
    value := m.llvm_global_value_buf&;
    @match(dat.type) {
        fn DZeroInit() => panic("TODO: bss llvm");
        fn DStart() => {
            type[] = list(temp());
            value[] = list(temp());
            @fmt(type, "@% = private unnamed_addr global { ", m.str(dat.lnk.id));
            symbol := m.get_symbol_info(dat.lnk.id); // :ThreadSafety
            symbol.kind = .Local;
        }
        fn DEnd() => {
            if type.items().ends_with(",") {
                type.len -= 1;
            };
            if value.items().ends_with(",") {
                value.len -= 1;
            };
            //@fmt_write(m.outf, "% } { % }\n", type.items(), value.items());  // TODO: this should be a type error?! :FUCKED
            @fmt(m.llvm_global_code_buf&, "% } { % }\n", type.items(), value.items());  // TODO: this should be a type error?! :FUCKED
        };
        fn DZ() => {
            @fmt(type, "[% x i8],", dat.u.num);
            @fmt(value, "[% x i8] zeroinitializer,", dat.u.num);
        }
        fn DB() => {
            @debug_assert(!dat.is_ref, "can't have a byte sized pointer");
            if dat.is_str {
                s := dat.u.str;
                dest := if dat.has_quotes_and_escapes {
                    // When building ir manually you'll probably just give us the raw bytes.
                    // But this makes it easy to run Qbe's text based tests. Really the parser should handle this. 
                    q :: "\"".ascii();
                    @debug_assert(s[0] == q && s[s.len - 1] == q, "strings are quoted");
                    s = s.slice(1, s.len - 1); // quotes
                    dest := u8.list(s.len, temp());
                    expand_string_escapes(s, dest&);
                    dest.items()
                } else {
                    s
                };
                @fmt(type, "[% x i8],", dest.len);
                @fmt(value, "[% x i8] [", dest.len);
                for dest { c |
                    @fmt(value, "i8 %,", c);
                };
                if dest.len > 0 {
                    value.len -= 1;
                };
                @fmt(value, "],");
            } else {
                @fmt(type, "i8,");
                @fmt(value, "i8 %,", dat.u.num);
            };
        }
        fn DL() => {
            if dat.is_ref {
                id := dat.u.ref.id;
                @assert(dat.u.ref.off == 0, "sorry can't do offset refs yet");
                @fmt(type, "ptr,");
                @fmt(value, "ptr @%,", m.str(id));
                use_symbol(m, id) { symbol | 
                    mark_referenced(m, id, symbol);
                    // TODO: do i need local_but_marked... ?
                };
            } else {
                @fmt(type, "i64,");
                @fmt(value, "i64 %,", dat.u.num);
            };
        }
        fn DW() =>  {
            @debug_assert(!dat.is_ref, "can't have a w sized pointer");
            @fmt(type, "i32,");
            @fmt(value, "i32 %,", dat.u.num);
        }
        fn DH() =>  {
            @debug_assert(!dat.is_ref, "can't have a h sized pointer");
            @fmt(type, "i16,");
            @fmt(value, "i16 %,", dat.u.num);
        }
    };
}
