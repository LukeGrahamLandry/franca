// Adapted from Qbe. MIT License. Â© 2015-2024 Quentin Carbonneaux <quentin@c9x.me>

//! The ISA gives us a limited number of registers to work with but programs can use an arbitrary number of temporaries. 
//! This pass limits the number of values live at any moment to the number of registers allowed,
//! by inserting loads and stores to stack slots as needed. Ensuring that a value is live when needed by an instruction. 
//! We also try to be smart about not spilling things that are used a bunch in a loop. 
//! After this pass we know which tmps will be in registers but not which registers they'll be in.  

fn aggreg(hd: *Qbe.Blk, b: *Qbe.Blk) void = {
    /* aggregate looping information at
     * loop headers */
    bsunion(hd.gen&, b.gen&);
    range(0, 2) { k | 
        if b.nlive&[k] > hd.nlive&[k] {
            hd.nlive&[k] = b.nlive&[k];
        }
    }
}

// TODO: "unhandled mutual recursion" is a useless error message if you forget the return type here.
fn tmpuse(f: *Qbe.Fn, r: Qbe.Ref, is_use: bool, loop: i32) void = {
    if rtype(r) == .RMem {
        m := f.mem[r.val()]&;
        f.tmpuse(m.base, true, loop);
        f.tmpuse(m.index, true, loop);
        return();
    };
    
    if rtype(r) == .RTmp && r.val() >= Qbe.Tmp0 {
        t := f.get_temporary(r.val());
        t.nuse += int(is_use).trunc();
        t.ndef += int(!is_use).trunc();
        t.cost = trunc(@as(i64) t.cost.zext() + loop.intcast()); // :Casts
    };
}

/* evaluate spill costs of temporaries,
 * this also fills usage information
 * requires rpo, preds
 */
fn fillcost(f: *Qbe.Fn) void = {
    loopiter(f, aggreg);
    
    out := f.globals.debug_out;
    if f.globals.debug["S".char()] {
        write(out, "\n> Loop information:\n");
        for_blocks f { b |
            a := 0;
            while => a < b.npred.zext() && b.id > b.pred[a].id {
                a += 1;
            };
            
            if a != b.npred.zext() {
                @fmt_write(out, "\t%", f_pad(b.name(), 10, .After));
                @fmt_write(out, " (% ", f_pad(b.nlive&[0], 3, .Before));
                @fmt_write(out, "%) ", f_pad(b.nlive&[1], 3, .Before));
                dumpts(b.gen&, f.tmp, out);
            }
        }
    };
    
    range(0, f.ntmp.zext()) { i |
        t := f.get_temporary(i);
        is_reg := i < Qbe.Tmp0;
        ::if(u32);
        t.cost = if(is_reg, => 1.shift_left(32) - 1, => 0); 
        t.nuse = 0;
        t.ndef = 0;
    };
    
    for_blocks f { b |
        for_phi b { p |
            t := f.get_temporary(p.to);
            f.tmpuse(p.to, false, 0);
            range(0, p.narg.zext()) { a | 
                n := p.blk[a].loop;
                t.cost = trunc(@as(i64) t.cost.zext() + n.intcast()); // :Casts
                f.tmpuse(p.arg[a], true, n);
            };
        };
        n := b.loop;
        for_insts_forward b { i |
            f.tmpuse(i.to, false, n);
            f.tmpuse(i.arg&[0], true, n);
            f.tmpuse(i.arg&[1], true, n);
        };
        f.tmpuse(b.jmp.arg, true, n);
    };
    
    if f.globals.debug["S".char()] {
        write(out, "\n> Spill costs:\n");
        range(Qbe.Tmp0, f.ntmp.zext()) { n | 
            @fmt_write(out, "\t% %\n", f_pad(f.tmp[n]&.name(), 10, .After), f.tmp[n].cost);
        };
        write(out, "\n");
    };
}

::FmtPad(CStr); ::FmtPad(i32);

SpillPass :: @struct(   
    f: *Qbe.Fn,
    locs: i32,                 /* stack size used by locals */
    slot4: i32,                /* next slot of 4 bytes */
    slot8: i32,                /* ditto, 8 bytes */
    class_mask: Array(Qbe.BSet, 2), 
    limit_buf: []i32 = empty(),
);

// Get the stack slot assigned for spilling t. 
// Reserving a new one if this is the first time we've spilled t.
fn slot(pass: *SpillPass, t: i64) Qbe.Ref = {
    @debug_assert(t >= Qbe.Tmp0, "cannot spill register");
    s := pass.f.tmp[t].slot;
    if s == -1 {
        /* specific to NAlign == 3 */
        /* nice logic to pack stack slots
         * on demand, there can be only
         * one hole and slot4 points to it
         *
         * invariant: slot4 <= slot8
         */
        if is_wide(pass.f.tmp[t].cls) {
            s = pass.slot8;
            if pass.slot4 == pass.slot8 {
                pass.slot4 += 2;
            };
            pass.slot8 += 2;
        } else {
            s = pass.slot4;
            if pass.slot4 == pass.slot8 {
                pass.slot8 += 2;
                pass.slot4 += 1;
            } else {
                pass.slot4 = pass.slot8;
            }
        };
        s += pass.locs;
        pass.f.tmp[t].slot = s;
    };
    SLOT(s.zext())
}

/* restricts b to hold at most k
 * temporaries, preferring those
 * present in `prioritize` (if given), then
 * those with the largest spill cost.
 */
fn limit(pass: *SpillPass, in_reg: *Qbe.BSet, max_in_reg: i32, prioritize: ?*Qbe.BSet) void = {
    f := pass.f;
    // Setup the list of tmps live right now,
    buf := pass.limit_buf&; // reuse memory because we really spam this function. 
    live_count: i64 = bscount(in_reg).zext();
    if live_count <= max_in_reg.intcast() {
        // easy, we have enough registers for everyone so we're done.
        return(); 
    };
    if live_count > buf.len { 
        buf[] = temp().alloc(i32, live_count);
    };
    live_tmps := buf[].slice(0, live_count);
    i := 0;
    for in_reg { t |
        bsclr(in_reg, t);
        live_tmps[i] = t.intcast();
        i += 1;
    };
    
    SContext :: @struct(f: *Qbe.Fn, prioritize: *Qbe.BSet);
    tcmp0 :: fn(pa: *i32, pb: *i32, f: *Qbe.Fn) bool = {
        ca := f.tmp[pa[].zext()].cost;
        cb := f.tmp[pb[].zext()].cost;
        cb <= ca 
    };
    tcmp1 :: fn(pa: *i32, pb: *i32, ctx: SContext) bool = {
        bb := bshas(ctx.prioritize, pb[].zext());
        aa := bshas(ctx.prioritize, pa[].zext());
        if aa == bb {
            tcmp0(pa, pb, ctx.f)
        } else {
            bb.int() <= aa.int()
        }
    };

    // then sort them by priority.
    if live_tmps.len > 1 {
        // TODO: none of the .ssa tests get here :MakeATestThatFails
        if prioritize { prioritize |
            sort :: quicksort(SContext, i32, tcmp1);
            live_tmps.sort(f = f, prioritize = prioritize);
        } else {
            sort :: quicksort(*Qbe.Fn, i32, tcmp0);
            live_tmps.sort(f);
        };
    };
    in_reg_count := min(live_tmps.len, max_in_reg.zext());
    for live_tmps.slice(0, in_reg_count) { t |
        bsset(in_reg, t.zext());
    };
    for live_tmps.slice(in_reg_count, live_tmps.len) { t |
        pass.slot(t.zext());
    };
}

/* spills temporaries to fit the
 * target limits using the same
 * preferences as limit(); 
 */
fn limit_in_reg(pass: *SpillPass, in_reg: *Qbe.BSet, is_for_call: bool, prioritize: ?*Qbe.BSet) void = {
    allowed_ints, allowed_floats := (pass.f.globals.target.ngpr, pass.f.globals.target.nfpr);
    if is_for_call { 
        // at the call we're allowed to have ((total - caller saved) = callee saved) registers live
        T := pass.f.globals.target;
        allowed_ints -= T.nrsave&[0];
        allowed_floats -= T.nrsave&[1];
    };
    floats := init_bitset(pass.f.ntmp.zext()); /* todo, free those */
    bscopy(floats&, in_reg);
    bsinter(in_reg, pass.class_mask&.index(0)); // now in_reg is just ints
    bsinter(floats&, pass.class_mask&.index(1));
    pass.limit(in_reg, allowed_ints, prioritize);
    pass.limit(floats&, allowed_floats, prioritize);
    bsunion(in_reg, floats&); // return both to the caller
}

fn hint_to_avoid(f: *Qbe.Fn, u: *Qbe.BSet, r: u64) void = {
    for(u, Qbe.Tmp0) { t |
        idx := phi_dest(t, f.tmp); 
        hint := f.tmp[idx].hint.avoid&;
        hint[] = hint[].bit_or(r);
    };
}

/* reloads temporaries in `required_in_reg` that are
 * not in `already_in_reg` from their slots
 */
fn reload_spilled(pass: *SpillPass, required_in_reg: *Qbe.BSet, already_in_reg: *Qbe.BSet) void = {
    for(required_in_reg, Qbe.Tmp0) { t | 
        if !bshas(already_in_reg, t) {
            pass.f.emit(.load, pass.f.tmp[t].cls, TMP(t), pass.slot(t), QbeNull);
        }
    };
}

fn maybe_store(f: *Qbe.Fn, r: Qbe.Ref, slot: i32) void = {
    if slot != -1 {
        op := Qbe.O.storew.raw().zext() + f.get_temporary(r)[].cls.raw().zext();
        op := @as(Qbe.O) @as(i32) op.intcast();
        f.emit(op, .Kw, QbeNull, r, SLOT(slot.zext()));
    };
}

fn is_copy_from_reg(i: *Qbe.Ins) bool #inline = 
    i.op() == .copy && isreg(i.arg&[0]);

fn do_parallel_moves(pass: *SpillPass, b: *Qbe.Blk, last_copy: *Qbe.Ins, in_reg: *Qbe.BSet) *Qbe.Ins = {
    f := pass.f;
    T := f.globals.target;
    /* consecutive copies from
     * registers need to be handled
     * as one large instruction
     *
     * fixme: there is an assumption
     * that calls are always followed
     * by copy instructions here, this
     * might not be true if previous
     * passes change
     */
     
    // Scan backwards to find the first in the group of consecutive copies.
    first_copy := {
        i := last_copy.offset(1);
        dowhile {
            i = i.offset(-1);
            t := i.to.val();
            if i.to != QbeNull && bshas(in_reg, t) {
                bsclr(in_reg, t);
                f.maybe_store(i.to, f.tmp[t].slot);
            };
            //bsset(v&, i.arg&[0].val()); // :ShitTypeCheck
            bsset(in_reg, i.arg&[0].val());
            !i.identical(b.ins.first) && is_copy_from_reg(i.offset(-1))
        };
        i
    };
    
    final_in_reg := init_bitset(f.ntmp.zext()); /* todo, free those */
    bscopy(final_in_reg&, in_reg);
    is_after_call := !first_copy.identical(b.ins.first) && first_copy.offset(-1).op() == .call;
    avoid_registers := if is_after_call { 
        discard := Array(i32, 2).ptr_from_int(0);
        retreg := ({T.retregs}(first_copy.offset(-1)[].arg&[1], discard));
        @debug_assert(in_reg.t[].bit_and(retreg) == retreg, "we should already know returns are live");
        in_reg.t[] = in_reg.t[].bit_and(bit_not(retreg)); // retregs arn't live before the call becuase we're making them now
        pass.limit_in_reg(in_reg, true, .None);
        arg_reg := {T.argregs}(first_copy.offset(-1)[].arg&[1], discard);
        in_reg.t[] = in_reg.t[].bit_or(arg_reg); // the arguments are live before because we need them at the call
        T.caller_saved_bits()
    } else {
        pass.limit_in_reg(in_reg, false, .None);
        in_reg.t[]
    };
    f.hint_to_avoid(in_reg, avoid_registers);
    pass.reload_spilled(final_in_reg&, in_reg);
    
    // Now emit all those copies
    i1 := last_copy.offset(1);
    dowhile {
        i1 = i1.offset(-1);
        pass.f.emit(i1[]);
        !i1.identical(first_copy)
    };
    first_copy
}

::if(u64);

fn merge(f: *Qbe.Fn, u: *Qbe.BSet, bu: *Qbe.Blk, v: *Qbe.BSet, bv: *Qbe.Blk) void = {
    if (bu.loop <= bv.loop) {
        bsunion(u, v);
    } else {
        for v { t |
            if f.tmp[t].slot == -1 {
                bsset(u, t);
            }
        };
    }
}

/* spill code insertion
 * requires spill costs, rpo, liveness
 *
 * Note: this will replace liveness
 * information (in, out) with temporaries
 * that must be in registers at block
 * borders
 *
 * Be careful with:
 * - Ocopy instructions to ensure register
 *   constraints
 */

fn spill(f: *Qbe.Fn) void = {
    T := f.globals.target;

    // TODO: are we copying these because we might resize the array or can i inline them?
    tmp := f.tmp;
    ntmp: i64 = f.ntmp.zext();
    pass: SpillPass = (f = f, locs = f.slot, slot4 = 0, slot8 = 0, class_mask = init(@slice(init_bitset(ntmp), init_bitset(ntmp))));
    range(0, ntmp) { t | 
        k := 0;
        if t >= T.fpr0.zext() && t < T.fpr0.zext() + T.nfpr.zext() {
            k = 1;
        };
        if t >= Qbe.Tmp0 {
            k = KBASE(tmp[t].cls);
        };
        bsset(pass.class_mask&.index(k), t);
    };

    // These are not used between blocks, we just want to reuse the memory. 
    all_needed_later := init_bitset(ntmp);
    in_reg := init_bitset(ntmp);
    prioritize := init_bitset(ntmp);
    
    bp := f.rpo.index(f.nblk.zext());
    while => !bp.identical(f.rpo.first) {
        bp = bp.offset(-1);
        b := bp[];
        
        /* invariant: all blocks with bigger rpo got
         * their in,out updated. */

        /* 1. find temporaries in registers at
         * the end of the block (put them in `in_reg`) */
        f.globals.curi[] = Qbe.Ins.ptr_from_int(0); // i guess this is just asserting that we don't try to emit until we reset it below?
        s1 := b.s1;
        s2 := b.s2;
        backwards: ?*Qbe.Blk = .None;
        if !s1.is_null() && s1.id <= b.id {
            backwards = (Some = s1);
        };
        if !s2.is_null() && s2.id <= b.id {
            if backwards.is_none() || s2.id >= backwards.Some.id {
                backwards = (Some = s2);
            }
        };
        if backwards { (backwards:*Qbe.Blk) |  // TODO: why does this need a type annotation after adding meta/parse.fr? -- Nov 12
            /* back-edge */
            bszero(in_reg&);
            backwards.gen.t[] = backwards.gen.t[].bit_or(T.rglob); /* don't spill registers */
            range(0, 2) { k |
                n := if(k == 0, => T.ngpr, => T.nfpr);
                bscopy(all_needed_later&, b.out&);
                bsinter(all_needed_later&, pass.class_mask&.index(k));
                bscopy(prioritize&, all_needed_later&);
                bsinter(all_needed_later&, backwards.gen&);
                bsdiff(prioritize&, backwards.gen&);
                if bscount(all_needed_later&).bitcast() < n {
                    j: i32 = bscount(prioritize&).bitcast(); /* live through */
                    l := backwards.nlive&[k];
                    pass&.limit(prioritize&, n - (l - j), .None);
                    bsunion(all_needed_later&, prioritize&);
                } else {
                    pass&.limit(all_needed_later&, n, .None);
                };
                bsunion(in_reg&, all_needed_later&);
            }
        } else {
            if !s1.is_null() {
                /* avoid reloading temporaries
                * in the middle of loops */
                bszero(in_reg&);
                live_on_edge(prioritize&, b, s1);
                f.merge(in_reg&, b, prioritize&, s1);
                if !s2.is_null() {
                    live_on_edge(all_needed_later&, b, s2);
                    f.merge(in_reg&, b, all_needed_later&, s2);
                    bsinter(prioritize&, all_needed_later&);
                };
                pass&.limit_in_reg(in_reg&, false, (Some = prioritize&));
            } else {
                bscopy(in_reg&, b.out&);
                if rtype(b.jmp.arg) == .RCall {
                    @debug_assert(b.jmp.type == .ret0, "expected return");
                    return_registers := {T.retregs}(b.jmp.arg, Array(i32, 2).ptr_from_int(0));
                    in_reg.t[] = in_reg.t[].bit_or(return_registers);
                };
            };
        };
        
        for(b.out&, Qbe.Tmp0) { t | 
            if !bshas(in_reg&, t) {
                pass&.slot(t);
            };
        };
        bscopy(b.out&, in_reg&);
        
        /* 2. process the block instructions */
        if rtype(b.jmp.arg) == .RTmp {
            t := b.jmp.arg.val();
            @debug_assert(tmp[t].cls.is_int(), "can only jump on int (previous pass removed ret with value)");
            arg_used_again := bshas(in_reg&, t);
            bsset(in_reg&, t);
            bscopy(all_needed_later&, in_reg&);
            pass&.limit_in_reg(in_reg&, false, .None);
            if !bshas(in_reg&, t) {
                if !arg_used_again {
                    bsclr(all_needed_later&, t);
                };
                b.jmp.arg = pass&.slot(t);
            };
            pass&.reload_spilled(all_needed_later&, in_reg&);
        };
        f.globals.curi[] = f.scratch_start();
        for_insts_rev b { i |
            continue :: local_return;
            if is_copy_from_reg(i[]) {
                i[] = pass&.do_parallel_moves(b, i[], in_reg&);
                continue();
            };
            bszero(prioritize&);
            if i.to != QbeNull {
                @debug_assert(rtype(i.to) == .RTmp, "can only assign tmp");
                t := i.to.val();
                if bshas(in_reg&, t) {
                    // we know we had t in a register after this, and we're creating t now, so its not in a register before this. 
                    bsclr(in_reg&, t);
                } else {
                    /* make sure we have a reg
                     * for the result */
                    @debug_assert_ge(t, Qbe.Tmp0, "dead reg");
                    bsset(in_reg&, t);
                    bsset(prioritize&, t);
                };
            };
            j := {T.memargs}(i[].op());
            for i.arg& { r |
                if rtype(r) == .RMem {
                    j -= 1;
                };
            };
            
            arg_used_again := Array(bool, 2).zeroed();
            range(0, 2) { n | 
                @match(rtype(i.arg&[n])) {
                    fn RMem() => {
                        t := i.arg&[n].val();
                        m := f.mem[t]&;
                        if rtype(m.base) == .RTmp {
                            bsset(in_reg&, m.base.val());
                            bsset(prioritize&, m.base.val());
                        };
                        if rtype(m.index) == .RTmp {
                            bsset(in_reg&, m.index.val());
                            bsset(prioritize&, m.index.val());
                        };
                    }
                    fn RTmp() => {
                        t := i.arg&[n].val();
                        arg_used_again&[n] = bshas(in_reg&, t);
                        bsset(in_reg&, t); // instructions want arguments in registers
                        if j <= 0 {
                            bsset(prioritize&, t);
                        };
                        j -= 1;
                    }
                    @default => ();
                };
            };
            bscopy(all_needed_later&, in_reg&);
            pass&.limit_in_reg(in_reg&, false, (Some = prioritize&));
            range(0, 2) { n | 
                if rtype(i.arg&[n]) == .RTmp {
                    t := i.arg&[n].val();
                    if !bshas(in_reg&, t) {
                        /* do not reload if the
                         * argument is dead
                         */
                        if !arg_used_again&[n] {
                            bsclr(all_needed_later&, t);
                        };
                        i.arg&[n] = pass&.slot(t);
                    }
                }
            };
            pass&.reload_spilled(all_needed_later&, in_reg&);
            if i.to != QbeNull {
                t := i.to.val();
                f.maybe_store(i.to, f.tmp[t].slot);
                if t >= Qbe.Tmp0 {
                    /* in case i.to was a
                     * dead temporary */
                    bsclr(in_reg&, t);
                }
            };
            f.emit(i[][]);
            r := in_reg.t[]; /* Tmp0 is NBit */
            if r != 0 {
                f.hint_to_avoid(in_reg&, r);
            };
        };
        if b.identical(f.start) {
            @debug_assert_eq(in_reg.t[], T.rglob.bit_or(f.reg), "global + callee saved % %", T.rglob, f.reg);
        } else {
            @debug_assert_eq(in_reg.t[], T.rglob, "just global");
        };

        for_phi b { p |
            @debug_assert(rtype(p.to) == .RTmp, "can only assign tmp");
            t := p.to.val();
            if bshas(in_reg&, t) {
                bsclr(in_reg&, t);
                f.maybe_store(p.to, f.tmp[t].slot);
            } else {
                if bshas(b.in&, t) {
                    /* only if the phi is live */
                    p.to = pass&.slot(p.to.val());
                }
            }
        };
        bscopy(b.in&, in_reg&);
        f.copy_instructions_from_scratch(b);
    };

    /* align the locals to a 16 byte boundary */
    /* specific to NAlign == 3 */
    pass.slot8 += pass.slot8.zext().bit_and(3).intcast();
    f.slot += pass.slot8;

    if f.globals.debug["S".char()] {
        out := f.globals.debug_out;
        write(out, "\n> Block information:\n");
        for_blocks f { b |
            @fmt_write(out, "\t% (%) ", f_pad(b.name(), 10, .After), f_pad(b.loop, 5, .Before));
            dumpts(b.out&, f.tmp, out);
        };
        write(out, "\n> After spilling:\n");
        printfn(f, out);
    };
}

fn for_caller_saved(target: *Qbe.Target, $body: @Fn(r: i64) void) void = {
    n := 0;
    while => target.caller_saved.offset(n)[] >= 0 {
        idx: i64 = target.caller_saved.offset(n)[].zext();
        body(idx);
        n += 1;
    };
}

fn caller_saved_bits(target: *Qbe.Target) u64 = {   
    r: u64 = 0; 
    for_caller_saved target { reg | 
        r = r.bit_or(BIT(reg));
    };
    r
}
