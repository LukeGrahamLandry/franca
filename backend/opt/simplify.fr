// Adapted from Qbe. MIT License. Â© 2015-2024 Quentin Carbonneaux <quentin@c9x.me>

fn simplify(f: *Qbe.Fn) void = {
    for_blocks f { b |
        moved_to_new_memory := false;
        for_insts_rev b { i |
            f.ins(i, moved_to_new_memory&, b);
        };
        
        if moved_to_new_memory {
            f.copy_instructions_from_scratch(b);
        };
    };
}

// TODO: divmod fusion? maybe should be a backend thing? dont really want to add two output instructions. 
//       maybe here should just see if you do a div and rem by the same divisor in a block and move them to be next to eachother.
//       or maybe global code motion should be its own seperate thing. 
fn ins(f: *Qbe.Fn, iter: **Qbe.Ins, moved_to_new_memory: *bool, b: *Qbe.Blk) void #once = {
    i := iter[];
    
    if i.op() == .blit1 {
        @debug_assert(i.in_memory_after(b.ins.first), "OOB inst");
        start_blit := i.offset(-1);
        @debug_assert(start_blit.op() == .blit0, "blits must be paired");
    
        // Currently (blit, rem, div) are the only simplifications that adds new instructions. 
        // So if a block does not contain those, the other simplifications (urem, udiv) can just update the instructions in place.
        // The first time we see one that calls emit(), we need to copy the instructions we've already seen into the scratch buffer (since we might have changed then).
        // And the at the end of the block, we'll replace the block with the contents of the scratch buffer. 
        f.move_end_of_block_to_scratch(b, i, moved_to_new_memory);
    
        f.expand_blit(start_blit.arg&[1], start_blit.arg&[0], rsval(i.arg&[0]).intcast());
        iter[] = i.offset(-1);  // deal with the variable length encoding (blit0, blit1). 
        return();
    };
    
    if (@is(i.op(), .udiv, .urem, .div, .rem)) {
        f.simplify_div_like(b, i, moved_to_new_memory);
    };
    
    if moved_to_new_memory[] {
       f.emit(i[]);
    };
}

fn move_end_of_block_to_scratch(f: *Qbe.Fn, b: *Qbe.Blk, i: *Qbe.Ins, changed: *bool) void #inline = {
    if !changed[] {
        f.globals.curi[] = f.scratch_start();
        ni := ptr_diff(i.offset(1), b.ins.index(b.nins.zext()));
        f.globals.curi[] = f.globals.curi[].offset(-ni);
        icpy(f.globals.curi[], i.offset(1), ni);
        changed[] = true;
    }
}

fn simplify_div_like(f: *Qbe.Fn, b: *Qbe.Blk, i: *Qbe.Ins, changed: *bool) void = {
    r := i.arg&[1];
    i.cls().is_int()            || return();
    rtype(r) == .RCon           || return();
    c := f.get_constant(r);
    c.type == .CBits            || return();
    ispow2(c.bits.i.bitcast())  || return();
    // The divisor is a constant power of 2. 
    
    is_rem := @is(i.op(), .urem, .rem);
    is_signed := @is(i.op(), .div, .rem);
    
    c.bits.i != 0 || return();
    if c.bits.i == 1 {
        r := if(is_rem, => QbeConZero, => i.arg&[0]);
        i[] = make_ins(.copy, i.cls(), i.to, r, QbeNull);
    };
    
    n := trailing_zeros(c.bits.i);
    
    o: Qbe.O = @if(is_rem, .and, @if(is_signed, .sar, .shr));
    magic := @if(is_rem, 1.shift_left(n) - 1, n);
    
    if is_signed {
        f.globals.goal.arch != .wasm32 || return(); // TODO: impl select
        
        // Negative numbers are supposed to round towards 0. 
        // But if you just do the shift, they'll round towards -infinity. 
        // This is (roughly) how clang solves that problem:
        // TODO: explain better!
        // https://godbolt.org/z/oecTh1bfz
        
        f.move_end_of_block_to_scratch(b, i, changed);
        
        k := i.cls();
        negative := f.newtmp("simpl", .Kw);
        new_dividend := f.newtmp("simpl", k);
        neg_dividend := f.newtmp("simpl", k);
        
        out := i.to;
        if is_rem {
            magic = -(magic + 1);
            out = f.newtmp("simpl", k);
            f.emit(.sub, k, i.to, i.arg&[0], out);
        };
        
        f.emit(o, k, out, new_dividend, f.getcon(magic));
        f.emit(.sel1, k, new_dividend, neg_dividend, i.arg&[0]);
        f.emit(.sel0, .Kw, QbeNull, negative, QbeNull);
        f.emit(@if(k == .Kw, .csltw, .csltl), .Kw, negative, i.arg&[0], QbeConZero);
        f.emit(.add, k, neg_dividend, i.arg&[0], f.getcon(1.shift_left(n) - 1));
        i.set_nop();
    } else {
        i.set_op(o);
        i.arg&[1] = f.getcon(magic);
    };
}

blit_op_table :: {
    T   :: @struct(store: Qbe.O, load: Qbe.O, cls: Qbe.Cls, size: i64);
    t   := ast_alloc().alloc(T, 4);
    t[0] = (store = .storel, load = .load,   cls = .Kl, size = 8);
    t[1] = (store = .storew, load = .load,   cls = .Kw, size = 4);
    t[2] = (store = .storeh, load = .loaduh, cls = .Kw, size = 2);
    t[3] = (store = .storeb, load = .loadub, cls = .Kw, size = 1);
    t
};
    
// Blit instructions are implemented as a sequence of loads and stores.
fn expand_blit(f: *Qbe.Fn, dest: Qbe.Ref, src: Qbe.Ref, blit_size: i64) void #once = {
    // TODO: if i keep this move the encoded Call arg value to the target struct.  
    // TODO
    //if f.globals.goal.type != .JitOnly && f.globals.goal.arch == .aarch64 && blit_size > 512  {  // :force_dep_on_memmove_hack
    //    // TODO: ugh, really shouldn't do this sort of thing. but it makes the generated code easier to read. 
    //    //       the main offender is zeroed() of something big and the correct fix for that would be returning with fewer copies.  
    //    s := f.getcon(blit_size.abs());
    //    c: Qbe.Con = (type = .CAddr, sym = (id = f.globals.symbol_memmove), bits = (i = 0));
    //    m := f.newcon(c&);
    //    f.emit(.copy, .Kl, QbeNull, TMP(1), QbeNull);
    //    f.emit(.call, .Kl, QbeNull, m, CALL(0b001100001));  // TODO: bad bad bad! hardcoded output of abi pass.
    //    f.emit(.copy, .Kl, TMP(3), s, QbeNull);
    //    f.emit(.copy, .Kl, TMP(2), src, QbeNull);
    //    f.emit(.copy, .Kl, TMP(1), dest, QbeNull);
    //    f.leaf = false;
    //    return();
    //};
    
    forward  := blit_size >= 0;
    blit_size = blit_size.abs();
    off := if(forward, => blit_size, => 0);
    each blit_op_table { p |
        while => blit_size >= p.size {
            blit_size -= p.size;
            if forward {
                off -= p.size;
            };
            r_value     := f.newtmp("blt", .Kl);
            r_dest_slot := f.newtmp("blt", .Kl);
            r_offset    := f.getcon(off);
            f.emit(p.store, .Kw, QbeNull, r_value, r_dest_slot);
            f.emit(.add, .Kl, r_dest_slot, dest, r_offset);
            r_src_slot  := f.newtmp("blt", .Kl);
            f.emit(p.load, p.cls, r_value, r_src_slot, QbeNull);
            f.emit(.add, .Kl, r_src_slot, src, r_offset);
            
            if !forward {
                off += p.size;
            };
        };
    };
}

fn ispow2(v: u64) bool = 
    v != 0 && v.bit_and(v - 1) == 0;

// TODO: this is not arch specific. it's just convient to call from isel because it needs tmp.def. 
//       so currently only done for arm64 where i do a prepass that folds some addressing stuff without emit() breaking the pointers. 
//       -- Jan 19, 2025
// this is the pattern i generate for boolean not
fn fix_ceqw_not(f: *Qbe.Fn, i: *Qbe.Ins) void #inline = {
    @debug_assert(i.op() == .ceqw);
    if i.arg&[1] == QbeConZero {
        r := i.arg&[0];
        if(rtype(r) != .RTmp, => return());
        t := f.get_temporary(r);
        if(t.def.is_null(), => return());
        ck := Qbe.Cls.zeroed();
        cc: i32 = 0;
        if iscmp(t.def.op(), ck&, cc&) {
            cc_rev := cmpneg(cc);
            if !ck.is_int() {
                cc_rev -= Qbe.CmpICount;
            };
            o := @as(Qbe.O) @as(i32) cmp_base(ck).raw() + cc_rev;
            
            a0, a1 := (t.def.arg&[0], t.def.arg&[1]);
            chuse(r, -1, f);
            if t.nuse == 0 {
                t.def.set_nop();
            } else {
                chuse(a0, 1, f);
                chuse(a1, 1, f);
            };
            i[] = make_ins(o, i.cls(), i.to, a0, a1);
        };
    };
}

fn cmp_base(k: Qbe.Cls) Qbe.O = @match(k) {  // :CmpOrder
    fn Kw() => .ceqw;
    fn Kl() => .ceql;
    fn Ks() => .ceqs;
    fn Kd() => .ceqd;
    @default => panic("invalid cls");
};

fn cmp_ne(k: Qbe.Cls) Qbe.O = @match(k) {  // :CmpOrder
    fn Kw() => .cnew;
    fn Kl() => .cnel;
    fn Ks() => .cnes;
    fn Kd() => .cned;
    @default => panic("invalid cls");
};