// Adapted from Qbe. MIT License. Â© 2015-2024 Quentin Carbonneaux <quentin@c9x.me>

fn simplify(f: *Qbe.Fn) void = {
    for_blocks f { b |
        moved_to_new_memory := false;
        for_insts_rev b { i |
            f.ins(i, moved_to_new_memory&, b);
        };
        
        if moved_to_new_memory {
            f.copy_instructions_from_scratch(b);
        };
    };
}

// TODO: divmod fusion? maybe should be a backend thing? dont really want to add two output instructions. 
//       maybe here should just see if you do a div and rem by the same divisor in a block and move them to be next to eachother.
//       or maybe global code motion should be its own seperate thing. 
fn ins(f: *Qbe.Fn, iter: **Qbe.Ins, moved_to_new_memory: *bool, b: *Qbe.Blk) void #once = {
    i := iter[];
    
    if i.op() == .blit1 {
        @debug_assert(i.in_memory_after(b.ins.ptr), "OOB inst");
        start_blit := i.offset(-1);
        @debug_assert(start_blit.op() == .blit0, "blits must be paired");
    
        // Currently (blit, rem, div) are the only simplifications that adds new instructions. 
        // So if a block does not contain those, the other simplifications (urem, udiv) can just update the instructions in place.
        // The first time we see one that calls emit(), we need to copy the instructions we've already seen into the scratch buffer (since we might have changed then).
        // And the at the end of the block, we'll replace the block with the contents of the scratch buffer. 
        f.move_end_of_block_to_scratch(b, i, moved_to_new_memory);
    
        f.expand_blit(start_blit.arg&[1], start_blit.arg&[0], rsval(i.arg&[0]).intcast());
        iter[] = i.offset(-1);  // deal with the variable length encoding (blit0, blit1). 
        return();
    };
    
    if (@is(i.op(), .udiv, .urem, .div, .rem)) {
        f.simplify_div_like(b, i, moved_to_new_memory);
    };
    
    if moved_to_new_memory[] {
       f.emit(i[]);
    };
}

fn simplify_div_like(f: *Qbe.Fn, b: *Qbe.Blk, i: *Qbe.Ins, changed: *bool) void = {
    r := i.arg&[1];
    i.cls().is_int()            || return();
    rtype(r) == .RCon           || return();
    c := f.get_constant(r);
    c.type() == .CBits            || return();
    ispow2(c.bits())  || return();
    // The divisor is a constant power of 2. 
    
    is_rem := @is(i.op(), .urem, .rem);
    is_signed := @is(i.op(), .div, .rem);
    
    c.bits() != 0 || return();
    if c.bits() == 1 {
        r := if(is_rem, => QbeConZero, => i.arg&[0]);
        i[] = make_ins(.copy, i.cls(), i.to, r, QbeNull);
    };
    
    n := trailing_zeros(c.bits());
    
    o: Qbe.O = @if(is_rem, .and, @if(is_signed, .sar, .shr));
    magic := @if(is_rem, 1.shift_left(n) - 1, n);
    
    if is_signed {
        f.globals.goal.arch != .wasm32 || return(); // TODO: impl select
        
        // Negative numbers are supposed to round towards 0. 
        // But if you just do the shift, they'll round towards -infinity. 
        // This is (roughly) how clang solves that problem:
        // TODO: explain better!
        // https://godbolt.org/z/oecTh1bfz
        
        f.move_end_of_block_to_scratch(b, i, changed);
        
        k := i.cls();
        negative := f.newtmp("simpl", .Kw);
        new_dividend := f.newtmp("simpl", k);
        neg_dividend := f.newtmp("simpl", k);
        
        out := i.to;
        if is_rem {
            magic = -(magic + 1);
            out = f.newtmp("simpl", k);
            f.emit(.sub, k, i.to, i.arg&[0], out);
        };
        
        f.emit(o, k, out, new_dividend, f.getcon(magic));
        f.emit(.sel1, k, new_dividend, neg_dividend, i.arg&[0]);
        f.emit(.sel0, .Kw, QbeNull, negative, QbeNull);
        f.emit(@if(k == .Kw, .csltw, .csltl), .Kw, negative, i.arg&[0], QbeConZero);
        f.emit(.add, k, neg_dividend, i.arg&[0], f.getcon(1.shift_left(n) - 1));
        i.set_nop();
    } else {
        i.set_op(o);
        i.arg&[1] = f.getcon(magic);
    };
}

blit_op_table :: {
    T   :: @struct(store: Qbe.O, load: Qbe.O, cls: Qbe.Cls, size: i64);
    t   := ast_alloc().alloc(T, 4);
    t[0] = (store = .storel, load = .load,   cls = .Kl, size = 8);
    t[1] = (store = .storew, load = .load,   cls = .Kw, size = 4);
    t[2] = (store = .storeh, load = .loaduh, cls = .Kw, size = 2);
    t[3] = (store = .storeb, load = .loadub, cls = .Kw, size = 1);
    t
};
    
// Blit instructions are implemented as a sequence of loads and stores.
fn expand_blit(f: *Qbe.Fn, dest: Qbe.Ref, src: Qbe.Ref, blit_size: i64) void #once = {
    // :ThisSureIsABigBlit
    // The threshold size is arbitrary, going lower you're trading off binary size for speed. 
    // (until you get to extremely small or large blits)
    if f.globals.goal.type != .JitOnly && blit_size > 128  {  // :force_dep_on_memmove_hack
        break :: local_return;
        // TODO: ugh, really shouldn't do this sort of thing. but it makes the generated code easier to read. 
        s := f.getcon(blit_size.abs());
        m := f.globals.builtin_memove_symbol() || break();
        m := f.symcon(m);
        r := f.globals.target.hack_builtin_memmove;
        r.len != 0 || break();  // TODO: wasm
        f.emit(.copy, .Kl, QbeNull, r[4], QbeNull);
        f.emit(.call, .Kl, QbeNull, m, r[3]);
        f.emit(.copy, .Kl, r[2], s, QbeNull);
        f.emit(.copy, .Kl, r[1], src, QbeNull);
        f.emit(.copy, .Kl, r[0], dest, QbeNull);
        f.leaf = false;
        return();
    };
    
    forward  := blit_size >= 0;
    blit_size = blit_size.abs();
    off := if(forward, => blit_size, => 0);
    
    // Try to take advantage of arm's load/store pair instructions. 
    // When emit sees a sequential pair, it will fuse them into a single instruction. 
    // Representing it this way means they can still get optimised by slots.fr. 
    while => blit_size >= 16 {
        blit_size -= 16;
        if forward {
            off -= 16;
        };
        
        r_offset2 := f.getcon(off + @if(forward, 8, -8));
        @emit_instructions((f = f), (src, dest, f.getcon(off), r_offset2), """
        @start
            %s0 =l add %0, %2
            %d0 =l add %1, %2
            %s1 =l add %0, %3
            %d1 =l add %1, %3
            %r0 =l load %s0
            %r1 =l load %s1
            storel %r0, %d0
            storel %r1, %d1
        """);
        
        if !forward {
            off += 16;
        };
    };
    
    each blit_op_table { p |
        while => blit_size >= p.size {
            blit_size -= p.size;
            if forward {
                off -= p.size;
            };
            r_value     := f.newtmp("blt", .Kl);
            r_dest_slot := f.newtmp("blt", .Kl);
            r_offset    := f.getcon(off);
            f.emit(p.store, .Kw, QbeNull, r_value, r_dest_slot);
            f.emit(.add, .Kl, r_dest_slot, dest, r_offset);
            r_src_slot  := f.newtmp("blt", .Kl);
            f.emit(p.load, p.cls, r_value, r_src_slot, QbeNull);
            f.emit(.add, .Kl, r_src_slot, src, r_offset);
            
            if !forward {
                off += p.size;
            };
        };
    };
}

// TODO: this is not arch specific. it's just convient to call from isel because it needs tmp.def. 
//       so currently only done for arm64 where i do a prepass that folds some addressing stuff without emit() breaking the pointers. 
//       -- Jan 19, 2025
// this is the pattern i generate for boolean not
fn fix_ceqw_not(f: *Qbe.Fn, i: *Qbe.Ins) void #inline = {
    @debug_assert(i.op() == .ceqw);
    if i.arg&[1] == QbeConZero {
        r := i.arg&[0];
        if(rtype(r) != .RTmp, => return());
        t := f.get_temporary(r);
        if(t.def.is_null(), => return());
        ck := Qbe.Cls.zeroed();
        cc: i32 = 0;
        if iscmp(t.def.op(), ck&, cc&) {
            cc_rev := cmpneg(cc);
            if !ck.is_int() {
                cc_rev -= Qbe.CmpICount;
            };
            o := @as(Qbe.O) @as(i32) cmp_base(ck).raw() + cc_rev;
            
            a0, a1 := (t.def.arg&[0], t.def.arg&[1]);
            chuse(r, -1, f);
            if t.nuse == 0 {
                t.def.set_nop();
            } else {
                chuse(a0, 1, f);
                chuse(a1, 1, f);
            };
            i[] = make_ins(o, i.cls(), i.to, a0, a1);
        };
    };
}

fn cmp_base(k: Qbe.Cls) Qbe.O = @match(k) {  // :CmpOrder
    fn Kw() => .ceqw;
    fn Kl() => .ceql;
    fn Ks() => .ceqs;
    fn Kd() => .ceqd;
    @default => panic("invalid cls");
};

fn cmp_ne(k: Qbe.Cls) Qbe.O = @match(k) {  // :CmpOrder
    fn Kw() => .cnew;
    fn Kl() => .cnel;
    fn Ks() => .cnes;
    fn Kd() => .cned;
    @default => panic("invalid cls");
};

#use("@/backend/lib.fr");

fn builtin_memove_symbol(m: *QbeModule) ?Qbe.Sym = {
    @if(m.goal.link_libc && prefer_libc_memmove) return(Some = m.symbol_memmove);
    @if(!matching_comptime_incremental_abi) return(.None);
    m.need_static_memmove = true;
    (Some = m.symbol_memmove)
}

emit_static_memmove :: fn(m: *Qbe.Module) void = {
    @if(!matching_comptime_incremental_abi) return();
    @if(m.have_static_memmove) return();
    m.have_static_memmove = true;
    
    h := check(static_memmove);
    h := h.unwrap();
    syms := preintern_syms(h, m);
    f := zeroed Qbe.Fn;
    f.globals = m;
    // without this it does if the funcid ends up being the same, 
    // which it will be because repro, so name collides with the real copy_bytes__XXX. 
    // oh but also you do need it to be a fixed thing. 
    syms[h.meta.entry_sym.off.zext()] = m.symbol_memmove;
    did_regalloc := load(h, f&, h.meta.entry_sym, syms);
    @debug_assert(!did_regalloc);
    {m.target.finish_passes}(f&);
};

static_memmove :: {
    fid  := resolve_overload(copy_bytes, Ty(rawptr, rawptr, i64), void, zeroed Span);
    fr   := current_compiler_context();
    name := fr'vtable'mangle_name(fr.data, fid);
    
    bytes := {
        m   := ast_alloc().box(Qbe.Module);
        init_default_module_dyn(m, fr.vtable, (arch = .aarch64, os = .macos, type = .CachedEarly));
        chunks := {fr.vtable.emit_qbe_included}(Qbe.Module.raw_from_ptr(m), fr&, @slice(fid), .GiveMeTheCodeAndGiveItToMeRaw);
        bytes := concat(chunks&, ast_alloc());
        drop(m);
        //write_entire_file_or_crash("target/a.frc", bytes);
        bytes
    };

    {
        h := check(bytes);
        h := h.unwrap();
        @assert(h.typ.count == 0 && h.fty.count == 0, "static_memmove.frc doesn't want type info");
        func_count := 0;
        h.meta.entry_sym.off = Qbe.no_symbol;
        for(h, h.all(Incremental.Sym)) { i, it |
            ::enum(@type it.segment);
            func_count += int(@is(it.segment, .Code, .MachineCode, .Import));
            if h.get(it.name) == name {  
                h.meta.entry_sym = i;
            }
        };
        
        @assert(h.meta.entry_sym.off != Qbe.no_symbol, "static_memmove symbol not found");
        // TODO: this should be true but it doesn't work out the first time until :UpdateBoot
        // @assert(func_count == 1, msg); 
        
        msg :: "static_memmove.frc shouldn't be making calls";
        @if(func_count != 1)
        for(h, h.all(Qbe.Ins)) { i, it |
            ::enum(Qbe.O);
            @assert(it.op() != .call, msg); 
        };
    };
    
    bytes
};
