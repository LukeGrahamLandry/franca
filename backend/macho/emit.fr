// this feels like a massive pain and i must be making it more complicated than it needs to be...
// but consider that the Zig has ~18000 lines of dealing with mach-o files: 
//  - https://github.com/ziglang/zig/tree/master/src/link/MachO
//  - https://github.com/ziglang/zig/blob/master/src/link/MachO.zig
// not at all a fair comparison, they do far more stuff, but the point remains. 

// life is better if you're always 8 byte aligned. 

fn output_macho(m: *QbeModule) List([]u8) = {  
    global_module.fill_from_libc(); // TODO: don't waste time doing this just to bump reloc state. 
    for_enum SegmentType { s | 
        m.align_to(s, 8);  // forgeting this manifested as getting fucked on __LINKEDIT (when reading not writing because you're writting into a new allocation)
    };
    
    m.fixups_locked = true; // we're going to stomp the data section with relocation info so you can run it jitted anymore after this. 
    chunks := list([]u8, 10, temp());
    chunks&.push(empty()); // commands
    chunks&.push(live_segment_part(m, .Code));  // :MySegmentsStartAt1 :CodeIsFirst
    chunks&.push(live_segment_part(m, .Stubs));
    chunks&.push(live_segment_part(m, .MutableData));
    chunks&.push(live_segment_part(m, .ConstantData));  // TODO: waste. dead zone ConstantData[got_cursor..MAX_GOT_SIZE]
    
    add_data_file_offset := list(*u32, 10, temp());
    COMMANDS_SIZE_GUESS := 16000;
    commands := u8.list(COMMANDS_SIZE_GUESS, temp());
    command_count := 0;
    segment_file_offsets := temp().alloc_zeroed(i64, m.segments.data&.len());
    
    macho_header := commands&.reserve_type(MachoHeader);
    macho_header[] = (
        cpu_type = 0x0100000C, // arm 64bit
        cpu_subtype = 0x00000000,
        file_type = 0x00000002, // Demand paged executable file. (idk, thats what rust uses ¯\_(ツ)_/¯ )
        commands_count = 0, 
        commands_size = 0, 
        // TODO: probably need to steal this from something else because I don't HAS_TLV_DESCRIPTORS
        flags = 0b00000000101000000000000010000101, // (idc, thats what rust uses ¯\_(ツ)_/¯ )
    );
    
    ::enum_basic(LoadCommand);
    // I guess this is to make sure you segfault on low addresses. 
    // But it can't guarentee my base address is zero right? so what's the point? clearly im missing something. 
    // TODO: probably don't do this if we're making a linkable .o file. 
    zero_page_size :: 0x100000000;
    {
        start := commands.len;
        h := commands&.reserve_type(LoadCommandHeader);
        h.type = LoadCommand.SegmentLoad.raw();
        command_count += 1;
        cmd := commands&.reserve_type(SegmentLoad);
        cmd[] = SegmentLoad.zeroed();
        cmd.name = str_to_16_byte_value("__ZEROPAGE");
        cmd.address_size = zero_page_size;
        h.size = trunc(commands.len - start);
    };
    file_offset := 0;
    base_file_offset := @slice(0, 0, 0, 0, 0); // you always need to use add_data_file_offset with this. 
    virtual_segment_offset := @slice(0, 0, 0, 0, 0);
    {
        segment_index := 0; // 0 is __ZEROPAGE
        names := @slice("", "__TEXT", "__STUBSHACK", "__DATA", "__DATA_CONST");
        prot := @slice(@as(u32) 0, 5, 5, 3, 3);
        virtual_offset := zero_page_size;
        for_enum SegmentType { s |
            segment_index += 1;
            start := commands.len;
            h := commands&.reserve_type(LoadCommandHeader);
            h.type = LoadCommand.SegmentLoad.raw();
            command_count += 1;
            cmd := commands&.reserve_type(SegmentLoad);
            cmd[] = SegmentLoad.zeroed();
            cmd.max_prot = prot[segment_index];
            cmd.init_prot = prot[segment_index];
            cmd.name = str_to_16_byte_value(names[segment_index]);
            cmd.address = virtual_offset.bitcast();
            vlen := m.segments&[s].mmapped.len;
            flen := chunks[segment_index].len;
            cmd.address_size = vlen.bitcast();
            virtual_segment_offset[segment_index] = virtual_offset;
            virtual_offset += vlen;
            cmd.file_offset = file_offset.bitcast();
            base_file_offset[segment_index] = file_offset;
            file_offset += flen;
            add_data_file_offset&.push(ptr_cast_unchecked(u64, u32, cmd.file_offset&)); // :overflow
            cmd.size = flen.bitcast(); // :MySegmentsStartAt1
            h.size = trunc(commands.len - start);
        };
    };
    
    // TODO: don't assume you want libc. but on macos you always do. 
    {  // LC_LOAD_DYLIB
        start := commands.len;
        h := commands&.reserve_type(LoadCommandHeader);
        h.type = LoadCommand.LinkLibrary.raw();
        command_count += 1;
        cmd := commands&.reserve_type(LinkLibrary);
        // TODO: where does one get these numbers? this is just what clang does. 
        cmd[] = (
            time_date_stamp = 2,
            current_version = 86467587,
            compatible_version = 65536,
        );
        append_padded_cstr(commands&, "/usr/lib/libSystem.B.dylib", 8);
        h.size = trunc(commands.len - start);
    };
    {  // LC_LOAD_DYLINKER
        start := commands.len;
        h := commands&.reserve_type(LoadCommandHeader);
        h.type = LoadCommand.LoadDynamicLinker.raw();
        command_count += 1;
        commands&.reserve_type(u32)[] = 12;
        append_padded_cstr(commands&, "/usr/lib/dyld", 8);
        h.size = trunc(commands.len - start);
    };
    {
        start := commands.len;
        h := commands&.reserve_type(LoadCommandHeader);
        h.type = LoadCommand.MainEntryPoint.raw();
        command_count += 1;
        cmd := commands&.reserve_type(MainEntryPoint);
        symbol := m.get_symbol_info(m.intern("main".sym().c_str()));
        assert(symbol.kind == .Local, "no main function?");
        // offset is from the start of interesting virtual memory? 
        cmd[] = (entry_offset = symbol.offset.bitcast(), stack_size = 0);  // :CodeIsFirst its fine to change this, you just have to do the math here. 
        h.size = trunc(commands.len - start);
    };
    {
        CHAINED_SIZE_GUESS :: 16000;
        chained := u8.list(CHAINED_SIZE_GUESS, temp());
        chain_header := chained&.reserve_type(ChainedFixupsHeader);
        
        fixups, symbols := collect_aot_fixups(m);
        @debug_assert_ge(fixups.len, m.got_cursor / 8, "at least each __got entry needs a fixup");
        sort :: quicksort(FixP, fn(a, b) => ptr_diff(a._1.patch_at, b._1.patch_at) <= 0); // TODO: flipped?
        sort(fixups);
        // at this point, `fixups` is in the order of the patch targets in virtual memory which is the order we need to emit the fixup chains. 
        import_count := 0;
        for symbols { s |
            if s.kind != .Local {
                s.got_lookup_offset = import_count;
                import_count += 1;
            };
        };
        // imports are fixed size. so we can reserve that early
        imports_len_b := import_count * 4;
        imports_offset := chained.len; // TODO: is this right?
        chained&.reserve(imports_len_b);
        chained.len += imports_len_b;
        symbols_offset := chained.len; // TODO: is this right?
        imports_bytes := chained.items().slice(chained.len - imports_len_b, chained.len);
        imports_bytes: []u32 = (ptr = ptr_cast_unchecked(u8, u32, imports_bytes.ptr), len = import_count);
        for symbols { s |
            if s.kind != .Local {
                n: u32 = trunc(chained.len - symbols_offset);
                imports_bytes[s.got_lookup_offset] = encode_import(lib_ordinal = 1, weak = false, name_offset = n); // TODO: don't assume libc
                append_padded_cstr(chained&, s.name.str(), 1);
            };
        };
        zero_pad_to_align(chained&, 4);
        
        //
        // Now we have to do the fixup chain page starts. 
        // This is how we tell it where it has to do relocations. 
        //
        starts_offset := chained.len;
        // TODO: uncomment the real number when ready
        seg_count :: 2 + enum_count(SegmentType);  // __zeropage, <the rest>, __linkedit
        chained&.reserve_type(u32)[] = seg_count.trunc();
        // indexed by segment index
        offset_to_csis: []u32 = (ptr = ptr_cast_unchecked(u8, u32, chained.maybe_uninit.ptr.offset(chained.len)), len = seg_count); // from chained[starts_offset]
        unprocessed_sentinal :: MAX_u32;
        range(0, seg_count) { i |
            o := chained&.reserve_type(u32);
            o[] = unprocessed_sentinal;
        };
        
        chained&.zero_pad_to_align(8);
        start_of_csis := chained.len;
        csis_off := chained.len - starts_offset;
        csis := chained&.reserve_type(ChainedStartsInSegment);  // one of these per segment.  
        chained.len -= 2; // take it back now yall
        csis[] = ChainedStartsInSegment.zeroed();
        // TODO: what if there's a page in the middle with no relocations? 
        fix := fixups.index(0);
        @assert_eq(fixups.len, 1, "tODO: more fixups");
        seg, off_in_segment := compiler_address_to_segment_offset(m, fix._1.patch_at);
        segment_index := seg.raw() + 1;  // :MySegmentsStartAt1
        page_index, offset_in_page := off_in_segment.div_mod(macos_page_size);
        if offset_to_csis[segment_index] == unprocessed_sentinal {
            @assert_eq(page_index, 0, "TODO: how do we skip pages without fixups?");
            offset_to_csis[segment_index] = csis_off.trunc();
            chained&.reserve_type(u16)[] = offset_in_page.trunc();
        } else {
            panic("TODO: multiple fixups");
        };
        csis.segment_offset = base_file_offset[segment_index].bitcast(); // this is the offset into the file to the first page in this segment. 
        add_data_file_offset&.push(ptr_cast_unchecked(u64, u32, csis.segment_offset&)); // :overflow
        encoded := encode_chained(
            next = 0,  // TODO
            reserved = 0,
            payload = @if(fix._0.kind != .Local, {
                @debug_assert(fix._0.got_lookup_offset >= 0 && fix._0.got_lookup_offset < import_count, "bad ordinal");
                (Bind = (addend = 0, ordinal = fix._0.got_lookup_offset.trunc()))
            }, {
                dest_segment := fix._0.segment.raw() + 1; // :MySegmentsStartAt1
                target := virtual_segment_offset[dest_segment] - zero_page_size + fix._0.offset;
                @assert_lt(target, 1.shift_left(36), "rebase > 36 bits");
                (Rebase = (high8 = 0, target = target))
            })
        );
        ptr_cast_unchecked(u8, i64, fix._1.patch_at)[] = encoded;
        csis.page_size = macos_page_size;
        csis.pointer_format = 6; // who knows man, i just work here. TODO
        
        csis.size = trunc(chained.len - start_of_csis);
        csis.max_valid_pointer = 0; // TODO: what does this mean?
        // TODO: handle multiple
        csis.page_count = 1;
        
        i := 0;
        each offset_to_csis { it |
            @debug_assert(u32.int_from_ptr(it) == u8.int_from_ptr(chained.maybe_uninit.ptr) + starts_offset + 4 + i * 4, "miscounted offset_to_csis");
            i += 1;
            if it[] == unprocessed_sentinal { 
                it[] = 0;  // zero means no fixups
            };
        };
        
        @debug_assert(offset_to_csis[0] == 0 && offset_to_csis[offset_to_csis.len - 1] == 0, "__PAGEZERO and __LINKEDIT shouldn't have fixups.");
        
        chained&.zero_pad_to_align(8);
        @assert_le(chained.len, CHAINED_SIZE_GUESS, "resized and now the header pointer is junk");
        chain_header[] = (
            imports_count = import_count.trunc(), 
            imports_format = 1, 
            symbols_format = 0, 
            version = 0, 
            starts_offset = starts_offset.trunc(), 
            imports_offset = imports_offset.trunc(), 
            symbols_offset = symbols_offset.trunc(),
        );
        chunks&.push(chained.items());
        start := commands.len;
        h := commands&.reserve_type(LoadCommandHeader);
        h.type = LoadCommand.ChainedFixups.raw();
        command_count += 1;
        cmd := commands&.reserve_type(LinkEditBlob);
        add_data_file_offset&.push(cmd.offset&);
        // TODO: using file_offset way down here feels a bit fragile. 
        cmd[] = (offset = file_offset.trunc(), size = chained.len.trunc());  // :CodeIsFirst its fine to change this, you just have to do the math here. 
        h.size = trunc(commands.len - start);
    };
    
    // - imports list and symbol table in __LINKEDIT
    // - insert chained fixups in data
    // - reference chained fixups start in __LINKEDIT
    
    zero_pad_to_align(commands&, 8);
    @assert_le(commands.len, COMMANDS_SIZE_GUESS, "we guessed wrong so the array resized and all the pointers are junk");
    macho_header.commands_size = (commands.len - MachoHeader.size_of()).trunc();
    macho_header.commands_count = command_count.trunc();
    for add_data_file_offset& { offset | 
        offset[] += commands.len.trunc();
    };
    chunks[0] = commands.items();
    
    chunks
}

fn compiler_address_to_segment_offset(m: *QbeModule, address: *u8) Ty(SegmentType, i64) = {
    low  := MAX_i64;
    high := 0;
    for_enum SegmentType { type | 
        seg := m.segments&[type]&;
        dist_from_start := ptr_diff(seg.mmapped.ptr, address);
        if dist_from_start >= 0 && dist_from_start < seg.mmapped.len {
            @assert(ptr_diff(seg.next, address) < 0, "address was inside segment %'s allocation but after next[]", type);
            return(type, dist_from_start);
        };
        // TODO: waste of code. they're always ordered. 
        high = high.max(u8.int_from_ptr(seg.mmapped.ptr) + seg.mmapped.len);
        low = low.min(u8.int_from_ptr(seg.mmapped.ptr));
    };
    @panic("% was not found in module.segments (low = %, high = %)", u8.int_from_ptr(address), low, high)
}

// TODO: collect_aot_fixups compiles if you typo to *Symbol, :FUCKED
FixP :: Ty(*SymbolInfo, *Fixup);
fn collect_aot_fixups(m: *QbeModule) Ty([]FixP, []*SymbolInfo) = {
    // :SLOW keep a list because most will probably be local with no relocations. 
    fixups := list(FixP, temp());
    symbols := list(*SymbolInfo, temp());
    
    symbol_count := 0;
    for_symbols m { s | 
        first := true;
        each s.fixups& { f | 
            if f.type&.is(.DataAbsolute) {
                fixups&.push(@as(FixP) (s, f));
                if first {
                    first = false;
                    symbols&.push(s);
                }
            };
        };
    };
    
    (fixups.items(), symbols.items())
}

fn live_segment_part(m: *QbeModule, s: SegmentType) []u8 = {
    s := m.segments&[s]&;
    s.mmapped.slice(0, ptr_diff(s.mmapped.ptr, s.next))
}

fn append_padded_cstr(bytes: *List(u8), s: Str, align: i64) i64 = {
    start := bytes.len;
    bytes.push_all(s);
    bytes.push(0);
    bytes.zero_pad_to_align(align);
    bytes.len - start
}

// TODO: do we want to put these helpers in a different file so other people can use them less painfully? 

fn reserve_type(bytes: *List(u8), $T: Type) *T #generic = {
    bytes.reserve(T.size_of());
    ptr := bytes.maybe_uninit.ptr.offset(bytes.len);
    @debug_assert(u8.int_from_ptr(ptr).mod(T.align_of()) == 0, "unaligned reserve");
    ptr := ptr_cast_unchecked(u8, T, ptr);
    bytes.len += T.size_of();
    ptr
}

fn zero_pad_to_align(bytes: *List(u8), align: i64) void = {
    ptr := bytes.maybe_uninit.ptr.offset(bytes.len);
    extra := u8.int_from_ptr(ptr).mod(align);
    if extra != 0 {
        extra := align - extra;
        bytes.reserve(extra);
        range(0, extra) { _ |
            bytes.push(0);
        };
    };
}

fn str_to_16_byte_value(s: Str) u128 = {
    assert(s.len.le(16), "A segment name cannot be larger than 16 text characters in bytes");
    low: u64 = 0;
    high: u64 = 0;
    enumerate s { i, c |
        c: u64 = c[].zext();
        if i < 8 {
            low = low.bit_or(c.shift_left(i * 8));
        } else {
            high = high.bit_or(c.shift_left((i - 8) * 8));
        };
    };
    (low = low, high = high)
}
