/// This defines the .frc file format used by the franca compiler. 
/// See @/docs/caching.md

MAGIC :: 0x000F_41434E415246;  // FRANCA__
Header :: @struct {
    meta: Meta #use;
    dep: Storage(Dep);
    sym: Storage(Sym);
    blk: Storage(Blk);
    ins: Storage(Qbe.Ins);
    con: Storage(Qbe.Con);
    mem: Storage(Qbe.Addr);
    rel: Storage(Dat2.Reloc);
    str: Storage(u8);
    lib: Storage(Lib);
    idx: Storage(u32);
    typ: Storage(Typ);
    fty: Storage(FTy);
    fld: Storage(Fld);
};

Meta :: @struct {
    magic_v: u64 = MAGIC;
    filelen: u32 = 0;  // patched by to_bytes()
    arch_os: u32;
    // Qbe.no_symbol if this file cannot be executed
    entry_sym:  One(Sym) = (off = Qbe.no_symbol);
    entry_dep:  One(Dep) = (off = Qbe.no_symbol);
    root_scope: One(FTy) = (off = Qbe.no_symbol);
    debug_name: Ref(u8)  = (off = 0, count = 0);
    all_deps := zeroed Sha256.Digest;  // patched by to_bytes()
};

// Hashes of all the input files that contributed to this module. 
Dep :: @struct {
    filename: Ref(u8);
    file_len: u32;
    hashcode: Sha256.Digest;
};

Sym :: @struct {
    segment: Seg; 
    align_log2: u8;
    name: Ref(u8);  // TODO: having names is kinda dumb
    // TODO: this should parse when inlined but then need to :UpdateBoot :Compiler
    P :: @union(fnc: Fnc, dat: Dat, imp: Imp, asm: Asm);  
    payload: P #use;  // active variant depends on segment
};

Seg :: @enum(u8) (
    Invalid,  // used while writing when the symbol has been referenced but not declared yet
    Code,  // payload: Fnc;
    ConstantData, MutableData, ZeroInitData,  // payload: Dat;
    Import,  // payload: Imp;
    MachineCode,  // payload: Asm; goes in Segment.Code
);

Asm :: @struct {
    arm64: Ref(u8);
    amd64: Ref(u8);
    rv64:  Ref(u8);
    // when adding a field make sure this doesn't become the biggest variant (rn it's Fnc) or have a less dumb repr for arches. 
};

// Currently i only save right before emitting machine code, 
// so no need for phi/typ/switch. Those can be added later when i want to do 
// inlining across modules or saving right after "parse". 
Fnc :: @struct {
    reg: u64;
    // When the instructions have Blk/Con indices, they're relative to these arrays, 
    // so they don't need to be remapped when saving. 
    blk: Ref(Blk);
    con: Ref(Qbe.Con);  // not including the first `fixed_const_count`
    mem: Ref(Qbe.Addr);
    either: @union(slot: i32, retty: Qbe.Ref);
    flags: u32;
    ntmp: u32 = Qbe.no_symbol;
};

// :BitFieldsCompileError
FncFlags :: @bit_fields(
    leaf   := 1,
    vararg := 1,
    salign := 4,
    dynalloc := 1,
    _ := 25,
);

Blk :: @struct {
    ins: Ref(Qbe.Ins);
    s1: u32;  // local in Fnc.blks
    s2: u32;  // loacl in Fnc.blks
    jmp: Qbe.BlkJmp;
    // the high two bits of narg are the Qbe.Cls
    phi: u32; // idx[phi] = (nphi, [nphi](narg, to, [narg](blk, arg)))
};

Dat :: @struct {
    bytes: Ref(u8);  // off=Qbe.no_symbol when it's all zeroes
    rel: Ref(Dat2.Reloc);
};

Imp :: @struct {
    lib: One(Lib);
    
    // TODO: this is a temporary crutch i should get rid of eventually.  
    //       it means you can't save the blob and load it in a different CompCtx. 
    //       it's used for implementing import_wasm/ffi.fr's import_from: ScopeId. 
    //       my idea of imports maps directly to wasm's so should just use that instead. 
    temporary_funcid: u32 = Qbe.no_symbol;
    weak := false;
};

Lib :: @struct {
    name: Ref(u8);
};

Typ :: @struct {
    header: Qbe.TypHeader;
    fields: Ref(u32);
};

Storage :: fn($T: Type) Type = {
    // SAFETY: the serialized data is immediately after the header in memory
    // check() ensures that storage.count is within filelen. 
    fn get(self: *Header, i: Ref(T)) []T = {
        f :: find_storage_field(T);
        storage := Header.get_field_ptr(self, f);
        first := T.ptr_from_raw(Header.raw_from_ptr(self).offset(storage.off.zext()));
        @debug_assert_ule(@as(i64) i.off.zext() + i.count.zext(), storage.count.zext(), "%", ::f[].name.str());
        (ptr = first.offset(i.off.zext()), len = i.count.zext())
    }
    
    fn get(self: *Header, i: u32) *T = {
        i: Ref(T) = (off = i, count = 1);
        self.get(i).index(0)
    }

    fn get(self: *Header, i: One(T)) *T = {
        i: Ref(T) = (off = i.off, count = 1);
        self.get(i).index(0)
    }
    
    fn for(self: *Header, i: Ref(T), $body: @Fn(it: One(T), itp: *T) void) void = {
        range(0, i.count.zext()) { j |
            it: One(T) = (off = i.off + j.trunc());
            body(it, self.get(it));
        };
    }
    
    @struct(
        off: u32 /* bytes from start of header to first element */, 
        count: u32, 
        StorageElement :: T,
    )
};

fn all(self: *Header, $T: Type) Ref(T) #generic = {
    f :: find_storage_field(T);
    storage := Header.get_field_ptr(self, f);
    (off = 0, count = storage.count)
}

Ref :: fn($T: Type) Type = 
    @struct(off: u32, count: u32, RefElement :: T);

One :: fn($T: Type) Type = 
    @struct(off: u32, OneElement :: T);

fn check(data: []u8) Result(*Header, Str) = {
    @if(data.len < size_of(Header)) return(Err = "too small");
    self := ptr_cast_unchecked(u8, Header, data.ptr);
    @if(self.magic_v != MAGIC) return(Err = "invalid magic");
    @if(self.filelen.zext() > data.len) return(Err = "filelen corrupted");
    
    for storage_fields { off, size |
        S :: @struct(off: u32, count: u32);
        storage := S.ptr_from_raw(Header.raw_from_ptr(self).offset(off.zext()));
        @if(storage.off > self.filelen) return(Err = "storage.off OOB");
        @if(storage.off + storage.count * size > self.filelen) return(Err = "storage.count OOB");
    };
    (Ok = self)
}

storage_fields :: {
    out := Ty(u32, u32).list(ast_alloc());
    for Header.get_fields() { f |
        if get_constant(Type, Type.scope_of(f.ty), @symbol StorageElement) { T |
            push(out&, (f.byte_offset.trunc(), T.size_of().trunc()));
        }
    };
    out.items()
};

// TODO: bucketarray. comptime generate this from the Header. 
Writer :: @struct {
    dep: List(Dep);
    sym: List(Sym);
    blk: List(Blk);
    ins: List(Qbe.Ins);
    con: List(Qbe.Con);
    mem: List(Qbe.Addr);
    rel: List(Dat2.Reloc);
    str: List(u8);
    lib: List(Lib);
    idx: List(u32);
    typ: List(Typ);
    fty: List(FTy);
    fld: List(Fld);
    symbols: HashMap(u32, i64);
};

fn init(a: Alloc) Writer = (
    symbols = init(a),
    // TODO: generate this
    dep = list(a),
    sym = list(a),
    blk = list(a),
    ins = list(a),
    con = list(a),
    mem = list(a),
    rel = list(a),
    str = list(a),
    lib = list(a),
    idx = list(a),
    typ = list(a),
    fty = list(a),
    fld = list(a),
);

fn drop(self: *Writer) void = {
    inline_for Writer.get_fields() { $f | 
        Writer.get_field_ptr(self, f).drop();
    };
};

fn push(self: *Writer, it: []u8) Ref(u8) = {
    r: Ref(u8) = (off = self.str.len.trunc(), count = it.len.trunc());
    self.str&.push_all(it);
    r
}

fn map_sym(self: *Writer, m: *QbeModule, id: Qbe.Sym) i64 = {
    self.symbols&.get_or_insert(id.id) {
        i := self.sym.len;
        self.sym&.push(zeroed Sym);
        self.sym[i].name = self.push(m.str(id));
        i
    }[]
}

fn push(self: *Writer, f: *Qbe.Fn, did_regalloc: bool) void = {
    @debug_assert_eq(f.switch_count, 0);
    id := self.map_sym(f.globals, f.lnk.id);
    
    self.sym[id].segment = .Code;
    
    // unfortunatly this includes constants that are no longer used. 
    // so a function will all uses inlined will still have an Invalid Sym because of this map_sym
    self.sym[id].fnc.con = (off = self.con.len.trunc(), count = trunc(f.ncon.zext() - fixed_const_count));
    self.con&.reserve(zext f.ncon);
    each f.con.slice(fixed_const_count, f.ncon.zext()) { c |
        self.con&.push_assume_capacity(
            // bleh, really this should be One(Sym) instead of Qbe.Sym
            sym = (id = @if(c.sym.id == Qbe.no_symbol, Qbe.no_symbol, trunc self.map_sym(f.globals, c.sym))), 
            bits = c.bits,
        );
    };
    
    first_mem := self.mem.len;
    self.sym[id].fnc.mem = (off = first_mem.trunc(), count = f.nmem.bitcast());
    self.mem&.push_all(f.mem.slice(0, zext f.nmem));
    
    @if(f.globals.goal.arch == .x86_64)
    range(first_mem, self.mem.len) { i |
        it := self.mem.index(i);
        if it.offset.sym != Qbe.no_symbol_S {
            it.offset.sym.id = trunc self.map_sym(f.globals, it.offset.sym);
        }
    };
    
    @debug_assert_gt(f.nblk, 0, "tried to save empty function");
    self.sym[id].fnc.blk = (off = self.blk.len.trunc(), count = f.nblk.bitcast());
    f.set_block_id();
    self.blk&.reserve(zext f.nblk);
    for_blocks f { b |
        phi := write_phi(self, b, f.nblk);
        self.blk&.push_assume_capacity(
            ins = (off = self.ins.len.trunc(), count = b.ins.len.trunc()),
            s1 = @if(b.s1.is_null(), Qbe.no_symbol, bitcast b.s1.id),
            s2 = @if(b.s2.is_null(), Qbe.no_symbol, bitcast b.s2.id),
            jmp = b.jmp,
            phi = phi,
        );
        self.ins&.push_all(b.ins.items());
    };
    
    self.sym[id].fnc.reg = f.reg;
    if did_regalloc {
        self.sym[id].fnc.either.slot = f.slot;
    } else {
        self.sym[id].fnc.either.retty = f.retty;
    };
    
    flags: FncFlags = construct(
        leaf = int(f.leaf),
        vararg = int(f.vararg),
        salign = f.salign.intcast(),
        dynalloc = int(f.dynalloc),
        _ = 0,
    );
    self.sym[id].fnc.flags = flags.repr;
    
    self.sym[id].fnc.ntmp = @if(did_regalloc, Qbe.no_symbol, f.ntmp.bitcast());
}

fn push(self: *Writer, m: *QbeModule, d: *Dat2) void = {
    id := self.map_sym(m, d.id);
    
    self.sym[id].segment = @as(Seg) @as(u8) trunc((@as(i64) d.seg) + 1);
    data_start := -1;
    @match(d.template) {
        fn Bytes(it) => {
            data_start = self.str.len;
            self.sym[id].dat.bytes = self.push(it);
        };
        fn Zeroes(it) => {
            self.sym[id].dat.bytes.count = it.trunc();
            self.sym[id].dat.bytes.off = Qbe.no_symbol;
        }
    };

    self.sym[id].dat.rel = (off = self.rel.len.trunc(), count = d.relocations.len.trunc());
    self.rel&.reserve(d.relocations.len);
    each d.relocations { it |
        self.rel&.push_assume_capacity(
            off = it.off,
            // bleh, really this should be One(Sym) instead of Qbe.Sym
            id = (id = self.map_sym(m, it.id).trunc()),
            addend = it.addend,
        );
        if data_start != -1 {
            // TODO: it would be nice to make it something recognisable (like 0x0123456789ABCDEF) if the relocation doesn't get applied somehow,
            //       but that means not storing as template.zeroed which seems wasteful. 
            ptr_cast_unchecked(u8, i64, self.str.index(data_start + zext it.off))[] = 0;
        }
    };
    
    self.sym[id].align_log2 = d.align.trailing_zeros().trunc();
}

fn push_asm(self: *Writer, m: *QbeModule, code: *MultiArchAsm, id: Qbe.Sym) void = {
    id := self.map_sym(m, id);
    self.sym[id].segment = .MachineCode;
    self.sym[id].asm = (
        arm64 = self.push(code[.aarch64]),
        amd64 = self.push(code[.x86_64]),
        rv64  = self.push(code[.rv64]),
    );
}

// TODO: this shouldn't suck this bad
find_storage_field :: fn(T: Type) *Field = {
    each Header.get_fields() { f | 
        ::AutoEq(?Type);
        ::RefEq(?Type);
        if get_type_info_ref(f.ty).is(.Struct) {
            c := get_constant(Type, Type.scope_of(f.ty), @symbol StorageElement);
            if c == (Some = T) {
                return(f);
            }
        }
    };
    unreachable()
};

fn to_bytes(self: *Writer, meta: Meta, m: *QbeModule) [][]u8 = {
    ::enum(@type m.goal.type);
    if m.goal.type == .CachedEarly {
        @debug_assert_eq(self.typ.len, 0, "cannot to_bytes(Writer) twice");
        write_types(self, m);
    };
    
    if self.dep.len > 0 {
        // TODO: maybe i don't want it to be order dependent
        meta.all_deps = Sha256'hash(self.dep.items().interpret_as_bytes());
    };

    bytes := list([]u8, 14, temp());
    
    n := size_of(Header);
    header := temp().box(Header);
    ::[]Header;
    bytes&.push(header.slice(1).interpret_as_bytes());
    header.meta = meta;
    
    X :: fn(storage, data) => {
        b := data.items().interpret_as_bytes();
        bytes&.push(b);
        storage[] = (off = n.trunc(), count = data.len.trunc());
        n += b.len;
    };
    
    // TODO: generate this
    X(header.dep&, self.dep&);
    X(header.sym&, self.sym&);
    X(header.blk&, self.blk&);
    X(header.ins&, self.ins&);
    X(header.con&, self.con&);
    X(header.mem&, self.mem&);
    X(header.rel&, self.rel&);
    X(header.str&, self.str&);
    X(header.lib&, self.lib&);
    X(header.idx&, self.idx&);
    X(header.typ&, self.typ&);
    X(header.fty&, self.fty&);
    X(header.fld&, self.fld&);
    header.filelen = n.trunc();
    
    // Maybe limitting to 4GB is too small and I should make all the offsets be u64 instead. 
    // Could probably produce a reasonable program that hit that by embedding a lot of data 
    // (like 3d meshes maybe) but I already can't do arbitrary sizes because I don't resize 
    // segments and the constants in ../lib.fr are already kinda low.  -- May 26, 2025
    @assert_lt(n, 0xFFFFFFFF, "overflow");
    
    bytes.items()
}

fn finish_imports(writer: *Writer, m: *QbeModule) void = {
    // :SLOW
    _, symbols := collect_aot_fixups(m);
    for symbols { s |
        if s.kind != .Local {
            if s.library == 0 {
                ::?u32;
                s.library = m.find_library("libc") || {
                    @panic("import % from unknown library", s.name)
                };
            };
            
            id := writer.map_sym(m, m.intern(s.name));
            it := writer.sym[id]&;
            it.segment = .Import;
            it.imp.lib.off = s.library - 1;
            it.imp.weak = !s.strong;
        };
    };
}

finish_module :: fn(m: *QbeModule) [][]u8 = {
    writer := m.save.unwrap();
    finish_imports(writer, m);
    t := Incremental'pack_target(m.goal.arch, m.goal.os);
    meta: Incremental.Meta = (
        arch_os = @if(m.goal.type == .CachedEarly, 0x0F0F, t),
        entry_sym = (off = writer.map_sym(m, m.intern("main")).trunc()), // :HardcodeMain
    );
    writer.to_bytes(meta, m)
};

// TODO: not true anymore: this only calls default_init if !did_rega
fn load(h: *Header, f: *Qbe.Fn, it: One(Sym), syms: []Qbe.Sym) bool /*did_regalloc*/ = {
    m := f.globals;
    @debug_assert(m.initialized, "tried to load() into uninit module");
    sym := h.get(it);
    ::enum(@type sym.segment);
    @debug_assert_eq(sym.segment, .Code, "tried to load() non-function: %", m.str(f.lnk.id));
    fnc := sym.fnc&;
    did_regalloc := fnc.ntmp == Qbe.no_symbol;
    // TODO: it's nice not to waste time recreating the tmps every time when loading a postregalloc cache file 
    //       but it's very shetchy to silently do that if they could be mixed
    //if !did_regalloc {
        default_init(f, m);
    //};
    f.consts = zeroed(@type f.consts); // TODO: maybe still want to use the map this if !did_regalloc
    f.lnk.id = syms[it.off.zext()];
    f.lnk.export = true;  // TODO: only for entry point?
    
    f.con = new(fnc.con.count.zext() + fixed_const_count);
    f.ncon = 0;
    push_fixed_consts(f);
    f.ncon = fixed_const_count.trunc() + fnc.con.count.bitcast();
    enumerate h.get(fnc.con) { i, src |
        dest := f.con[i + fixed_const_count]&;
        dest[] = src[];
        if src.sym != Qbe.no_symbol_S {
            new := syms[src.sym.id.zext()];
            @debug_assert_ne(new.id, Qbe.no_symbol);
            dest.sym = new;
        }
    };
    
    flags: FncFlags = (repr = fnc.flags);
    if !did_regalloc {
        f.retty = fnc.either.retty;
        read_tmp(h, f, fnc.ntmp);
        @debug_assert_eq(fnc.mem.count, 0);
    } else {
        f.slot = fnc.either.slot;
        f.reg = fnc.reg;
        f.salign = flags.get(.salign).intcast();
        
        // TODO: these are pretty chunky. it would be nice to deduplicate them. 
        //       need to be careful, there might be something in amd64/emit.fr that assumes they don't alias?
        f.nmem = fnc.mem.count.bitcast();
        f.mem = new_copy(h.get(fnc.mem));
        
        @if(f.globals.goal.arch == .x86_64)
        each f.mem.slice(0, f.nmem.zext()) { it |
            if it.offset.sym != Qbe.no_symbol_S {
                it.offset.sym = syms[it.offset.sym.id.zext()];
            }
        };
    };
    f.leaf = flags.get(.leaf) != 0;
    f.dynalloc = flags.get(.dynalloc) != 0;
    f.vararg = flags.get(.vararg) != 0;
    
    blks := temp().alloc_zeroed(Qbe.Blk, fnc.blk.count.zext());
    enumerate h.get(fnc.blk) { i, b |
        blks[i].id = i.trunc();
        // TODO: this extra copy of the instructions is only required when the module is going to be reused (ie. FrcImport comptime+runtime). 
        //       (because the first pass makes some changes in place and it gets super confused if those were already done)
        blks[i].ins = as_raw_list(h.get(b.ins).shallow_copy(temp()));
        blks[i].jmp = b.jmp;
        if b.s1 != Qbe.no_symbol {
            blks[i].s1 = blks.index(b.s1.zext());
        }
        if b.s2 != Qbe.no_symbol {
            blks[i].s2 = blks.index(b.s2.zext());
        }
        if i != blks.len - 1 {
            blks[i].link = blks.index(i + 1);
        }
        
        read_phi(h, blks, b, i, f.tmp.slice(0, f.ntmp.zext()));
    };
    f.start = blks.index(0);
    f.nblk = fnc.blk.count.bitcast();
    
    did_regalloc
}

fn load(header: *Header, m: *QbeModule, i: One(Sym), syms: []Qbe.Sym) Dat2 = {
    it := header.get(i);
    relocs := header.get(it.dat.rel).shallow_copy(temp());
    each relocs { it |
        if it.id != Qbe.no_symbol_S {
            it.id = syms[it.id.id.zext()];
        }
    };
    
    (
        template = @if(it.dat.bytes.off == Qbe.no_symbol, 
            (Zeroes = it.dat.bytes.count.zext()),
            (Bytes = header.get(it.dat.bytes)),
        ),
        relocations = relocs,
        align = 1.shift_left(@as(i64) it.align_log2.zext()),
        seg = @as(SegmentType) @as(i64) zext(@as(u8) it.segment) - 1,
        id = syms[i.off.zext()],
        export = false, // TODO
    )
}

pack_current_target :: fn() u32 = {
    arch, os := (query_current_arch(), query_current_os());
    pack_target(arch, os)
};

pack_target :: fn(arch: Arch, os: Os) u32 = {
    ::@assert(Arch.enum_count() < 8 && Os.enum_count() < 8);
    bit_or(1.shift_left(@as(i64) os), 1.shift_left(8 + @as(i64) arch)).trunc()
};

fn preintern_syms(header: *Header, m: *QbeModule) []Qbe.Sym = {
    count: i64 = header.sym.count.zext();
    lock m.intern_mutex&;
    syms := m.forever&.borrow().alloc(Qbe.Sym, count);
    unlock m.intern_mutex&;
    for(header, header.all(Sym)) { i, it |
        syms[i.off.zext()] = m.intern(header.get(it.name));
    };
    syms
}

#use("@/compiler/profile.fr");

fn compile_all_symbols(header: *Header, m: *QbeModule) void = {
    // TODO: maybe entry_sym should be export=true
    f := @uninitialized Qbe.Fn;
    default_init(f&, m);
    
    syms := preintern_syms(header, m);
    type_offset := read_types(header, m);
    
    for(header, header.all(Sym)) { i, it |
        mark := mark_temporary_storage();
        ::enum(@type it.segment);
        @match(it.segment) {
            fn Code() => {
                //@println("%", header.get(it.name));
                did_regalloc := load(header, f&, i, syms);
                zone := @if(ENABLE_ENABLE_TRACY, zone_begin(.Backend), ());
                if f.globals.debug["P".char()] {
                    out := f.globals.debug_out;
                    write(out, "\n> After loading:\n");
                    printfn(f&, out);
                };
                if did_regalloc {
                    @debug_assert_ne(m.goal.type, .CachedEarly, "can't go backwards");
                    emit_fn(f&);
                } else {
                    apply_type_offset(f&, type_offset);
                
                    // TODO: suspend for inlining (can be a bit in FncFlags)
                    {f.globals.target.finish_passes}(f&);
                };
                @if(ENABLE_ENABLE_TRACY) zone_end(zone);
            }
            fn MachineCode() => {
                // todo: nice macro so it's not order dependent
                code: MultiArchAsm = (data = (
                    header.get(it.asm.arm64),
                    header.get(it.asm.amd64),
                    empty(),
                    header.get(it.asm.rv64),
                ));
                m.add_code_bytes(syms[i.off.zext()], code&);
            }
            fn Import() => {
                lib := header.get(it.imp.lib);
                lib := header.get(lib.name);
                m.set_library(syms[i.off.zext()], lib, it.imp.weak);
            }
            fn Invalid() => ();
            @default => {
                dat := load(header, m, i, syms);
                m.emit_data(dat);
            };
        };
        reset_temporary_storage(mark);
    };
    m.emit_suspended_inlinables();  // only meaningful if !did_regalloc
    
    // TODO: it would kinda feel better to keep track of the imports
    //       instead of making the caller loop over all the symbols again 
    //       (probably by calling fill_from_libc), but that gets messed up by m.symbol_memmove, 
    //       which i guess doesn't get set_library called on it (should be fixed anyway). 
    //       + need to do a more complicated thing to allow non-libc libraries anyway. 
}

// 
// Some fields (tmp, phi, typ) are only used when the function is pre-regalloc 
// (which happens when it needs to be inlinable). 
// 

read_tmp :: fn(header: *Header, f: *Qbe.Fn, ntmp: u32) void #once = {
    if(ntmp == Qbe.no_symbol, => return());
    @debug_assert_eq(f.ntmp, Qbe.Tmp0);
    f.tmp&.grow(ntmp.zext());
    range(0, ntmp.zext() - Qbe.Tmp0) { _ |
        _ := f.newtmp("", .Kw);  // cls doesn't matter because it's reset by fill_use
    };
};

read_phi :: fn(header: *Header, blks: []Qbe.Blk, b: *Blk, i: i64, tmp: []Qbe.Tmp) void #once = {
    if(b.phi == Qbe.no_symbol, => return());
    idx: u32 = b.phi;
    nphi: u32 = header.get(idx)[]; idx += 1;
    range(0, nphi.zext()) { i_phi | 
        narg: u32 = header.get(idx)[]; idx += 1;
        to: u32 = header.get(idx)[]; idx += 1;
        k := @as(Qbe.Cls) @as(u32) narg.shift_right_logical(30);
        narg = narg.bit_and(1.shift_left(30) - 1);
        p := new_phi(blks[i]&, k, narg.zext(), TMP(to.zext()));
        range(0, narg.zext()) { _ |
            blk_i: u32 = header.get(idx)[]; idx += 1;
            arg_i: u32 = header.get(idx)[]; idx += 1;
            p.push(blks[blk_i.zext()]&, (type3_val29 = arg_i));
        };
    };
};

write_phi :: fn(self: *Writer, b: *Qbe.Blk, nblk: i32) u32 #once = {
    ::ptr_utils(@type b.phi[]);
    if(b.phi.is_null(), => return(Qbe.no_symbol));
    phi: u32 = self.idx.len.trunc();
    self.idx&.push(0);  // nphi
    for_phi b { p |
        self.idx[phi.zext()] += 1;
        k := @as(u32) bitcast @as(i32) p.cls;
        self.idx&.push(p.narg.bit_or(k.shift_left(30)));
        self.idx&.push(p.to.val().trunc());
        range(0, p.narg.zext()) { n |
            @debug_assert_ult(p.blk&[n].id, nblk);
            self.idx&.push(p.blk&[n].id.bitcast());
            self.idx&.push(p.arg&[n].type3_val29);
        };
    };
    phi
};

write_types :: fn(self: *Writer, m: *QbeModule) void = {
    @debug_assert_eq(self.typ.len, 0, "can only write types once");
    lock(m.types_mutex&);
    self.typ&.reserve(m.types.len);
    enumerate m.types { i, t |
        m.flush_debug();
        self.typ&.push(
            header = t.header,
            fields = (off = trunc self.idx.len, count = t.nfield),
        );
        self.idx&.push_all(t.fields.slice(0, zext t.nfield));
    };
    unlock(m.types_mutex&);
};

// This returns the offset into the new module of the first type in the old module. 
// You need to pass it to apply_type_offset() whenever you load a (!did_regalloc) function. 
read_types :: fn(header: *Header, m: *QbeModule) i64 = {
    if(header.typ.count == 0, => return(0));  // if there are no types (like if did_regalloc) it doesn't matter
    
    lock(m.types_mutex&);
    offset := m.types.len;
    
    types: Ref(Typ) = (off = 0, count = header.typ.count);
    each header.get(types) { t | 
        // TODO: this copy is lame. make it a slice instead of a QList
        //       but that doesn't work now that i need to reuse the same Header so can't mutate and have type_offset. 
        //       tho could save a copy when offset==0
        fields := m.new_copy_long_life(header.get(t.fields));
        m.new_type(
            name = "",
            header = t.header,
            nfield = t.fields.count,
            fields = fields,
        );
        
        @if(offset != 0)
        each fields.slice(0, t.fields.count.zext()) { it |
            f := unpack it[];
            ::enum(@type f.type);
            if f.type == .FTyp {
                it[] = pack(type = .FTyp, len = f.len + offset.trunc());
            }
        };
    };
    
    @debug_assert_ult(m.types.len, 1.shift_left(24), "types overflow");
    unlock(m.types_mutex&);
    offset
};

apply_type_offset :: fn(f: *Qbe.Fn, type_offset: i64) void = {
    if(type_offset == 0, => return());
    fix :: fn(a: *Qbe.Ref) => if rtype(a[]) == .RType {
        a[] = TYPE(a[].val() + type_offset);
    };
    
    fix(f.retty&);
    for_blocks f { b |
        for_insts_forward b { i |
            each(i.arg&.items(), fix);
        };
    };
};

// 
// Some fields are for frontend declaraction/type info. 
//

FTy :: @rec @struct {
    Tag :: @enum(u8) (
        Invalid, Alias,
        Number, Array, Ptr, Func, 
        Enum, Scope, Struct, Union, Tagged, Params,
        AbiOnly,  // TODO: implement this in the compiler + make a test for it
    );
    tag: Tag;
    align_log2: u8 = 0;
    // franca structs can have runtime fields and also an associated scope. TODO: might need more bits for this field. 
    scope: u16 = 0xFFFF;
    payload: @union(
        array:  @struct(inner: One(FTy), count: u32 = 1),  // or ptr
        fields: Ref(Fld),  // enum/scope/struct/union/tagged/params
        func:   @struct(arg: One(FTy), ret: One(FTy)),
        int:    @struct(bits: u32, signed: bool = false, float: bool = false, bitfield: bool = false),
        abi:    One(Typ),
        alias:  One(FTy),
    );
    
    UNKNOWN  ::  0;
    VOID     ::  1;
    TYPE     ::  2;
    I64      ::  3;
    BOOL     ::  4;
    VARIADIC ::  5;
    NEVER    ::  6;
    F64      ::  7;
    OVERLOAD ::  8;
    SCOPE    ::  9;
    U32      :: 10;
    RAWPTR   :: 11;
    F32      :: 12;
    FUNCID   :: 13;
    LABELID  :: 14;
    SYMBOL   :: 15;
    COUNT    :: 16;
};

Fld :: @rec @struct {
    name: Ref(u8) = (off = 0, count = 0);
    type: One(FTy);
    payload: (@union(
        // TODO: maybe just calculate `offset` and then don't need an extra slot for default value?
        offset: u32,         // a runtime offset in bytes for struct/union
        value: One(Qbe.Con), // a constant value for scope
        type: One(FTy),
        sym: One(Sym),
    )) = (offset = 0);
    source_location: u32 = 0;
};

////////////////////////////

// If a frontend doesn't want to deal with giving real type info, 
// this translates the abi info the backend requires anyway into 
// the frontend type format so the franca compiler can use that for jit-shims.
fn abi_function_type(writer: *Writer, f: *Qbe.Fn) One(FTy) = {
    @debug_assert_eq(f.reg, 0, "abi_function_type() after regalloc");
    
    abi_type :: fn(r: Qbe.Ref) One(FTy) => {
        writer.fty&.push(tag = .AbiOnly, payload = (abi = (off = trunc r.val())));
        (off = trunc(writer.fty.len - 1))
    }
    ::if(One(FTy));
    ret := if f.retty == QbeNull {
        k := Qbe.Cls.Ke;
        for_blocks f { b |
            ::enum(Qbe.J);
            if @is(b.jmp.type, .retw, .retl, .rets, .retd) {
                k = b.jmp.type.cls();
            }
        };
        cls_to_fty(k)
    } else {
        abi_type(f.retty)
    };
    
    par := Fld.list(temp());
    for_pars f { i |
        @match(i.op()) {
            fn pare() => ();
            fn parc() => par&.push(type = abi_type i.arg&[0]);
            fn par()  => par&.push(type = cls_to_fty i.cls());
            @default  => ();
        };
    };
    if(f.vararg, => par&.push(type = (off = FTy.VARIADIC)));
    arg := writer.fld_to_par(par.items());
    writer.fty&.push(tag = .Func, payload = (func = (arg = arg, ret = ret)));
    (off = trunc(writer.fty.len - 1))
}

fn fld_to_par(writer: *Writer, par: []Fld) One(FTy) = {
    @switch(par.len) {
        @case(0)   => @as(One(FTy)) (off = FTy.VOID);
        @case(1)   => par[0].type;
        @default() => save_fields(writer, .Params, par);
    }
}

fn save_fields_fty(writer: *Writer, tag: FTy.Tag, fields: []Fld) FTy = {
    out: FTy = (tag = tag, payload = (fields = (off = trunc writer.fld.len, count = trunc fields.len)));
    writer.fld&.push_all(fields);
    out
}

fn save_fields(writer: *Writer, tag: FTy.Tag, fields: []Fld) One(FTy) = {
    writer.fty&.push(save_fields_fty(writer, tag, fields));
    (off = trunc(writer.fty.len - 1))
}

fn cls_to_fty(k: Qbe.Cls) One(FTy) = {
    ::enum(Qbe.Cls);
    @match(k) {
        fn Kw()  => (off = FTy.U32);
        fn Kl()  => (off = FTy.I64);
        fn Ks()  => (off = FTy.F32);
        fn Kd()  => (off = FTy.F64);
        @default => (off = FTy.VOID);
    }
}

////////////////////////////

ENABLE_ENABLE_TRACY :: get_environment_variable("FRANCA_TRACY").is_some();

#use("@/backend/lib.fr");
