fn fill_target_arm(t: *Qbe.Target, apple: bool) void = {
    t.memargs = fn(op: Qbe.O) i32 = 0;  // arm is a load-store architecture
    t.isel = arm64_isel;
    t.abi1 = arm64_abi;
    t.argregs = arm64_argregs;
    t.retregs = arm64_retregs;
    t.fixup = fixup_arm64;
    t.apple = apple;
    if apple {
        t.abi0 = apple_extsb;
        @if(LINK_QBE_C) {
            t.emitfin = macho_emitfin;
        }; // TODO
    } else {
        t.abi0 = elimsb;
        panic("TODO: flip the switch on linux abi");
    };
    // TODO: we have emitfn and emitfin. that's confusing.
    t.emitfn = emit_func_arm64;
    
    t.gpr0 = Arm64Reg.R0.raw().intcast();
    t.ngpr = (Arm64Reg.SP.raw() - Arm64Reg.R0.raw() + 1).intcast();
    t.fpr0 = Arm64Reg.V0.raw().intcast();
    t.nfpr = (Arm64Reg.V30.raw() - Arm64Reg.V0.raw() + 1).intcast();
    t.rglob = BIT(Arm64Reg.FP.raw()).bit_or(BIT(Arm64Reg.SP.raw())).bit_or(BIT(Arm64Reg.PLA.raw())).bit_or(BIT(Arm64Reg.IP1.raw()));
    t.nrglob = 4;  // TODO: is popcnt really that slow? 
    
    // can't use x18 and reserve x17 for scratch in emit (swap, etc.)
    NGPS: i32 : intcast(Arm64Reg.IP0.raw() - Arm64Reg.R0.raw() + 1 /* LR */ + 1);
    NFPS: i32 : intcast((Arm64Reg.V7.raw() - Arm64Reg.V0.raw() + 1) + (Arm64Reg.V30.raw() - Arm64Reg.V16.raw() + 1));
    t.nrsave = init(@slice(NGPS, NFPS));
    assert_eq(intcast(NGPS + NFPS), arm64_rsave.len());
    t.caller_saved = convert_to_i32_and_append_minus_1(Arm64Reg, arm64_rsave).as_ptr();
    
    l: List(u8) = (maybe_uninit = t.name&.items(), len = 0, gpa = panicking_allocator);
    @fmt(l&, "arm64%\0", if(apple, => "_apple", => ""));
    l: List(u8) = (maybe_uninit = t.asloc&.items(), len = 0, gpa = panicking_allocator);
    @fmt(l&, "%L\0", if(apple, => "", => "."));
    l: List(u8) = (maybe_uninit = t.assym&.items(), len = 0, gpa = panicking_allocator);
    @fmt(l&, "%\0", if(apple, => "_", => ""));
}

fn macho_emitfin(_0: *FILE) void #import("qbe");
fn emitfnlnk(_0: CStr, _1: *Qbe.Lnk, _2: *FILE) void #import("qbe");

// can't give []Arm64Reg to the c code becuase they're i64 instead of i32.
fn convert_to_i32_and_append_minus_1($T: Type, r: []T) []i32 #fold #generic = {
    mem: List(i32) = list(r.len + 1, ast_alloc());
    for r { r |
        mem&.push(r.raw().int().intcast()); 
    };
    mem&.push(-1);
    mem.items()
}

::List(Arm64Reg);

arm64_rsave :: @const_slice(
    Arm64Reg.R0,  .R1,  .R2,  .R3,  .R4,  .R5,  .R6,  .R7,
            .R8,  .R9,  .R10, .R11, .R12, .R13, .R14, .R15,
            .IP0,             .LR,
            .V0,  .V1,  .V2,  .V3,  .V4,  .V5,  .V6,  .V7,
            .V16, .V17, .V18, .V19, .V20, .V21, .V22, .V23,
            .V24, .V25, .V26, .V27, .V28, .V29, .V30,
);

arm64_rclob :: @const_slice(
          Arm64Reg.R19, .R20, .R21, .R22, .R23, .R24, .R25, .R26, .R27, .R28,
             .V8,  .V9, .V10, .V11, .V12, .V13, .V14, .V15,
);

fn is_float(r: Arm64Reg) bool #inline = 
    r.raw() >= Arm64Reg.V0.raw();

fn int_id(r: Arm64Reg) u5 #fold = {
    x := @as(i64) r.raw() - Arm64Reg.R0.raw();
    @debug_assert_lt(x, 32, "not an int reg");
    x
} 

fn float_id(r: Arm64Reg) u5 #inline = 
    @as(i64) r.raw() - Arm64Reg.V0.raw();

// TODO: debug_assert tmp and in range
// TODO: you lose the type hint for @bits if you inline this
fn int_reg(r: Qbe.Ref) u5 = {
    @debug_assert(r.rtype() == .RTmp, "int_reg of non-tmp %", r.rtype());
    @as(i64) int_id(@as(Arm64Reg) r.val())
}
    
fn float_reg(r: Qbe.Ref) u5 = 
    @as(i64) float_id(@as(Arm64Reg) r.val());

// Note: these numbers are NOT the ones you encode in the instructions. ints are of by 1, floats are off by 1+32
//        it's nice to be able to zero init stuff and have that as a sentinal value. (tmp.phi, arrays in rega)
//        TMP(0) is QbeNull
Arm64Reg :: @enum(i64) (
    RXX,
     R0,  R1,  R2,  R3,  R4,  R5,  R6,  R7,  
     R8,  R9, R10, R11, R12, R13, R14, R15, 
    IP0, IP1, PLA, R19, R20, R21, R22, R23,
    R24, R25, R26, R27, R28,  FP,  LR,  SP,
    
     V0,  V1,  V2,  V3,  V4,  V5,  V6,  V7,
     V8,  V9, V10, V11, V12, V13, V14, V15,
    V16, V17, V18, V19, V20, V21, V22, V23,
    V24, V25, V26, V27, V28, V29, V30, /* V31, // we wasted a bit so don't have space :V31 */
);
::assert(Arm64Reg.enum_count() <= Qbe.Tmp0, "too many reg names");

::List(Cond);
arm_condition_codes :: @const_slice( // :CmpOrder
    // Cieq Cine Cisge Cisgt Cisle Cislt Ciuge Ciugt Ciule Ciult
    Cond.EQ, .NE,  .GE,  .GT,  .LE,  .LT,  .HS,  .HI,  .LS,  .LO,
    // Cfeq Cfge Cfgt Cfle Cflt Cfne  Cfo Cfuo
        .EQ, .PL, .HI, .LE, .LT, .NE, .VC, .VS
);

::enum_basic(Arm64Reg);
