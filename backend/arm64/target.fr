fn fill_target_arm(t: *Qbe.Target, apple: bool, $emit_only: bool) void = {
    ::enum_basic(Arm64Reg);
    ::List(Arm64Reg);
    Emit :: import("@/backend/arm64/emit.fr");
    Abi  :: import("@/backend/arm64/abi.fr");

    t.memargs = fn(op: Qbe.O) i32 = 0;  // arm is a load-store architecture
    @if(!emit_only) {
        t.finish_passes = finish_qbe_passes_native;
        t.isel = import("@/backend/arm64/isel.fr").arm64_isel;
        t.abi1 = Abi.arm64_abi;
    };
    t.argregs = Abi.arm64_argregs;
    t.retregs = Abi.arm64_retregs;
    t.fixup = Emit.fixup_arm64;
    t.apple = apple;
    t.emit_fn = Emit.emit_func_arm64;
    
    t.gpr0 = Arm64Reg.R0.raw().zext();
    t.ngpr = (Arm64Reg.SP.raw() - Arm64Reg.R0.raw() + 1).zext();
    t.fpr0 = Arm64Reg.V0.raw().zext();
    t.nfpr = (Arm64Reg.V30.raw() - Arm64Reg.V0.raw() + 1).zext();
    // can't use x18 and reserve x17 for scratch in emit (swap, etc.)
    RGLOB :: @const_slice(Arm64Reg.FP, .SP, .PLA, .IP1);
    t.rglob = @run RGLOB.interpret_as_bytes().bytes_to_bit_mask();
    
    assert_eq(size_of(Arm64Reg), size_of(u8));
    t.caller_saved = @run arm64_rsave.interpret_as_bytes().bytes_to_bit_mask();
    t.hack_builtin_memmove = @const_slice(TMP(1), TMP(2), TMP(3), CALL(0b001100001), TMP(1));
}

// Caller Saved
arm64_rsave :: @const_slice(
    Arm64Reg.R0,  .R1,  .R2,  .R3,  .R4,  .R5,  .R6,  .R7,
            .R8,  .R9,  .R10, .R11, .R12, .R13, .R14, .R15,
            .IP0,             .LR,
            .V0,  .V1,  .V2,  .V3,  .V4,  .V5,  .V6,  .V7,
            .V16, .V17, .V18, .V19, .V20, .V21, .V22, .V23,
            .V24, .V25, .V26, .V27, .V28, .V29, .V30,
);

// Callee Saved
arm64_rclob :: @const_slice(
          Arm64Reg.R19, .R20, .R21, .R22, .R23, .R24, .R25, .R26, .R27, .R28,
             .V8,  .V9, .V10, .V11, .V12, .V13, .V14, .V15,
);

arm64_clob_mask :: arm64_rclob.interpret_as_bytes().bytes_to_bit_mask();

fn is_float(r: Arm64Reg) bool #inline = 
    r.raw() >= Arm64Reg.V0.raw();

fn int_id(r: Arm64Reg) u5 #fold = {
    x := @as(u8) r.raw() - Arm64Reg.R0.raw();
    @debug_assert_lt(x, 32, "not an int reg");
    @as(i64) x.zext()
} 

fn float_id(r: Arm64Reg) u5 #inline = 
    @as(i64) zext(@as(u8) r.raw() - Arm64Reg.V0.raw());

fn int_reg(r: Qbe.Ref) u5 = {
    @debug_assert(r.rtype() == .RTmp && r.val() < Qbe.Tmp0, "int_reg %", r);
    @as(i64) int_id(@as(Arm64Reg) @as(u8) trunc r.val())
}
    
fn float_reg(r: Qbe.Ref) u5 = 
    @as(i64) float_id(@as(Arm64Reg) @as(u8) trunc r.val());

// Note: these numbers are NOT the ones you encode in the instructions. ints are of by 1, floats are off by 1+32
//        it's nice to be able to zero init stuff and have that as a sentinal value. (tmp.phi, arrays in rega)
//        TMP(0) is QbeNull
Arm64Reg :: @enum(u8) (
    RXX,
     R0,  R1,  R2,  R3,  R4,  R5,  R6,  R7,  
     R8,  R9, R10, R11, R12, R13, R14, R15, 
    IP0, IP1, PLA, R19, R20, R21, R22, R23,
    R24, R25, R26, R27, R28,  FP,  LR,  SP,
    
     V0,  V1,  V2,  V3,  V4,  V5,  V6,  V7,
     V8,  V9, V10, V11, V12, V13, V14, V15,
    V16, V17, V18, V19, V20, V21, V22, V23,
    V24, V25, V26, V27, V28, V29, V30, /* V31, // we wasted a bit so don't have space :V31 */
);
::assert(Arm64Reg.enum_count() <= Qbe.Tmp0, "too many reg names");

Cond :: Arm.Cond;

arm_condition_codes :: @const_slice( // :CmpOrder
    // Cieq Cine Cisge Cisgt Cisle Cislt Ciuge Ciugt Ciule Ciult
    Cond.EQ, .NE,  .GE,  .GT,  .LE,  .LT,  .HS,  .HI,  .LS,  .LO,
    // Cfeq Cfge Cfgt Cfle Cflt Cfne  Cfo Cfuo
        .EQ, .PL, .HI, .LE, .LT, .NE, .VC, .VS
);

#use("@/backend/lib.fr");

fn TMP(r: Arm64Reg) Qbe.Ref = {
    ::enum(@type r);
    TMP(@as(i64) r.raw().zext())
}
