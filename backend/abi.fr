// Adapted from Qbe. MIT License. Â© 2015-2024 Quentin Carbonneaux <quentin@c9x.me>
//! Some helpers used by the abi for multiple targets. 

// 
// This is untested, my frontend does not use b/h par/arg instructions. 
// 
// arm64-apple and wasm32 expect sign extensions for calls and returns of sub-word things. 
// sysv, rv64, and non-apple-arm64 treat the high bits as arbitrary. 
// Qbe only does the extensions when the target requires it and otherwise just converts them to normal par/arg. 
// Since I want to keep all the target specific stuff at the end (so the beginning can be cached), 
// I just do the extends for all targets. Sign extended is a valid arbitrary high bits, right? 
//

fn extsb_parargret(f: *Qbe.Fn) void = {
    for_blocks f { b |
        changed := false; 
        f.reset_scratch();
        j := b.jmp.type;
        if is_retbh(j) {
            changed = true;
            r := f.newtmp("abi", .Kw);
            o := @as(Qbe.O) @as(i32) Qbe.O.extsb.raw() + (j.raw() - Qbe.J.retsb.raw());
            f.emit(o, .Kw, r, b.jmp.arg, QbeNull);
            b.jmp.arg = r;
            b.jmp.type = .retw;
        };
        for_insts_rev b { i | 
            if changed {
                f.emit(i[][]);
            };
            if i[].op() == .call {
                i1 := i[];
                i0 := b.find_first_arg(i[]); 
                i[] = i1;
                while => i[].in_memory_after(i0) {
                    i[] = i[].offset(-1);
                    if is_argbh(i[].op()) {
                        f.move_end_of_block_to_scratch(b, i[], changed&);
                        prev := f.emit(i[][]);
                        i.to = f.newtmp("abi", .Kl);
                        prev.arg&[0] = i.to;
                    } else {
                        if changed {
                            f.emit(i[][]);
                        };
                    }
                };
                i[] = i1;
                while => i[].in_memory_after(i0) {
                    i[] = i[].offset(-1);
                    if is_argbh(i[].op()) {
                        f.move_end_of_block_to_scratch(b, i[], changed&);
                        o := rebase(i[].op(), .extsb, .argsb);
                        f.emit(o, .Kw, i.to, i.arg&[0], QbeNull);
                    }
                };
            };
        };
        if changed {
            f.copy_instructions_from_scratch(b); 
        };
    };

    if f.globals.debug["A".char()] {
        out := f.globals.debug_out;
        write(out, "\n> After Apple pre-ABI:\n");
        printfn(f, out);
    }
}

fn split(f: *Qbe.Fn, b: *Qbe.Blk) *Qbe.Blk = {
    f.nblk += 1;
    bn := newblk();
    f.copy_instructions_from_scratch(bn);
    b.visit += 1;
    bn.visit = b.visit;
    @if(f.track_ir_names()) {
        bn.name = @tfmt("%.%", b.name(), @as(i64) b.visit.zext());
    };
    bn.loop = b.loop;
    bn.link = b.link;
    b.link = bn;
    bn
}

fn chpred(b: *Qbe.Blk, bp: *Qbe.Blk, bp1: *Qbe.Blk) void = {
    for_phi b { p |
        a := index_in_phi(bp, p);
        p.blk[a] = bp1;
    }
}

fn realloc_for_params(f: *Qbe.Fn, i: *Qbe.Ins) void = {
    b := f.start;
    param_count := ptr_diff(b.ins.ptr, i);
    if f.len_scratch() == 0 && param_count == 0 {
        // avoid useless reallocation if we have no params  (and no big ret pointer)
        return();
    };
    n: i64 = b.ins.len - param_count + f.len_scratch();
    i0: RawList(Qbe.Ins) = init(temp(), n);
    i0&.push_all_assume_capacity(f.globals.curi.slice(f.len_scratch()));
    i0&.push_all_assume_capacity(between(i, b.ins.index_unchecked(b.ins.len)));
    b.ins = i0;
}

fn find_past_last_param(f: *Qbe.Fn) *Qbe.Ins = {
    for_insts_forward f.start { i | 
        if !is_par(i.op()) {
            return(i);
        }
    };
    f.start.ins.ptr.offset(f.start.ins.len)
}

fn find_first_arg(b: *Qbe.Blk, call: *Qbe.Ins) *Qbe.Ins = {
    i := call;
    while => i.in_memory_after(b.ins.ptr) {
        if !is_arg(i.offset(-1).op()) {
            return(i);
        };
        i = i.offset(-1);
    };
    i
}

// used by arm64/amd64 isel       TODO: worth a new file? 
// Any alloc with constant size gets assigned a fixed slot that we know as a constant offset into the stack frame. 
// Then the instruction for the alloc is removed. 
// So any remaining alloc instructions after this must be a dynamic alloca.  
// Note: We only do this for allocs in the start block. 
//       I guess if you conditionally do a large but constant size alloc, you don't want to always use the stack space. 
fn assign_alloc_slots(f: *Qbe.Fn) void = {
    @debug_assert(f.slot == 0 || f.globals.goal.arch == .wasm32, "slots should not be assigned yet");
    approx := align_to(f.slot.intcast(), 16) + 16;
    for_insts_forward f.start { i |
        if is_alloc(i.op()) {
            if f.get_int(i.arg&[0]) { size |
                approx += align_to(size, 16);
            };
        }
    };
    f.escaping_slots = init_bitset(approx);
    
    allocs := @slice(Qbe.O.alloc4, Qbe.O.alloc8, Qbe.O.alloc16); // TODO: for_enum_range (these are sequentual)
    
    /* specific to NAlign == 3 */ /* or change align=4 and size /= 4 below */
    align := 4;
    for allocs { alloc_type |
        break :: local_return; // TODO: make break less of a pain in this language
        for_insts_forward f.start { i |
            if i.op() == alloc_type {
                if f.get_int(i.arg&[0]) { size |
                    if size < 0 || size >= MAX_i32 - 15 {
                        @panic("invalid alloc size %", size);
                    };
                    size = size.add(align - 1).bit_and(-align);
                    t := f.get_temporary(i.to);
                    t.slot = f.slot;
                    f.slot += size.intcast();
                    f.salign = 2 + alloc_type.raw() - Qbe.O.alloc4.raw();
                
                    // TODO: unfortunate that all my tests still work if you don't do this
                    //       i think it will matter more if i get store elimination working?  -- Jan 15
                    if escapes(i.to, f) { 
                        range(0, size) { i |
                            bsset(f.escaping_slots&, t.slot.intcast() + i);
                        };
                    };
                
                    i.set_nop();
                } else {
                    align *= 2; // :break
                    break(); 
                };
            }
        };
        align *= 2; // :break
        
        if f.slot.intcast().mod(align) != 0 {
            f.slot += align.intcast() / 2;
        };
        
        // on arm: ~23KB -- Nov 6
        //         It's actually fine if they're unaligned, you just can't use the immediate in ldr/str,
        //         so doing it this way lets fuse_addressing catch a few more cases at the cost of wasting 4 bytes of stack half the time. 
        //if align == 8 && f.slot.intcast().mod(align) != 0 {
        //    f.slot += 4;
        //    f.salign = 3;
        //};
    };
    @debug_assert_ge(approx, f.slot.zext(), "failed at guessing stack size");
};

fn chuse(r: Qbe.Ref, du: i64, f: *Qbe.Fn) void = {
    if rtype(r) == .RTmp {
        nuse := f.get_temporary(r)[].nuse&;
        nuse[] = trunc(nuse[].zext() + du);
    };
    if rtype(r) == .RMem {
        m := f.get_memory(r);
        chuse(m.index, du, f);
        chuse(m.base, du, f);
    };
}

fn try_kill_inst(f: *Qbe.Fn, i: *Qbe.Ins) bool #inline = {
    if rtype(i.to) == .RTmp
    && !isreg(i.to) && !isreg(i.arg&[0]) && !isreg(i.arg&[1])
    && f.get_temporary(i.to)[].nuse == 0 {
        chuse(i.arg&[0], -1, f);
        chuse(i.arg&[1], -1, f);
        return(true);
    };
    false
}

fn to_rcall(r: Qbe.Ref, $RCall: Type) RCall #generic = {
    @debug_assert(rtype(r) == .RCall, "can't decode non call");
    r: RCall = (repr = r.val().trunc());
    r
}
