// Adapted from Qbe. MIT License. Â© 2015-2024 Quentin Carbonneaux <quentin@c9x.me>
//! Some helpers used by the abi for multiple targets. 

// 
// note: my frontend does not use b/h par/arg instructions but harec does. 
// 
// arm64-apple and wasm32 expect sign extensions for calls and returns of sub-word things. 
// sysv, rv64, and non-apple-arm64 treat the high bits as arbitrary. 
// Qbe only does the extensions when the target requires it and otherwise just converts them to normal par/arg. 
// Since I want to keep all the target specific stuff at the end (so the beginning can be cached), 
// I just do the extends for all targets. Sign extended is a valid arbitrary high bits, right? 
//

#use("@/backend/lib.fr");
fn extsb_parargret(f: *Qbe.Fn) void = {
    any_changed := false;
    for_blocks f { b |
        changed := false; 
        f.reset_scratch();
        j := b.jmp.type;
        if is_retbh(j) {
            changed = true;
            r := f.newtmp("abi", .Kw);
            o := @as(Qbe.O) @as(i32) Qbe.O.extsb.raw() + (j.raw() - Qbe.J.retsb.raw());
            f.emit(o, .Kw, r, b.jmp.arg, QbeNull);
            b.jmp.arg = r;
            b.jmp.type = .retw;
        };
        for_insts_rev b { i | 
            if changed {
                f.emit(i[]);
            };
            if i[].op() == .call {
                i1 := i[];
                i0 := b.find_first_arg(i[]); 
                i[] = i1;
                while => i[].in_memory_after(i0) {
                    i[] = i[].offset(-1);
                    if is_argbh(i[].op()) {
                        f.move_end_of_block_to_scratch(b, i[], changed&);
                        prev := f.emit(i[]);
                        prev.set_op(.arg);
                        i.to = f.newtmp("abi", .Kl);
                        prev.arg&[0] = i.to;
                    } else {
                        if changed {
                            f.emit(i[]);
                        };
                    }
                };
                i[] = i1;
                while => i[].in_memory_after(i0) {
                    i[] = i[].offset(-1);
                    if is_argbh(i[].op()) {
                        o := rebase(i[].op(), .extsb, .argsb);
                        f.emit(o, .Kw, i.to, i.arg&[0], QbeNull);
                    }
                };
            };
        };
        if changed {
            f.copy_instructions_from_scratch(b); 
            any_changed = true;
        };
    };

    @if(any_changed)
    when_debug_printfn(f, .Abi, "\n## After Apple pre-ABI:\n");
}

fn split(f: *Qbe.Fn, b: *Qbe.Blk) *Qbe.Blk = {
    f.nblk += 1;
    bn := newblk();
    f.copy_instructions_from_scratch(bn);
    b.visit += 1;
    bn.visit = b.visit;
    @if(f.track_ir_names()) {
        bn.name = @tfmt("%.%", b.name(), @as(i64) b.visit.zext());
    };
    bn.loop = b.loop;
    bn.link = b.link;
    b.link = bn;
    bn
}

fn chpred(b: *Qbe.Blk, bp: *Qbe.Blk, bp1: *Qbe.Blk) void = {
    for_phi b { p |
        a := index_in_phi(bp, p);
        p.blk[a] = bp1;
    }
}

fn realloc_for_params(f: *Qbe.Fn, i: *Qbe.Ins) void = {
    b := f.start;
    param_count := ptr_diff(b.ins.ptr, i);
    if f.len_scratch() == 0 && param_count == 0 {
        // avoid useless reallocation if we have no params  (and no big ret pointer)
        return();
    };
    n: i64 = b.ins.len - param_count + f.len_scratch();
    i0: RawList(Qbe.Ins) = init(temp(), n);
    i0&.push_all_assume_capacity(f.globals.curi.slice(f.len_scratch()));
    i0&.push_all_assume_capacity(between(i, b.ins.index_unchecked(b.ins.len)));
    b.ins = i0;
}

fn find_past_last_param(f: *Qbe.Fn) *Qbe.Ins = {
    for_insts_forward f.start { i | 
        if !is_par(i.op()) {
            return(i);
        }
    };
    f.start.ins.ptr.offset(f.start.ins.len)
}

fn find_first_arg(b: *Qbe.Blk, call: *Qbe.Ins) *Qbe.Ins = {
    i := call;
    while => i.in_memory_after(b.ins.ptr) {
        if !is_arg(i.offset(-1).op()) {
            return(i);
        };
        i = i.offset(-1);
    };
    i
}

// used by arm64/amd64 isel
// Any alloc with constant size gets assigned a fixed slot that we know as a constant offset into the stack frame. 
// Then the instruction for the alloc is removed. 
// So any remaining alloc instructions after this must be a dynamic alloca.  
// Note: We only do this for allocs in the start block. 
//       I guess if you conditionally do a large but constant size alloc, you don't want to always use the stack space. 
fn assign_alloc_slots(f: *Qbe.Fn) void = {
    @debug_assert(f.slot == 0 || f.globals.goal.arch == .wasm32, "slots should not be assigned yet");
    approx := align_to(f.slot.intcast(), 16) + 16;
    for_insts_forward f.start { i |
        if is_alloc(i.op()) {
            if f.get_int(i.arg&[0]) { size |
                approx += align_to(size, 16);
            };
        }
    };
    f.escaping_slots = init_bitset(approx / 4);
    
    allocs := @slice(Qbe.O.alloc4, Qbe.O.alloc8, Qbe.O.alloc16); // TODO: for_enum_range (these are sequentual)
    
    /* specific to NAlign == 3 */ /* or change align=4 and size /= 4 below */
    align := 4;
    for allocs { alloc_type |
        break :: local_return; // TODO: make break less of a pain in this language
        for_insts_forward f.start { i |
            if i.op() == alloc_type {
                if f.get_int(i.arg&[0]) { size |
                    if size < 0 || size >= MAX_i32 - 15 {
                        @panic("invalid alloc size %", size);
                    };
                    size = size.add(align - 1).bit_and(-align);
                    t := f.get_temporary(i.to);
                    t.slot = f.slot;
                    f.slot += size.intcast();
                    f.salign = 2 + alloc_type.raw() - Qbe.O.alloc4.raw();
                
                    // TODO: unfortunate that all my tests still work if you don't do this
                    //       i think it will matter more if i get store elimination working?  -- Jan 15
                    if escapes(i.to, f) { 
                        s := t.slot.intcast()/4;
                        range(0, size/4) { i |
                            bsset(f.escaping_slots&, s + i);
                        };
                    };
                
                    i.set_nop();
                } else {
                    align *= 2; // :break
                    break(); 
                };
            }
        };
        align *= 2; // :break
        
        if f.slot.intcast().mod(align) != 0 {
            f.slot += align.intcast() / 2;
        };
        
        // on arm: ~23KB -- Nov 6
        //         It's actually fine if they're unaligned, you just can't use the immediate in ldr/str,
        //         so doing it this way lets fuse_addressing catch a few more cases at the cost of wasting 4 bytes of stack half the time. 
        //if align == 8 && f.slot.intcast().mod(align) != 0 {
        //    f.slot += 4;
        //    f.salign = 3;
        //};
    };
    @debug_assert_ge(approx, f.slot.zext(), "failed at guessing stack size");
};

fn chuse(r: Qbe.Ref, du: i64, f: *Qbe.Fn) void = {
    if rtype(r) == .RTmp {
        nuse := f.get_temporary(r)[].nuse&;
        nuse[] = trunc(nuse[].zext() + du);
    };
    if rtype(r) == .RMem {
        m := f.get_memory(r);
        chuse(m.index, du, f);
        chuse(m.base, du, f);
    };
}

fn try_kill_inst(f: *Qbe.Fn, i: *Qbe.Ins) bool #inline = {
    if rtype(i.to) == .RTmp
    && !isreg(i.to) && !isreg(i.arg&[0]) && !isreg(i.arg&[1])
    && f.get_temporary(i.to)[].nuse == 0 {
        @debug_assert(!@is(i.op(), .sel1, .cas1));
        chuse(i.arg&[0], -1, f);
        chuse(i.arg&[1], -1, f);
        return(true);
    };
    false
}

fn to_rcall(r: Qbe.Ref, $RCall: Type) RCall #generic = {
    @debug_assert(rtype(r) == .RCall, "can't decode non call");
    r: RCall = (repr = r.val().trunc());
    r
}

// TODO: use move_end_of_block_to_scratch? how common are large blocks that don't make any calls? 
native_abi :: fn(
    f: *Qbe.Fn,
    $Params: Type, 
    $selpar: @Fn(f: *Qbe.Fn, par_i: []Qbe.Ins) Params,
    $selcall: @Fn(f: *Qbe.Fn, arg_i: []Qbe.Ins, allocs_out: *List(Qbe.Ins)) void,
    $selvastart: @Fn(f: *Qbe.Fn, fa: Params, ap: Qbe.Ref) void,
    $selvaarg: @Fn(f: *Qbe.Fn, b: *Qbe.Blk, i: *Qbe.Ins) void, 
    $selret: @Fn(b: *Qbe.Blk, f: *Qbe.Fn) void,
) void #generic = {
    T := f.globals.target&;
    for_blocks f { b | 
        b.visit = 0;
    };
    
    /* lower parameters */
    i := f.find_past_last_param();
    m := f.globals;
    p := selpar(f, between(f.start.ins.ptr, i));
    f.realloc_for_params(i);

    /* lower calls, returns, and vararg instructions */
    il := Qbe.Ins.list(temp());
    b := f.start;
    dowhile {
        continue :: local_return;
        b = b.link;
        if b.is_null() {
            b = f.start; /* do it last */
        };
        if(b.visit != 0, => continue(!b.identical(f.start)));
        f.reset_scratch();
        selret(b, f);

        for_insts_rev b { i |
            @match(i[].op()) {
                fn call() => {
                    i0 := b.find_first_arg(i[]);
                    selcall(f, between(i0, i[]), il&);
                    i[] = i0;
                }
                fn vastart() => selvastart(f, p, i.arg&[0]);
                fn vaarg() => selvaarg(f, b, i[]);
                @default => {
                    // TODO: check this in fails_typecheck
                    @debug_assert(!@is(i[].op(), .arg, .argc, .arge));
                    f.emit(i[]);
                };
            };
        };
        if b.identical(f.start) {
            // stkblob wants to insert allocs in the beginning of the start block so they isel-ed to fast-allocs. 
            // since emit() is backwards so these get emitted after processing the start block. 
            for_rev il { it |
                f.emit(it);
            };
        };
        f.copy_instructions_from_scratch(b);
        !b.identical(f.start)
    };

    when_debug_printfn(f, .Abi, "\n## After ABI lowering:\n");
};

fn collapse_addr(f: *Qbe.Fn) void = {
    for_blocks_rpo_forward f { b |
        for_insts_forward b { i |
            continue :: local_return;
            @if(i.op() != .add) continue();
            @if(i.cls().is_float()) continue();
            a := f.get_tmp(i.arg&[0]) || continue();
            @if(a.slot < -1) continue();
            delta := f.get_int(i.arg&[1]) || continue();
            d := f.get_temporary(i.to);
            @debug_assert(!i.to.isreg());
            new := a.slot.intcast() + delta;
            if a.slot != -1 {
                if new >= 0 && fits_in_i32(new) && d.slot == -1 {
                    d.slot = intcast(new);
                    d.def = Qbe.Ins.ptr_from_int(0);
                    chuse(i.arg&[0], -1, f);
                    i.set_nop();
                }
            } else {
                i2 := a.def;
                @if(i2.is_null() || i2.op() != .add) continue();
                delta2 := f.get_int(i2.arg&[1]) || continue();
                @debug_assert(i.arg&[0] != i2.arg&[0], "cycle in add chain");
                chuse(i.arg&[0], -1, f);
                chuse(i2.arg&[0], 1, f);
                i.arg&[0] = i2.arg&[0];
                i.arg&[1] = f.getcon(delta + delta2);
            };
        };
    };
}

native_isel :: fn(
    f: *Qbe.Fn,
    $fixarg: @Fn(a: *Qbe.Ref, k: Qbe.Cls, nullable_i: *Qbe.Ins, f: *Qbe.Fn) void #duplicated,
    $sel_terminator: @Fn(b: *Qbe.Blk, f: *Qbe.Fn) void,
    $sel_inst: @Fn(i: **Qbe.Ins, b: *Qbe.Blk, f: *Qbe.Fn) void,
) void #generic = {
    f.assign_alloc_slots();
    f.collapse_addr();
    
    // In this pass, if `t.slot != -1` then `TMP(t) == addr SLOT(t.slot)`
    
    for_blocks f { b | 
        f.reset_scratch();
        for_jump_targets b { sb | 
            for_phi sb { p |
                a := index_in_phi(b, p);
                fixarg(p.arg.index(a), p.cls, Qbe.Ins.ptr_from_int(0), f);
            };
        };
        sel_terminator(b, f);
        for_insts_rev b { i |
            sel_inst(i, b, f);
        };
        f.copy_instructions_from_scratch(b);
    };

    when_debug_printfn(f, .InstSelect, "\n## After instruction selection:\n");
};

zip_args_g :: fn($Class: Type) FuncId = fn(i0: *Qbe.Ins, i1: *Qbe.Ins, ac: []Class, $body: @Fn(i: *Qbe.Ins, a: *Class, $c: LabelId) void) void = {
    i := i0.offset(-1);
    ai := 0;
    while => i1.in_memory_after(i.offset(1)) {
        continue :: local_return;
        a := ac.index(ai);
        i = i.offset(1);
        ai += 1;
        body(i, a, continue);
    };
};

fn salloc(rt: Qbe.Ref, rs: Qbe.Ref, f: *Qbe.Fn) bool = {
    /* we need to make sure
    * the stack remains aligned
    * (rsp = 0) mod 16
    */
    f.dynalloc = true;
    if rtype(rs) == .RCon {
        sz := f.con[rs.val()]&.bits();
        if sz < 0 || sz >= MAX_i32 - 15 {
            @panic("invalid alloc size %", sz);
        };
        sz = (sz + 15).bit_and(-16);
        f.emit(.salloc, .Kl, rt, f.getcon(sz), QbeNull);
        false
    } else {
        @emit_instructions((f = f), (rs, rt), """
        @start
            %r1 =l add %0, 15
            %r0 =l and %r1, -16
            %1  =l salloc %r0
        """);
        if f.tmp[rs.val()].slot != -1 {
            @panic("unlikely alloc argument % for %", f.tmp[rs.val()]&.name(), f.tmp[rt.val()]&.name());
        };
        true
    }
}
