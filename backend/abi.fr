// Adapted from Qbe. MIT License. Â© 2015-2024 Quentin Carbonneaux <quentin@c9x.me>
//! Some helpers used by the abi for multiple targets. 

/* eliminate sub-word abi op
 * variants for targets that
 * treat char/short/... as
 * words with arbitrary high
 * bits
 */
fn elimsb(f: *Qbe.Fn) void = {
    for_blocks f { b |
        for_insts_forward b { i |
            if(is_argbh(i.op()), => i.set_op(.arg));
            if(is_parbh(i.op()), => i.set_op(.par));
        };
        if is_retbh(b.jmp.type) {
            b.jmp.type = .retw;
        }
    }
}

fn split(f: *Qbe.Fn, b: *Qbe.Blk) *Qbe.Blk = {
    f.nblk += 1;
    bn := newblk();
    f.copy_instructions_from_scratch(bn);
    b.visit += 1;
    bn.visit = b.visit;
    @if(TRACK_IR_NAMES) {
        l: List(u8) = (maybe_uninit = bn.name&.items(), len = 0, gpa = panicking_allocator); // :UnacceptablePanic
        @fmt(l&, "%.%", b.name(), @as(i64) b.visit.zext());
    };
    bn.loop = b.loop;
    bn.link = b.link;
    b.link = bn;
    bn
}

fn chpred(b: *Qbe.Blk, bp: *Qbe.Blk, bp1: *Qbe.Blk) void = {
    for_phi b { p |
        a := 0;
        while => !p.blk[a].identical(bp) {
            @debug_assert(a + 1 < p.narg.zext(), "didn't find phi for block");
            a += 1;
        };
        p.blk[a] = bp1;
    }
}

fn realloc_for_params(f: *Qbe.Fn, i: *Qbe.Ins) void = {
    b := f.start;
    param_count := ptr_diff(b.ins.first, i);
    if f.len_scratch() == 0 && param_count == 0 {
        // avoid useless reallocation if we have no params  (and no big ret pointer)
        return();
    };
    n: i64 = b.nins.zext() - param_count + f.len_scratch();
    i0: QList(Qbe.Ins) = new(n);
    ip := i0.first;
    ip = icpy(ip, f.globals.curi[], f.len_scratch());
    ip = icpy(ip, i, ptr_diff(i, b.ins.index(b.nins.zext())));  
    b.nins = n.trunc();
    b.ins = i0;
}

fn find_past_last_param(f: *Qbe.Fn) *Qbe.Ins = {
    for_insts_forward f.start { i | 
        if !is_par(i.op()) {
            return(i);
        }
    };
    f.start.ins.first.offset(f.start.nins.zext())
}

fn find_first_arg(b: *Qbe.Blk, call: *Qbe.Ins) *Qbe.Ins = {
    i := call;
    while => Qbe.Ins.int_from_ptr(i) > Qbe.Ins.int_from_ptr(b.ins.first) {
        if !is_arg(i.offset(-1).op()) {
            return(i);
        };
        i = i.offset(-1);
    };
    i
}

// used by arm64/amd64 isel       TODO: worth a new file? 
// Any alloc with constant size gets assigned a fixed slot that we know as a constant offset into the stack frame. 
// Then the instruction for the alloc is removed. 
// So any remaining alloc instructions after this must be a dynamic alloca.  
// Note: We only do this for allocs in the start block. 
//       I guess if you conditionally do a large but constant size alloc, you don't want to always use the stack space. 
fn assign_alloc_slots(f: *Qbe.Fn) void = {
    approx := 0;
    for_insts_forward f.start { i |
        if is_alloc(i.op()) {
            if f.get_int(i.arg&[0]) { size |
                align := 16; 
                size = size.add(align - 1).bit_and(-align);
                approx += size / 4;
            };
        }
    };
    f.escaping_slots = init_bitset(approx);
    
    allocs := @slice(Qbe.O.alloc4, Qbe.O.alloc8, Qbe.O.alloc16); // TODO: for_enum_range (these are sequentual)
    
    /* specific to NAlign == 3 */ /* or change align=4 and size /= 4 below */
    align := 4;
    for allocs { alloc_type |
        break :: local_return; // TODO: make break less of a pain in this language
        for_insts_forward f.start { i |
            if i.op() == alloc_type {
                if f.get_int(i.arg&[0]) { size |
                    if size < 0 || size >= MAX_i32 - 15 {
                        @panic("invalid alloc size %", size);
                    };
                    size = size.add(align - 1).bit_and(-align);
                    size /= 4;
                    t := f.get_temporary(i.to);
                    t.slot = f.slot;
                    f.slot += size.intcast();
                    f.salign = 2 + alloc_type.raw() - Qbe.O.alloc4.raw();
                    
                    if escapes(i.to, f) { 
                        range(0, size) { i |
                            bsset(f.escaping_slots&, t.slot.intcast() + i);
                        };
                    };
                    i.set_nop();
                } else {
                    panic("TODO: none of my tests get here (alloca a dynamically sized stack slot)");
                    align *= 2; // :break
                    break(); 
                };
            }
        };
        align *= 2; // :break
        
        // on arm: ~23KB -- Nov 6
        //         It's actually fine if they're unaligned, you just can't use the immediate in ldr/str,
        //         so doing it this way lets fuse_addressing catch a few more cases at the cost of wasting 4 bytes of stack half the time. 
        if align == 8 && f.slot.intcast().mod(align / 4) != 0 {
            f.slot += 1;
            f.salign = 3;
        };
    };
    
    @debug_assert(approx >= f.slot.zext(), "failed at guessing stack size");
};

fn chuse(r: Qbe.Ref, du: i64, f: *Qbe.Fn) void #inline = {
    if rtype(r) == .RTmp {
        nuse := f.get_temporary(r)[].nuse&;
        nuse[] = trunc(nuse[].zext() + du);
    }
}

fn try_kill_inst(f: *Qbe.Fn, i: *Qbe.Ins) bool #inline = {
    if rtype(i.to) == .RTmp
    && !isreg(i.to) && !isreg(i.arg&[0]) && !isreg(i.arg&[1])
    && f.get_temporary(i.to)[].nuse == 0 {
        chuse(i.arg&[0], -1, f);
        chuse(i.arg&[1], -1, f);
        return(true);
    };
    false
}
