// #foreign("llvm-mc");

SegmentCursor :: @struct(
    mmapped: []u8,
    next: *u8,
);

SegmentType :: @enum(i64) (
    Code,
    ConstantData,
    MutableData,
    ZeroInitData,
);

SymbolBucket :: @struct(
    n: u32,
    mutex: Mutex,
    data: QList(SymbolInfo),
);

// TODO: make this less chunky
SymbolInfo :: @struct(
    name: Str,
    inline: *Qbe.InlineFn, // nullable
    fixups: RawList(Fixup),
    // or -1 if not referenced yet. valid: DynamicPatched
    // this gets repurposed when fixups_locked. 
    // when targetting wasm this is the index of the function (need to offset by import count if imported)
    got_lookup_offset: i64,
    segment: SegmentType, // valid: Local
    //  local: offset in the segment
    // import: offset in stubs to trampoline (if function)
    offset: i64,
    jit_addr: rawptr, // valid when kind == .DynamicPatched and goal == .JitOnly
    shim_addr: rawptr, // TODO: it would be great if i didn't need this
    kind: SymbolKind,
    local_but_marked_for_relocation: bool,
    referenced: bool,  // took address or called before knowing it was inlinable so you must actually emit the function.
    pledge_local: bool,
    strong: bool,
    export: bool,
    inlinable: bool,
    pledge_function: bool,
    size: u32,
    library: u32,  // for imports. index into m.libraries. 0 is reserved for locals
    wasm_type_index: i32,
    // this is a bit dumb because it's redundant with `name` but it means you can get
    // it from just a *SymbolInfo without calling intern() if you want to add it to a 
    // list from inside a use_symbol so the bucket is already locked. 
    id: Qbe.Sym,
    alias: Qbe.Sym,
    wasm_module_function_index: i32,
);

SymbolKind :: @enum(u8) (
    // We haven't compiled this yet so we've emitted references as lookups into a table in the data section. 
    // 
    // It might also be a dynamic import. 
    // - For aot, you may want to go through the fixups again and translate them to use a GOT section. 
    //   That way you don't make the loader waste time patching two tables. 
    //
    Pending,
    // We've already compiled this and we know its close to the code and addressable by a static offset. 
    Local,
    // This is an import and we've already patched it in the code. 
    DynamicPatched,
);

FixupType :: @tagged(
    // arm64
    //  local: adrp,add to the address directly
    // import: ??
    InReg: @struct(r: i64, increment: i64, got_load := false),
    // arm64
    //  local: b(l) to the address
    // import: b(l) to a trampoline which adrp,ldr,br from __got
    //         but currently its adrp,add,br to the address directly
    Call,
    // all 
    //  local: rebase.
    //         It's a local symbol but since we want its absolute address in memory, we need the loader to add our base address.  
    // import: bind.
    //         We want the absolute address of an import to be in memory. ie. __got uses this. 
    DataAbsolute: @struct(increment: i64),
    
    // amd64
    RipDisp32: @struct(
        increment: i64,
        call: bool, 
        got_load := false /*only used when .Relocatable*/
    ), // TODO: add safety checks for size of Qbe.Con.bits.i
    
    WasmIndex,
    WasmAddr: @struct(increment: u32),
);

Fixup :: @struct(
    patch_at: @union(
        addr: rawptr,
        raw: *rawptr,
        u8: *u8,
        u32: *u32,
        i32: *i32,
        i64: *i64,
        //chain: *import("@/backend/macho/bits.fr").ChainedReloc,  // TODO: this crashes :compilerbug
    ),
    type: FixupType,
);

fn reserve(s: *SegmentCursor, $T: Type) *T #generic = {
    @debug_assert_ge(s.mmapped.len - s.len(), T.size_of(), "not enough space in segment for reserve total=%", s.mmapped.len);
    ptr := s.next;
    // TODO: is alignment real?
    //@debug_assert(u8.int_from_ptr(ptr).mod(T.align_of()) == 0, "unaligned reserve");
    s.next = s.next.offset(T.size_of());
    ptr_cast_unchecked(u8, T, ptr)
}

fn len(s: *SegmentCursor) i64 = 
    ptr_diff(s.mmapped.ptr, s.next);

fn cap(s: *SegmentCursor) i64 = 
    s.mmapped.len;

// TODO: this is stupid
// only call this on the codegen thread!
fn set_library(m: *QbeModule, sym_id: Qbe.Sym, name: Str, weak: bool) void = {
    i := m.find_library(name) ||    
        m.new_library(name);
    
    use_symbol(m, sym_id) { s | 
        @debug_assert(s.library == 0 || s.library == i, "set_library(%) conflict % %", s.name, i, s.library);
        s.library = i;
        s.strong = s.strong || !weak;
        weak = !s.strong;
    };
    
    @if(enable_incremental()) if m.save { save |
        id := save.map_sym(m, sym_id);
        save.sym[id].segment = .Import;
        save.sym[id].imp.lib = (off = i - 1);
        save.sym[id].imp.weak = weak;
    };
}

fn set_library(m: *QbeModule, sym_id: Qbe.Sym, name: Str) void = set_library(m, sym_id, name, false);

fn new_library(m: *QbeModule, name: Str) u32 = {
    i: u32 = trunc(m.libraries.len);
    m.libraries&.push(name.shallow_copy(general_allocator()), general_allocator());
    
    @if(enable_incremental()) if m.save { save |
        save.lib&.push(name = save.push(name));
    };
    
    i
}

// :SLOW
fn find_library(m: *QbeModule, name: Str) ?u32 = {
    enumerate m.libraries { i, check |
        if name == check[] {
            return(Some = i.trunc());
        }
    };
    .None
}

fn make_exec(self: *QbeModule) void = {
    ::enum(Arch); ::enum(@type self.goal.type);
    @debug_assert_eq(self.goal.arch, query_current_arch());
    @debug_assert_eq(self.goal.type, .JitOnly);
    if self.goal.expecting_wx {
        @debug_assert_ne(self.goal.arch, .wasm32);
        return();  // already executable so this is a nop
    };
    
    @if(TODOWASM)
    if self.goal.arch == .wasm32 {
        import("@/backend/wasm/emit.fr")'make_exec(self);
        return();
    };
    
    segment := SegmentType.Code;
    prot := bit_or(@as(i64) MapProt.Exec, @as(i64) MapProt.Read);
    segment := self.segments&.index(segment);
    end := segment.next&;
    len := self.start_of_writable_code.ptr_diff(end[]);
    if(len == 0, => return());
    PAGE_SIZE := page_size();
    segment.align_to(PAGE_SIZE);
    
    page_start := u8.int_from_ptr(self.start_of_writable_code) / PAGE_SIZE * PAGE_SIZE;
    
    // it seems to want `addr` to be page aligned
    res := Syscall'mprotect(rawptr_from_int(page_start), u8.int_from_ptr(end[]) - page_start, prot); 
    Posix :: import("@/lib/sys/posix.fr");
    // TODO: get serious about getting a useful error message out of syscall return
    @assert_eq(res.value, 0, "mprotect failed %", Posix'errno()[]);
    clear_instruction_cache(u8.raw_from_ptr(self.start_of_writable_code), u8.raw_from_ptr(end[]));  // IMPORTANT
    
    self.start_of_writable_code = end[];
}

fn get_addr(self: *QbeModule, id: Qbe.Sym) ?Ty(rawptr, i64) = {
    @debug_assert(!self.fixups_locked, "you can't get a jit pointer after emitting for aot becuase it stomps data with relocation info.");
    result: ?Ty(rawptr, i64) = .None;
    use_symbol(self, id) { symbol | 
        result = get_addr(self, symbol);
        if result.is_none() {
            msg :: "Tried to get_addr for uncompiled '%' because it was suspended for inlining. it should be marked as exported.";
            ::ptr_utils(Qbe.InlineFn);
            @debug_assert(!symbol.inlinable || symbol.export, msg, symbol.name);
        };
    };
    result
}

fn get_addr(self: *QbeModule, name: Str) ?rawptr = {
    if get_addr(self, self.intern(name)) { a |
        return(Some = a._0);
    };
    .None
}

fn get_addr(self: *QbeModule, symbol: *SymbolInfo) ?Ty(rawptr, i64) = {
    ::enum(SymbolKind);
    (Some = (symbol.jit_addr, symbol.size.zext()))
}

// TODO: add_asm functions don't go through this currently but they should
fn maybe_add_export(self: *QbeModule, id: Qbe.Sym, export: bool) void = if export {
    ::enum(@type self.goal.type);
    if (self.goal.arch == .wasm32 || @is(self.goal.type, .Relocatable, .Dynamic)) {
        self.exports&.push(id);
    };
    
    // this makes sure it will be emitted even if all uses are inlined. 
    use_symbol(self, id) { s | 
        mark_referenced(self, id, s);
        s.export = true;
    };
};

// TODO: can still use bss if there's only pointers and all data is zeros.
// TODO: be able to specify mutable or constant

Dat2 :: @struct {
    Reloc :: @struct(off: u32, id: Qbe.Sym, addend: i64 = 0);
    Template :: @tagged(Bytes: []u8, Zeroes: i64);
    template: Template;
    relocations: []Reloc; 
    align: u32 = 1;  // TODO: respect this in emit_data()
    seg := SegmentType.MutableData;
    id: Qbe.Sym;
    export: bool = false;
};

// Reserve a chunk of memory in the module's data segment, fill it with the right bytes, and record the necessary relocations. 
// The memory in `dat` is not needed after this call, caller can free it. 
fn emit_data(self: *QbeModule, dat: Dat2) void = {
    @debug_assert(!self.fixups_locked, "you cannot add more data after emitting for aot");
    ::tagged(@type dat.template);
   
    when_debug(self, .Data) { out |
        print_data(self, dat&, out);
    };
    
    @if(enable_incremental())
    if self.save { save |
        each dat.relocations { r |
            use_symbol(self, r.id) { symbol | 
                mark_referenced(self, r.id, symbol);
            }
        };
        
        save.push(self, dat&);
        return();
    };
    
    if dat.template&.is(.Zeroes) && dat.relocations.len == 0 {
        // TODO: i want to remvoe this limitation so you can use this function
        //       to materialize things made by import_c or meta/parse. 
        //@debug_assert_ne(self.goal.type, .JitOnly, "TODO: the franca compiler doens't do this because the data's already in the comptime address space\nat the very least you need to mmap something for ZeroInitData before you can turn this on.");
        ::enum(@type self.goal.type);
        if self.goal.type == .JitOnly || self.goal.arch == .wasm32 {
            @debug_assert_ne(dat.seg, .ZeroInitData, "no allocation for jitted/wasm bss");
        } else {
            dat.seg = .ZeroInitData;
        }
    };
    segment := self.segments&.index(dat.seg);

    // TODO: kinda dumb to pad short strings          :MiscompileCStr  -- May 11, 2025
    //       it seems like you only require 8 if there are relocations but it doesn't work
    //       suspicious that it breaks the tests that make the same string literal as a Str and a CStr
    //       yeah: `Expected (Hello Worldfail/usr/lib/libc.dylib == Hello World)`  
    // segment.align_to((@if(dat.relocations.len > 0, 8, 1)).max(dat.align.zext()));
    segment.align_to(8);
    // that wastes ~5kb on the compiler -- Dec 15, 2025
    
    next := segment.next&;
    start_off := segment.len();
    dest := @match(dat.template) {
        fn Zeroes(size) => next[].slice(size);  // it will already be zeroed since it's from the page allocator
        fn Bytes(bytes) => {
            dest := next[].slice(bytes.len);
            dest.copy_from(bytes);
            dest
        }
    };    
    next[] = next[].offset(dest.len);
    use_symbol(self, dat.id) { s | 
        s.size = dest.len.trunc();
    };
    // TODO: wasm data export can just be a global that has the pointer in it? 
    if self.goal.arch != .wasm32 {
        maybe_add_export(self, dat.id, dat.export);
        if self.goal.exe_debug_symbol_table {
            self.local_needs_reloc&.push(dat.id);
        };
    };
    self.do_jit_fixups(dat.id, dat.seg, start_off);
    
    each dat.relocations { r |
        @assert_eq(r.off.mod(8), 0, "sorry can't do unaligned constants yet");
        ptr := ptr_cast_unchecked(u8, i64, dest.index(r.off.zext()));
        use_symbol(self, r.id) { symbol | 
            mark_referenced(self, r.id, symbol);
            filled := false;
            if self.goal.type == .JitOnly {
                if !filled && !symbol.jit_addr.is_null() {
                    ptr[] = int_from_rawptr(symbol.jit_addr) + r.addend;
                    filled = true;
                };
                if !filled && !symbol.shim_addr.is_null() {
                    ptr[] = int_from_rawptr(symbol.shim_addr) + r.addend;
                    filled = true;
                }
            } else {
                ptr[] = 0;
            };
            ::enum(@type symbol.kind);
            // Since we need the absolute address in memory, even local symbols need a relocation. 
            push_fixup(self, symbol, (patch_at = (i64 = ptr), type = (DataAbsolute = (increment = r.addend))));
            @if(symbol.kind == .Local)
            if self.goal.arch != .wasm32 && self.goal.type == .Relocatable && !symbol.local_but_marked_for_relocation {
                self.local_needs_reloc&.push(r.id);
                symbol.local_but_marked_for_relocation = true;
            };
        };
    };
}

fn with_write_protect(m: *QbeModule, $body: @Fn() void) void = {
    xxx := m.need_write_protect;
    @if(xxx) apple_thread_jit_write_protect(false);
    @must_return body();
    @if(xxx) apple_thread_jit_write_protect(true);
}

MultiArchAsm :: EnumMap(Arch, []u8);

// :ThreadSafety we can't have both threads fucking with self.segments
fn add_code_bytes(m: *QbeModule, name_id: Qbe.Sym, code: *MultiArchAsm) void = {
    when_debug(m, .AddAsm, fn(out) => print_multi_asm(code, m.str(name_id), out));

    @if(enable_incremental())
    if m.save { save |
        save.push_asm(m, code, name_id);
        return();
    };
    
    @debug_assert(!m.currently_emitting_function);
    m.currently_emitting_function = true;
    
    bytes := code[m.goal.arch];
    
    code := m.segments&[.Code]&;
    
    @if(TODOWASM)
    if m.goal.arch == .wasm32 {
        import("@/backend/wasm/emit.fr")'record_wasm_function_index(m, name_id);
    };
    
    start_offset := ptr_diff(code.mmapped.ptr, code.next);
    use_symbol(m, name_id) { s |
        start_debug_info(m, s);
    };
    
    dest := "";
    marker := function_start_marker(m.goal.arch);
    with_write_protect m {
        if marker { i |
            // TODO: probably shouldn't this. it's kinda creepy. but it's convient to be able to check if something is a valid function pointer. 
            code.reserve(u32)[] = i;
        };
    
        dest = slice(code.next, bytes.len);
        dest.copy_from(bytes);
        if marker { _ |
            dest.ptr = dest.ptr.offset(-4);
            dest.len += 4;
        };
    };
    code.next = code.next.offset(bytes.len);
    
    m.do_jit_fixups(name_id, .Code, start_offset);
    finish_function(m, dest, name_id);
}

// TODO: make this work when the alias is exported but the target isn't. 
fn declare_alias(m: *Qbe.Module, target: Qbe.Sym, alias: *Qbe.Lnk) void = {
    // if the target thing is inlinable, this function can inline to the same thing. 
    target_kind := SymbolKind.Pending;
    use_symbol(m, alias.id) { a | 
        // makes future push_fixup go to the target symbol instead. 
        a.alias = target;
        
        use_symbol(m, target) { t | 
            mark_referenced(m, target, t);
            target_kind = t.kind;
            when_debug(m, .Patch, fn(o) => @fmt(o, "# declare_alias(%) = % %\n", a.name, t.name, target_kind));
            
            if target_kind == .Pending {
                for a.fixups { it |
                    push_fixup(m, t, it);
                };
                a.fixups.len = 0;
            };
            
            @if(!IS_BOOTSTRAPPING)
            if m.save { writer |
                id := writer.map_sym(m, a.id);
                it := writer.sym[id]&;
                it.segment = .Alias;
                it.alias.off = writer.map_sym(m, t.id).trunc();
            };
            
            a.inline = t.inline;
            a.inlinable = t.inlinable;
            // make sure it never gets added to inlinable_but_referenced_later (inline being non-null normally means it wasn't emitted). 
            // other than being wasteful, redefining something that already exists is bad for business, and since the other one aliases 
            // the Qbe.Fn, it would be emitted twice and double free arrays, or something bad i guess. the problem only exhibits when 
            // constant folding is disabled (which has to happen to re-bootstrap whenever the .frc version number changes). 
            // TODO: simpler repro than the whole compiler!
            a.referenced = a.referenced || !t.inline.is_null();  
        };
    };
    
    if target_kind == .Pending {
        return();
    };
    
    m.finish_alias(target, alias.id, alias.export);
}

fn finish_alias(m: *Qbe.Module, target: Qbe.Sym, alias: Qbe.Sym, export: bool) void = {
    maybe_add_export(m, alias, export);
    use_symbol(m, target) { t | 
        use_symbol(m, alias) { a | 
            a.alias = target;
            a.kind = t.kind;
            a.segment = t.segment;
            a.offset = t.offset;
            a.jit_addr = t.jit_addr;
            a.shim_addr = t.shim_addr;
            @if(!IS_BOOTSTRAPPING) {
            ::import("@/backend/wasm/abi.fr");
            @if(t.wasm_type_index != -1) save_signature(m, alias, t.wasm_type_index);
            @if(a.wasm_type_index != -1) save_signature(m, target, a.wasm_type_index);
            };
            if t.got_lookup_offset != -1 {
                a.got_lookup_offset = t.got_lookup_offset;
            };
            if a.got_lookup_offset != -1 {
                t.got_lookup_offset = a.got_lookup_offset;
            };
            a.wasm_module_function_index = t.wasm_module_function_index;
            
            when_debug(m, .Patch, fn(o) => @fmt(o, "# finish_alias(%) = %\n", a.name, t.name));
            m.do_fixups(a);
        };
    };
}

fn finish_function(m: *QbeModule, dest: []u8, name_id: Qbe.Sym) void #inline = {
    m.last_function_end = dest.ptr.offset(dest.len);
    use_symbol(m, name_id) { s |
        s.size = dest.len.trunc();
        end_debug_info(m, s);
    };
    
    @if(m.goal.arch != .wasm32)
    if m.goal.exe_debug_symbol_table {
        m.local_needs_reloc&.push(name_id);
    };
    
    ::enum(@type m.goal.type);
    if m.goal.expecting_wx && m.goal.type == .JitOnly && m.goal.arch == .aarch64 {
        // :SLOW this is done redundantly in emit_fn
        clear_instruction_cache(u8.raw_from_ptr(dest.ptr), dest.len);
    };
    
    @debug_assert(m.currently_emitting_function);
    m.currently_emitting_function = false;
}

// not a repro problem because the memory is already zeroed by page allocator
fn align_to(s: *SegmentCursor, align: i64) void = {
    extra := s.len().mod(align);
    if extra != 0 {
        s.next = s.next.offset(align - extra); 
    };
}

fn put_jit_addr(self: *QbeModule, name: Qbe.Sym, addr: rawptr) void = {
    @debug_assert_eq(self.goal.type, .JitOnly);
    use_symbol(self, name) { symbol |
        when_debug(self, .Patch, fn(o) => @fmt(o, "# put_jit_addr(%, %)\n", symbol.name, addr));
        @if(TODOWASM)
        if self.goal.arch == .wasm32 {
            // TODO: only do this if it's a function
            addr := addr.int_from_rawptr();
            if symbol.got_lookup_offset == -1 {
                symbol.got_lookup_offset = addr;
            } else {
                when_debug(self, .Patch, fn(o) => @fmt(o, "# Assign T[%] = T[%]\n", symbol.got_lookup_offset, addr));
                (self.target.wasm_jit_event)(Assign = (dest = symbol.got_lookup_offset, src = addr));
            };
        };
    
        @debug_assert(symbol.kind == .Pending, "(put_jit_addr) redeclared symbol %: %", name.id, symbol.name);
        symbol.kind = .DynamicPatched;
        symbol.jit_addr = addr;
        self.do_fixups(symbol);
    };
}

fn for_symbols(m: *QbeModule, $body: @Fn(id: Qbe.Sym, s: *SymbolInfo) void) void = {
    enumerate m.symbols& { h, bucket | 
        n := m.lock_bucket(bucket);
        syms := bucket.data.slice(0, n.zext());
        enumerate syms { i, symbol | 
            id := h + i.shift_left(IBits);
            @must_return body((id = trunc id), symbol);
        };
        @debug_assert_eq(bucket.n, n);
        bucket.mutex&.unlock();
    };
}

fn do_jit_fixups(self: *QbeModule, id: Qbe.Sym, segment: SegmentType, final_offset: i64) void = {
    use_symbol(self, id) { symbol | 
        break :: local_return;
        ::enum(@type symbol.kind);
        inbounds := segment == .ZeroInitData || (final_offset >= 0 && final_offset < self.segments&[segment].mmapped.len);
        @debug_assert(inbounds, "thats not in the segment $% = %[%]", symbol.name, segment, final_offset);
        @debug_assert(int_from_ptr(@type symbol[], symbol) != 0, "fixups for a null symbol! (forgot to set Fn.lnk.id?)"); // only catches it if you haven't had something hash to 0 yet. 
        @debug_assert(symbol.kind != .Local, "(do_jit_fixups) redeclared symbol %: % %[%]", id.id, symbol.name, segment, final_offset);
        symbol.segment = segment;
        symbol.offset = final_offset;
        symbol.kind = .Local;
        
        // harvard: jit_addr in code segment is useless. 
        @if(self.goal.arch == .wasm32 && segment == .Code) break();
        
        dest := self.segment_address(symbol.segment, symbol.offset);
        symbol.jit_addr = dest;
        fixups := symbol.fixups&;
        self.do_fixups(symbol);
        
        if self.goal.type == .Relocatable {
            // you still care about relocations because the static linker wants to move things around. :track_got_reloc
            if !symbol.local_but_marked_for_relocation {
                self.local_needs_reloc&.push(id);
                symbol.local_but_marked_for_relocation = true;
            };
            break();
        };
        
        // Since it's a local symbol, we don't care about the relocations anymore. The linker never needs to know. 
        // TODO: actually thats also true for imports becuase calls go through __got. 
        // TODO: for jitonly you do need to keep __got for weak. 
        ::tagged(@type fixups[0].type);
        unordered_retain(fixups, fn(it) => it.type&.is(.DataAbsolute));
    };
}

fn do_fixups(self: *QbeModule, symbol: *SymbolInfo) void = {
    ::tagged(FixupType);
    with_write_protect self { 
        do_fixups_impl(self, symbol);
    };
}

fn do_fixups_impl(self: *QbeModule, symbol: *SymbolInfo) void = {
    @debug_assert(!self.fixups_locked, "you cannot add more fixups after emitting for aot");
    ::enum(@type symbol.kind);
    // confusing: on wasm you need to make_exec and thus fill patches, 
    // which can reference something that has a shim before i want to mark it as Local.  
    // this feels bad, idk. 
    @debug_assert(symbol.kind != .Pending || self.goal.arch == .wasm32, "cannot do fixups of pending symbol");
    if self.goal.type == .JitOnly {
        // TODO: should probably still have the frontend make a shim for weak symbols or it sucks to debug if you make a mistake. 
        @debug_assert(!symbol.strong || !symbol.jit_addr.is_null(), "do_fixups jit null symbol %", symbol.name);
    };
    
    @if(TODOWASM)
    if self.goal.arch == .wasm32 && symbol.segment == .Code && symbol.got_lookup_offset == -1 {
        if symbol.alias == Qbe.no_symbol_S || self.goal.type != .JitOnly {
            @debug_assert(self.goal.type != .JitOnly, "wasm-jit $% should have known got_lookup_offset", symbol.name);
            // Need to wait until the end of compilation to know its index. 
            return();
        };
        
        // TODO: can this move to declare_alias?
        use_symbol(self, symbol.alias) { a |
            // :wasmgotunify
            if a.got_lookup_offset == -1 {
                a.got_lookup_offset = (self.target.wasm_jit_event)(Grow = (delta = 1));
                // TODO: only if it's a function
                if a.jit_addr.is_null() {
                    a.jit_addr = a.got_lookup_offset.rawptr_from_int();
                }
            };
            symbol.got_lookup_offset = a.got_lookup_offset;
            symbol.wasm_module_function_index = a.wasm_module_function_index;
            symbol.jit_addr = a.jit_addr;
            symbol.kind = .DynamicPatched;
        };
    };
    
    ::enum(@type symbol.kind);
    @debug_assert(symbol.kind == .Local || !symbol.pledge_local, "trying to fixup an import (%, %) but pledge_local=true", symbol.kind, symbol.name);
    
    fixups := symbol.fixups.items();
    when_debug(self, .Patch, fn(out) => @fmt(out, "# % fixups for %\n", fixups.len, symbol.name));
    new_got_reloc: ?Fixup = .None;
    fix := self.target.fixup;
    each fixups { fixup | 
        fix(self, symbol, fixup, new_got_reloc&);
    };
    if new_got_reloc { it | // avoided reallocating while iterating. rustc would be proud.
        push_fixup(self, symbol, it);
    };
}

fn ensure_got_slot(self: *QbeModule, symbol: *SymbolInfo, jit_address: rawptr) ?Fixup = {
    @if(TODOWASM) @debug_assert_ne(self.goal.arch, .wasm32);
    
    @debug_assert(!self.fixups_locked);
    new_got_reloc: ?Fixup = .None;
    if symbol.got_lookup_offset == -1 {
        // need to reserve a new __got entry.  :GotAtConstantDataBase 
        symbol.got_lookup_offset = self.got&.len();
        got := self.got&.reserve(rawptr);  // :TodoErrorMessage
        when_debug(self, .Patch) { out |
            @fmt(out, "# reserve __got[%] = %\n", symbol.got_lookup_offset / 8, symbol.name);
        };
        new_got_reloc = (Some = (patch_at = (raw = got), type = (DataAbsolute = (increment = 0))));
        if !(self.goal.got_indirection_instead_of_patches && jit_address.is_null()) { // TODO: remove this condition
            got[] = jit_address; // because we don't loop again to handle `new_got_reloc`
        }
    };
    got := self.segment_address(.ConstantData, symbol.got_lookup_offset);  // :GotAtConstantDataBase 
    got := rawptr.ptr_from_raw(got);
    if self.goal.got_indirection_instead_of_patches {
        // TODO: having a nice error message is good but it fucks you up if the code 
        //       is trying to do something sane when a weak import is missing (like choose_syscall does)
        if jit_address.is_null() {
            got[] = @as(rawptr) (fn() Never = panic("ICE: tried to call got null jit_address"));
        } else {
            got[] = jit_address;
        };
    } else {
        @debug_assert_eq(got[], jit_address, "ensure_got_slot with different address");
    };
    new_got_reloc
}

func_size_limit_bytes :: 1.shift_left(20);

fn emit_fn(f: *Qbe.Fn) void = {
    @if(enable_incremental())
    if f.globals.save { save | 
        save.push(f, true);
        return();
    };
    
    m := f.globals;
    @debug_assert(!m.currently_emitting_function);
    m.currently_emitting_function = true;
    
    code := m.segments&[.Code]&;
    start_offset := code.len();
    name_id := f.lnk.id;
    
    // We know we're emitting the function right here so we can do old fixups now. 
    maybe_add_export(m, name_id, f.lnk.export);
    m.do_jit_fixups(name_id, .Code, start_offset);
    
    use_symbol(m, name_id) { s |
        start_debug_info(m, s);
    };
    pending_immediate_fixup_got := {m.target.emit_fn}(f);
    size := code.len() - start_offset;
    @assert_lt(code.len(), code.mmapped.len, "too much code");
    
    // :FuncSizeLimit 
    // b.cond gives you 19 bits, but encoded/4, but signed so that's 20 bits.  
    // you can remove this limit on the function but then have to add the check when emitting each branch. 
    @assert_lt(size, func_size_limit_bytes, "we don't allow a function larger than one arm64 instruction can jump");
    
    code_bytes := code.mmapped.subslice(start_offset, size);
    finish_function(m, code_bytes, name_id);
    
    @if(m.goal.arch != .wasm32 || m.goal.type != .JitOnly)
    when_debug(m, .Disassemble) { out |
        @fmt(out, "# disassembly of '%' (% bytes)\n", m.str(f.lnk.id), code_bytes.len);
        dis := m.goal.dis;
        dis(out, code_bytes, m.goal.arch);
    };
    
    // TODO: don't clear_instruction_cache in finish_function if i have to redo it here
    @if(pending_immediate_fixup_got.len != 0)
    with_write_protect m {
        fixup := m.target.fixup;
        start := code_bytes.ptr;
        //start := m.segments&[.Code].next;
        for pending_immediate_fixup_got& { patch, id |
            use_symbol(m, id) { symbol |
                new_got_slot: ?Fixup = .None;
                fixup(m, symbol, patch&, new_got_slot&);
                if new_got_slot { it |
                    push_fixup(m, symbol, it);
                };
            };
        };
        
        m.last_function_end = m.segments&[.Code].next;
        @if(m.goal.expecting_wx && m.goal.type == .JitOnly && m.goal.arch == .aarch64)
        clear_instruction_cache(u8.raw_from_ptr(start), u8.raw_from_ptr(m.last_function_end));
    };
}

fn reserve_stub(m: *Qbe.Module, symbol: *SymbolInfo, $T: Type) *T #generic = {
    start_debug_info(m, symbol);
    code := m.segments&.index(.Code);
    @debug_assert(!m.currently_emitting_function);
    @debug_assert_eq(symbol.offset, -1);
    symbol.offset = code.len();
    symbol.size = size_of(T);
    @debug_assert_eq(symbol.segment, .Code, "zero value");
    trampoline := code.reserve(T);
    m.last_function_end = code.next;
    end_debug_info(m, symbol);
    trampoline
}

// TODO: this sucks. should generate my own disassemblers (that can be statically linked in easily) from the cpu specs. 
fn llvm_mc_dis(out: *List(u8), code: []u8, arch: Arch) void = {
    #use("@/lib/sys/subprocess.fr");
    #use("@/lib/sys/fs.fr");
    
    if!is_linking_libc() {
        out.push_all("no disassembler included\n");
        return();
    };
    
    arch_name := @match(arch) {
        fn x86_64()  => "--arch=x86-64";
        fn aarch64() => "--arch=aarch64";
        fn wasm32()  => "--arch=wasm32";
        fn rv64()    => "--arch=riscv64";
    };
    hex: List(u8) = list(code.len * 5, temp());
    enumerate code { i, byte |
        hex&.push_prefixed_hex_byte(byte[]);
        hex&.push_all(@if(i != 0 && i.add(1).mod(4) == 0, "\n", " "));
    };
    file := open_temp_file();
    file.fd&.write(hex.items());
    DIS :: "llvm-mc";
    // varient 1 means intel syntax. ignored when doing arm. 
    args := @slice(arch_name, "--disassemble", "-output-asm-variant=1", "--show-encoding", file&.s_name());
    _ok, o, e := exec_and_catch(DIS, args, temp());
    file.remove();
    out.push_all(o.items());
    out.push_all(e.items());
}

fn push_fixup(m: *QbeModule, symbol: *SymbolInfo, fix: Fixup) void = {
    a := m.forever&.borrow();
    if symbol.alias != Qbe.no_symbol_S {
        use_symbol(m, symbol.alias) { target |
            push_fixup(m, target, fix);
        };
        return();
    };
    
    when_debug(m, .Patch) { out |
        @fmt(out, "# push % at % to '%'\n", fix.type&, fmt_hex(fix.patch_at.addr), symbol.name);
    };
    
    symbol.fixups&.push(fix, a);
}

fn follow_alias(m: *Qbe.Module, id: Qbe.Sym) Qbe.Sym = {
    use_symbol(m, id) { s |
        if s.alias != Qbe.no_symbol_S {
            id = follow_alias(m, s.alias);
        };
    };
    id
}

//////////////////////////////////
// Shared by native AOT targets //
//////////////////////////////////

fn main_entry_point_vaddr(m: *QbeModule) i64 = {
    @debug_assert_ne(m.goal.arch, .wasm32, "only makes sense for native targets");
    @debug_assert_ne(m.goal.type, .Dynamic, "shared libraries don't have an entry point");
    @debug_assert(m.fixups_locked, "this is not threadsafe");
    symbol := m.get_symbol_info(m.intern(m.goal.entry_point));
    assert(symbol.kind == .Local, "no exported main function?");
    @debug_assert_ge(symbol.offset, m.goal.commands_size_guess);
    symbol.offset
}

fn patch_pending_symbols(m: *QbeModule) void = {
    @debug_assert_ne(m.goal.arch, .wasm32, "only makes sense for native targets");
    // fill_from_libc is wrong because you might be cross compiling and disagree about what things exist. 
    for_symbols m { id, symbol |  // :SLOW  just keep list of pending symbols instead
        if symbol.kind == .Pending && symbol.fixups.len != 0 {
            m.imports&.push(id); 
            symbol.kind = .DynamicPatched;
            @debug_assert(symbol.jit_addr.is_null());
            m.do_fixups(symbol);
        };
    };
}

fn debug_log_byte_size(m: *QbeModule) void = {
    // TODO: remove
    code_count := m.segments&[.Code]&.len() - m.goal.commands_size_guess;
    data_count := m.segments&[.MutableData]&.len();
    @if(show_backend_stats())
    @eprintln(">>> % bytes of code, % bytes of data.", code_count, data_count); 
}

fn live_segment_part(m: *QbeModule, s: SegmentType) []u8 = {
    s := m.segments&[s]&;
    s.mmapped.slice(0, ptr_diff(s.mmapped.ptr, s.next))
}

AotDebugInfo :: import("@/lib/crash_report.fr").AotDebugInfo;

// on wasm the code isn't in accessible memory, so this way of doing stack traces doesn't work at all. 
fn seal_debug_info(m: *QbeModule, debug_source_code: []u8, include: bool, files_bytes: []u8) void = {
    base_p    := m.intern("__franca_base_address");
    harvard := m.goal.arch == .wasm32;
    
    ::enum(@type m.goal.type);
    if m.goal.type == .Exe || harvard {
        // TODO: figure out how to make this work for .Relocatable
        //       it is needed for relocations without libc on linux (in franca_runtime_init).
        // HACK: you have to be able to have it in the frc and then !include when importing it so just use the existing one :AnnoyingDoubleSeal
        use_symbol(m, base_p) { s |
            ::enum(@type s.kind);
            if s.kind != .Local { 
                m.do_jit_fixups(base_p, @if(harvard, .MutableData, .Code), 0);
            };
        };
    };
    
    ::[]u64;
    if @is(m.goal.type, .Relocatable, .JitOnly) {
        b := FRHOSTED_MAGIC;
        m.emit_data(id = base_p, template = (Bytes = b&.slice(1).interpret_as_bytes()), align = 8, relocations = empty());
    };
    if @is(m.goal.type, .Cached, .CachedEarly) {
        //m.set_library(base_p, "franca", false);
    };
        
    id := m.intern("__franca_aot_debug_info");
    if harvard || !include || @is(m.goal.type, .Relocatable) {
        // HACK: you have to be able to have it in the frc and then !include when importing it so just use the existing one :AnnoyingDoubleSeal
        use_symbol(m, id) { s |
            ::enum(@type s.kind);
            if s.kind != .Local {
                m.emit_data(id = id, template = (Zeroes = size_of(AotDebugInfo)), align = 8, relocations = empty());
            };
        };
        return();
    };
    // TODO: figure out how to make this work for .Relocatable
    
    code := m.segments&.index(.Code);
    data: AotDebugInfo = (
        code_segment = (ptr = zeroed(*u8), len = ptr_diff(code.mmapped.ptr, code.next) - m.text_padding()),
        headers = m.debug_info.headers.items(),
        payload = m.debug_info.data.items(),
        source = debug_source_code,
        files = files_bytes,
        nullable_cached_codemap = zeroed rawptr,
    );
    @if(::safety_check_enabled(.DebugAssertions))
    check_debug_info(data&, code.mmapped.ptr.offset(m.text_padding()), m.goal.arch);
    
    // TODO: don't force having a name for these. 
    names := @const_slice("__franca_code_segment", "__franca_debug_headers", "__franca_debug_data", "__franca_debug_source", "__franca_debug_files");

    // `code_segment` doesn't point to new data, it's already in the exe
    start_id := m.intern("__franca_code_segment");
    use_symbol(m, start_id) { s |
        s.segment = .Code;
        s.offset = m.text_padding();
        s.kind = .Local;
        s.jit_addr = u8.raw_from_ptr(code.mmapped.ptr.offset(m.text_padding()));
        mark_referenced(m, start_id, s);
    };
    
    i := 0;
    r := temp().alloc_uninit(Dat2.Reloc, 5);
    inline_for get_fields(AotDebugInfo) { $f | 
        @if(::(size_of(f[].ty) == 16)) {
            // a relocation for the data pointer of this field
            r[i] = (id = m.intern(names[i]), off = ::f[].byte_offset.trunc());
            if i > 0 { // skip code_segment since that's already in the executable 
                // a seperate symbol for the raw bytes this field references
                m.emit_data(id = r[i].id, template = (Bytes = AotDebugInfo.get_field_ptr(data&, f)[]), align = 8, relocations = empty());
            };
            i += 1;
        };
    };
    @debug_assert_eq(i, r.len);
    ::[]AotDebugInfo;
    m.emit_data(id = id, template = (Bytes = data&.slice(1).interpret_as_bytes()), align = 8, relocations = r);
}

fn function_start_marker(a: Arch) ?u32 = {
    (Some = @match(a) {
        fn aarch64() => import("@/backend/arm64/bits.fr").branch_target_marker;
        fn x86_64()  => import("@/backend/amd64/bits.fr").endbr64;
        @default => return(.None);
    })
}

check_debug_info :: fn(debug_info: *AotDebugInfo, code_segment_base: *u8, arch: Arch) void = {
    function_start_marker := function_start_marker(arch) || return();
    cursor := debug_info.headers;
    off := 0;
    while => cursor.len > 0 {
        @assert_lt(off, debug_info.code_segment.len, "malformed debug info. (sum of function sized > code segment).");
        off_to_data, r, ok := read_leb128(cursor, false);
        cursor = r;
        size, r, ok := read_leb128(cursor, false);
        cursor = r;
        
        @assert_lt(off_to_data, debug_info.payload.len);
        data := debug_info.payload.rest(off_to_data);
        name_len, r, ok := read_leb128(data, false);
        data = r;
        name := data.slice(0, name_len);
        data = data.rest(name_len);
        
        first_4_bytes := code_segment_base.offset(off).slice(4);
        @assert_eq(first_4_bytes.peek_type(u32)[], function_start_marker, "missing fn start marker for %", name);
        
        off += size;
    };
}

#use("@/compiler/codemap.fr");
fn encode_debug_files(files: []File) Ty([]u8, []u8) = {
    source := u8.list(temp());
    headers := u8.list(temp());
    leb128_unsigned(headers&, files.len);
    for files { file | 
        source&.push_all(file.content);
        leb128_unsigned(headers&, file.content.len);
        leb128_unsigned(headers&, file.name.len);
        push_all(headers&, file.name);
    };
    (source.items(), headers.items())
}

fn start_debug_info(m: *QbeModule, s: *SymbolInfo) void = {
    d := m.debug_info&;
    @if(!d.enabled) return();
    leb128_unsigned(d.headers&, d.data.len);
    leb128_unsigned(d.data&, s.name.len);
    push_all(d.data&, s.name);
    d.last_off_func = 0;
    d.last_off_source = 0;
}

fn end_debug_info(m: *QbeModule, s: *SymbolInfo) void = {
    d := m.debug_info&;
    if m.goal.exe_debug_symbol_table && m.goal.os == .macos {
        leb128_unsigned(d.macho_function_starts&, s.size.zext());
    };
    @if(!d.enabled) return();
    leb128_unsigned(d.headers&, s.size.zext());
    // TODO: length prefix but that's annoying
    leb128_unsigned(d.data&, 4);  // :DebugTag
    leb128_unsigned(d.data&, 0);
    leb128_unsigned(d.data&, 0);
}

fn add_debug_info(m: *QbeModule, i: *Qbe.Ins, off_in_func: i64) void = {
    d := m.debug_info&;
    @if(!d.enabled) return();
    hi, lo := (rsval(i.arg&[0]).intcast(), rsval(i.arg&[1]).intcast());
    tag := hi.shift_right_logical(16);  // :DebugTag
    offset_in_source := hi.bit_and(0xFFFF).shift_left(16).bit_or(lo);
    code_delta := off_in_func - d.last_off_func;
    source_delta := offset_in_source - d.last_off_source;
    push(d.data&, tag.trunc());
    leb128_unsigned(d.data&, code_delta);
    d.last_off_func = off_in_func;
    leb128_signed(d.data&, source_delta);
    d.last_off_source = offset_in_source;
}

// TODO: collect_aot_fixups compiles if you typo to *Symbol, :FUCKED
FixP :: @struct(symbol: *SymbolInfo, fix: *Fixup);
fn collect_aot_fixups(m: *QbeModule) Ty([]FixP, []*SymbolInfo) = {
    // :SLOW keep a list because most will probably be local with no relocations. 
    fixups := list(FixP, temp());
    symbols := list(*SymbolInfo, temp());
    
    symbol_count := 0;
    for_symbols m { id, s | 
        first := true;
        each s.fixups& { f | 
            ::tagged(@type f.type);
            if f.type&.is(.DataAbsolute) { 
                fixups&.push(symbol = s, fix = f);
                if first {
                    first = false;
                    symbols&.push(s);
                }
            };
        };
    };
    @debug_assert_ge(symbols.len, m.imports.len, "more imports than symbols!"); 
    (fixups.items(), symbols.items())
}

Patch :: @struct(offset_from_start: i64, cond: i32, target_bid: i32, reg: Qbe.Ref = Qbe.Null/*rv only*/);

fn store_op(k: Qbe.Cls) Qbe.O = {
    k := @as(i32) k;
    @debug_assert_lt(k, 4);
    @as(Qbe.O) @as(i32) Qbe.O.storew.raw() + k  // :StoreOrder
}

fn segment_address(self: *QbeModule, segment: SegmentType, offset_in_segment: i64) rawptr = {
    data := self.segments&[segment]&;
    u8.raw_from_ptr(data.mmapped.ptr.offset(offset_in_segment))
}

// This will get more complicated when i can have multiple of the same segment. 
fn distance_between(m: *QbeModule, start_segment: SegmentType, start_offset: i64, end_segment: SegmentType, end_offset: i64) i64 = {
    @debug_assert(end_offset >= 0 && start_offset >= 0);
    ptr_diff(m.segment_address(start_segment, start_offset), m.segment_address(end_segment, end_offset))
}

fn current_offset(m: *QbeModule, segment: SegmentType) i64 = {
    ptr_diff(m.segments&[segment].mmapped.ptr, m.segments&[segment].next)
}

fn align_to(m: *QbeModule, segment: SegmentType, align: i64) void = {
    m.segments&.index(segment).align_to(align);
}
