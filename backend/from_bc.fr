// This is a temporary measure. The plan is for the frontend to generate the qbe-style ir directly. 
// But before I start ripping stuff apart I need to make sure this is better in every way than what i had before. 
// - I have to be able to understand the qbe passes enough to port them to Franca and make the variable names less obfuscated. 
// - I have to be able to replace thier backends with generating machine code directly.
//   Both for aot and jitting into an mmap-exec-ed buffer for comptime execution. 
// - It has to be faster than llvm debug mode (it already runs faster, i think it will compile faster by not needing to parse + emit text).
// - It has to be able to generate llvm-ir for release or debug-info builds.
//   I'm sure that will involve painfully inserting casts. Also have to be able to track debug source locations through the passes (i think Odbgloc already does that). 
// - Have to expose it to user comptime code for #bc (examples/bf2bc.fr)
//   maybe add optional function argument type checking to catch basic mistakes.
// - Have to make easy to build static + dynamic.
// - expose the pass debug logging with #log_ir("AF") or something
// - be able to run thier .ssa tests
//
// TODO: at the end i should make the math stuff not #fold becuase its probably faster to let the backend do it. 
//       but then the front end wouldn't see those expressions as constant for other #fold calls.

fn finished(self: *EmitQbe2, fid: FuncId) void = {
    name: List(u8) = list(temp()); 
    self.fmt_fn_name(fid, name&);
    fnn := self.b&.build(name.items());
    run_qbe_passes(fnn&);
    self.body = zeroed(*FnBody); // :EVIL     but just avoiding confusion. 
    self.context = QbeNull;
}; 

#include_std("compiler/backend/walk_bc.fr");

fn fdopen(fd: Fd, mode: CStr) *FILE #libc;
fn fopen(filename: CStr, mode: CStr) *FILE #libc;
fn fwrite(ptr: rawptr, size: i64, nmemb: i64, stream: *FILE) i64 #libc;
fn fclose(stream: *FILE) voidResult #libc;

fn write(stream: *FILE, bytes: []u8) voidResult = {
    written := fwrite(u8.raw_from_ptr(bytes.ptr), 1, bytes.len, stream);
    if written < bytes.len {
        return(value = -1);
    };
    (value = 0)
}

emit_qbe_included_dyn :: fn(m: *QbeModule, comp: *CompCtx, fns: [] FuncId, entry: ProgramEntry) BucketArray(u8) = {  
    @assert(ptr_cast_unchecked(@type comp.vtable.emit_qbe_included, i64, comp.vtable.emit_qbe_included&)[] != 0, "emit_qbe_included is not enabled");
    {comp.vtable.emit_qbe_included}(QbeModule.raw_from_ptr(m), comp, fns, entry)
};

emit_qbe_included_sta :: fn(m: *QbeModule, comp: *CompCtx, fns: [] FuncId, entry: ProgramEntry) BucketArray(u8) = {    
    emit_qbe_included(QbeModule.raw_from_ptr(m), comp, fns, entry)
};

init_default_qbe_module :: fn(module_out: rawptr, qbe_env_goal: rawptr) void = {
    m := QbeModule.ptr_from_raw(module_out);
    e := QbeTargetEnv.ptr_from_raw(qbe_env_goal);
    m[] = init_default_module(e[]);
};

init_default_module_dyn :: fn(vtable: *ImportVTable, goal: QbeTargetEnv) QbeModule = {  
    m := @uninitialized QbeModule;
    @assert(ptr_cast_unchecked(@type vtable.init_default_qbe_module, i64, vtable.init_default_qbe_module&)[] != 0, "init_default_qbe_module is not enabled");
    {vtable.init_default_qbe_module}(QbeModule.raw_from_ptr(m&), QbeTargetEnv.raw_from_ptr(goal&));
    m
};

init_default_module_sta :: fn(_: *ImportVTable, goal: QbeTargetEnv) QbeModule = {      // just for consistant naming
    init_default_module(goal)
};

// this returns asm text or mach-o bytes depending on m.goal
emit_qbe_included :: fn(m: rawptr, comp: *CompCtx, fns: [] FuncId, entry: ProgramEntry) BucketArray(u8) = {    
    m := QbeModule.ptr_from_raw(m);
    smuggle_module_pointer[] = m;
    comp := comp[];
    out_fd := TmpFile.zeroed();
    if !m.making_macho() { 
        out_fd = open_temp_file();
        outf_local := fdopen(out_fd.fd, "a".sym().c_str());
        ::ptr_utils(FILE);
        assert(!outf_local.is_null(), "failed to open temp file");
        @println("Output asm to %", out_fd&.s_name());
        m.outf = outf_local;
    };
    
    target: TargetEnv = (arch = m.goal.arch, os = m.goal.os);
    ir_text := {CodeGen(EmitQbe2).emit}(comp, fns, entry, target&);

    aaa: BucketArray(u8) = init(0, temp());
    
    m.emit_suspended_inlinables();
    if m.making_macho() { 
        chunks := output_macho(m);
        for chunks { c |
            aaa&.push_bucket(maybe_uninit = c, len = c.len, gpa = temp());
        };
    } else {
        inline_asm_functions := ir_text&.pop_current_bucket().unwrap();
        ::ptr_utils(FILE);
        write(m.outf, inline_asm_functions.items()).unwrap();
        fclose(m.outf).unwrap();
        asm := temp().read_to_string(out_fd&.s_name());
        aaa&.push_bucket(asm);
    };
    aaa
};

smuggle_module_pointer :: @static(*QbeModule);

EmitQbe2 :: @struct(
    comp: CompCtx,
    b: QbeBuilder,
    block_args: List(Qbe.Ref),
    indirect_return_slot := Qbe.Ref.zeroed(),
    out: BucketArray(u8),
    current: BbId,
    next_var: i64 = 0,
    return_value_type_sizes: BitSet,
    inline_asm: List(u8),
    current_has_indirect_return := false,
    os: Os,
    signeture := PrimSig.zeroed(), // TODO: HACK   also now redundant except that you don't always have a body. 
    body := zeroed(*FnBody), // :EVIL
    pair_type_id := 99999999, // filled by init
    context := QbeNull,
    implicit_context: bool,
    
    $Val := Qbe.Ref, // TODO: const can't be first (doesn't parse).  -- Jun 14
);

// TODO: dependency problem so can't call this `init`
fn new(comp: CompCtx, alloc: Alloc, arch: Arch, os: Os) EmitQbe2 #inline = {
    s: EmitQbe2 = (
        comp = comp, 
        b = init(libc_allocator, smuggle_module_pointer[]), 
        block_args = list(temp()), 
        out = init(12, alloc), 
        current = BbId.zeroed(), 
        return_value_type_sizes = empty(), 
        inline_asm = list(alloc), 
        os = os,
        // TODO: this will get more complicated when we want to support comptime execution with this backend. 
        implicit_context = comp.get_build_options()[].implicit_context_runtime,
    );
    smuggle_module_pointer[] = zeroed(*QbeModule);
    
    f: []Qbe.Field = @slice(@as(Qbe.Field) (type = .Fl, len = 1.trunc()), @as(Qbe.Field) (type = .Fl, len = 1.trunc()));
    s.pair_type_id = s.b&.struct_type(f, 16, 3);
    
    if arch == .x86_64 {
        s.inline_asm&.push_all(".intel_syntax noprefix\n");
    };
    s
}

fn emit_function_husk(self: *EmitQbe2, fid: FuncId, signeture: PrimSig, $emit_body: @Fn() void) void = {
    //@println("Emitting F% %", fid.to_index(), self.comp.get_string(self.comp.get_function(fid)[].name));
    emit_body();
}

fn emit_entry_points_and_debug_info(gen: *CodeGen(EmitQbe2), comp: CompCtx, fns: []FuncId, entry: ProgramEntry) void = {
    self := gen.backend&;
    
    // give it a chance to spit out the constants it wanted to add (like when it loads to get a double literal)
    if self.b.globals.want_text_asm {
        {self.b.globals.target.emitfin}(self.b.globals.outf);
    };
    //self.b.globals.debug_out = fdopen(STD_ERR, "a".sym().c_str());
    //each self.b.globals.debug { b | 
    //    b[] = true;
    //};

    @match(entry) {
        fn TestRunnerMain() => {
            fake_decl_name := @format("test_runner_main\0") temp();
            entry := self.b&.push_block();
            self.current = entry;
            env := self.b&.push_inst(self.current, .pare, .Kl, QbeNull, QbeNull);
            _ := self.b&.push_inst(self.current, .par, .Kl, QbeNull, QbeNull);
            _ := self.b&.push_inst(self.current, .par, .Kl, QbeNull, QbeNull);
            // TODO: warn if fns has duplicates
            for fns {f|
                callee := self.inst_func_ref(f);
                self.b&.push_inst0(self.current, .arge, .Kl, env, QbeNull);
                self.b&.push_inst0(self.current, .call, .Kw, callee, QbeNull);
            };
            self.b&.end_block(self.current, (type = .retl, arg = self.b&.push_literal(0)));
            fnn := self.b&.build(fake_decl_name.items());
            run_qbe_passes(fnn&);
            
            // now actually call it
            self.init_runtime_entry_point(ptr = fake_decl_name.maybe_uninit.ptr);
        };
        fn GiveMeTheCodeAndGiveItToMeRaw() => ();
        fn ExportWithNames() => {
            // TODO: warn if fns has duplicates
            for fns { fid |
                gen.backend&.write_export_bounce(fid);
            };
        };
        fn WrapMain() => {
            @assert(fns.len == 1, ".WrapMain expected a single entry point");
            self.init_runtime_entry_point(self.fn_name_cstr(fns[0]));
        }
    };
    
    // HACK we rely on this being called at the very end for our secret returning inline asm
    // TODO: clean this up and just return a struct
    gen.backend.out&.push_bucket(gen.backend.inline_asm);
    gen.backend.inline_asm = List(u8).zeroed();
}

fn init_runtime_entry_point(self: *EmitQbe2, usermain_name: CStr) void = {
    env := self.comp.get_comptime_env();
    runtime_init := env.runtime_init.expect("declaration of franca_runtime_init");
    
    self.b.lnk.export = true;
    entry := self.b&.push_block();
    self.current = entry;

    argc := self.b&.push_inst(self.current, .par, .Kl, QbeNull, QbeNull);
    argv := self.b&.push_inst(self.current, .par, .Kl, QbeNull, QbeNull);
    user_main := self.b&.push_symbol(usermain_name);
    runtime_init := self.inst_func_ref(runtime_init);
    self.b&.push_inst0(self.current, .arg, .Kl, argc, QbeNull);
    self.b&.push_inst0(self.current, .arg, .Kl, argv, QbeNull);
    self.b&.push_inst0(self.current, .arg, .Kl, user_main, QbeNull);
    self.b&.push_inst0(self.current, .call, .Kw, runtime_init, QbeNull);
    self.b&.end_block(self.current, (type = .ret0, arg = QbeNull));
    fake_decl_name := @format("main\0") temp();
    fnn := self.b&.build(fake_decl_name.items());
    run_qbe_passes(fnn&);
}

fn emit_bounce_fn(self: *EmitQbe2, impl_name_callee: Str, fake_decl_name: Str, signeture: PrimSig, private: bool) void = {
    //@println("emit_bounce_fn %", fake_decl_name);
    self.b.lnk.export = !private;
    self.context = QbeNull;
    
    entry := self.b&.push_block();
    self.current = entry;
    self.block_args = list(0, temp());
    
    params: List(Qbe.Ref) = list(temp());
    for signeture.args { prim | 
        params&.push(self.b&.push_parameter(qbe_real_class(prim)));
    };
    
    self.current_has_indirect_return = signeture.first_arg_is_indirect_return;
    if signeture.first_arg_is_indirect_return {
        size := self.b&.push_literal(@as(i64) signeture.return_value_bytes.zext());
        self.indirect_return_slot = self.b&.push_inst(entry, .alloc8, .Kl, size, QbeNull);
        params&.insert(0, self.indirect_return_slot);
        // :set_aggragate_return_index
        self.b.aggragate_return_index = (Some = self.b&.opaque_type_slow(signeture.return_value_bytes.zext(), 3));
    };
    if signeture.ret2.is_some() {
        self.indirect_return_slot = self.b&.push_inst(entry, .alloc8, .Kl, self.b&.push_literal(16), QbeNull);
    };
    
    fuck := @format("%\0", impl_name_callee) temp();
    callee := self.b&.push_symbol(ptr = fuck.maybe_uninit.ptr);
    self.signeture = signeture;
    ret := self.inst_call(params.items(), signeture, callee, true); // TODO: :Context?
    
    self.inst_return(ret);
    fnn := self.b&.build(fake_decl_name);
    run_qbe_passes(fnn&);
}

// TODO: copy-paste from DynamicImport but reversed so its a pain. 
fn write_export_bounce(self: *EmitQbe2, fid: FuncId) void = {
    func := self.comp.get_function(fid);
    export_name := self.comp.get_string(func.name);
    internal_name: List(u8) = list(temp()); 
    self.fmt_fn_name(fid, internal_name&);
    
    sig := {self.comp.vtable.prim_sig}(self.comp.data, func).unwrap();
    self.emit_bounce_fn(internal_name.items(), export_name, sig, false);
}

fn emit_constant(self: *EmitQbe2, id: BakedVarId) void = {
    _, value := {self.comp.vtable.get_baked}(self.comp.data, id)[];
    idx: i64 = id.id.zext();
    
    dat := Qbe.Dat.zeroed();
    lnk: Qbe.Lnk = ();
    fuck := @format("g%\0", idx) temp();
    dat.name = (ptr = fuck.maybe_uninit.ptr);
    dat.lnk = lnk&;
    
    emit_data :: fn(d) => self.b.globals.new_emit_data(d);
    
    dat.type = .DStart;
    emit_data(dat&);
    @match(value&) {
        (fn Zeros(len) => {
            dat.type = .DZ;
            dat.u.num = len[];
            emit_data(dat&);
        });
        (fn Bytes(bytes) => {
            dat.type = .DB;
            dat.is_str = true;
            dat.u.str = bytes[].items();
            emit_data(dat&);
            dat.is_str = false;
        });
        (fn VoidPtrArray(parts) => {
            for(parts[].items()){inner|
                @match(inner) {
                    (fn FnPtr(f) => {
                        dat.type = .DL;
                        // TODO: hack because of new deduplication
                        func := self.comp.get_function(f);
                        @if_let(func.body&) fn Redirect(inner) => {
                            f = inner[];
                        };
                        dat.is_ref = true;
                        fuck := @format("%\0", (self, f)) temp();
                        dat.u.ref = (name = (ptr = fuck.maybe_uninit.ptr), off = 0);
                        emit_data(dat&);
                        dat.is_ref = false;
                        // TODO: make sure we emitted the function. 
                    });
                    (fn AddrOf(id) => {
                        dat.type = .DL;
                        dat.is_ref = true;
                        fuck := @format("g%\0", @as(i64) id.id.zext()) temp();
                        dat.u.ref = (name = (ptr = fuck.maybe_uninit.ptr), off = 0);
                        emit_data(dat&);
                        dat.is_ref = false;
                    });
                    (fn Num(v) => {
                        dat.type = .DL; // TODO: small prims
                        dat.u.num = v.value;
                        emit_data(dat&);
                    });
                };
            };
        });
    };
    dat.type = .DEnd;
    emit_data(dat&);
}

fn emit_special(self: *EmitQbe2, f_id: FuncId, body: *FuncImpl, func: *Func, bc: *FnBody, pending: *List(FuncId)) bool = {
    comp := self.comp;
    @match(body) {
        fn Normal(_) => { panic("ICE: empty body but expr"); };
        fn Redirect(f) => {
            // TODO: assert that 'f' is flagged for being emitted?
            //       currently just trusting that emit_bc replaced all actual uses. 
            //       could also just have the front end check if body is redirect before adding to callees list. -- Jun 27
            
            pending.push(f[]);
            
            // :sema_regression :ExtraRedirectShim
            assert(f[] != f_id, "redirect to yourself");
            new_name := @format("%", (self, f[])) temp();
            old_name := @format("%", (self, f_id)) temp();
            self.emit_bounce_fn(new_name.items(), old_name.items(), bc.signeture, true);
            return(true);
        }
        fn Merged(parts) => { 
            each(parts[].items()) {check: *FuncImpl| 
                if(self.emit_special(f_id, check, func, bc, pending), => return(true));
            };
        }
        fn DynamicImport(name) => { 
            // TODO: do i need to hackily do the same for ComptimeAddr and hope for the best? ideally the forntend would handle that instead. 
            import_name := comp.get_string(name[]);
            self.forward_declare(bc.signeture, false, import_name);
            name := @format("%", (self, bc.func)) temp();
            self.emit_bounce_fn(import_name, name.items(), bc.signeture, true);
            return(true);
        }
        fn TargetOsSplit(it) => {
            if it.os == self.os {
                // TODO: :copy-paste from emit_special:redirect
                pending.push(it.fid);
                assert(it.fid != f_id, "redirect to yourself");
                new_name := @format("%", (self, it.fid)) temp();
                old_name := @format("%", (self, f_id)) temp();
                self.emit_bounce_fn(new_name.items(), old_name.items(), bc.signeture, true);
                return(true);
            };
        }
        @default fn() void => return(false);
    };
    false
}

fn forward_declare(self: *EmitQbe2, sig: PrimSig, private: bool, name: Str) void = {
    // Qbe doesn't need external functions to be declared. The call instruction has the type information. 
}

fn emit_special_asm(self: *EmitQbe2, body: *FuncImpl, func: *Func, bc: *FnBody, target: *TargetEnv) bool = {
    arch := target.arch;
    comp := self.comp;
    @match(body) {
        (fn Merged(parts) => { 
            each(parts[].items()) {check: *FuncImpl| 
                if(self.emit_special_asm(check, func, bc, target), => return(true));
            };
        });
        (fn JittedAarch64(code) => { 
            if(arch.ne(Arch.aarch64), => { return(false); });
            fuck := @format("%\0", (self, bc.func)) temp();
            self.b.globals.add_code_bytes(@as(CStr) (ptr = fuck.maybe_uninit.ptr), @as([]u8) (ptr = ptr_cast_unchecked(u32, u8, code.ptr), len = code.len * 4));
            return(true);
        });
        fn X86AsmBytes(code) => { // :copy-paste
            if target.arch != .x86_64 { 
                return(false); 
            };
            fuck := @format("%\0", (self, bc.func)) temp();
            self.b.globals.add_code_bytes(@as(CStr) (ptr = fuck.maybe_uninit.ptr), code.items());
            return(true);
        }
        @default fn() void => return(false);
    };
    false
}

fn setup(self: *EmitQbe2, body: *FnBody, vars_out: *List(Qbe.Ref)) void = {
    entry := self.b&.push_block();
    self.signeture = body.signeture;
    self.body = body;
    params: List(Qbe.Ref) = list(temp());
    self.context = QbeNull;
    if body.context && self.implicit_context {
        self.context = self.b&.push_inst((id = 0), .pare, .Kl, QbeNull, QbeNull);
    };
    for body.signeture.args { prim | 
        params&.push(self.b&.push_parameter(qbe_real_class(prim)));
    };
    
    // TODO: waste for ssa vars, they just get set to the value. -- Jun 14
    enumerate body.vars.items() { i, ty |
        op := Qbe.O.alloc4;
        align := 4;
        if(ty.align > align.trunc(), => { align = 8; op = .alloc8; });
        if(ty.align > align.trunc(), => { align = 16; op = .alloc16; });
        
        size := self.b&.push_literal(@as(i64) ty.size.zext());
        v := self.b&.push_inst(entry, op, .Kl, size, QbeNull);
        vars_out.push(v);
    };
    // TODO: use phi nodes cause this is stupid but that's such a pain in the ass. 
    // TODO: actually qbe vars are mutable so could just use those. 
    // I use these for block arguments. 
    max_args := 0;
    each body.blocks.items() { b |
        max_args = max_args.max(b.arg_prims.len);
    };
    self.block_args = list(max_args, temp());
    range(0, max_args) {i|
        v := self.b&.push_inst(entry, .alloc8, .Kl, self.b&.push_literal(8), QbeNull);
        self.block_args&.push(v);
    };
    
    self.current_has_indirect_return = body.signeture.first_arg_is_indirect_return;
    shift := if body.signeture.first_arg_is_indirect_return {
        size := self.b&.push_literal(@as(i64) body.signeture.return_value_bytes.zext());
        self.indirect_return_slot = self.b&.push_inst(entry, .alloc8, .Kl, size, QbeNull);
        self.b&.push_inst0(entry, .storel, .Kw, self.indirect_return_slot, self.block_args[0]);
        // :set_aggragate_return_index
        self.b.aggragate_return_index = (Some = self.b&.opaque_type_slow(body.signeture.return_value_bytes.zext(), 3));
        1
    }{| 0 };
    
    if body.signeture.ret2.is_some() {
        self.indirect_return_slot = self.b&.push_inst(entry, .alloc8, .Kl, self.b&.push_literal(16), QbeNull);
    };
    
    enumerate body.signeture.args {i, ty|
        // :StoreAlwaysKw
        self.b&.push_inst0(entry, qbe_store(ty[]), .Kw, params[i], self.block_args[i + shift]);
    };
    
    // It's crimes to jump to the start block so don't use that as our entry block. 
    self.b&.end_block(entry, (type = .jmp, target1 = (id = 1)));
    
    // :AllOurBlocksUpFront
    // The backend might not go to blocks in order but we want BbIds to match. 
    // And we need to add more later for switches (and not have those indices mess us up)
    while => self.b.blocks.len <= body.blocks.len + 1 {
        self.b&.push_block();
    };
}

fn fmt_fn_name(self: *EmitQbe2, f: FuncId, out: *List(u8)) void = {
    opts := self.comp.get_build_options();
    if opts.retain_function_names {
        func := self.comp.get_function(f);
        real_name := self.comp.get_string(func.name);
        @fmt(out, "%__%", real_name, f.to_index());
    } else {
        @fmt(out, "F%", f.to_index());
    }
}

fn fn_name_cstr(self: *EmitQbe2, f: FuncId) CStr = {
    name: List(u8) = list(temp()); 
    self.fmt_fn_name(f, name&);
    name&.push(0);
    (ptr = name.maybe_uninit.ptr)
}

fn display(self: Ty(*EmitQbe2, FuncId), out: *List(u8)) void = {
    self._0.fmt_fn_name(self._1, out);
}

// TODO: are the float cmp ordered or unordered? 
fn inst_intrinsic(self: *EmitQbe2, args: []Qbe.Ref, op: Intrinsic) []Qbe.Ref = {
    bin :: fn(self: *EmitQbe2, args: [] Qbe.Ref, op: Qbe.O, out: Qbe.Cls) [] Qbe.Ref = {
        a := temp().alloc(EmitQbe2.Val, 1);
        a.ptr[] = self.b&.push_inst(self.current, op, out, args[0], args[1]);
        a
    };
    cast :: fn(self: *EmitQbe2, args: []Qbe.Ref, ty: Prim, op: Qbe.O) []Qbe.Ref = {
        a := temp().alloc(EmitQbe2.Val, 1);
        a.ptr[] = self.b&.push_inst(self.current, op, qbe_real_class(ty), args[0], QbeNull);
        a
    };

    @match(op) {
        fn Add() => self.bin(args, .add, .Kl);
        fn Sub() => self.bin(args, .sub, .Kl);
        fn Mul() => self.bin(args, .mul, .Kl);
        fn Div() => self.bin(args, .div, .Kl);
        fn Eq() => self.bin(args, .ceql, .Kl);
        fn Ne() => self.bin(args, .cnel, .Kl);
        fn Ge() => self.bin(args, .csgel, .Kl);
        fn Le() => self.bin(args, .cslel, .Kl);
        fn Gt() => self.bin(args, .csgtl, .Kl);
        fn Lt() => self.bin(args, .csltl, .Kl);
        // sketch aliasing because walk_bc is gonna copy the slice back onto itself but it seems to be fine. -- Jul 24  
        fn IntToPtr() => args.slice(0, 1); // no-op 
        fn PtrToInt() => args.slice(0, 1); // no-op
        fn ShiftLeft()            => self.bin(args, .shl, .Kl);
        fn ShiftRightLogical()    => self.bin(args, .shr, .Kl);
        fn ShiftRightArithmetic() => self.bin(args, .sar, .Kl);
        fn BitOr()  => self.bin(args, .or, .Kl);
        fn BitAnd() => self.bin(args, .and, .Kl);
        fn BitXor() => self.bin(args, .xor, .Kl);
        fn FAdd() => self.bin(args, .add, .Kd);
        fn FSub() => self.bin(args, .sub, .Kd);
        fn FMul() => self.bin(args, .mul, .Kd);
        fn FDiv() => self.bin(args, .div, .Kd);
        fn FEq() => self.bin(args, .ceqd, .Kl);
        fn FNe() => self.bin(args, .cned, .Kl);
        fn FGe() => self.bin(args, .cged, .Kl);
        fn FLe() => self.bin(args, .cled, .Kl);
        fn FGt() => self.bin(args, .cgtd, .Kl);
        fn FLt() => self.bin(args, .cltd, .Kl);
        
        // I'm not quite sure what these should do. 
        // 
        fn Trunc64To32() => self.cast(args, .I32, .copy);  // args.slice(0, 1); // extuw
        fn Trunc64To16() => self.cast(args, .I32, .extuh); // args.slice(0, 1);
        fn Trunc64To8()  => self.cast(args, .I32, .extub); // args.slice(0, 1);
        fn Trunc32To16() => self.cast(args, .I32, .extuh); // args.slice(0, 1);
        fn Trunc32To8()  => self.cast(args, .I32, .extub); // args.slice(0, 1);
        fn Trunc16To8()  => self.cast(args, .I32, .extub); // args.slice(0, 1);
        
        fn SignExtend32To64() => self.cast(args, .I64, .extsw);
        fn ZeroExtend32To64() => self.cast(args, .I64, .extuw);
        fn ZeroExtend16To64() => self.cast(args, .I64, .extuw);
        fn ZeroExtend8To64()  => self.cast(args, .I64, .extuw);
        fn ZeroExtend16To32() => args.slice(0, 1); // no-op 
        fn ZeroExtend8To32()  => args.slice(0, 1); // no-op 
        fn ZeroExtend8To16()  => args.slice(0, 1); // no-op 
        
        fn IntToFloatValue() => self.cast(args, .F64, .sltof); 
        fn FloatToIntValue() => self.cast(args, .I64, .dtosi); 
        fn IntToFloatBits()  => self.cast(args, .F64, .cast); 
        fn FloatToIntBits()  => self.cast(args, .I64, .cast); 
        fn ShrinkFloat()     => self.cast(args, .F32, .truncd); 
        fn GrowFloat()       => self.cast(args, .F64, .exts); 
        fn BitNot() => {
            a := temp().alloc(EmitQbe2.Val, 1);
            a.ptr[] = self.b&.push_inst(self.current, .xor, .Kl, args[0], self.b&.push_literal(-1));
            a
        }
        fn GetContext() => {
            @debug_assert(self.implicit_context);
            @debug_assert(self.context != QbeNull, "Cannot used GetContext in function without context.");
            args[0] = self.b&.push_inst(self.current, .copy, .Kl, self.context, QbeNull);
            args
        }
        fn SetContext() => {
            @debug_assert(self.implicit_context);
            if self.context == QbeNull {
                self.context = self.b&.push_inst(self.current, .copy, .Kl, args[0], QbeNull); 
            } else {
                self.b&.push_inst(self.current, .copy, .Kl, self.context, args[0], QbeNull); 
            };
            args[0] = QbeConZero;
            args
        }
        @default => @panic("ICE: unhandled qbe inst_intrinsic %", op);
    }
}

fn inst_call(self: *EmitQbe2, args: Slice(Qbe.Ref), sig: PrimSig, f: FuncId, tail: bool, _loc: ?Span, context: bool) Slice(EmitQbe2.Val) = {
    name := self.fn_name_cstr(f);
    callee := self.b&.push_symbol(name);
    //@println("% %", name, context);
    self.inst_call(args, sig, callee, context)
}

fn inst_call(self: *EmitQbe2, args: Slice(Qbe.Ref), sig: PrimSig, callee: Qbe.Ref, context: bool) Slice(EmitQbe2.Val) = {
    self.b.leaf = false;
    out_vals: List(Qbe.Ref) = list(temp());
    return_value := Qbe.Ref.zeroed();
    return_type := Qbe.Cls.zeroed();
    maybe_struct_return_type := Qbe.Ref.zeroed();
    if sig.ret1 { fst: Prim |
        if sig.ret2 { snd: Prim | // two
            return_value = self.get_var(.P64);
            return_type = .Kl;
            maybe_struct_return_type = ref(.RType, self.pair_type_id);
            out_vals&.push(self.get_var(fst));
            out_vals&.push(self.get_var(snd));
        } else { // one
            return_value = self.get_var(fst);
            out_vals&.push(return_value);
            return_type = qbe_real_class(fst);
        };
    } else { // void or indirect
        if sig.first_arg_is_indirect_return {
            return_type = .Kl;
            return_value = self.get_var(.P64);
            size: i64 = sig.return_value_bytes.zext();
            type_id := self.b&.opaque_type_slow(size, 3);
            maybe_struct_return_type = ref(.RType, type_id);
        };
        // TODO: push call
    };
    
    shift := if(sig.first_arg_is_indirect_return, => 1, => 0);
    @debug_assert_eq(args.len, sig.args.len.add(shift), "mismatch args");
    
    if self.context != QbeNull && context {
        self.b&.push_inst0(self.current, .arge, .Kl, self.context, QbeNull);
    };
    range(0, sig.args.len) {i|
        ty := sig.args[i];
        v := args[i + shift];
        self.b&.push_argument(self.current, qbe_real_class(ty), v);
    };
    
    self.b&.push_inst(self.current, .call, return_type, return_value, callee, maybe_struct_return_type);
    if sig.ret2 { t2 | // two
        t1 := sig.ret1.unwrap();
        self.b&.push_inst(self.current, qbe_load(t1), qbe_real_class(t1), out_vals[0], return_value, QbeNull);
        // TODO: for now i always use (i64, i64) but that probably needs to change (ie floats!). 
        offset_to_second_field := self.b&.push_literal(@as(i64) 8);
        struct_out_2 := self.b&.push_inst(self.current, .add, .Kl, return_value, offset_to_second_field);
        self.b&.push_inst(self.current, qbe_load(t2), qbe_real_class(t2), out_vals[1], struct_out_2, QbeNull);
    };
    if sig.first_arg_is_indirect_return {
        size: i64 = sig.return_value_bytes.zext();
        self.b&.push_blit(self.current, args[0], return_value, size);
    };
    out_vals.items()
}

fn inst_trap(self: *EmitQbe2) void = {
    self.b&.end_block(self.current, (type = .hlt));
}

fn inst_call_ptr(self: *EmitQbe2, args: Slice(Qbe.Ref), sig: PrimSig, ptr: EmitQbe2.Val, _loc: ?Span, context: bool) Slice(EmitQbe2.Val) = {
    self.inst_call(args, sig, ptr, context)
}

fn inst_offset(self: *EmitQbe2, ptr: EmitQbe2.Val, bytes: i64) EmitQbe2.Val = {
    bytes := self.b&.push_literal(bytes);
    self.b&.push_inst(self.current, .add, .Kl, ptr, bytes)
}

fn inst_literal(self: *EmitQbe2, value: i64, ty: Prim) EmitQbe2.Val = {
    @match(ty) {    
        fn F64() => self.b&.push_literal(@as(f64) value.bitcast()); 
        fn F32() => self.b&.push_literal(@as(f32) value.trunc().bitcast());
        @default => self.b&.push_literal(value);
    }
}

fn inst_store(self: *EmitQbe2, addr: EmitQbe2.Val, value: EmitQbe2.Val, ty: Prim) void = {
    // :StoreAlwaysKw
    self.b&.push_inst0(self.current, qbe_store(ty), .Kw, value, addr);
}

fn inst_copy(self: *EmitQbe2, from: EmitQbe2.Val, to: EmitQbe2.Val, bytes: u16) void = {
    self.b&.push_blit(self.current, to, from, bytes.zext()); 
    
    // Just an option for debugging to make sure overlapping isn't the problem. 
    //self.b&.push_argument(self.current, .Kl, to);
    //self.b&.push_argument(self.current, .Kl, from);
    //self.b&.push_argument(self.current, .Kl, self.b&.push_literal(@as(i64) bytes.zext()));
    //self.b&.push_inst(self.current, .call, .Kw, QbeNull,  self.b&.push_symbol("memmove".sym().c_str()), QbeNull);
}

fn inst_func_ref(self: *EmitQbe2, fid: FuncId) EmitQbe2.Val = {
    self.b&.push_symbol(self.fn_name_cstr(fid))
}

fn inst_jump_if(self: *EmitQbe2, cond: EmitQbe2.Val, true: BbId, false: BbId, args: Slice(EmitQbe2.Val)) void = {
    assert(args.len.eq(0), "i dont use this yet");
    self.b&.end_block(self.current, (type = .jnz, arg = cond, target1 = (id = true.id + 1), target2 = (id = false.id + 1)));
}

fn inst_jump(self: *EmitQbe2, always: BbId, args: Slice(EmitQbe2.Val)) void = {
    enumerate(args){i, arg|
        ty := self.body.blocks[always.id.zext()].arg_prims[i];  // TODO: ask qbe for the type instead of smuggling the whole body here
        r := arg[];
        store_op := qbe_store(ty);
        if rtype(r) == .RTmp {
            t := self.b.temporaries.index(r.val())[].cls;
            store_op = store_ops[t.raw().zext()];
        };
        self.b&.push_inst0(self.current, store_op, .Kw, r, self.block_args[i]);
    };
    self.b&.end_block(self.current, (type = .jmp, target1 = (id = always.id + 1)));
}

fn is_kw_tmp(self:  *EmitQbe2, r: Qbe.Ref) bool = {
   if rtype(r) == .RTmp {
        t := self.b.temporaries.index(r.val())[].cls;
        if t == .Kw {
            return(true);
        };
    };
    false
}

fn inst_switch(self: *EmitQbe2, info: *RsVec(SwitchPayload), inspected: Qbe.Ref, uid: i64) void = {
    cmp_op := @if(is_kw_tmp(self, inspected), Qbe.O.ceqw, Qbe.O.ceql);
    // :AllOurBlocksUpFront
    normal_branches, default := info.decode_switch();
    default := default.expect("switch node has default");
    if normal_branches.len > 4 {
        sort :: quicksort(SwitchPayload, fn(a, b) => a.value > b.value);
        sort(normal_branches);
        binary_search_switch(self, normal_branches, inspected, default);
        return();
    };
    linear_search_switch(self, normal_branches, inspected, default);
    self.current.id = 999;
}

fn binary_search_switch(self: *EmitQbe2, cases: []SwitchPayload, inspected: Qbe.Ref, default: BbId) void = {
    if cases.len < 3 {
        linear_search_switch(self, cases, inspected, default);
        return();
    };
    mid := cases.len/2;
    high_block := self.b&.push_block();
    low_block  := self.b&.push_block();
    case := cases[mid];
    
    value := self.b&.push_literal(case.value);
    cmp_op := @if(is_kw_tmp(self, inspected), Qbe.O.cslew, Qbe.O.cslel);
    ok := self.b&.push_inst(self.current, cmp_op, .Kw, inspected, value);
    self.b&.end_block(self.current, (type = .jnz, arg = ok, target1 = low_block, target2 = high_block));
    
    self.current = high_block;
    binary_search_switch(self, cases.slice(0, mid), inspected, default);
    
    // include mid
    self.current = low_block;
    binary_search_switch(self, cases.slice(mid, cases.len), inspected, default);
}

fn linear_search_switch(self: *EmitQbe2, cases: []SwitchPayload, inspected: Qbe.Ref, default: BbId) void = {
    cmp_op := @if(is_kw_tmp(self, inspected), Qbe.O.ceqw, Qbe.O.ceql);
    next_block := self.b&.push_block();
    for cases { case | 
        value := self.b&.push_literal(case.value);
        ok := self.b&.push_inst(self.current, cmp_op, .Kw, inspected, value);
        self.b&.end_block(self.current, (type = .jnz, arg = ok, target1 = (id = case.block.id + 1), target2 = next_block));
        self.current = next_block;
        next_block = self.b&.push_block();
    };
    self.b&.end_block(self.current, (type = .jmp, target1 = (id = default.id + 1)));
}

fn inst_return(self: *EmitQbe2, args: Slice(EmitQbe2.Val)) void = {
    @switch(args.len){
        @case(0) => {
            if self.current_has_indirect_return {
                self.b&.end_block(self.current, (type = .retc, arg = self.indirect_return_slot));
                // :set_aggragate_return_index
            } else {
                self.b&.end_block(self.current, (type = .ret0));
            };
        };
        @case(1) => {
            // TODO: this should be the same? does llvm mess with it somehow? 
            //k := qbe_real_class(self.signeture.ret1.unwrap());
            //op: Qbe.J = @as(Qbe.J) @as(i64) Qbe.J.xxx.raw().zext() + k.raw().zext() + 1;
            op := qbe_ret(self.signeture.ret1.unwrap());
            self.b&.end_block(self.current, (type = op, arg = args[0]));
        };
        @case(2) => {
            t1 := self.signeture.ret1.unwrap();
            t2 := self.signeture.ret2.unwrap();
            self.b&.push_inst0(self.current, qbe_store(t1), .Kw, args[0], self.indirect_return_slot);
            // TODO: for now i always use (i64, i64) but that probably needs to change (ie floats!). 
            offset_to_second_field := self.b&.push_literal(@as(i64) 8);
            struct_out_2 := self.b&.push_inst(self.current, .add, .Kl, self.indirect_return_slot, offset_to_second_field);
            self.b&.push_inst0(self.current, qbe_store(t2), .Kw, args[1], struct_out_2);
            self.b&.end_block(self.current, (type = .retc, arg = self.indirect_return_slot));
            self.b.aggragate_return_index = (Some = self.pair_type_id);
        };
        @default fn() => unreachable();
    };
}

fn move_to_block(self: *EmitQbe2, block: *BasicBlock, ip: BbId) Slice(EmitQbe2.Val) = {
    // :AllOurBlocksUpFront
    self.current = (id = ip.id + 1); // off by one for entry block
    args: List(EmitQbe2.Val) = list(block.arg_prims.len, temp());
    
    enumerate block.arg_prims { i, ty |
        v := self.b&.push_inst(self.current, qbe_load(ty[]), qbe_real_class(ty[]), self.block_args[i], QbeNull);
        args&.push(v);
    };
    
    args.items()
}

fn var(ty: Prim, id: i64) Qbe.Ref = {
    (ty = ty, data = (Var = id))
}

// TODO: need to sign extend sometimes. 
fn inst_load(self: *EmitQbe2, addr: EmitQbe2.Val, ty: Prim) EmitQbe2.Val = {
    // note: cls of the dest is not the same as the cls in the load opcode. 
    self.b&.push_inst(self.current, qbe_load(ty), qbe_real_class(ty), addr, QbeNull)
}

fn inst_global(self: *EmitQbe2, id: BakedVarId) EmitQbe2.Val = {
    name := @format("g%", @as(i64) id.id.zext()) temp();
    name&.push(0);
    self.b&.push_symbol(ptr = name.maybe_uninit.ptr)
}

fn get_var(self: *EmitQbe2, ty: Prim) Qbe.Ref = {
    self.b&.push_temp(qbe_real_class(ty))
}

fn qbe_real_class(ty: Prim) Qbe.Cls = {
    @match(ty) {
        fn P64() => .Kl;
        fn I64() => .Kl;
        fn I32() => .Kw;
        fn I16() => .Kw;
        fn I8() =>  .Kw;
        fn F64() => .Kd;
        fn F32() => .Ks;
    }
}

fn qbe_ret(ty: Prim) Qbe.J = {
    @match(ty) {
        fn P64() => .retl;
        fn I64() => .retl;
        fn I32() => .retw;
        fn I16() => .retw;
        fn I8() =>  .retw;
        fn F64() => .retd;
        fn F32() => .rets;
    }
}

fn qbe_fake_class(ty: Prim) Qbe.Cls = {
    @match(ty) {
        fn P64() => .Kl;
        fn I64() => .Kl;
        fn I32() => .Kw;
        fn I16() => .Kuh;
        fn I8() =>  .Kub;
        fn F64() => .Kd;
        fn F32() => .Ks;
    }
}

// :StoreAlwaysKw no result type so the instruction must have .Kw
fn qbe_store(ty: Prim) Qbe.O = {
    ::enum(Prim);
    @match(ty) {
        fn P64() => .storel;
        fn I64() => .storel;
        fn I32() => .storew;
        fn I16() => .storeh;
        fn I8() =>  .storeb;
        fn F64() => .stored;
        fn F32() => .stores;
    }
}

// TODO: wrong becuase sometimes you want sign extend
fn qbe_load(ty: Prim) Qbe.O = {
    @match(ty) {
        fn P64() => .load;
        fn I64() => .load;
        fn I32() => .loaduw;
        fn I16() => .loaduh;
        fn I8() =>  .loadub;
        fn F64() => .load;
        fn F32() => .load;
    }
}


fn display(self: Qbe.Ref, out: *List(u8)) void = {
    out.push_all("TODO:Qbe.Ref");
}
