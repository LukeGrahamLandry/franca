//! - Wasm is a bit annoying because it's designed to be compact and fast to load, not to be output in one pass. 
//!   For example, you can't know the index of any functions until you know how many imports there are. 
//! - It requires structured control flow. 
// TODO: rotr, rotl, byteswap, selCC, cas (?),  

EmitWasmFn :: @struct(
    m: *QbeModule,
    f: *Qbe.Fn,
    locals: []i32,
    a: List(u8),
    block_stack: List(*Qbe.Blk),
);

WASM_INDEX_PADDING :: 4;

fn emit_func_wasm32(f: *Qbe.Fn) void = {
    code := f.globals.segments&[.Code]&;
    e: EmitWasmFn = (
        f = f,
        m = f.globals,
        locals = temp().alloc(i32, f.ntmp.zext()),
        a = (maybe_uninit = (ptr = code.next, len = code.cap() - code.len()), len = 0, gpa = panicking_allocator),
        block_stack = list(temp()), 
    ); e := e&;
   
    printfn(f, f.globals.debug_out);
    use_symbol(e.m, f.lnk.id) { s |
        s.got_lookup_offset = e.m.local_needs_reloc.len;
        s.referenced = true;
    };
    e.m.local_needs_reloc&.push(f.lnk.id);
    
    e.pad(WASM_INDEX_PADDING); // reserve space for length of code. 
    
    pack_locals(e);
    
    emit_block(e, e.f.start);
    e.op(.Unreachable);  // keep the verifier happy (wihtout this the implicit return needs to typecheck)
    e.op(.End);
    code.next = code.next.offset(e.a.len());
    
    size_of_func := e.a.len;
    e.a.len = 0;
    leb128_unsigned(e.a&, size_of_func - WASM_INDEX_PADDING, WASM_INDEX_PADDING); 
    // TODO: fix -d D llvm-mc dis needs to not include the locals part
}

// im so impressed that this works
fn pack_wasm_result_type(m: *QbeModule, $iter_args: @Fn(yield: @Fn(k: Qbe.Cls) void) void, $iter_ret: @Fn(yield: @Fn(k: Qbe.Cls) void) void) i32 = {
    m.stubs&.reserve(Wasm.ValType)[] = .ResultStart;
    body :: fn($iter) => {
        count := m.stubs&.reserve(u8);
        n := 0;
        iter { k |
            m.stubs&.reserve(Wasm.ValType)[] = to_wasm_type(k);
            n += 1;
        };
        @debug_assert_lt(n, 128, "TODO: so so many types"); 
        count[] = n.trunc();
    };
    body(iter_args);
    body(iter_ret);
    // TODO: deduplicate these
    c := m.wasm_function_type_count&;
    c[] += 1;
    c[] - 1
}

fn pack_locals(e: *EmitWasmFn) void = {
    // 0-4 uleb fits in one byte so this patch is easy. 
    patch := e.a.index_unchecked(e.a.len);
    e.pad(1);
   
    e.locals.interpret_as_bytes().set_bytes(0xFF);
    total_locals: i32 = 0;
    for_pars e.f { i |
        e.locals[i.to.val()] = total_locals;
        // TODO: use cls to say function signeture. 
        total_locals += 1;
        i.set_nop();
    };
    // TODO: this probably isn't worth the time. 
    // Declaration of locals uses run-length-encoding so group by type to shrink the module. 
    k_ :: @const_slice(Qbe.Cls.Kw, .Kl, .Ks, .Kd);
    wasm_type_ :: @const_slice(Wasm.ValType.I32, .I64, .F32, .F64);
    entries := 0;
    range(0, 4) { i |
        k, wasm_type := (k_[i], wasm_type_[i]);
        prev_locals := total_locals;
        range(Qbe.Tmp0, e.f.ntmp.zext()) { i |
            t := e.f.tmp.index(i);
            if e.locals[i].intcast() == -1 && t.nuse > 0 && t.cls == k {
                e.locals[i] = total_locals;
                total_locals += 1;
            };
        };
        n := total_locals - prev_locals;
        if n > 0 {
            leb128_unsigned(e.a&, n.zext());
            ::enum(@type wasm_type);
            e.a&.push(wasm_type.raw());
            entries += 1;
        };
    };
    
    patch[] = entries.trunc();
}

fn to_wasm_type(k: Qbe.Cls) Wasm.ValType = {
    wasm_type :: @const_slice(Wasm.ValType.I32, .I64, .F32, .F64);
    wasm_type[k.raw().zext()]
}

// TODO: this way of recreating nested structure is super dumb,
//       if you get unlucky the same block will be emitted multiple times. 
//       even trivial cases like a branch that rejoins will generate garbage redundant code. 
fn emit_block(e: *EmitWasmFn, b: *Qbe.Blk) void = {
    depth := 0;
    for_rev e.block_stack& { check |
        if check.identical(b) {
            e.op(.Br);
            leb128_unsigned(e.a&, depth);
            return();
        };
        depth += 1;
    };

    e.block_stack&.push(b);
    e.op(.Loop);
    
    leb128_signed(e.a&, b.wasm_type.intcast());
    
    for_insts_forward b { i |
        emit(e, i);
    };
    
    @match(b.jmp.type) {
        fn ret0() => e.op(.Return);
        fn hlt()  => e.op(.Unreachable);
        fn jmp() => {
            emit_block(e, b.s1);
            e.op(.Unreachable);
        }
        fn jnz() => {
            e.block_stack&.push(zeroed(*Qbe.Blk));
            e.op(.If);
            e.a&.push(@as(u8) Wasm.ValType.EmptyBlock);
            emit_block(e, b.s1);
            e.op(.Else);
            emit_block(e, b.s2);
            e.op(.End);
            e.block_stack&.pop();
            e.op(.Unreachable);
        }
        @default => @panic("invalid terminator");
    };
    e.op(.End);
    e.block_stack&.pop();
}
fn emit(e: *EmitWasmFn, i: *Qbe.Ins) void = {
    if Wasm'lookup_wasm_encoding(i.op(), i.cls()) { byte |
        e.a&.push(byte);
        if maybe_load(i) { size |
            e.a&.push(@as(u8) size.zext().trailing_zeros().trunc());  // align hint
            e.a&.push(0);
        };
        if maybe_store(i) { size | 
            e.a&.push(@as(u8) size.zext().trailing_zeros().trunc());  // align hint
            e.a&.push(0);
        };
        return();
    };
    
    @match(i.op()) {
        fn call() => {
            e.op(.Call);
            @debug_assert(i.arg&[0].rtype() == .RCon, "use call_indirect for non-constant callee");
            c := e.f.get_constant(i.arg&[0]);
            @debug_assert(c.type == .CAddr && c.bits.i == 0, "wasm can only call symbols");
            e.index_patch(c.sym.id, .Func);
        }
        fn call_indirect() => {
            e.m.wasm_has_any_indirect_calls = true;
            
            // Lookup a function reference in a table and call it. 
            e.op(.CallIndirect);
            type_index := i.arg&[1].rsval().intcast();
            @debug_assert_ge(type_index, 0);
            leb128_unsigned(e.a&, type_index); // type index
            leb128_unsigned(e.a&, 0);  // table index
        }
        fn push() => @match(rtype(i.arg&[0])) {
            fn RCon() => {
                c := e.f.get_constant(i.arg&[0]);
                @match(c.type) {
                    fn CBits() => {
                        @match(i.cls()) {
                            fn Ks() => {
                                e.op(.F32_Const);
                                e.a&.reserve_type(f32)[] = c.bits.s.s;
                            }
                            fn Kd() => {
                                e.op(.F64_Const);
                                e.a&.reserve_type(f64)[] = c.bits.d;
                            }
                            @default => {
                                e.op(@if(i.cls().is_wide(), .I64_Const, .I32_Const));
                                leb128_signed(e.a&, c.bits.i);
                            };
                        };
                    }
                    fn CAddr() => {
                        use_symbol(e.m, c.sym.id) { symbol | 
                            // if it's a function address we have to wait until the end to know its index in the table. 
                            if symbol.kind == .Local && symbol.segment == .MutableData {
                                e.op(@if(i.cls().is_wide(), .I64_Const, .I32_Const));
                                leb128_signed(e.a&, symbol.offset + c.bits.i);
                            } else {
                                @debug_assert(symbol.segment != .ConstantData, "TODO: ConstantData");
                                patch_at := u8.raw_from_ptr(e.a.maybe_uninit.ptr.offset(e.a.len));
                                push_fixup(e.m, symbol, (patch_at = patch_at, type = (WasmAddr = (wide = i.cls().is_wide(), increment = c.bits.i.trunc()))));
                                // note: we don't push an op here. 
                                e.pad(WASM_INDEX_PADDING);  // TODO: might need more space than this.
                            };
                        };
                    }
                    fn CUndef() => unreachable();
                };
            }
            fn RTmp() => {
                local_index := e.locals[i.arg&[0].val()];
                @debug_assert_ne(local_index, -1, "read from tmp without assigned local");
                e.op(.LocalGet);
                leb128_unsigned(e.a&, local_index.zext());
            }
            fn RSlot() => {
                eprintln("TODO");
            }
            @default => {
                printfn(e.f, e.m.debug_out);
                @panic("invalid argument for op push");
            };
        };
        fn pop() => {
            if i.to == QbeNull {
                e.op(.Drop);
                return();
            };
            @debug_assert(rtype(i.to) == .RTmp);
            local_index := e.locals[i.to.val()];
            @debug_assert_ne(local_index, -1, "write to tmp without assigned local");
            e.op(.LocalSet);
            leb128_unsigned(e.a&, local_index.zext());
        }
        fn global_set() => {
            id, off := e.f.get_sym(i.arg&[0]) || @panic("global_set arg0 must be a symbol");
            @debug_assert_eq(off, 0);
            @debug_assert(i.arg&[1] == QbeNull, "should be on stack, not in a local");
            e.op(.GlobalSet);
            e.push_global_index(id);
        }
        fn global_get() => {
            id, off := e.f.get_sym(i.arg&[0]) || @panic("global_get arg0 must be a symbol");
            @debug_assert_eq(off, 0);
            e.op(.GlobalGet);
            e.push_global_index(id);
        }
        fn nop()    => ();
        fn dbgloc() => ();
        @default => @panic("TODO: wasm encoding for %", i.op());
    };
}

fn index_patch(e: *EmitWasmFn, id: u32, _space: Wasm.ImportType) void = {
    use_symbol(e.m, id) { s |
        patch_at := u8.raw_from_ptr(e.a.maybe_uninit.ptr.offset(e.a.len));
        push_fixup(e.m, s, (patch_at = patch_at, type = .WasmIndex));
    };
    e.pad(WASM_INDEX_PADDING);
}

fn pad(e: *EmitWasmFn, count: i64) void = range(0, count) { _ |
    e.op(.Nop);
};

fn op(e: *EmitWasmFn, o: Wasm.Inst) void = 
    e.a&.push(o.raw());

fn fixup_wasm32(self: *QbeModule, symbol: *SymbolInfo, fixup: *Fixup, new_got_reloc: *?Fixup) void = {
    @match(fixup.type) {
        fn WasmIndex() => {
            @debug_assert_ne(symbol.got_lookup_offset, -1, "missing index for $%", symbol.name);
            lst: List(u8) = (maybe_uninit = (ptr = u8.ptr_from_raw(fixup.patch_at), len = WASM_INDEX_PADDING), len = 0, gpa = panicking_allocator);
            leb128_unsigned(lst&, symbol.got_lookup_offset);
        }
        fn WasmAddr(it) => {
            lst: List(u8) = (maybe_uninit = (ptr = u8.ptr_from_raw(fixup.patch_at), len = WASM_INDEX_PADDING), len = 0, gpa = panicking_allocator);
            o := @if(it.wide, Wasm.Inst.I64_Const, Wasm.Inst.I32_Const);
            lst&.push(@as(u8) o);
            value := if(symbol.segment == .Code, => symbol.got_lookup_offset, => symbol.offset + it.increment.zext());
            @debug_assert_ge(value, 0, "missing index for $%", symbol.name);
            leb128_unsigned(lst&, value);
        }
        @default => panic("invalid fixup type for wasm");
    };
}

fn push_global_index(e: *EmitWasmFn, id: u32) void = @if_else {
    @if(id == e.m.wasm_symbol_stackbase) => e.a&.push(0);
    @if(id == e.m.wasm_symbol_env_parameter) => {
        e.m.wasm_any_pare = true;
        e.a&.push(1);
    };
    @else => panic("unknown symbol for wasm global");  // :OnlyTwoGlobals e.index_patch(id, .Global);
};

// order matters
fn output_wasm_module(m: *QbeModule) [][]u8 = {
    default_import_module := "env";
    min_mem_pages := 200; // TODO: set this to something good
    stack_size := 1.shift_left(23); // 8MB
    
    memory_reserved := wasm_page_size;  // :WasmZeroPage
    data_seg := m.segments&[.MutableData]&;
    data_size := data_seg.len() - wasm_page_size;  // :WasmZeroPage
    memory_reserved += data_size;
    
    // TODO: remove
    code_count := m.segments&[.Code]&.len() - COMMANDS_SIZE_GUESS - SIZE_OF_STUBS;
    @if(show_backend_stats())
    @eprintln(">>> % bytes of code, % bytes of data.", code_count, data_size);
    
    // we need to know how many imports there are before we can start patching anything. 
    for_symbols m { id, symbol | // :SLOW  just keep list of pending symbols instead
        if symbol.kind == .Pending && symbol.fixups.len != 0 {
            symbol.got_lookup_offset = m.imports.len;
            m.imports&.push(id); 
            symbol.kind = .DynamicPatched;
        };
    };
    
    for_symbols m { id, symbol |
        if symbol.referenced || symbol.fixups.len != 0 {
            if symbol.kind == .Local && symbol.segment == .Code {
                @debug_assert(symbol.got_lookup_offset != -1, "missing local function $%", symbol.name);
                symbol.got_lookup_offset += m.imports.len;
            };
            m.do_fixups(rawptr_from_int(0), symbol);
        };
    };
    
    code_segment := m.segments&[.Code]&;
    chunks := list([]u8, temp());
    cursor: List(u8) = (maybe_uninit = (ptr = code_segment.mmapped.ptr, len = COMMANDS_SIZE_GUESS), len = 0, gpa = panicking_allocator);  // :UnacceptablePanic
    push_buf :: fn($body: @Fn(buf: *List(u8)) void) void = {
        start := cursor.len;
        body(cursor&);
        chunks&.push(cursor.items().rest(start)); 
    };
    
    push_buf { buf |
        buf.push_all(Wasm.version_magic); 
    };
    
    f_count := m.local_needs_reloc.len;
    
    {
        push_buf { buf |
            buf.push(@as(u8) Wasm.Section.Type);
            leb128_unsigned(buf, m.stubs&.len() + uleb_size(m.wasm_function_type_count.intcast()));
            leb128_unsigned(buf, m.wasm_function_type_count.intcast());
        };
        chunks&.push(m.stubs.mmapped.slice(0, m.stubs&.len()));
    }; 
    
    push_buf { buf |
        buf.push(@as(u8) Wasm.Section.Import);
        uleb_patch_delta buf {
            leb128_unsigned(buf, m.imports.len);
            for m.imports& { id |
                use_symbol(m, id) { s |
                    sep := index_of(s.name, "$".ascii());
                    mod, name := ("", s.name);
                    if sep { sep |
                        name = s.name.slice(0, sep);
                        mod = s.name.rest(sep + 1);
                    } else {
                        mod = default_import_module;
                    };
                    leb128_unsigned(buf, mod.len);
                    push_all(buf, mod);
                    leb128_unsigned(buf, name.len);
                    push_all(buf, name);
                    // For now we only do functions
                    push(buf, @as(u8) Wasm.ImportType.Func);
                    @debug_assert_ge(s.wasm_type_index, 0, "unknown type for function $%", s.name);
                    leb128_unsigned(buf, s.wasm_type_index.intcast());
                };
            };
        };
    };
    
    push_buf { buf |
        buf.push(@as(u8) Wasm.Section.Function);
        uleb_patch_delta buf {
            leb128_unsigned(buf, f_count);
            for m.local_needs_reloc& { id |
                use_symbol(m, id) { s |
                    @debug_assert_ge(s.wasm_type_index, 0, "unknown type for function $%", s.name);
                    leb128_unsigned(buf, s.wasm_type_index.intcast()); 
                };
            };
        };
    };
    
    fn write_limits(buf: *List(u8), min: i64, max: ?i64) void = {
        buf.push(int(max.is_some()));
        leb128_unsigned(buf, min);
        if max { max |
            leb128_unsigned(buf, max);
        };
    }
    
    // :OnlyOneTable for indirect function calls
    @if(m.wasm_has_any_indirect_calls)
    push_buf { buf |
        buf.push(@as(u8) Wasm.Section.Table);
        uleb_patch_delta buf {
            buf.push(1); // length of tables vec
            buf.push(@as(u8) Wasm.ValType.FuncRef); 
            number_of_functions := m.imports.len + m.exports.len;
            write_limits(buf, number_of_functions, (Some = number_of_functions));
        };
    };
    
    push_buf { buf |
        buf.push(@as(u8) Wasm.Section.Memory);
        uleb_patch_delta buf {
            buf.push(1); // length of memories vec
            write_limits(buf, min_mem_pages, .None);
        };
    };
    
    {
        // :OnlyTwoGlobals [__stackbase, __env_parameter] so don't need patches
        // TODO: this will have to change if we want to allow frontends to create thier own wasm globals. 
    
        // Create a global for the stack pointer
        memory_reserved += stack_size;
        stack_base := memory_reserved;  // :WasmZeroPage
        
        push_buf { buf |
            buf.push(@as(u8) Wasm.Section.Global);
            uleb_patch_delta buf {
                push(buf, 1 + int(m.wasm_any_pare)); // length of globals vector
                
                // __stackbase
                push(buf, @as(u8) Wasm.ValType.I32); // type
                push(buf, 1); // mutable
                
                // initial value
                push(buf, @as(u8) Wasm.Inst.I32_Const);
                leb128_signed(buf, stack_base);
                push(buf, @as(u8) Wasm.Inst.End);
                
                if m.wasm_any_pare {
                    // __env_parameter
                    push(buf, @as(u8) Wasm.ValType.I64); // type
                    push(buf, 1); // mutable
                    
                    // initial value
                    push(buf, @as(u8) Wasm.Inst.I64_Const);
                    leb128_signed(buf, 0);
                    push(buf, @as(u8) Wasm.Inst.End);
                };
            };
        };
    };
    
    @if(m.exports.len > 0)
    push_buf { buf |
        buf.push(@as(u8) Wasm.Section.Export);
        uleb_patch_delta buf {
            leb128_unsigned(buf, m.exports.len);
            for m.exports& { id |
                use_symbol(m, id) { s |
                    leb128_unsigned(buf, s.name.len);
                    push_all(buf, s.name);
                    buf.push(@as(u8) Wasm.ImportType.Func);
                    leb128_unsigned(buf, s.got_lookup_offset);
                };
            };
        };
    };
    
    // START goes here
    
    // :OnlyOneTable 
    // TODO: would be better to assign indexes out of order so we wouldn't need fixups 
    //       and would only need to put functions that are actually referenced indirectly in the table. 
    @if(m.wasm_has_any_indirect_calls)
    push_buf { buf |
        buf.push(@as(u8) Wasm.Section.Element);
        uleb_patch_delta buf {
            leb128_unsigned(buf, 1);  // length
            
            leb128_unsigned(buf, 0);  // elem tag for active, table 0, funcref
            // offset in table
            push(buf, @as(u8) Wasm.Inst.I32_Const);
            leb128_unsigned(buf, 0);
            push(buf, @as(u8) Wasm.Inst.End);
            
            leb128_unsigned(buf, f_count);  // length
            range(0, f_count) { i |
                leb128_unsigned(buf, i);
            };
        };
    };
    
    {
        padding :: COMMANDS_SIZE_GUESS + SIZE_OF_STUBS;
        total_code_bytes := code_segment.len() - padding;
        push_buf { buf |
            buf.push(@as(u8) Wasm.Section.Code);
            f_count := m.local_needs_reloc.len;
            total_section_bytes := total_code_bytes + uleb_size(f_count);
            leb128_unsigned(buf, total_section_bytes);
            leb128_unsigned(buf, f_count);
        };
        
        chunks&.push(code_segment.mmapped.slice(padding, code_segment.len()));
    };
    
    if data_size > 0 {
        push_buf { buf |
            buf.push(@as(u8) Wasm.Section.Data);
            leb128_unsigned(buf, 1 + 1 + 1 + uleb_size(wasm_page_size) + 1 + uleb_size(data_size) + data_size);
            leb128_unsigned(buf, 1); // number of datas 
            leb128_unsigned(buf, 0); // mode: active
            
            // offset expr
            buf.push(@as(u8) Wasm.Inst.I32_Const);
            leb128_signed(buf, wasm_page_size); 
            buf.push(@as(u8) Wasm.Inst.End);
            
            leb128_unsigned(buf, data_size);
        };
        chunks&.push(data_seg.mmapped.slice(wasm_page_size, data_seg.len()));
    };
    
    total_size := 0;
    for chunks { c |
        total_size += c.len;
    };
    @if(show_backend_stats())
    @eprintln(">>> % bytes total module", total_size); 
    @assert_le(memory_reserved, min_mem_pages * wasm_page_size);
    
    chunks.items()
}

fn uleb_patch_delta(buf: *List(u8), $body: @Fn() void) void = {
    PAD :: WASM_INDEX_PADDING;
    buf.reserve(PAD);
    buf.len += PAD;
    start := buf.len;
    body();
    length := buf.len - start;
    buf.len = start - PAD;
    leb128_unsigned(buf, length, PAD);
    buf.len += length;
}

//
// After the magic + version, the thing is a list of sections. 
// Each section is [id byte, size u32, data]
// Note that many sections are a vec of something which is encoded as [count u32, data], 
// so you sometimes have two lengths, one in bytes and then one in elements. 
// Also, when the spec says sizes like u32, that doesn't mean encode using that many bytes, 
// you still use the leb128 stuff. The type is just a range restriction. 
//
