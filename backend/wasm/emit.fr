//! - Wasm is a bit annoying because it's designed to be compact and fast to load, not to be output in one pass. 
//!   For example, you can't know the index of any functions until you know how many imports there are. 
//! - It requires structured control flow. 

EmitWasmFn :: @struct(
    m: *QbeModule,
    f: *Qbe.Fn,
    locals: []i32,
    a: List(u8),
    block_stack: List(*Qbe.Blk),
);

WASM_INDEX_PADDING :: 3;

fn emit_func_wasm32(f: *Qbe.Fn) void = {
    code := f.globals.segments&[.Code]&;
    e: EmitWasmFn = (
        f = f,
        m = f.globals,
        locals = temp().alloc(i32, f.ntmp.zext()),
        a = (maybe_uninit = (ptr = code.next, len = code.cap() - code.len()), len = 0, gpa = panicking_allocator),
        block_stack = list(temp()), 
    ); e := e&;
    e.m.local_needs_reloc&.push(f.lnk.id);
    use_symbol(e.m, f.lnk.id) { s |
        s.got_lookup_offset = e.m.number_of_functions;
    };
    
    e.pad(WASM_INDEX_PADDING); // reserve space for length of code. 
    
    start_locals := e.a.len;
    pack_locals(e);
    end_locals := e.a.len;
    
    emit_block(e, e.f.start);
    e.op(.End);
    code.next = code.next.offset(e.a.len());
    
    // TODO: this is so convoluted
    size_of_func := e.a.len;
    e.a.len = 0;
    inner_size := size_of_func - uleb_size(size_of_func);
    @debug_assert_eq(uleb_size(size_of_func), uleb_size(inner_size), "TODO: deal with variable length numbers here");
    leb128_unsigned(e.a&, size_of_func - uleb_size(size_of_func)); // :FUCKED
    @assert_le(e.a.len, WASM_INDEX_PADDING, "function $% is too big to patch length", f.name());
    end_of_length := e.a.len;
    e.a.len = size_of_func;
    size_of_locals := end_locals - start_locals;
    e.a.items().copy_overlapping(end_of_length, start_locals, size_of_locals);
    extra := start_locals - end_of_length;
    e.a.len = end_of_length + size_of_locals;
    e.pad(extra);
    e.a.len = size_of_func;
}

fn pack_locals(e: *EmitWasmFn) void = {
    // 0-4 uleb fits in one byte so this patch is easy. 
    patch := e.a.index_unchecked(e.a.len);
    e.pad(1);
    
    memset(i32.raw_from_ptr(e.locals.ptr), 0xFF, e.locals.len * size_of(@type e.locals[0]));
    total_locals: i32 = 0;
    for_pars e.f { i |
        e.locals[i.to.val()] = total_locals;
        // TODO: use cls to say function signeture. 
        total_locals += 1;
        i.set_nop();
    };
    // TODO: this probably isn't worth the time. 
    // Declaration of locals uses run-length-encoding so group by type to shrink the module. 
    k_ :: @const_slice(Qbe.Cls.Kw, .Kl, .Ks, .Kd);
    wasm_type_ :: @const_slice(Wasm.ValType.I32, .I64, .F32, .F64);
    entries := 0;
    range(0, 4) { i |
        k, wasm_type := (k_[i], wasm_type_[i]);
        prev_locals := total_locals;
        range(Qbe.Tmp0, e.f.ntmp.zext()) { i |
            t := e.f.tmp.index(i);
            if e.locals[i].intcast() == -1 && t.nuse > 0 && t.cls == k {
                e.locals[i] = total_locals;
                total_locals += 1;
            };
        };
        n := total_locals - prev_locals;
        if n > 0 {
            leb128_unsigned(e.a&, n.zext());
            ::enum(@type wasm_type);
            e.a&.push(wasm_type.raw());
            entries += 1;
        };
    };
    
    patch[] = entries.trunc();
}

// TODO: this way of recreating nested structure is super dumb,
//       if you get unlucky the same block will be emitted multiple times. 
//       even trivial cases like a branch that rejoins will generate garbage redundant code. 
fn emit_block(e: *EmitWasmFn, b: *Qbe.Blk) void = {
    depth := 0;
    for_rev e.block_stack& { check |
        if check.identical(b) {
            e.op(.Br);
            leb128_unsigned(e.a&, depth);
            return();
        };
        depth += 1;
    };

    e.block_stack&.push(b);
    e.op(.Loop);
    
    for_insts_forward b { i |
        emit(e, i);
    };
    
    @match(b.jmp.type) {
        fn ret0() => e.op(.Return);
        fn hlt()  => e.op(.Unreachable);
        // :TodoSwitch
        fn jmp() => emit_block(e, b.s1);
        fn jnz() => {
            // TODO: br_if
            emit_block(e, b.s1);
            emit_block(e, b.s2);
        }
        @default => @panic("invalid terminator");
    };
    e.op(.End);
    e.block_stack&.pop();
}

fn emit(e: *EmitWasmFn, i: *Qbe.Ins) void = {
    if lookup_wasm_encoding(i.op(), i.cls()) { byte |
        e.a&.push(byte);
        return();
    };
    
    @match(i.op()) {
        fn call() => {
            e.op(.Call);
            @debug_assert(i.arg&[0].rtype() == .RCon, "use call_indirect for non-constant callee");
            c := e.f.get_constant(i.arg&[0]);
            @debug_assert(c.type == .CAddr && c.bits.i == 0, "wasm can only call symbols");
            use_symbol(e.m, c.sym.id) { s |
                patch_at := e.a.maybe_uninit.ptr.offset(e.a.len);
                push_fixup(e.m, s, (patch_at = patch_at, type = (WasmIndex = (space = .Func))));
            };
            e.pad(WASM_INDEX_PADDING);
        }
        fn call_indirect() => {
            todo();
        }
        fn push() => @match(rtype(i.arg&[0])) {
            fn RCon() => {
                c := e.f.get_constant(i.arg&[0]);
                @match(c.type) {
                    fn CBits() => {
                        e.op(@match(i.cls()) {
                            fn Kw() => .I32_Const;
                            fn Kl() => .I64_Const;
                            fn Ks() => .F32_Const;
                            fn Kd() => .F64_Const;
                            @default => unreachable();
                        });
                        imm := c.bits.i;
                    }
                    fn CAddr() => {
                        // TODO
                    }
                    fn CUndef() => unreachable();
                };
            }
            fn RTmp() => {
                local_index := e.locals[i.arg&[0].val()];
                @debug_assert_ne(local_index, -1, "read from tmp without assigned local");
                e.op(.LocalGet);
                leb128_unsigned(e.a&, local_index.zext());
            }
            fn RSlot() => {
                // TODO: offset from stack pointer 
            }
            @default => @panic("invalid argument for op push");
        };
        fn pop() => {
            if i.to == QbeNull {
                e.op(.Drop);
                return();
            };
            @debug_assert(rtype(i.to) == .RTmp);
            local_index := e.locals[i.to.val()];
            @debug_assert_ne(local_index, -1, "write to tmp without assigned local");
            e.op(.LocalSet);
            leb128_unsigned(e.a&, local_index.zext());
        }
        fn nop()    => ();
        fn dbgloc() => ();
        @default => @panic("TODO: wasm encoding for %", i.op());
    };
}

fn pad(e: *EmitWasmFn, count: i64) void = range(0, count) { _ |
    e.op(.Nop);
};

fn op(e: *EmitWasmFn, o: Wasm.Inst) void = 
    e.a&.push(o.raw());

fn output_wasm_module(m: *QbeModule) [][]u8 = {
    // TODO: remove
    code_count := m.segments&[.Code]&.len() - COMMANDS_SIZE_GUESS - SIZE_OF_STUBS;
    data_count := m.segments&[.MutableData]&.len();
    @eprintln(">>> % bytes of code, % bytes of data.", code_count, data_count);
    
    // we need to know how many imports there are before we can start patching anything. 
    for_symbols m { id, symbol | // :SLOW  just keep list of pending symbols instead
        if symbol.kind == .Pending && symbol.fixups.len != 0 {
            symbol.got_lookup_offset = m.imports.len;
            m.imports&.push(id); 
            symbol.kind = .DynamicPatched;
        };
    };
    
    for_symbols m { id, symbol |
        if symbol.fixups.len != 0 {
            @debug_assert(symbol.got_lookup_offset != -1, "TODO: wasm data entries");
            if symbol.kind == .Local && symbol.segment == .Code {
                symbol.got_lookup_offset += m.imports.len;
            };
            m.do_fixups(u8.ptr_from_int(0), symbol);
        };
    };
    
    code_segment := m.segments&[.Code]&;
    cursor: List(u8) = (maybe_uninit = (ptr = code_segment.mmapped.ptr, len = COMMANDS_SIZE_GUESS), len = 0, gpa = panicking_allocator);
    push_buf :: fn($body: @Fn(buf: *List(u8)) void) void = {
        start := cursor.len;
        body(cursor&);
        chunks&.push(cursor.items().rest(start));
    };
    chunks := list([]u8, temp());
    
    push_buf { buf |
        //buf.push_all(Wasm.version_magic); // :UpdateBoot "Panicked: Assertion Failed: unhanlded mutual recursion!"
        version_magic :: @const_slice(0x00, 0x61, 0x73, 0x6D, 0x01, 0x00, 0x00, 0x00);
        buf.push_all(version_magic);
        
        buf.push(@as(u8) Wasm.Section.Code);
        total_code_bytes := code_segment.len() - COMMANDS_SIZE_GUESS - SIZE_OF_STUBS;
        f_count := m.local_needs_reloc.len;
        total_section_bytes := total_code_bytes + uleb_size(f_count);
        leb128_unsigned(buf, total_section_bytes);
        leb128_unsigned(buf, f_count);
    };
    
    for m.local_needs_reloc& { id |
        use_symbol(m, id) { s |
            chunks&.push(code_segment.mmapped.subslice(s.offset, s.size));
        };
    };
    
    if m.exports.len > 0 {
        chunk_i := chunks.len;
        exports_size := uleb_size(m.exports.len);
        for(m.exports&, fn(id) => use_symbol(m, id) { s |
            exports_size += 1 + uleb_size(s.name.len) + s.name.len + uleb_size(s.got_lookup_offset);
        });
        
        push_buf { buf |
            buf.push(@as(u8) Wasm.Section.Export);
            leb128_unsigned(buf, exports_size);
            leb128_unsigned(buf, m.exports.len);
        };
        for m.exports& { id |
            use_symbol(m, id) { s |
                push_buf { buf |
                    leb128_unsigned(buf, s.name.len);
                };
                chunks&.push(s.name);
                push_buf { buf |
                    buf.push(@as(u8) Wasm.ImportType.Func);
                    leb128_unsigned(buf, s.got_lookup_offset);
                };
            };
        };
        
        //real_exports_size := 0;
        //for chunks.items().rest(chunk_i) { c |
        //    real_exports_size += c.len;
        //};
        //@debug_assert_eq(exports_size, real_exports_size);
    };
   
    for chunks { c |
    print("|");
    for c { b|
    @print("%, ", b);
    }
    ;};
    println("");
    
    total_size := 0;
    for chunks { c |
        total_size += c.len;
    };
    @eprintln(">>> % bytes total module", total_size);
    
    chunks.items()
}

fn fixup_wasm32(self: *QbeModule, symbol: *SymbolInfo, fixup: *Fixup, new_got_reloc: *?Fixup) void = {
    idx := symbol.got_lookup_offset;
    @match(fixup.type) {
        fn WasmIndex(it) => {
            lst: List(u8) = (maybe_uninit = (ptr = fixup.patch_at, len = WASM_INDEX_PADDING), len = 0, gpa = panicking_allocator);
            leb128_unsigned(lst&, idx);
        }
        @default => panic("invalid fixup type for wasm");
    };
}

//
// After the magic + version, the thing is a list of sections. 
// Each section is [id byte, size u32, data]
// Note that many sections are a vec of something which is encoded as [count u32, data], 
// so you sometimes have two lengths, one in bytes and then one in elements. 
// Also, when the spec says sizes like u32, that doesn't mean encode using that many bytes, 
// you still use the leb128 stuff. The type is just a range restriction. 
//

// TODO: we're not going to do it this way at all i think, 
//       want to just spam out functions in one chunk like other backends 
// TODO: use bucket arrays for less copying? 
fn dump(self: *Wasm.Module, out: *List(u8)) void = {
    :: enum(Wasm.Section);
    @debug_assert(self.imports.len == 0, "TODO: dump wasm imports");
    @debug_assert(self.data.len == 0, "TODO: dump wasm data");
    @debug_assert(self.memories.len == 0, "TODO: dump wasm");
    @debug_assert(self.tables.len == 0, "TODO: dump wasm");
    @debug_assert(self.globals.len == 0, "TODO: dump wasm");
    @debug_assert(self.elements.len == 0, "TODO: dump wasm");
    out.push_all(@slice(0x00, 0x61, 0x73, 0x6D));  // magic
    out.push_all(@slice(0x01, 0x00, 0x00, 0x00));  // version
    buf: List(u8) = list(temp());
    buf := buf&;
    inner_buf: List(u8) = list(temp());
    inner_buf := inner_buf&;
    
    Section :: Wasm.Section;
    out.push(Section.Type.raw());
    buf.leb128_unsigned(self.types.len); 
    for self.types { it | 
        buf.push(0x60);
        buf.leb128_unsigned(it.arg.len);
        for it.arg { ty |
            buf.push(ty.repr);
        };
        buf.leb128_unsigned(it.ret.len);
        for it.ret { ty |
            buf.push(ty.repr);
        };
    };
    out.leb128_unsigned(buf.len);
    out.push_all(buf.items());
    buf.clear();
    
    out.push(Section.Function.raw());
    buf.leb128_unsigned(self.functions.len); 
    for self.functions { it | 
        buf.leb128_unsigned(it.id.zext());
    };
    out.leb128_unsigned(buf.len);
    out.push_all(buf.items());
    buf.clear();
    
    out.push(Section.Export.raw());
    buf.leb128_unsigned(self.exports.len); 
    each self.exports { it | 
        buf.leb128_unsigned(it.name.len);
        buf.push_all(it.name.items());
        ::tagged(@type it.desc);
        tag: u8 = it.desc&.tag().ordinal().trunc();
        buf.push(tag);
        @match(it.desc) {  // TODO: this is kinda sad
            fn Function(idx) => buf.leb128_unsigned(idx.id.zext());
            fn Table(idx)    => buf.leb128_unsigned(idx.id.zext());
            fn Memory(idx)   => buf.leb128_unsigned(idx.id.zext());
            fn Global(idx)   => buf.leb128_unsigned(idx.id.zext());
        };
    };
    out.leb128_unsigned(buf.len);
    out.push_all(buf.items());
    buf.clear();
    
    out.push(Section.Code.raw());
    buf.leb128_unsigned(self.code.len); 
    each self.code { it | 
        inner_buf.leb128_unsigned(it.locals.len);
        each it.locals { local | 
            inner_buf.leb128_unsigned(local.count);
            inner_buf.push(local.ty.repr);
        };
        
        // Expressions aren't length prefixed, they have a terminator. 
        inner_buf.push_all(it.insts.items());
        ::?*u8;
        end := it.insts.items().last().unwrap()[];
        @assert_eq(end, Wasm.Inst.End.raw()); // TODO: move @debug_assert_eq to lib
        
        buf.leb128_unsigned(inner_buf.len);
        buf.push_all(inner_buf.items());
        inner_buf.clear();
    };
    out.leb128_unsigned(buf.len);
    out.push_all(buf.items());
    buf.clear();
}
