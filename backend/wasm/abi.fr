//! https://github.com/WebAssembly/tool-conventions/blob/main/BasicCABI.md
//! - non-scalar aggragates are always passed by pointer 
//! - aggragate return pointer is prepended to arguments
//! - varargs pointer is appended to arguments
//! - need an entry in the type table for the function's signeture. 
//! - env parameter (handled by isel. here just passes through the arge/pare)
//!   passed by storing it at the caller's sp (so callee gets it by doing a load before decrementing sp). 
//!   normally sp points at uninitialized memory that the calle will use. 
//!   since there's no limit to number of args, never have to spill 
//!   to the stack like on native so no complicated interaction with that.

// TODO: untangle Kw vs Kl: vararg, indirect return
//       should use the same k_mem as isel does and it should be dynamic so i can support memory64 as well.
k_mem :: Qbe.Cls.Kl;
// TODO: blit for argc

#use("@/backend/abi.fr");
fn wasm_abi(f: *Qbe.Fn) void = {
    f.native_abi(Qbe.Ref, selpar, sel_call, selvastart, selvaarg, selret);
}

selpar :: fn(f: *Qbe.Fn, par_i: []Qbe.Ins) Qbe.Ref = {
    // params come in as locals, not on the stack, which seems odd, 
    // but to be fair, the first thing i would do here is save them in locals anyway so i can't complain. 
    // we leave par instructions, emit.fr needs to create those locals as the first ones (instead of ordered by tmp index). 
    
    @if(f.retty != Qbe.Null) if f.scalar_struct(f.retty) { k |
        // single element struct returned by value 
        f.ret_cls = k;
        f.retty = Qbe.Null;
    };
    f.retr = @if(f.retty != QbeNull, f.newtmp("abi", k_mem), QbeNull);
    
    each par_i { i |
        @if_let(i.op()) fn parc() => if f.scalar_struct(i.arg&[0]) { k |
            // TODO: none of the .ssa tests get here
            r := f.newtmp("abi", k);
            f.emit(k.store_op(), .Kw, Qbe.Null, r, i.to);
            f.emit(.alloc8, .Kw, i.to, f.getcon(8), Qbe.Null);
            i[] = make_ins(.par, k, r, Qbe.Null, Qbe.Null);
        };
    };
    
    va_base := @if(f.vararg, f.newtmp("va", k_mem), Qbe.Null);
    if va_base != QbeNull {
        // append varargs pointer
        f.emit(.par, k_mem, va_base, QbeNull, QbeNull);
    };
    
    m := f.globals;
    par_cls := Qbe.Cls.list(par_i.len, temp());
    each_rev par_i { i |
        @match(i.op()) {
            fn pare() => {
                f.emit(i);
            }
            fn parc() => {
                // TODO: the par should be .Kw for the abi
                f.emit(.par, i.cls(), i.to, Qbe.Null, Qbe.Null);
                par_cls&.push(i.cls());
            }
            fn par() => {
                f.emit(.par, i.cls(), i.to, Qbe.Null, Qbe.Null);
                par_cls&.push(i.cls());
            }
            @default => unreachable();
        };
    };
    
    if f.retr != QbeNull {
        // prepend aggragate return pointer to our parameters
        f.emit(.par, k_mem, f.retr, QbeNull, QbeNull);
    };
    
    type := pack_wasm_result_type m { $yield_arg #duplicated |
        @if(f.retr != Qbe.Null) yield_arg(k_mem);
        for_rev(par_cls, yield_arg);
        @if(va_base != Qbe.Null) yield_arg(k_mem);
    } and { $yield_ret |
        if(!@is(f.ret_cls, .Ke, .Kx), => yield_ret(f.ret_cls));
    };
    save_signature(m, f.lnk.id, type);
    
    va_base
};

selret :: fn(b: *Qbe.Blk, f: *Qbe.Fn) void = {
    if !is_ret(b.jmp.type) || b.jmp.arg == QbeNull {
        return();
    };
    @debug_assert(b.jmp.type != .ret0, "J.ret0 had arg");
    
    if b.jmp.type == .retc && f.retty == Qbe.Null {
        r := f.newtmp("abi", f.ret_cls);
        f.emit(.push, f.ret_cls, QbeNull, r, QbeNull);
        f.emit(.load, f.ret_cls, r, b.jmp.arg, QbeNull);
        b.jmp = (type = .ret0, arg = QbeNull);
        return();
    };
    
    // TODO: check if they said its a type but really there's only one scalar 
    is_scalar := b.jmp.type != .retc;
    if is_scalar {
        k := f.ret_cls;
        if need_trunc(f, k, b.jmp.arg) {
            f.emit(.truncl, k, QbeNull, QbeNull, QbeNull);
            k = .Kl;
        };
        f.emit(.push, k, QbeNull, b.jmp.arg, QbeNull);
    } else {
        @debug_assert_ne(f.retr, QbeNull, "missing indirect return pointer");
        size := f.get_type(f.retty)[].header.size; 
        f.emit(.blit1, .Kw, QbeNull, INT(zext size), QbeNull);
        f.emit(.blit0, .Kw, QbeNull, b.jmp.arg, f.retr);  // src, dest
    };
    b.jmp = (type = .ret0, arg = QbeNull);
};

sel_call :: fn(f: *Qbe.Fn, args: []Qbe.Ins, il: *List(Qbe.Ins)) *Qbe.Ins = {
    arg0, i := (args.ptr, args.ptr.offset(args.len));
    m    := f.globals;
    
    @if(i.arg&[1].rtype() == .RType) 
    if scalar_struct(f, i.arg&[1]) { k |
        // single element struct passed by value but the ir expects it in memory. 
        r := f.newtmp("abi", k);
        i.set_cls(k);
        i.arg&[1] = Qbe.Null;
        f.emit(k.store_op(), .Kw, Qbe.Null, r, i.to);
        il.push(make_ins(.alloc8, .Kw, i.to, f.getcon(8), Qbe.Null));
        i.to = r;
    };
    
    before := Qbe.Ins.list(temp());
    each args { i |
        @if_let(i.op()) fn argc() => if f.scalar_struct(i.arg&[0]) { k |
            r := f.newtmp("abi", k);
            before&.push(make_ins(.load, k, r, i.arg&[1], Qbe.Null));
            i[] = make_ins(.arg, k, Qbe.Null, r, Qbe.Null);
        };
    };
    
    type := type_index_for_call(f, i, arg0);
    if f.get_sym(i.arg&[0]) { id, off | 
        msg :: "tried to call offset from symbol ($% + %)\nwhich is probably a mistake for any target but certainly not possible on wasm.";
        @debug_assert_eq(off, 0, msg, m.str(id), off);
        // We allow imports without type declarations, but wasm's import table does not. 
        // So if we haven't seen this symbol yet, it might be an import, so we need to save the type info from this call. 
        save_signature(m, id, type);
    };
    
    is_scalar := i.arg&[1] == QbeNull;
    pending_indirect_return := QbeNull;
    if is_scalar {
        if i.to != QbeNull {
            f.emit(.pop, i.cls(), i.to, QbeNull, QbeNull);
        };
    } else {
        pending_indirect_return = i.to;
    };
    placeholder := f.emit(.nop, .Kw, Qbe.Null, Qbe.Null, Qbe.Null);
    i.to = QbeNull;
    call_arg1 := i.arg&[1];
    i.arg&[1] = CALL(type.intcast());
    f.emit(i);
    
    // varargs are passed by writing them to memory and appending that pointer as an argument. 
    is_va := false;
    va_slot := QbeNull;
    va_size := 0;
    enumerate args { j, i |
        if is_va {
            @debug_assert_eq(i.op(), .arg);
            ::if(i32);
            // write the argument to the next stack slot
            size := if(i.cls().is_wide(), => 8, => 4);
            va_size = va_size.align_to(size);
            r := f.newtmp("abi", k_mem);
            f.emit(i.cls().store_op(), .Kw, QbeNull, i.arg&[0], r);
            f.emit(.add, k_mem, r, va_slot, f.getcon(va_size));
            va_size += size;
        };
        if i.op() == .argv {
            @debug_assert(!is_va);
            f.slot = f.slot.align_to(16);  
            va_slot = f.newtmp("abi", k_mem);
            is_va = true;
            args = args.slice(0, j);  // remove the rest of the args
        };
    };
    
    if args.len > 0 && args.index(0).op() == .arge {
        f.emit(args[0]);
    };
    
    if is_va {
        f.emit(.push, k_mem, QbeNull, va_slot, QbeNull);
        il.push(make_ins(.alloc8, k_mem, va_slot, f.getcon(va_size), Qbe.Null));
    };
    
    each_rev args { i |
        @match(i.op()) {
            fn argc() => {
                // TODO: need to insert a blit.
                //       but this doesn't work. maybe just because the dynalloc isnt respecting alignment? 
                //       (TODO: try again now that i fixed which end the SP local points to). 
                //       it doesn't matter for franca because emit_ir.fr/compile_for_arg_impl() uses NewMemory anyway. 
                // TODO: add a .ssa test that cares about this
                
                //k := i.cls();
                //dest := f.newtmp("abi", k);
                //t := f.get_type(i.arg&[0])[].header;
                //allocation := make_ins(alloc_op(t.align_log2.zext()), k, dest, f.getcon(zext t.size), QbeNull);
                ////il.push(allocation);  // TODO: but need to skip pars
                //f.emit(.push, k, QbeNull, dest, QbeNull);
                //f.emit(.blit1, .Kw, QbeNull, INT(zext t.size), QbeNull);
                //f.emit(.blit0, .Kw, QbeNull, i.arg&[1], dest);
                //f.emit(allocation); f.dynalloc = true;
                
                f.emit(.push, i.cls(), QbeNull, i.arg&[1], QbeNull);
            }
            fn arg()  => {
                f.emit(.push, i.cls(), QbeNull, i.arg&[0], QbeNull);
            }
            fn arge() => ();
            @default => unreachable();
        };
    };
    
    if pending_indirect_return != QbeNull {
        t := m.get_type(call_arg1.val());
        op := alloc_op(t.header.align_log2.zext());
        r := pending_indirect_return;
        s := f.getcon(t.header.size.zext());
        il.push(make_ins(op, k_mem, r, s, Qbe.Null));
        f.emit(.push, k_mem, QbeNull, r, QbeNull);
    };
    for(before, fn(i) => f.emit(i));
    
    arg0
};

selvastart :: fn(f: *Qbe.Fn, va_base: Qbe.Ref, ap: Qbe.Ref) void = {
    @debug_assert(va_base != Qbe.Null);
    f.emit(.storel, .Kw, QbeNull, va_base, ap);
};

selvaarg :: fn(f: *Qbe.Fn, b: *Qbe.Blk, i: *Qbe.Ins) void = {
    // move the pointer up by one slot and load the new value
    size := if(i.cls().is_wide(), => 8, => 4);
    @emit_instructions((f = f), (i.arg&[0], i.to, i.cls(), size-1, bit_not(size-1), size), """
    @start
        %old =l load %0
        %raw =l add %old, %3  # align
        %cur =l and %raw, %4  # ^
        %new =l add %cur, %5
        storel %new, %0
        %1   =2 load %cur
    """);
};

fn save_signature(m: *Qbe.Module, id: Qbe.Sym, type: i32) void = {
    @debug_assert_ge(type, 0);
    use_symbol(m, id) { s |
        if s.wasm_type_index != -1 {
            @debug_assert_eq(s.wasm_type_index, type, "wasm signature mismatch $%", s.name);
        };
        s.wasm_type_index = type;
        //@println("% is type %", s.name, s.wasm_type_index);
    }; 
};

fn type_index_for_call(f: *Qbe.Fn, call: *Qbe.Ins, arg0: *Qbe.Ins) i32 = {
    void := call.to == QbeNull;
    scalar := !void && rtype(call.arg&[1]) != .RType;
    #use("@/backend/wasm/emit.fr");
    pack_wasm_result_type f.globals { $yield_arg #duplicated |
        if !void && !scalar {
            // TODO: really this pointer should be Kw but then i have to change the par added above. 
            yield_arg(.Kl);
        };
        va := false;
        for(arg0, call) { i |
            if i.op() == .argv {
                va = true;
                yield_arg(.Kl);
            };
            if !va && i.op() != .arge {
                yield_arg(i.cls());
            };
        };
    } and { $yield_ret |
        if(scalar, => yield_ret(call.cls()));
    }
}

fn scalar_struct(f: *Qbe.Fn, maybe_type: Qbe.Ref) ?Qbe.Cls = {
    @debug_assert_eq(rtype(maybe_type), .RType);
    scalar_struct(f, maybe_type.val())
}

fn scalar_struct(f: *Qbe.Fn, type_index: i64) ?Qbe.Cls = {
    m := f.globals;
    type := m.get_type(type_index);
    if(type.is_union(), => return(.None));
    fst := type.fields[0].unpack();
    @debug_assert(fst.type != .FEnd, "You should not have 0-sized types in the IR. Lower them in the frontend instead please.");
    snd := type.fields[1].unpack();
    if(snd.type != .FEnd, => return(.None));
    k := fst.type.cls();
    @if(k != .Ke) return(Some = k);
    @if(fst.type == .FTyp) return(scalar_struct(f, fst.len.zext()));
    .None
}

#use("@/backend/lib.fr");
