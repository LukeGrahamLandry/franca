// TODO: These are just cringe forward declarations to create the overload sets. 
fn for();
fn each();
fn enumerate();
fn get();
fn set();
fn fill();
fn subslice();
fn index();
fn slice();
fn len();
fn copy_from();
fn rest();
fn find();
fn last();
fn is_empty();
fn slice_last();
fn empty() void;
fn each_rev();
fn contains();
fn index_unchecked();

fn range(start: i64, end: i64, const yield: Fn(i64, void)) void = {
    i := start;
    while(=> i.lt(end)) {|
        yield(i);
        i = i.add(1);
    };
}

// TODO: PROBLEM: now that im not just taking the first overload, this not using comptiem cache because its not #generic so multiple versions of inner functions can get made 
//       I still want to replace @comptiem with just having const args but need to make @impl use the cache. 

// :blessed: String literals and @slice create values of this type. 
fn Slice(const T: Type) Type = {
    Self :: @struct(ptr: *T, len: i64);
    
    ::ptr_utils(T);
    
    fn slice(ptr: *T) Self = (ptr = ptr, len = 1);
    fn slice(ptr: *T, count: i64) Self = (ptr = ptr, len = count);
    // TODO: this is jail if you pass it to rust
    fn empty() Self = Self.zeroed();
    
    
    fn len(self: *Self) i64 #inline = self.len;
    fn index(self: *Self, i: i64) *T #inline =  {
        assert(i.lt(self.len), "OOB<");
        self.ptr.offset(i)
    }
    
    fn len(self: Self) i64 #inline = self.len;
    fn index(self: Self, i: i64) *T #inline = {
        assert(i.lt(self.len), "OOB!"); 
        self.ptr.offset(i)
    }
    
    fn index_unchecked(self: Self, i: i64) *T = {
        self.ptr.offset(i)
    }
    
    ::DeriveIndexable(Self, T);
    ::DeriveIndexable(*Self, T); 
    
    fn slice(self: Self, first: i64, past_last: i64) Self = {
        // TODO: first should be lt
        // TODO: its sad that im doing double bounds check in common case where its just index()
        assert(first.le(self.len()).and(past_last.le(self.len())), "OOB$"); 
        new_ptr := self.ptr.offset(first);
        // TODO: shouldn't need the extra binding. broke with scan ahead consts / renumber comptime. 
        //       only for tests/fmt.fr, that can't be the only place that calls items(), some scary ordering thing? -- Apr 22
        res: Self = (ptr = new_ptr, len = past_last.sub(first)); 
        res
    }
    
    fn subslice(self: Self, first: i64, count: i64) Self = {
        self.slice(first, first.add(count))
    }
    
    fn rest(self: Self, first: i64) Self = {
        self.slice(first, self.len())
    }
    
    fn slice_last(self: Self, count: i64) ?Slice(T) = {
        ::if(?Slice(T));
        if(self.len.lt(count), fn()?Slice(T)=> (None = unit)) {|
            (Some = self.slice(self.len.sub(count), self.len))
        }
    }
    
    // TODO: sad to JIT compile this for all types when emitting AOT, not just needed. :SLOW
    //       can outline this because it can't call bake_relocatable_value(T) directly anyway. but should fix the actual problem anyway.
    // TODO: this api involves hella copying. caller should pass in a list of BakedEntry. :SLOW
    // This looks kinda ugly but it used to be 35 lines of rust (instead of 31 here) and was a magic special case that assumed anything with ptr,len field names was a slice. 
    fn bake_relocatable_value(self: *Self) Slice(BakedEntry) = {
        ::List(BakedEntry); ::if(BakedEntry); ::if(BakedVarId);
        
        // TODO: StructName.(initilizer) so you're not forced to use @as or put the type on the other side? 
        len: BakedEntry = (Num = (value = self.len, ty = .I64));
        ptr: BakedEntry = if self.len.eq(0) {|
            (Num = (value = 0, ty = .P64))
        } {|
            info := ::get_meta(T);
            // TODO: assert alignment
            // TODO: assert len isnt big enough to be a pointer?
            // TODO: need to check against c.baked.lookup (the first ptr not each individual element) :BLOAT
            id := if info.contains_pointers {|
                parts: List(BakedEntry) = list(ast_alloc());
                each self {v| 
                    ptr := ptr_cast_unchecked(T, u8, v);
                    bytes := slice(ptr, info.stride_bytes.zext());
                    // TODO: its a bit un-intuative that you can't just call bake_relocatable_value(v), the dyn version uses the compiler auto implementation if none exists. 
                    entries := dyn_bake_relocatable_value(bytes, T, false); // TODO: default arg. TTODO: explain somewhere
                    parts&.push_all(entries);
                };
                // TODO: without cast
                bake_value(@as(BakedVar) (VoidPtrArray = parts.rs()))
            }{|
                ptr := ptr_cast_unchecked(T, u8, self.ptr);
                bytes := slice(ptr, self.len.mul(info.stride_bytes.zext()));
                bytes := bytes.clone(ast_alloc());
                bake_value(@as(BakedVar) (Bytes = bytes.rs())) // TODO: this should take jit_ptr param? even tho its sad if you had to do work just for me to throw away. and then would want to warn if conflicting handlers or it could be super confusing.  -- Jun 30
            };
            (AddrOf = id)
        };
        
        @slice(ptr, len) ast_alloc()
    }
    
    Self
}

// TODO: single element if arg isn't a tuple.
#macro fn slice(elements: FatExpr, allocator: FatExpr) FatExpr = @{
    s := @slice @[elements];
    s := clone(s, @[allocator]);
    s.items()
};

#macro fn slice(elements: FatExpr) FatExpr = @{ @[elements]!slice };

#macro fn list(elements: FatExpr, allocator: FatExpr) FatExpr = @{
    s := @slice @[elements];
    s := clone(s, @[allocator]);
    s
};

// TODO: can't do this in fn Slice because it tries to deal with all the overloads too soon? 
fn display_slice(const T: Type) void = {
    fn display(self: Slice(T), writer: *List(u8)) void = {
        "[".display(writer);
        // TODO: use each? but then need better error if its defined for T but not *T. 
        prefix := "";
        for(self) { (e: T) void | 
            prefix.display(writer);
            e.display(writer);
            prefix = ", ";
        };
        "]".display(writer);
    }
}

/// A null terminated sequence of bytes.
CStr :: @struct(ptr: *u8);

/// When emitting an aot constant, include all the way until a zero, not just a single byte like it would for a normal *u8. 
fn bake_relocatable_value(self: *CStr) Slice(BakedEntry) = {
    // TODO: need to check against  c.baked.lookup :BLOAT
    bytes: List(u8) = list(ast_alloc());
    for self[] { b|
        bytes&.push(b);
    };
    bytes&.push(@as(u8) 0.trunc());
    value := bake_value(@as(BakedVar) (Bytes = bytes.rs()));
    ptr: BakedEntry = (AddrOf = value);
    ptr.repeated(1, temp()).items()
}

:: {
    temp : Fn(Type, Type) : Slice; // TODO: coerce in arg
    __save_slice_t(temp);
    __save_bake_os(bake_relocatable_value);
};

Str :: Slice(u8);

fn as_array();

// A value type fixed size array. Like [T; len] in Rust or [len] T in Zig.
fn Array(const T: Type, const count: i64) Type = {
    Self :: {
        // TODO: HACK. I should be able to call intern_type directly but can't call deconstruct_values on a tagged thing. this mostly just works by luck. -- May 27
        info: TypeInfo = (Array = (inner = T, len = count.trunc()));
        intern_type_ref(info&)
    };
    
    fn init(elements: Slice(T)) Self #no_tail = {
        assert(eq(elements.len, count), "arrays have fixed length"); // TODO: better message 
        self := Self.uninitialized();
        enumerate(elements){ i, t |
            self&.index(i)[] = t[];
        };
        self
    }
    
    fn init(copied: T) Self #no_tail = {
        self := Self.uninitialized();
        range(0, count){ i |
            self&.index(i)[] = copied;
        };
        self
    }
    
    /// If a slice is the right length, it can be cast to a pointer to an array. 
    fn as_array(elements: Slice(T)) ?*Self = {
        :: if(?*Self);
        if(elements.len.ne(count), => .None) {|
            (Some = ptr_cast_unchecked(From = T, To = Self, ptr = elements.ptr))
        }
    }
    
    fn eq(lhs: Self, rhs: Self) bool = lhs&.slice().eq(rhs&.slice());
    
    ::ptr_utils(T);
    fn index(self: *Self, i: i64) *T = {
        assert(lt(i, count), "OOB@");
        self.as_ptr().offset(i)
    }
    
    fn len(self: *Self) i64 #inline = count;
    
    fn slice(self: *Self) Slice(T) = (ptr = self.as_ptr(), len = count);
    
    fn as_ptr(self: *Self) *T = ptr_cast_unchecked(From = Self, To = T, ptr = self);
    
    // TODO: instead of generating whole new versions of all these functions,
    //       have a DeriveAsSliceIndexable that just aliases Self as a Slice(T) and reuses the slice ones. 
    //       can use that for List too. 
    ::DeriveIndexable(*Self, T);
    
    Self
}

// Note: Passing *Self and Self mean different things. Containers that are already logically a pointer may want both for convenience. 
// TODO: trait bounds. fn index(Self) *T; fn len(Self) i64;
fn DeriveIndexable(const Self: Type, const T: Type) void = {
    #inline
    fn set(self: Self, i: i64, v: T) void = {
        self.index(i)[] = v; 
    }
    
    #inline
    fn get(self: Self, i: i64) T = {
        v: *T = self.index(i);  // TODO: fix so dont need useless binding 
        v[]
    }
    
    // TODO: the other fn type syntax so you can name the arguments in the closure as documentation. 
    // TODO: be more consistant about how tuples are expanded into args to fix Fn((a, b), c) === Fn(a, b, c) when you want Fn(Ty(a, b), c)
    //       seems like a massive mistake that I create ambiguity and then just guess something stupid and hope for the best. 
    fn enumerate(arr: Self, const f: Fn(Ty(i64, *T), void)) void = {
        i := 0;
        while(=> lt(i, arr.len())) {|
            e: *T = arr.index(i);
            f(i, e);
            i = i.add(1);
        };
    }
    
    // TODO: I don't love that I have to write the deref version seperatly
    //       but I dont have let destructuring (only function args) so its a pain to take tuples by pointer. 
    //       I should be able to destructure Ptr(A, B) to (Ptr(A), Ptr(B))
    fn for(arr: Self, const f: @Fn(e: T) void) void = 
        each(arr, fn(v: *T) void => f(v[]));
    
    fn each(arr: Self, const f: Fn(*T, void)) void = {
        i := 0;
        l := arr.len();
        while(=> lt(i, l)) {|
            f(arr.index(i));
            i = i.add(1);
        };
    }
    
    fn each_rev(arr: Self, const f: Fn(*T, void)) void = {
        i := arr.len() - 1;
        while(=> i >= 0) {|
            f(arr.index(i));
            i -= 1;
        };
    }
    
    fn contains(self: Self, needle: *T) bool = {
        each self { check |
            if(check == needle, => { return(true); });
        };
        false
    }
    
    // TODO: Something's fucked! doesn't work if not inlined!
    #inline fn copy_from(dest: Self, src: Self) void = {
        assert(eq(len(dest), len(src)), "OOB#");  // Note: not using `asser t_eq` because the vm tracks those for my tests
        // TODO: sad that this does the bounds check every iteration but a real optimiser would fix it for me anyway so meh. 
        // TODO: this used to work as binding. new syntax is better but old should still work. broke when scan ahead resolve. -- Apr 22
        // const f = fn(i: i64, e: *T) void = dest.set(i, e[]);
        enumerate src {i, e|
            dest.set(i, e[]);
        };
    }
    
    // TODO: add addr_eq/identical if that's really what you want but like... it never is I feel. 
    // TODO: Something's fucked! doesn't work if not inlined!
    // TODO: fast path if same pointer or is that creepy? 
    #inline fn eq(lhs: Self, rhs: Self) bool = {
        eq(lhs.len(), rhs.len()).and() { () bool |
            i := 0;
            while(fn()bool=>i.lt(len(lhs)).and(fn()bool=> lhs.get(i).eq(rhs.get(i)))) {| 
                i = i.add(1); 
            };
            eq(i, lhs.len())
        }
    }
    
    /// Set all elements of the slice to 't'. 
    fn fill(self: Self, t: T) void = {
        each(self){ ptr |
            ptr[] = t;
        };
    }
    
    fn last(self: Self) ?*T = {
        ::if(?*T);
        if(self.is_empty(), => (None = unit)) {|
            (Some = self.index(self.len.sub(1)))
        }
    }
    
    fn is_empty(self: Self) bool = self.len().eq(0);
}

fn ends_with(haystack: Str, needle: Str) bool = {
    if(lt(len(haystack), len(needle)),
        => false,
        => {
            start := subslice(haystack, sub(len(haystack), len(needle)), len(needle)); 
            eq(start, needle)
        }
    )
}

// TODO: these should just be on Slice(T)
fn starts_with(haystack: Str, needle: Str) bool = {
    if(lt(len(haystack), len(needle)), => false,
        fn() bool => {
            start := subslice(haystack, 0, len(needle)); 
            eq(start, needle)
        }
    )
}
