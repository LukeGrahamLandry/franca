fn StaticBitSet($bit_capacity: i64) Type = {
    count :: bit_capacity.add(63).div(64);
    Self  :: @struct(bits: Array(i64, count));
    
    fn empty() Self #fold = Self.zeroed();
    fn set_all(self: *Self) void = {
        self.bits&.items().interpret_as_bytes().set_bytes(255);
    }
    
    fn get(self: *Self, i: i64) bool = {
        @safety(.Bounds) i.ult(bit_capacity);
        index, bit := i.udiv_mod(64);
        self.bits&[index].bit_and(1.shift_left(bit)).ne(0)
    }
    
    fn contains(self: *Self, i: *i64) bool = self.get(i[]); // match api of List
    
    fn set(self: *Self, i: i64) void = {
        @safety(.Bounds) i.ult(bit_capacity);
        index, bit := i.udiv_mod(64);
        self.bits&[index] = self.bits&[index].bit_or(1.shift_left(bit));
        //self.set(i, true);  // TODO: make the backend good enough that this generates the same asm
    }
    
    fn unset(self: *Self, i: i64) void = {
        @safety(.Bounds) i.ult(bit_capacity);
        index, bit := i.udiv_mod(64);
        self.bits&[index] = self.bits&[index].bit_and(1.shift_left(bit).bit_not());
        //self.set(i, false);  // TODO: make the backend good enough that this generates the same asm
    }
    
    fn set(self: *Self, i: i64, value: bool) void = {
        @safety(.Bounds) i.ult(bit_capacity);
        index, bit := i.udiv_mod(64);
        bits := self.bits&[index];
        bits = bits.bit_and(1.shift_left(bit).bit_not());
        bits = bits.bit_or(value.int().shift_left(bit));
        self.bits&[index] = bits;
    }
    
    fn clear(self: *Self) void = {
        self[] = empty();
    }
    
    fn capacity(self: *Self) i64 = bit_capacity;
    
    fn count_ones(self: *Self) i64 = {
        n := 0;
        for self.bits& { it |
            n += it.count_ones().zext();
        };
        n
    }
    
    Self
}

// TODO: unmanaged version where you store the allocator yourself
DynamicBitSet :: @struct(bits: List(i64));

fn empty(a: Alloc) DynamicBitSet = (bits = list(a));

fn get(self: *DynamicBitSet, i: i64) bool = {
    //@println("i=% len=% cap=% % self=%", 
    //    i, self.bits.len, self.bits.maybe_uninit.len, 
    //    i64.raw_from_ptr(self.bits.maybe_uninit.ptr), DynamicBitSet.raw_from_ptr(self));
    @if(i >= self.bits.len*64) return(false);
    index, bit := i.div_mod(64);
    self.bits&[index].bit_and(1.shift_left(bit)) != 0
}

fn set(self: *DynamicBitSet, i: i64) void = {
    cap := self.bits.len.mul(64);
    if(i >= cap, => self.reserve(i.sub(cap).add(1)));
    index, bit := i.div_mod(64);
    self.bits&[index] = self.bits&[index].bit_or(1.shift_left(bit));
}

// returns true if it was already set before
fn get_set(self: *DynamicBitSet, i: i64) bool = {
    cap := self.bits.len.mul(64);
    if(i >= cap, => self.reserve(i - cap + 1));
    index := i.shift_right_logical(6);
    bit   := i.bit_and(63);
    old := self.bits&[index];
    mask := 1.shift_left(bit);
    self.bits&[index] = old.bit_or(mask);
    old.bit_and(mask) != 0
}

fn unset(self: *DynamicBitSet, i: i64) void = {
    @safety(.Bounds) i.ult(self.bits.len * 64);
    index, bit := i.div_mod(64);
    self.bits&[index] = self.bits&[index].bit_and(1.shift_left(bit).bit_not());
}

fn reserve(self: *DynamicBitSet, extra: i64) void = 
    self.bits&.push_repeated(extra.align_to(64)/64, 0);

fn clear(self: *DynamicBitSet) void = {
    self.bits&.clear();
}

fn unset_all(self: *DynamicBitSet) void = {
    self.bits.items().set_zeroed();
}

fn capacity(self: *DynamicBitSet) i64 = self.bits.len.mul(64);

fn set_all_from(self: *DynamicBitSet, other: *DynamicBitSet) void = {
    // TODO: this reserves more than needed
    self.bits&.reserve(other.bits.len);
    while => self.bits.len < other.bits.len {
        self.bits&.push(0);
    };
    range(0, other.bits.len) { i |
        self.bits[i] = self.bits[i].bit_or(other.bits[i]);
    };
}
