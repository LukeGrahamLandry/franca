//! I have mixed feelings about this. It's a heavier runtime than I really want... 
//! but it makes debugging a hell of a lot less painful. 
//! 
//! For reference,
//! - libbacktrace 16k lines of c. 
//! - addr2line is 3k lines of rust... plus a 700 line lock file (including gimli for dwarf parsing, 42k lines).
//! Both rely on your executable having metadata in standard format (itanium c++ exception tables or dwarf debug info),
//! that is more complicated to generate than I'm willing to deal with (I could have llvm do it but that's still painful and I want to support many backends). 
//! I'm sure they solve a hard problem and solve it well/fast/whatever, but its clearly a more complicated problem than the one I have. 

RuntimeContext :: @struct(
    stack_trace: List(u32), // func indices
);

// TODO: this is unacceptable. there's like 3x overhead now that more of compiler is self hosted. -- Jun 30
RUNTIME_STACK_TRACE :: false;
:: {
    if(RUNTIME_STACK_TRACE){|
        ctx := get_context();
        // TODO: deal with constant lists correctly. 
        //   if you callstack is ever bigger than 100 this gives constant memory to free (which is why we use todo_allocator which leaks).
        ctx.stack_trace = list(100, todo_allocator);
        // TODO: this is still a super dumb version of this. really i want manual linked list on the stack frames, not seperatly allocated thing! -- Jun 25 
        runtime_push_call :: fn(f: u32) void = {
            ctx := get_context();
            ctx.stack_trace&.push(f);
        };
        runtime_pop_call :: fn() void = {
            ctx := get_context();
            // SAFETY: We know we each pop has a matching push because only emit_bc calls these. 
            //        this saves makes it ~10% faster -- Jun 30
            // ctx.stack_trace&.pop();
            ctx.stack_trace.len -= 1;
        };
        
        // force them to be compiled
        // this ensures anything called in thier body WONT have tracing calls injected (just like #no_trace)
        runtime_push_call(0);
        runtime_pop_call();
        
        // :blessed: the compiler injects calls to these functions in the prelude and epilogue of every function. 
        // this allows platform independent stack traces. 
        env := get_comptime_environment();
        env.inject_function_header = (Some = (runtime_push_call, runtime_pop_call));
    };
};

_context :: @static(RuntimeContext);
fn get_context() *RuntimeContext #no_trace  = _context;

// TODO: its really funny that this is not in fact a compile time known constant! HACK 
//       footgun that if you ':: is_aot()' it will compile but give missleading answer.  -- Jun 26
fn is_aot() bool = {
    ComptimeMarker :: @struct(aot: rawptr);
    marker :: @static(ComptimeMarker);
    :: { marker[] = (aot = 1.rawptr_from_int()); };
    fn bake_relocatable_value(self: *ComptimeMarker) Slice(BakedEntry) = 
        @slice(@as(BakedEntry) (Num = 0)) ast_alloc();
    
    marker[].aot.is_null()   // TODO: why do i need [] ????  
}

fn get_debug_name(i: u32) CStr = {
    names := franca_aot_get_debug_function_names();
    names: Slice(CStr) = slice(names._0, names._1[]);
    names[i.zext()]
}

fn franca_aot_get_debug_function_names() Ty(*CStr, *i64) #llvm #c_call #asm = """
    ret { ptr, ptr } { ptr @debug_names, ptr @debug_names_len }
""";
