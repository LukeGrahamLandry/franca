fn has_pointers(T: Type) bool #fold = {
    i := T.get_meta();
    i.contains_pointers
}

fn align_of(T: Type) i64 #fold = {
    i := T.get_meta();
    i.align_bytes.zext()
}

fn get_fields(S: Type) Slice(Field) #fold = {
    info := get_type_info_ref(S); 
    assert(info.is(.Struct), "Expected struct type");
    info.Struct.fields.items() 
}

get_field_type :: fn(S: Type, name: Symbol) Type #fold = {
    fields := S.get_fields();
    for fields { f | 
        if f.name == name {
            return(f.ty);
        };
    };
    debug_log_type(S);
    panic("Could not find field")
};

fn get_variants(S: Type) Slice(Ty(Symbol, Type)) #fold = {
    info := get_type_info_ref(S); 
    assert(info.is(.Tagged), "Expected @tagged type");
    fuck := info.Tagged.cases;
    ::List(Ty(Symbol, Type));
    fuck.items() 
}

// SAFETY: S must be a struct with field f. 
get_field_ptr :: fn($S: Type, self: *S, $f: *Field) *f[].ty #generic #inline = {
    inner := S.int_from_ptr(self);
    inner := inner + (:: f[].byte_offset);
    inner := f[].ty.ptr_from_int(inner);
    inner
};

get_variant_ptr :: fn($E: Type, self: *E, $t: E.Tag()) *E.get_variant_type(t) #generic #inline = {
    inner := E.int_from_ptr(self);
    inner := inner + 8;
    inner := E.get_variant_type(t).ptr_from_int(inner);
    inner
};

// TODO: if you get garbage memory / safety cvheck failed here its becasue it doesnt typecheck maybe. -- Jul 16 :FUCKED
get_variant_type :: fn($E: Type, t: E.Tag()) Type #generic #fold = {
    cases := E.get_variants();
    ::tagged(E); // :sema_regression. but might just be order?
    // TODO: it doesn't like this being debug_assert when i moved some of the Hash impls on ast types into emit_bc. 
    if !(t.ordinal() < cases.len && t.ordinal() >= 0) {
        panic("ICE: invalid tag");
    };
    data := cases.index(t.ordinal());
    data._1
};

get_variant_ptr_for :: fn($E: Type, self: *E, $case: *Ty(Symbol, Type)) *case[]._1 #generic #inline = {
    inner := E.int_from_ptr(self);
    inner := inner + 8;
    inner := case[]._1.ptr_from_int(inner);
    inner
};

EnumBacking :: fn(E: Type) Type = {
    info := get_type_info_ref(T); 
    assert(info.is(.Enum), "Expected @enum type");
    info.Enum.raw 
};

get_cases :: fn($E: Type) []E #generic #fold = {
    info := get_type_info_ref(E); 
    assert(info.is(.Enum), "Expected @enum type");
    fields := info.Enum.fields&;
    out: List(E) = list(fields.len, ast_alloc());
    each fields { f |
        ptr := f._1&.rawptr_from_value();
        ptr := E.ptr_from_raw(ptr);
        out&.push(ptr[]);
    };
    out.items()
};

fn enum_count(E: Type) i64 #fold = {
    info := get_type_info_ref(E); 
    assert(info.is(.Enum), "Expected @enum type");
    info.Enum.fields.len
}

for_enum :: fn($E: Type, $f: @Fn(e: E) void) void #generic = {
    values := @run E.get_cases();
    for(values, f);
};

inline_for_enum :: fn($E: Type, $f: @Fn(e: *E) void) void #generic = {
    values :: E.get_cases();
    @inline_for(values) f;
};

// TODO: footgun: they might not be in order by oridinal or the values might not even be ints. 
// TODO: make it clear that the slice should be in a constant somehow. 
fn get_enum_names(E: Type) Slice(Str) #fold = {
    info := get_type_info_ref(E);
    assert(info.is(.Enum), "expected enum type");
    names: List(Str) = list(ast_alloc());
    
    for (info.Enum.fields.items()) { i|
        names&.push(i._0.str());
    };
    names.items()
}

fn get_enum_names_symbols(E: Type) Slice(Symbol) = {
    info := get_type_info_ref(E);
    assert(info.is(.Enum), "expected enum type");
    names: List(Symbol) = list(ast_alloc());
    
    for (info.Enum.fields.items()) { i|
        names&.push(i._0);
    };
    names.items()
}

#use("@/lib/collections/map.fr") 
fn create_enum_name_table_outlined(E: Type, names: *PackedStrings) HashMap(Str, *u8).Raw = {
    // These are passed in so the binary doesn't include two copies of the name bytes if you also call E.name_str(). 
    packed, offs := names[];

    t: HashMap(Str, *u8) = init(ast_alloc());
    info := get_type_info_ref(E); 
    assert(info.is(.Enum), "Expected @enum type for from_name");
    enumerate info.Enum.fields.items() { i, f |
        ptr := f[]._1&.rawptr_from_value();
        // TODO: reboxing the copy is a dumb hack :SLOW -- Nov 14
        bytes1: []u8 = (ptr = u8.ptr_from_raw(ptr), len = size_of(E));
        bytes2 := bytes1.shallow_copy(ast_alloc());   // TODO: is alignment real
        
        name := packed.subslice(offs[i*2].zext(), offs[i*2+1].zext());
        t&.insert(name, bytes2.ptr);
    };
    t.raw&.zero_unused_slots();
    t.raw
}

// TODO: could do some fancy perfect hashing thing since we know the keys at comptime. 
#use("@/lib/collections/map.fr") 
fn from_name($E: Type, name: Str) ?E #generic = {
    @if(E.enum_count() < 5) {
        inline_for_enum E { $e |
            ee :: e[];
            if name == (:: ee.name_str()) {
                return(Some = ee);
            };
        }; 
        return(.None);
    };

    // TODO: we can't always store a hash table with E by value in a constant because we don't support field sizes that are not a multiple of 8 bytes -- Nov 14
    M :: HashMap(Str, *E);
    table :: @static(M.Raw) {
        t := create_enum_name_table_outlined(E, packed_enum_names(E));
        t2 := ptr_cast_unchecked(@type t, M.Raw, t&)[];  // IMPORTANT TO CAST BACK so the compiler knows to include the constants as the right type
        t2
    };
    
    if table.get(name) { p |
        return(Some = p[])
    };
    .None
}

// get an enum representing the fields of struct.
fn Fields($S: Type) Type = :: {
    T :: Ty(Symbol, Values);
    info := get_type_info_ref(S);
    assert(info.is(.Struct), "Fields expected struct type");
    ff := info.Struct.fields&;
    fields := T.list(ff.len, ast_alloc());
    enumerate ff { i, f |
        fields&.push(@as(T) (f.name, (Small = (i, 8))));
    };
    type: TypeInfo = (Enum = (raw = i64, fields = fields.as_raw(), sequential = true));
    intern_type_ref(type&)
}

fn is_sequential_enum(E: Type) bool #fold = {
    info := get_type_info_ref(E);
    info.is(.Enum) && info.Enum.sequential
}

fn is_enum(E: Type) bool #fold = {
    info := get_type_info_ref(E);
    info.is(.Enum)
}

fn offset_of($S: Type, f: Fields(S)) i64 #generic #fold = {
    ::enum(Fields(S));
    require_layout_ready(S); 
    info := get_type_info_ref(S);
    off := info.Struct.fields[f.raw()].byte_offset;
    off
}

fn is_ptr(T: Type) bool #fold = 
    get_type_info_ref(T).is(.Ptr);

fn Deref(T: Type) Type #fold = {
    info := get_type_info_ref(T);
    @assert(info.is(.Ptr), "used Deref(Type) on non-pointer");
    info.Ptr
}

fn has_field(S: Type, name: Symbol) bool #fold = {
    info := get_type_info_ref(S);
    if(!info.is(.Struct), => return(false));
    each info.Struct.fields& { f |
        if(f.name == name, => return(true));
    };
    false
}

fn has_const_field(S: Type, name: Symbol) bool #fold = {
    info := get_type_info_ref(S);
    if(!info.is(.Struct), => return(false));
    s := scope_of(Type, S);
    if(s == NOSCOPE, => return(false));  // :UpdateBoot get_constant used to crash on this
    get_constant(s, name).is_some()
}

fn has_feature($s: Str) bool #fold = 
    __builtin_compiler_has_feature(s);

fn scope_of($T: Type, t: T) ScopeId #generic = {
    it := scope_from_value(T, raw_from_ptr(T, t&));
    it.expect("scope_of to succeed")
}

fn get_constant($T: Type, s: ScopeId, name: Symbol) ?T #generic = {
    out := zeroed(T);
    get_constant(s, name, T, T.raw_from_ptr(out&)) || return(.None);
    (Some = out)
}

fn FieldType($S: Type, name: Fields(S)) Type #generic #fold = {
    ::enum(Fields(S));
    S.get_fields()[name.raw()].ty
}

fn get_field($S: Type, self: *S, $name: Fields(S)) *FieldType(S, name) #generic = {
    p := S.raw_from_ptr(self);
    p := p.offset(offset_of(S, name));
    p := FieldType(S, name).ptr_from_raw(p);
    p
}

fn scope_to_new_type($s: ScopeId) Type #fold = {
    t: TypeInfo = (Struct = (
        fields = empty(),
        layout_done = true,
        is_tuple = false,
        is_union = false,
        scope = s,
    ));
    intern_type_ref(t&)
}

// Holds a value that is zeroed when baking an AOT executable. 
// If a constant holds transient state, you can use this to avoid bloating your executable. 
// (even more important for something that changes depending on the build environment like lib/context.fr/OS). 
// The clearing happens both for real exes and .frc cache files. 
fn ClearOnAotBake($T: Type) Type = {
    Self :: @struct {
        it: T;
        // this forces TypeMeta.contains_pointers so the bake overload get called even if T is a value type
        _hack := @static(u8);  

    };
    
    fn bake_relocatable_value(self: *Self) Slice(BakedEntry) = {
        empty := zeroed Self;
        bytes := Self.cast_to_bytes(empty&);
        entries := dyn_bake_relocatable_value(bytes, Self, true);
        entries
    }
    
    Self
}

fn AsmFunction(template: FuncId, arm64: []u32, amd64: @FnPtr(out: *List(u8)) void) FuncId = {
    crash :: fn(out: *List(u8)) void = 
        out.push_all(@const_slice(@as(u8) 3, 0, 0x00, 0x0B));  // 3 bytes. 0 locals. unreachable. end. 
    AsmFunction(template, arm64, amd64, crash)
}

fn AsmFunction(template: FuncId, arm64: []u32, amd64: @FnPtr(out: *List(u8)) void, wasm32: @FnPtr(out: *List(u8)) void) FuncId = {
    a := ast_alloc();
    amd64_bytes := u8.list(a);
    amd64(amd64_bytes&);
    wasm32_bytes := u8.list(a);
    wasm32(wasm32_bytes&);
    create_asm_func(template, arm64.shallow_copy(a).as_raw_list(), amd64_bytes.as_raw(), wasm32_bytes.as_raw())
}

fn create_asm_func(template: FuncId, arm64: RawList(u32), amd64: RawList(u8), wasm32: RawList(u8)) FuncId = {
    func := get_function_ast(template, true, true, false, false);
    
    rv64 := u8.list(temp()); // TODO
    
    if has_feature("@franca/no_merged_funcimpl") {
        func.body = (Asm = (
            arm64 = arm64.items().interpret_as_bytes(), 
            amd64 = amd64.items(), 
            rv64 = rv64.items(),
            wasm32 = wasm32.items(),
        ));
    } else {
        // :UpdateBoot get rid of this case
        impl := FuncImpl.list(2, ast_alloc());
        impl&.push(JittedAarch64_OLD = arm64);
        impl&.push(X86AsmBytes_OLD = amd64);
        func.body = (Merged_OLD = impl.as_raw());
    };
    
    func.set_flag(.BodyIsSpecial);
    func.set_flag(.EnsuredCompiled);
    
    template
}

// 
// `path` is a string like you would pass to import(), the scope it resolves to must have a variable called `exports` 
// of type ScopeId containing FuncId constants. The scope you get back from `import_module("@/foo.fr")` is equivalent to 
// what you'd get from `import("@/foo.fr").exports`, except that you're explictly declaring that you don't care about 
// any side effects from running the comptime code required to compile the imported functions. So instead of the new 
// code loading in the same CompCtx as calls this import_module(), it can be done in a new CompCtx and saved in a .frc 
// file to be reused without recompiling (if none of the contributing files have changed). 
//
// TODO: reuse if the same path is used from multiple places in the same compiler instance
fn import_module(path: Str) ScopeId = {
    fr := current_compiler_context();
    opts := get_build_options();
    no_cache := opts.no_cache || IS_BOOTSTRAPPING;
    exports0 := const_eval(ScopeId)(@{ @[@literal path].import().exports });
    if no_cache || true {
        // The reference implementation just loads the new module in the same CompCtx. 
        return exports0;
    };
    // else, start a new CompCtx, compile the imported module there, export it as frc_inlinable and import that back into the original CompCtx. 
    
    exports1 := {
        s := fr'vtable'cached_compile_module(path, opts, ast_alloc());
        s := s.or(fn(err) => fr.report_error(err));
        s := fr'vtable'import_frc(fr.data, s);
        s := s.or(fn(err) => fr.report_error(err));
        s
    };
    
    // The FrcModule includes type information but i don't have a way to link them to the corresponding types in our CompCtx. 
    // So the hacky solution for now is to load only the signetures from our version of the exports scope and just stomp 
    // it over the signetures of the imported functions. This avoids any complicated nominal-ness of types and still lets 
    // you call the imported functions without casting through a rawptr every time. 
    for get_constants(exports0) { name |
        fid0  := get_constant(FuncId, exports0, name).unwrap();
        fid1  := get_constant(FuncId, exports1, name).unwrap();
        func0 := get_function_ast(fid0, true, true, true, false);
        func1 := get_function_ast(fid1, true, true, true, false);
        
        func1.finished_arg = func0.finished_arg;
        func1.finished_ret = func0.finished_ret;
        func1.ret = func0.ret;
        @debug_assert_eq(func0.arg.bindings.len, func1.arg.bindings.len);
        range(0, func0.arg.bindings.len) { i |
            func1.arg.bindings[i].ty = func0.arg.bindings[i].ty;
        };
        
        // for good luck...
        func0.body = (Redirect = fid1);
        func0.set_flag(.BodyIsSpecial);;
        func0.set_flag(.EnsuredCompiled);
    };
    
    exports1
}

fn cache_baked(vbytes: []u8, v: BakedVarId) void = {
    @if(has_feature("@franca/internal_pointers"), {
        cache_baked_vbytes(vbytes, v);
    }, {
        cache_baked(u8.int_from_ptr(vbytes.ptr), v);
    })
}

fn lookup_baked(vbytes: []u8) ?Ty(BakedVarId, i32) = {
    @if(has_feature("@franca/internal_pointers"), {
        return(lookup_baked_vbytes(vbytes));
    }, {
        id := lookup_baked(u8.int_from_ptr(vbytes.ptr)) || return(.None);
        return(Some = (id, 0));
    })
}

fn emplace_bake(vbytes: []u8, $body: @Fn() BakedVar) Ty(BakedVarId, i32) = {
    xx := lookup_baked(vbytes);
    or xx {
        id := @if(has_feature("@franca/internal_pointers"), {
            fr := current_compiler_context();
            id := fr'vtable'reserve_baked(fr.data, (Some = vbytes));
            var := body();
            fr'vtable'put_baked_var(fr.data, id, var);
            id
        }, {
            var := body();
            bake_value(var)
        });
        (id, @as(i32) 0)
    }
}

fn entry_with_addend(id: BakedVarId, addend: i32) BakedEntry = {
    if has_feature("@franca/internal_pointers") {
        return(AddrOfA = (base = id, addend = addend))
    };
    @assert_eq(addend, 0, ":UpdateBoot");
    (AddrOf = id)
}

fn import() ScopeId #fold = import("@");
