//! About #ir:
//! These used to be just normal functions defined in the language that used inline assembly. 
//! Now they're implemented in the compiler (see ../backend). 
//! They behave like #inline functions: type checking, overloading, and function pointers work as normal. 
//! Some can be used by thier conventional infix operator syntax which the parser desugars to a function call to the intrinsic. 

// TODO: float to int rounding

// TODO: define behaviour when shift > log size. make it a SafetyCheck

fn int_from_rawptr(ptr: rawptr) i64 #ir(.copy, .Kl);
fn rawptr_from_int(ptr: i64) rawptr #ir(.copy, .Kl);

fn add(a: f64, b: f64) f64 #ir(.add, .Kd); // +
fn sub(a: f64, b: f64) f64 #ir(.sub, .Kd); // -
fn mul(a: f64, b: f64) f64 #ir(.mul, .Kd); // *
fn div(a: f64, b: f64) f64 #ir(.div, .Kd); // /

fn eq(a: f64, b: f64) bool #ir(.ceqd, .Kl); // ==
fn ne(a: f64, b: f64) bool #ir(.cned, .Kl); // !=
fn le(a: f64, b: f64) bool #ir(.cled, .Kl); // <=
fn ge(a: f64, b: f64) bool #ir(.cged, .Kl); // >=
fn lt(a: f64, b: f64) bool #ir(.cltd, .Kl); // <
fn gt(a: f64, b: f64) bool #ir(.cgtd, .Kl); // >

// Note: remember i32->i8 is probably a noop if you wanted a value preserving intcast!
fn trunc(v: i64) u8   #ir(.copy, .Kw);
fn trunc(v: i64) u16 #ir(.copy, .Kw);
fn trunc(v: u64) u16 #ir(.copy, .Kw);
fn trunc(v: u64) u32 #ir(.copy, .Kw);
fn trunc(v: u32) u16 #ir(.copy, .Kw);
fn trunc(v: i32) u16 #ir(.copy, .Kw);
fn trunc(v: i64) u32 #ir(.copy, .Kw); 
fn trunc(v: u16) u8   #ir(.copy, .Kw);
fn trunc(v: u64) u8   #ir(.copy, .Kw);  // Nobody uses this it seems? 
fn trunc(v: u32) u8   #ir(.copy, .Kw);  // Nobody uses this it seems? 
fn trunc(v: i64) i32 #ir(.copy, .Kw);

// TODO: if you typo copy paste this conflicting overload, you try to call an uncompiled function! -- Jul 25 :FUCKED
// TODO: bring back system for testing that things fail with the right error message. 
// fn zext(v: u32) u64 #intrinsic(.ZeroExtend32To64);

fn ne(a: bool, b: bool) bool = !(a == b);

fn uext(v: u32) u64 #ir(.extuw, .Kl);
fn zext(v: u8)  u64  #ir(.extub, .Kl);
fn zext(v: u8)  u32  #ir(.extub, .Kw);
fn zext(v: u16) u32 #ir(.extuh, .Kw);
fn zext(v: u32) i64 #ir(.extuw, .Kl);
fn zext(v: u16) i64 #ir(.extuh, .Kl);
fn zext(v: u16) u64 #ir(.extuh, .Kl);
fn zext(v: i32) i64 #ir(.extuw, .Kl);  // its a bad habit to get into using this. i should make unsigned numbers less painful. 
fn zext(v: u8)  i64  #ir(.extub, .Kl);
fn zext(v: u8)  u16  #ir(.extub, .Kw);

fn bit_or(a: i16, b: i16) i16 #redirect(Ty(i32, i32), i32);
fn bit_or(a: u16, b: u16) u16 #redirect(Ty(i32, i32), i32);
fn zext(v: u8) i32 #ir(.extub, .Kw);

fn int(a: f64) i64     #ir(.dtosi, .Kl); // preserves the value (not the bit pattern)
fn float(a: i64) f64   #ir(.sltof, .Kd); // preserves the value (not the bit pattern)
fn bitcast(a: f64) i64 #ir(.cast, .Kl);  // preserves the bit pattern (not the value)
fn bitcast(a: i64) f64 #ir(.cast, .Kd);  // preserves the bit pattern (not the value)
fn cast(v: f64) f32 #ir(.truncd, .Ks);
fn cast(v: f32) f64   #ir(.exts, .Kd);

fn intcast(v: i64) i32 #ir(.copy, .Kw);
fn intcast(v: i32) i64 #ir(.extsw, .Kl);
fn zext(v: i16) i32    #ir(.extsh, .Kw);
fn zext(v: i16) i64    #ir(.extsh, .Kl);

NaN :: 0.0 / 0.0;

::if(f64);

fn abs(val: f64) f64 = @if(val < 0.0, -val, val);
fn abs(val: f32) f32 = @if(val < 0.0, -val, val);

fn eq(lhs: Symbol, rhs: Symbol) bool #redirect(Ty(u32, u32), bool);
fn to_bool(b: i64) bool = 
    b != 0;

// TODO: this gets a bit silly if I have to define this stuff all again but with different types. 
//       it would be cool if it could be done with traits. like anything with an ordering could have a fn max (bad example for floats i guess)
fn neg(a: f64) f64 #ir(.neg, .Kd);
fn neg(a: f32) f32 #ir(.neg, .Ks);

/// Yes, really...
/// TODO: this could be fewer instructions but this is more fun. 
fn is_nan(a: f64) bool = a != a;  
fn is_nan(a: f32) bool = a != a;

// Convert an i64 to an i<bit_count> with the leading bits 0.
// so the mask takes care of negative numbers. 
fn signed_truncate(x: i64, bit_count: i64) u32 = {
    mask := 1.shift_left(bit_count).sub(1);
    mask.bit_and(x).trunc()
}

fn s_trunc(x: i64, $bit_count: i64) SInt(bit_count) #generic = {
    mask :: 1.shift_left(bit_count).sub(1);
    mask.bit_and(x) // todo: this wont work for real sizes i8/i16, it will want a trunc. really need to store the other small sizes properly and have real bit fields.
}

////////////////
/// Booleans ///
////////////////
// u1 is a number so this is kinda like math... idk.

// Note: its a fun game to make this call the other fn if instead of the macro and measure how much slower it compiles itself. 
fn if(cond: bool, $then: @Fn() void) void =
    @if(cond, then(), ());

fn if($T: Type) void = {
    fn if(cond: bool, $then: @Fn() T, $else: @Fn() T) T = @if(cond, then(), else());
}

// TODO: auto impl generics
::if(i64); ::if(void); ::if(bool); ::if(u8); 

fn eq(a: bool, b: bool) bool #ir(.ceqw, .Kw);

fn not(b: bool) bool #fold =
    b == false;

fn int(val: bool) i64 #ir(.extuw, .Kl); // bool is always 0 or 1

// Note: these are not short circuiting because arguments are always evaluated. 
fn and(a: bool, b: bool) bool #ir(.and, .Kw);
fn or(a: bool, b: bool)  bool #ir(.or, .Kw);
fn xor(a: bool, b: bool) bool #ir(.xor, .Kw);

fn nand(a: bool, b: bool) bool = or(!a, !b);

// Note: these are short circuiting. The closure will only be called if necessary. 
fn and(a: bool, $b: @Fn() bool) bool = 
    @if(a, b(), false);  // operator &&
fn or(a: bool, $b: @Fn() bool) bool = 
    @if(a, true, b());   // operator ||
// TODO: those should go in sugar.fr

/// This is intended to be used with non-local early returns... obviously.
fn loop($f: FuncId) Never = @loop(f());

fn while($cond: @Fn() bool, $body: @Fn() void) void = 
    @loop(@if(cond(), body(), return()));

fn dowhile($f: @Fn() bool) void = while(f, =>());

fn whileb($cond: @Fn() bool, $body: @Fn(break: LabelId) void) void = {
    break :: return;
    loop(=> if(cond(), => body(break), => break()));
}

fn loop($T: Type, $body: @Fn(break: @Fn(result: T) Never) void) T #generic = {
    break :: fn(result: T) Never => return(result);
    loop(=> body(break))
}

/////////////////
/// Fake Ints ///
/////////////////
// TODO: this sucks. dynamically make these for uxx & ixx.
// TODO: store these in the next sane size up, not always i64. 

fn UInt(bits: i64) Type #fold = IntType(bits, false);
fn SInt(bits: i64) Type #fold = IntType(bits, true);

u1  :: UInt(1);
u2  :: UInt(2);
u3  :: UInt(3);
u4  :: UInt(4);
u5  :: UInt(5);
u6  :: UInt(6);
u7  :: UInt(7);
u8  :: UInt(8);
u12 :: UInt(12);
u13 :: UInt(13);
u16 :: UInt(16);
u19 :: UInt(19);
u32 :: UInt(32);
u64 :: UInt(64);
i7  :: SInt(7);
i8  :: SInt(8);
i9  :: SInt(9);
i12 :: SInt(12);
i13 :: SInt(13);
i16 :: SInt(16);
i19 :: SInt(19);
i20 :: SInt(20);
i21 :: SInt(21);
i26 :: SInt(26);
i32 :: SInt(32);
i33 :: SInt(33);

/////////////////
/// Redirects ///
/////////////////

// TODO: new backend has real unsigned cmp, use them here.

fn Ord($T: Type) void = {
    fn eq(lhs: T, rhs: T) bool = lhs.int().eq(rhs.int());
    fn ne(lhs: T, rhs: T) bool = lhs.int().ne(rhs.int());
    fn lt(lhs: T, rhs: T) bool = lhs.int().lt(rhs.int());
    fn le(lhs: T, rhs: T) bool = lhs.int().le(rhs.int());
    fn gt(lhs: T, rhs: T) bool = lhs.int().gt(rhs.int());
    fn ge(lhs: T, rhs: T) bool = lhs.int().ge(rhs.int());
}

fn int(i: i64) i64 #ir(.copy, .Kl);
fn int(i: u8)  i64 #ir(.extub, .Kl);    ::Ord(u8);
fn int(i: u32) i64 #ir(.extuw, .Kl);
fn int(i: u64) i64 #ir(.copy, .Kl);
fn int(i: i32) i64 #ir(.extsw, .Kl);
fn int(i: u16) i64 #ir(.extuh, .Kl);    ::Ord(u16);
fn int(i: i16) i64 #ir(.extsh, .Kl);    //::Ord(i16);

// These are useful for bounds checks with signed indices. 
// When you know len is positive, (i.ult(len)) == (i < len && i >= 0)
fn ult(lhs: i64, rhs: i64) bool #ir(.cultl, .Kl);
fn ule(lhs: i64, rhs: i64) bool #ir(.culel, .Kl);
fn ult(lhs: i32, rhs: i32) bool #ir(.cultw, .Kl);
fn ule(lhs: i32, rhs: i32) bool #ir(.culew, .Kl);

// TODO: this is silly. should just be able to pass Kw vs Kl as a comptime value without it being painful. 
:: {
    Num(u64, false, true);
    Num(i64, true, true);
    Num(u32, false, false);
    Num(i32, true, false);
    
    Num :: fn($T: Type, $signed: bool, $wide: bool) void = {
        fn min(a: T, b: T) T #inline #fold = @if(gt(a, b), b, a);
        fn max(a: T, b: T) T #inline #fold = @if(lt(a, b), b, a);
        fn bit_not(a: T) T #fold #inline = bit_xor(a, 0 - 1);  
        
        // TODO: infer #fold when all calls are #fold and there are no loads/stores? 
        //       the latter is nontrivial if you want to allow struct arguments  
        
        fn div_mod(big: T, divisor: T) Ty(T, T) #inline #fold = {
            d := big / divisor;
            (d, big - d * divisor)
        }
        
        fn align_to(offset: T, align: T) T = 
            ((offset + align - 1) / align) * align;
        
        fn align_back(offset: T, align: T) T = 
            (offset / align) * align;
        
        @if(signed) {
            fn abs(val: T) T = {
                all_sign_bit := val.shift_right_arithmetic(size_of(T) * 8 - 1);
                // +) nop 
                // -) subtract one and flip all the bits. https://en.wikipedia.org/wiki/Two%27s_complement
                bit_xor(val + all_sign_bit, all_sign_bit)
            }
            
            fn neg(a: T) T #fold = 0 - a;
        };
        
        @if(wide, {
            fn bit_or(lhs: T, rhs: T) T #ir(.or, .Kl);
            fn bit_and(lhs: T, rhs: T) T #ir(.and, .Kl);
            fn bit_xor(a: T, b: T) T #ir(.xor, .Kl);
           
            fn rotate_left(x: T, amount: i64) T #ir(.rotl, .Kl); 
            fn rotate_right(x: T, amount: i64) T #ir(.rotr, .Kl); 
            fn byte_swap(x: T) T #ir(.byteswap, .Kl);
 
            fn shift_right_logical(value: T, shift_amount: i64) T #ir(.shr, .Kl);
            fn shift_right_arithmetic(value: T, shift_amount: i64) T #ir(.sar, .Kl);
            fn shift_left(value: T, shift_amount: i64) T #ir(.shl, .Kl);
        
            fn add(a: T, b: T) T #ir(.add, .Kl);
            fn sub(a: T, b: T) T #ir(.sub, .Kl);
            fn mul(a: T, b: T) T #ir(.mul, .Kl);
        
            fn eq(lhs: T, rhs: T) bool #ir(.ceql, .Kl);
            fn ne(lhs: T, rhs: T) bool #ir(.cnel, .Kl);
            @if(signed, {
                fn div(a: T, b: T) T #ir(.div, .Kl);
                fn mod(a: T, b: T) T #ir(.rem, .Kl);
            
                fn lt(lhs: T, rhs: T) bool #ir(.csltl, .Kl);
                fn le(lhs: T, rhs: T) bool #ir(.cslel, .Kl);
                fn gt(lhs: T, rhs: T) bool #ir(.csgtl, .Kl);
                fn ge(lhs: T, rhs: T) bool #ir(.csgel, .Kl);
            }, {
                fn div(a: T, b: T) T #ir(.udiv, .Kl);
                fn mod(a: T, b: T) T #ir(.urem, .Kl);
            
                fn lt(lhs: T, rhs: T) bool #ir(.cultl, .Kl);
                fn le(lhs: T, rhs: T) bool #ir(.culel, .Kl);
                fn gt(lhs: T, rhs: T) bool #ir(.cugtl, .Kl);
                fn ge(lhs: T, rhs: T) bool #ir(.cugel, .Kl);
            });
        }, {
            fn bit_or(lhs: T, rhs: T) T #ir(.or, .Kw);
            fn bit_and(lhs: T, rhs: T) T #ir(.and, .Kw);
            fn bit_xor(a: T, b: T) T #ir(.xor, .Kw);
            
            fn rotate_left(x: T, amount: i64) T #ir(.rotl, .Kw); 
            fn rotate_right(x: T, amount: i64) T #ir(.rotr, .Kw); 
            fn byte_swap(x: T) T #ir(.byteswap, .Kw);
            
            fn shift_right_logical(value: T, shift_amount: i64) T #ir(.shr, .Kw);
            fn shift_right_arithmetic(value: T, shift_amount: i64) T #ir(.sar, .Kw);
            fn shift_left(value: T, shift_amount: i64) T #ir(.shl, .Kw);
        
            fn add(a: T, b: T) T #ir(.add, .Kw);
            fn sub(a: T, b: T) T #ir(.sub, .Kw);
            fn mul(a: T, b: T) T #ir(.mul, .Kw);
            
            fn eq(lhs: T, rhs: T) bool #ir(.ceqw, .Kl);
            fn ne(lhs: T, rhs: T) bool #ir(.cnew, .Kl);
            @if(signed, {
                fn div(a: T, b: T) T #ir(.div, .Kw);
                fn mod(a: T, b: T) T #ir(.rem, .Kw);
            
                fn lt(lhs: T, rhs: T) bool #ir(.csltw, .Kl);
                fn le(lhs: T, rhs: T) bool #ir(.cslew, .Kl);
                fn gt(lhs: T, rhs: T) bool #ir(.csgtw, .Kl);
                fn ge(lhs: T, rhs: T) bool #ir(.csgew, .Kl);
            }, {
                fn div(a: T, b: T) T #ir(.udiv, .Kw);
                fn mod(a: T, b: T) T #ir(.urem, .Kw);
            
                fn lt(lhs: T, rhs: T) bool #ir(.cultw, .Kl);
                fn le(lhs: T, rhs: T) bool #ir(.culew, .Kl);
                fn gt(lhs: T, rhs: T) bool #ir(.cugtw, .Kl);
                fn ge(lhs: T, rhs: T) bool #ir(.cugew, .Kl);
            });
        });
    };
    UNum :: fn($T: Type) void = {
        fn add(lhs: T, rhs: T) T = lhs.int().add(rhs.int()).trunc();
        fn sub(lhs: T, rhs: T) T = lhs.int().sub(rhs.int()).trunc();
        fn mul(lhs: T, rhs: T) T = lhs.int().mul(rhs.int()).trunc();
        fn div(lhs: T, rhs: T) T = lhs.int().div(rhs.int()).trunc(); 
        fn min(lhs: T, rhs: T) T = lhs.int().min(rhs.int()).trunc(); 
        fn max(lhs: T, rhs: T) T = lhs.int().max(rhs.int()).trunc(); 
        fn mod(lhs: T, rhs: T) T = lhs.int().mod(rhs.int()).trunc();
    };
    UNum(u8); 
    UNum(u16);
};

fn bit_or(lhs: u8, rhs: u8) u8 #ir(.or, .Kw);
// TODO: bit_not can't just redirect because that would flip the leading zeros too. 

// TODO: :SLOW?
fn pow(base: i64, exp: i64) i64 = {
    n := 1;
    range(0, exp) {_|
        n *= base;
    };
    n
}

MAX_u16 :: 0xFFFF;
MAX_i32 :: 2147483647;
MIN_i32 :: -2147483648;
MAX_u32 :: 0xFFFFFFFF;
MAX_i64 :: 9223372036854775807;
MIN_i64 :: -MAX_i64 - 1;  // -9223372036854775808 but it feels fragile to parse that (tho it does overflow into the right thing). 
                          // there are more negative numbers than positive numbers!

MANTISSA_DIGITS_f64 :: 53;
MANTISSA_DIGITS_f32 :: 24;

fn eq(a: f32, b: f32) bool #ir(.ceqs, .Kl);
fn ne(a: f32, b: f32) bool #ir(.cnes, .Kl);
fn le(a: f32, b: f32) bool #ir(.cles, .Kl);
fn ge(a: f32, b: f32) bool #ir(.cges, .Kl);
fn lt(a: f32, b: f32) bool #ir(.clts, .Kl);
fn gt(a: f32, b: f32) bool #ir(.cgts, .Kl);

fn add(a: f32, b: f32) f32 #ir(.add, .Ks);
fn sub(a: f32, b: f32) f32 #ir(.sub, .Ks);
fn mul(a: f32, b: f32) f32 #ir(.mul, .Ks);
fn div(a: f32, b: f32) f32 #ir(.div, .Ks);

fn trailing_zeros(b: i64) i64 #ir(.ctz, .Kl);
fn trailing_zeros(b: u32) u32 #ir(.ctz, .Kw);
fn leading_zeros(b: i64) i64 #ir(.clz, .Kl);
fn count_ones(b: u64) u32 #ir(.ones, .Kl);
fn count_ones(b: *u64) u32 = 
    count_ones(b[]);
fn count_ones(b: i64) u32 #ir(.ones, .Kl);

fn leading_ones(b: i64) i64 = 
    b.bit_not().leading_zeros();

fn trailing_ones(b: i64) i64 = 
    b.bit_not().trailing_zeros();

NS_PER_MS :: 1000 * 1000;
NS_PER_S  :: NS_PER_MS * 1000;
NS_PER_US :: 1000;
US_PER_S  :: 1000 * 1000;

fn sqrt(x: f64) f64 #fold = {  // :UpdateBoot
    slow :: fn(x: f64) f64 = newton_root(x, 2);
    fast :: fn(x: f64) f64 #ir(.sqrt, .Kd);
    (@if(IS_BOOTSTRAPPING, slow, fast))(x)
}

fn cbrt(x: f64) f64 = 
    newton_root(x, 3);

// TODO: im sure there's some trick because we know how much precision a float has. 
fn newton_root(x: f64, $p: i64) f64 = {
    guess := x;
    range(0, 15 /* chosen by fair die roll */) { _ |
        x1 := 1.0;
        x2 := guess;
        inline_range(0, p - 1) { $_ |
            x1 *= guess;
            x2 *= guess;
        };
        guess -= (x2 - x) / (x1 * p.float());
    };
    guess
}

fn floor(x: f64) f64 =
    x.int().float();

fn fmodf(a: f32, b: f32) f32 #libc;
fn roundf(a: f32) f32 #libc;

PI :: 3.1415926535897932;

fn clamp(v: f64, lo: f64, hi: f64) f64 #inline =
    v.max(lo).min(hi);

fn clamp(v: f32, lo: f32, hi: f32) f32 #inline =
    v.max(lo).min(hi);

fn clamp(v: i64, lo: i64, hi: i64) i64 #inline =
    @if(v < lo, lo, @if(v > hi, hi, v));
        
RAD_PER_DEG :: PI / 180.0;
DEG_PER_RAD :: 180.0 / PI;
fn deg_to_rad(deg: f32) f32 = deg * RAD_PER_DEG;
fn rad_to_deg(rad: f32) f32 = rad * DEG_PER_RAD;

fn bit_and(a: u8, b: u8) u8 #ir(.and, .Kw);
fn shift_right_logical(a: u8, b: u8) u8 #ir(.shr, .Kw);
fn shift_right_logical(a: u16, b: u16) u16 #ir(.shr, .Kw);
fn shift_left(a: u8, b: i64) u8 = 
    (@as(i64) a.zext()).shift_left(b).trunc();
fn bit_and(a: u16, b: u16) u16 #ir(.and, .Kw);
fn div_mod(a: u8, b: i64) Ty(u8, u8) = {
    xxx: i64 = a.zext();
    aa, bb := xxx.div_mod(b);
    (aa.trunc(), bb.trunc())
}

fn sin_cos(rad: f32) Ty(f32, f32) = {
    (rad.sinf(), rad.cosf())
}

fn max(a: f64, b: f64) f64 #ir(.max, .Kd);
fn min(a: f64, b: f64) f64 #ir(.min, .Kd);
fn max(a: f32, b: f32) f32 #ir(.max, .Ks);
fn min(a: f32, b: f32) f32 #ir(.min, .Ks);

// TODO: is there a general trick for this? 
//       special case powers of two since base is $const. 
//       maybe i want to let you say `if is_constant(base)` and have it treat it 
//       as though it were $const if possible at the callsite. 
//       could express that as `#fold` on the parameter. 
fn log(i: i64, $base: i64) i64 = {
    n := 0;
    while => i > 0 {
        i /= base;
        n += 1;
    };
    n
}

fn float(x: u32) f64 = 
    float(@as(i64) x.zext()); 

fn sign_extend(i: i64, $sign_bit: i64) i64 = {
    @if(sign_bit == 63) return(i);
    @if(sign_bit == 31) return({ f :: fn(i: i64) i64 #ir(.extsw, .Kl); f(i) });
    @if(sign_bit == 15) return({ f :: fn(i: i64) i64 #ir(.extsh, .Kl); f(i) });
    @if(sign_bit == 7 ) return({ f :: fn(i: i64) i64 #ir(.extsb, .Kl); f(i) });
    
    sign := i.shift_right_logical(sign_bit).bit_and(1);
    ones := sign.shift_left(64 - sign_bit).sub(sign).shift_left(sign_bit);
    low := i.bit_and(1.shift_left(sign_bit) - 1);
    low.bit_or(ones)
}

fn ms(t: TimeSpec) i64 =
    t.seconds * 1000 + t.nanoseconds / NS_PER_MS;

fn add_ns(t: *TimeSpec, nanoseconds: i64) void = {
    nanoseconds += t.nanoseconds;
    s, n := nanoseconds.div_mod(NS_PER_S);
    t.nanoseconds = n;
    t.seconds += s;
}

fn add(a: TimeSpec, b: TimeSpec) TimeSpec = {
    a&.add_ns(b.nanoseconds);
    a.seconds += b.seconds;
    a
}
