fn hackheap(ops: Slice(u32)) Slice(u32) = {
    var out: List(u32) = list(ops&.len[]);
    push_all(out!addr, ops);
    var out: Slice(u32) = items(out!addr);
    out
}

const AsmInst = Unique(u32);
const InstPtr = *AsmInst;  // TODO: **AsmInst as return type doesnt work?? 

// The first 16 bytes of a stack frame is always one of these. 
const Frame = (
    // TODO: be able to say this type is *Frame. this is harder than fixing the forward declarations thing i feel. 
    fp: VoidPtr,  // Pointer to the previous Frame (start of its stack). 
    lr: InstPtr  // Saved instruction pointer value. 
)!struct;

@no_interp @aarch64 
fn get_fp() *Frame = hackheap((
    mov(Bits.X64[], x0, fp),
    ret(),
)!slice)!asm;

/// An array of compiled asm function pointers. Indices are FuncId and missing entries are 0. 
@no_interp @aarch64
fn get_indirect_fn_array() Slice(InstPtr) = {
    @no_interp @aarch64 
    fn get_indirect_fn_array_ptr() *InstPtr = hackheap((
        mov(Bits.X64[], x0, x21),
        ret(),
    )!slice)!asm;

    (ptr: get_indirect_fn_array_ptr(), len: number_of_functions())
}

@no_interp @aarch64 
fn ptr_to_int(ptr: VoidPtr) i64 = hackheap((
    ret(),
    ret(),
)!slice)!asm;

@no_interp @aarch64 
fn int_to_ptr(ptr: i64) VoidPtr = hackheap((
    ret(),
    ret(),
)!slice)!asm;

/// Guess which function contains the instruction pointer 'ip'.
/// 'f' will be the one that starts closest to 'ip' but before it. 
/// 'rel_ip' is how many bytes into the function 'ip' is (1 asm instruction is 4 bytes). 
/// If 'ip' is in an ffi (or compiler builtin) function, 'rel_ip' will be very large. 
@no_interp @aarch64
fn get_func_id(ip: InstPtr) (f: FuncId, rel_ip: i64)!struct = {
    var functions = get_indirect_fn_array();
    var best_index: FuncId = number_of_functions();
    var best_distance = 99999999;
    
    // Check every function id. 
    functions.enumerate(fn(i: i64, func: *InstPtr) Unit = {
        let func = func[].ptr_to_int();
        // Skip missing functions (null start ptr).  
        @if(func.ne(0)) {
            let dist = ip.ptr_to_int().sub(func);
            // If distance is negative, 'ip' is before 'func' so can't be inside it (don't care if its closer). 
            @if(dist.lt(best_distance).and(dist.ge(0))) {
                best_distance = dist;
                best_index = i;
            };
        };
    });
    
    // TODO: return optional. 
    (f: best_index, rel_ip: best_distance)
}

/// Note: This relies on the stack frame layout used by bc_to_asm and rustc matching. 
@no_interp @aarch64 @pub
fn collect_backtrace() Unit = {
    var addr: *Frame = get_fp();
    var i = 0;
    var info: RsResolvedSymbol;
    // TODO: nullable pointer should be spelled ?*T
    (fn() = addr.fp[].ptr_to_int().ne(0), fn() = {
        (resolve_backtrace_symbol(addr.lr[], info&), fn() = {
            let len = info&.name_len[];
            (len.ne(0), fn() = {
                // TODO: HACK. be able to address bytes so puts doesnt .div(8)
                let s: Str = (info&.owned_name[], len.mul(8));
                puts(s);
            }, fn()= {
                puts("Rust found but len=0.");
            })!if;
        }, fn()= {
            // TODO: check that its not some other ffi thing that rust couldn't find a name for. 
            var func = addr.lr[].get_func_id();
            let name = func&.f[].name().str();
            puts(name);
        })!if;
        putchar(10);
        
        let fp: *Frame = addr.fp[];
        addr = fp;
        i = i.add(1);
    })!while;
}


// TODO: deduplicate if same function, same args (ie. panic("OOB") probably gets called a lot)
@struct fn ColdFn(callsite: InstPtr, f: InstPtr);
@struct fn RuntimeData(functions: Slice(InstPtr), cold_calls: Slice(ColdFn));

fn get_runtime_data() *RuntimeData;

// TODO: allow declaring any function @cc(SuperColdIndirect). save registers. reserve some scratch memory for the runtime? 
@no_interp @aarch64 @pub
fn do_very_cold_call() Never = {
    var myself = get_fp();
    var caller = myself.lr[];
    var found = false;
    let cold_calls = get_runtime_data().cold_calls;
    foreach(cold_calls, fn(check: *ColdFn) Unit = {
        @if(check.callsite[].eq(caller)) {
            found = true; // for later. currently unused. 
            
            // TODO: actually call
            panic("Cold call returned");
        };
    });
    
    @if(found.not()) { 
        panic("Missing cold call") 
    };
}

