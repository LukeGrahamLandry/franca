BlockAlloc :: BlockAllocImpl(@const_slice(16, 32, 64, 128, 256, 512, 1024, 2048));

// TODO: have a free_all to return memory to the backing allocator. 

// SAFETY: all block_sizes must be a factor of page_size() and <= to it. 
fn BlockAllocImpl($block_sizes: []i64) Type = {
    Self :: @struct(
        parent: Alloc,
        free_lists: Array(rawptr, block_sizes.len()),
        mutex: import("@/lib/sys/sync/mutex.fr").Mutex,
    );
    
    fn init(parent: Alloc) Self #inline = {
        s := Self.zeroed();
        s.parent = parent;
        s
    }
    
    fn borrow(self: *Self) Alloc = 
        (data = Self.raw_from_ptr(self), vptr = allocator_fn);
    
    allocator_fn :: fn(self: rawptr, action: Alloc.Action, ptr: rawptr, count: i64, align: i64) []u8 = {
        self := Self.ptr_from_raw(self);
        if action == .Allocate {
            size_index := size_index_for(count) || return(self.parent.alloc_raw(count, align));
            // TODO: align
            return(self.next_block(size_index));
        };
        if action == .Deallocate {
            if size_index_for(count) { size_index |
                self.free_block(size_index, ptr);
            } else {
                self.parent.dealloc_raw(ptr, count, align);
            };
            return Alloc.void_result;
        };
        
        empty()
    };
    
    fn next_block(self: *Self, size_index: i64) []u8 = {
        size := block_sizes[size_index];
        first := 0.rawptr_from_int();
        with self.mutex& {
            slot  := self.free_lists&.index(size_index);
            first = slot[];
            if first.is_null() {
                // The list is empty so we need to ask for more memory. 
                page_size := page_size();
                page := self.parent.alloc_uninit(u8, page_size);
                first = u8.raw_from_ptr(page.ptr);
                slot[] = first;
                n := page_size / size - 1;
                range(0, n) { i |
                    rawptr.ptr_from_raw(first.offset(i * size))[] = first.offset((i+1) * size);
                };
                rawptr.ptr_from_raw(first.offset(n * size))[] = 0.rawptr_from_int();
            };

            // Pop this off the free list. 
            next := rawptr.ptr_from_raw(first)[];
            next_candidate := first.offset(block_sizes[size_index]);
            slot[] = next;
        };
        (ptr = u8.ptr_from_raw(first), len = size)
    }
    
    fn free_block(self: *Self, size_index: i64, ptr: rawptr) void = {
        @if(SLOW_MEMORY_DEBUGGING) u8.ptr_from_raw(ptr).slice(block_sizes[size_index]).set_bytes(SLOW_MEMORY_JUNK);
        with self.mutex& {
            slot := self.free_lists&.index(size_index);
            rawptr.ptr_from_raw(ptr)[] = slot[];
            slot[] = ptr;
        };
    }
    
    fn size_index_for(bytes: i64) ?i64 = {
        i := 0;
        inline_for block_sizes { $size |
            if(bytes <= ::size[], => return(Some = i));
            i += 1;
        };
        .None
    }
    
    Self
}
