//!
//! Similar to Zig, the standard library collections require you to explicitly pass them an allocator.
//! This makes it easy to choose an algorithm tailored to your application's allocation pattern.
//! You can place groups of objects with similar lifetimes in an arena and then not bother freeing them individually. 
//! 
//! Maybe I should treat allocation as a fallible operation but I don't really care. 
//! Most operating systems over-commit anyway so you can't even tell you're out of memory until it randomly decides to kill your process.
//! The main opposition I could see is targetting web assembly, 
//! which is 32 bit and 4GB really isn't enough memory to pretend you'll never run out. 
//!

// TODO: it seems like a good idea to allow it to return more memory than you asked for (like for a growable collection),
//       so this would return a slice. but rust's GlobalAlloc and zig's allocator interface don't do that so maybe there's a reason. 
//       tho rust's new Allocator does return a slice. 
// TODO: add resize function that tries to extend an allocation in place if possible. 
Alloc :: @struct(data: rawptr, vptr: AllocatorFn);

// Allocators provide one function that changes behaviour based on the `action` argument. 
// I can't decide if this is worse than the vtable, I figure this means you can add a bunch of optional actions easily. 
// It's not how zig does it tho so maybe there's a reason this is worse... odin does it this way tho so it's probably fine. 
// You save a load of the vtable and add a branch.
// There are nice wrapper functions that deal with martialing the arguments to this.  
AllocatorFn :: @FnPtr(self: rawptr, action: AllocatorAction, ptr: rawptr, count: i64, align: i64) []u8;

AllocatorAction :: @enum(i64) (
    // Request new memory from the allocator. 
    // Returns []u8 (which may be more than the amount requested for allocators with fixed size blocks). 
    // Via alloc(), box(), alloc_zeroed(), box_zeroed(), alloc_raw()
    Allocate = 0,
    // You must pass the same alignment as passed to Allocate, either the requested or returned size. 
    // and the pointer must be exactly the one returned by Allocate. 
    // This will be a no-op for arena allocators. 
    // Via dealloc(), dealloc_one(), dealloc_raw()
    Deallocate = 1,
    // Some allocations are required to have 'static lifetime and should not be reported as leaks by debugging allocators. 
    // This is a no-op on allocators that do not support leak checking. 
    // Via ignore_leak(). 
    IgnoreLeak = 2,
);
::enum(AllocatorAction);

fn alloc(allocator: Alloc, $T: Type, count: i64) Slice(T) #generic = { // #inline = {
    mem := alloc_raw(allocator, count * T.size_of(), T.align_of());
    @if(SLOW_MEMORY_DEBUGGING) if mem.len < 16384 {
        mem.len = count * T.size_of();
        mem.set_bytes(SLOW_MEMORY_JUNK);
    };
    (ptr = ptr_cast_unchecked(u8, T, mem.ptr), len = count)
}

fn alloc_raw(allocator: Alloc, bytes: i64, align: i64) []u8 = { // #inline = {
    if(bytes == 0, => return(empty()));
    {allocator.vptr}(allocator.data, .Allocate, rawptr_from_int(0), bytes, align)
}

fn dealloc_raw(allocator: Alloc, ptr: rawptr, bytes: i64, align: i64) void = {
    if(bytes == 0, => return());
    {allocator.vptr}(allocator.data, .Deallocate, ptr, bytes, align);
}

fn alloc_zeroed(allocator: Alloc, $T: Type, count: i64) []T #generic = {
    // TODO: be able to ask the allocator for zeroed memory since it might already have that (page_allocator?)
    mem := alloc_raw(allocator, count * T.size_of(), T.align_of());
    mem.len = count * T.size_of();  // :UpdateBoot
    set_bytes(mem, 0);
    (ptr = ptr_cast_unchecked(u8, T, mem.ptr), len = count)
}

fn box(allocator: Alloc, $T: Type) *T #generic = {
    mem := alloc_raw(allocator, T.size_of(), T.align_of());
    @if(SLOW_MEMORY_DEBUGGING && !IS_BOOTSTRAPPING) mem.set_bytes(SLOW_MEMORY_JUNK);
    ptr_cast_unchecked(u8, T, mem.ptr)
}

fn box_zeroed(allocator: Alloc, $T: Type) *T #generic = {
    mem := allocator.alloc_zeroed(T, 1);
    mem.ptr
}

fn dealloc(allocator: Alloc, $T: Type, mem: Slice(T)) void #generic = {
    bytes := (:: T.size_of()).mul(mem.len);
    dealloc_raw(allocator, T.raw_from_ptr(mem.ptr), bytes, T.align_of());
}

fn dealloc_one(allocator: Alloc, $T: Type, mem: *T) void #generic = 
    allocator.dealloc(T, mem.slice(1));

fn ignore_leak(allocator: Alloc, $T: Type, mem: []T) void #generic = {
    allocator'vptr(allocator.data, .IgnoreLeak, T.raw_from_ptr(mem.ptr), mem.len * T.size_of(), T.align_of());
}

libc_allocator: Alloc : (data = 0.rawptr_from_int(), vptr = libc_allocator_fn);

libc_allocator_fn :: fn(_: rawptr, action: AllocatorAction, ptr: rawptr, count: i64, align: i64) []u8 = {
    @match(action) {
        // TODO: respect alignment. but im pretty sure malloc always gives you 16 bytes and mostly good enough. 
        //       should do what zig does tho https://github.com/ziglang/zig/blob/master/lib/std/heap.zig#L57
        fn Allocate() => (ptr = u8.ptr_from_raw(malloc(count)), len = count);
        fn Deallocate() => {
            @if(SLOW_MEMORY_DEBUGGING) u8.ptr_from_raw(ptr).slice(count).set_bytes(SLOW_MEMORY_JUNK);
            free(ptr);
            empty()
        }
        @default => empty();
    }
};

// TODO: :sema_regression switch to match when i fix v2 `early return before ret type infered (could try more aggressivly in handle_compile_body)`
// TODO: respect alignment. but im pretty sure malloc always gives you 16 bytes and that's almost always good enough. 
page_allocator_fn :: fn(_: rawptr, action: AllocatorAction, ptr: rawptr, size: i64, align: i64) []u8 = {
    action := @as(i64) action;
    ::if(rawptr);
    if action == 0 {
        // TODO: subtyping so working with enum flags sucks less. 
        prot := bit_or(@as(i64) MapProt.Write, @as(i64) MapProt.Read);
        n1   := 1.neg();
        addr := 0.rawptr_from_int();
        ptr  := mmap_anon(addr, size, prot, 0);
        if(ptr.int_from_rawptr().eq(n1)) {
            // Note: printing here also makes life super confusing
            //println(get_errno());  // TODO: ugly
            panic("mmap failed");
        };
        return(ptr = u8.ptr_from_raw(ptr), len = align_to(size, page_size()));
    };
    if action == 1 {
        /// SAFETY: EASY: 'arr' must be from 'os_alloc', only passed to this function once, and never accessed again. 
        ///         HARD: If you're careful, its fine to split an allocation from 'os_alloc' and release seperate pages at different times. 
        res := Syscall'munmap(ptr, size);
        assert(res.value.eq(0), "munmap failed");
        return(empty())
    };
    empty()
};

/// This requests new pages from the operating system on *every* allocation. 
/// Thus it should generally only be used in the implimentation of other allocators. 
/// https://man7.org/linux/man-pages/man2/mmap.2.html
page_allocator: Alloc : (data = 0.rawptr_from_int(), vptr = page_allocator_fn);

// TODO: it's too easy to accidentally call this in a constant and get the host value instead of the target value.
fn page_size() i64 = {
    #use("@/lib/sys/process.fr");
    @if(query_current_os() == .linux, 4096,  // TODO: blink
            @if(query_current_arch() == .aarch64, 16384, 4096)) // macos
}

ExecSlice :: @struct(ptr: rawptr, len: i64); 

fn make_write(arr: ExecSlice) Slice(u8) = {
    ptr := arr.ptr;
    prot := bit_or(@as(i64) MapProt.Write, @as(i64) MapProt.Read);
    res := Syscall'mprotect(ptr, arr.len, prot);
    assert(res.value.eq(0), "mprotect failed");
    (ptr = u8.ptr_from_raw(ptr), len = arr.len)
}

/// Read the comment on clear_instruction_cache
/// SAFETY: 'arr' must be from 'os_alloc' and not written to until 'make_write' is called on it.   
fn make_exec(arr: Slice(u8)) ExecSlice = {
    ptr := u8.raw_from_ptr(arr.ptr);
    prot := bit_or(@as(i64) MapProt.Exec, @as(i64) MapProt.Read);
    res := Syscall'mprotect(ptr, arr.len, prot);
    assert(res.value.eq(0), "mprotect failed");
    (ptr = ptr, len = arr.len)
}

fn os_dealloc(arr: ExecSlice) void = {
    page_allocator.dealloc(u8, make_write(arr)); // TODO: dont do an extra syscall just for type
}

// TODO: pass requested type through generic args so this isn't so clunky. -- Jun 23
boxed :: fn(a: Alloc, $T: Type, t: T) *T #generic = {
    out := a.alloc(T, 1);
    out.ptr[] = t;
    out.ptr
};

// TODO: if i'm doing this clearly my stance on not treating allocation as fallible was wrong. 
//       the compiler does it in the x64 backend where i wrote the encoding functions to take a list, 
//       but the compiler allocates a big chunk of memory for the code and declares that you're never allowed to use more than that. 
//       so that specific situation could also be fixed by less annoying generics (so you could impl the encoding for anything with push(u8)),
//       but in general its fair for a program to have some invalient on amount of memory used even if the os would give you more than that. 
//       but its such a pain to thread errors through everywhere, and i don't like exceptions. 
//       TLDR: this is kinda trash but i don't have a better solution 
//       -- Sep 8
//
// Can use this when you know a List won't need to grow. 
panicking_allocator: Alloc : (data = 0.rawptr_from_int(), vptr = panicking_allocator_fn);
panicking_allocator_fn :: fn(_: rawptr, action: AllocatorAction, ptr: rawptr, count: i64, align: i64) []u8 = {
    @match(action) {
        fn Allocate()   => @panic("Tried to allocate % bytes with panicking_allocator", count);
        @default => empty();
    }
};

fn alloc_init(a: Alloc, $T: Type, n: i64, $body: @Fn(i: i64) T) []T #generic = {
    mem := a.alloc(T, n);
    enumerate mem { i, it |
        it[] = body(i);
    };
    mem
}
