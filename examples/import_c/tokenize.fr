// Adapted from chibicc. MIT License. Copyright (c) 2019 Rui Ueyama
#use("@/examples/import_c/lib.fr");

// TODO: make this smaller!
Token :: @rec @struct(
    next: *Token,
    val: @union(f: f64, i: i64, str_buf: *u8),  // bits of an integer or float
    ty: *CType,  // string, number
    file: *File,
    off: i32,  // TODO: should be u32
    len: i32,
    kind: Tokens.TokenKind,
    no_macro: bool,
    at_bol: bool,
    has_space: bool,
    line_no: i32,
    origin: *Token,
);

File :: @struct(
    name: Str,
    contents: Str,
    
    // For #line directive
    display_name: Str,
    line_delta: i32,
);

/*********************
*   Parser Helpers   *
**********************/

#use(Types);
Ctx :: Compile.Ctx;

Unicode :: import("@/examples/import_c/unicode.fr");

fn str(tok: *Token) Str = {
    if(tok.is_null(), => return("?NULL?"));
    tok.file.contents.subslice(tok.off.intcast(), tok.len.intcast())
}

// Consumes the current token if it matches `op`.
fn consume(rest: **Token, tok: *Token, $str: Str) bool #inline = {
    b := equal(tok, str);
    ::if(@type tok);
    rest[] = if(b, => tok.next, => tok);
    b
}

fn equal(tok: *Token, $op: Str) bool #inline = 
    @inline_match(@static(?TokenKind) TokenKind.from_name(op)) {  // TODO: make @inline_match work on values
        fn Some(kind) => tok.kind == kind[];
        fn None() => tok.str() == op;
    };

// Ensure that the current token is `op`.
fn skip(c: *Compile.Ctx, tok: *Token, $op: Str) *Token #inline = {
    if !equal(tok, op) {
        @error_tok(c, tok, "expected %", op);
    };
    tok.next
}

fn consume_end(tok: **Token, $end: Str) bool #inline = {
    if equal(tok[], end) {
        tok[] = tok.next;
        return(true);
    };
    if equal(tok[], ",") && equal(tok.next, end) {
        tok[] = tok.next.next;
        return(true);
    };
    false
}

fn warn_tok(ee: FatExpr) FatExpr #macro = {
    e := ee&.items();
    @ct_assert(e.len >= 3, ee.loc, "@error_tok expected (*Ctx, *Token, \"msg\", ...)");
    c, tok := (e[0], e[1]);
    @{
        c := @[c];
        out := u8.list(temp()); out := out&;
        out.push_all("\n");
        fmt_error_prefix(@[tok], out);
        @[format_into(@{ out }, e.rest(2), ee.loc)];
        println(out.items());
    }
}

fn error_tok(ee: FatExpr) FatExpr #macro = {
    e := ee&.items();
    @ct_assert(e.len >= 3, ee.loc, "@error_tok expected (*Ctx, *Token, \"msg\", ...)");
    c, tok := (e[0], e[1]);
    @{
        c := @[c];
        out := c.error_buf&;
        fmt_error_prefix(@[tok], out);
        @[format_into(@{ out }, e.rest(2), ee.loc)];
        throw(c.a_little_hidden_control_flow&)
    }
}

fn error_at(ee: FatExpr) FatExpr #macro = {
    e := ee&.items();
    @ct_assert(e.len >= 3, ee.loc, "@error_tok expected (*Ctx, *u8, \"msg\", ...)");
    e[1] = @{ p := @[e[1]]; new_token(@[e[0]], .TK_ERROR, p, p) };  // TODO: e[0] used twice. this is a crime!
    error_tok(ee)
}

// Reports an error message in the following format.
//
// foo.c:10: x = y + 1;
//               ^ <error message here>
fn fmt_error_prefix(tok: *Token, msg: *List(u8)) void = {
    // if it's somehow not in the file don't try to print something. 
    // this will happen for error_at if you pass in a pointer that's not in c.current_file. 
    ::ptr_utils(Token);
    if tok.is_null() || tok.off < 0 || tok.off.intcast() > tok.file.contents.len {
        return();
    };
    
    if !tok.origin.is_null() {
        // This token was expanded from a macro, show the invocation site as well
        fmt_error_prefix(tok.origin, msg);
        @fmt(msg, "while expanding '%'\n", tok.origin.str());
        // Now fallthrough to show the macro definition
    };
    
    // Find a line containing `loc`.
    line := tok.str().as_ptr();
    while => ptr_diff(tok.file.contents.ptr, line) > 0 && line.offset(-1)[] != "\n".ascii() {  // TODO: make sure this is safe
        line = line.offset(-1);
    };
    end := tok.str().as_ptr();
    while => end[] != 0 && end[] != "\n".ascii() {
        end = end.offset(1);
    };
    
    // Show the file location
    col_no := ptr_diff(line, tok.str().as_ptr());
    @fmt(msg, "%:%:%: ", tok.file.name, tok.line_no, col_no + 1);
    msg.push_all("\n");
    
    // Show the line's text
    pos := col_no;  // TODO: handle unicode variable width stuff. for now just aligning by byte length. 
    line_str: Str = (ptr = line, len = ptr_diff(line, end));
    ::FmtPad(Str);
    @fmt(msg, "%\n%^ ", line_str, f_pad("", pos, .Before)); 
    
    // Then the caller prints the error message
}

// Create a new token.
fn new_token(c: *Ctx, kind: TokenKind, start: *u8, end: *u8) *Token = {
    tok := temp().box_zeroed(Token);
    tok.kind = kind;
    off := ptr_diff(c.current_file.contents.ptr, start);
    @debug_assert_lt(off, 1.shift_left(31));
    @debug_assert_ge(off, - 1.shift_left(31));  // TODO: should always be in the file
    tok.off = off.trunc();
    tok.len = ptr_diff(start, end).intcast();
    tok.file = c.current_file;
    //tok.filename = c.current_file.display_name;
    tok.at_bol = c.at_bol;
    tok.has_space = c.has_space;
    update_kind(tok);
    c.at_bol = false;
    c.has_space = false;
    tok
}

//
// TODO:
// this is all such c shaped code. 
// unfortunate. 
//

// Read an identifier and returns the length of it.
// If p does not point to a valid identifier, 0 is returned.
fn read_ident(start: *u8) i64 #inline = {
    p := start;
    c := Unicode'decode_utf8(p&, p);
    if(!Unicode'is_ident1(c), => return(0));
    
    loop {
        q := p;
        c = Unicode'decode_utf8(q&, p);
        if(!Unicode'is_ident2(c), => return(ptr_diff(start, p)));
        p = q;
    }
}

// Read a punctuator token from p and returns its length.
fn read_punct(p: *u8) Ty(i64, TokenKind) #inline = {
    kw :: @const_slice(
        "<<=", ">>=", "...", "==", "!=", "<=", ">=", "->", "+=", "-=", "*=", "/=",
        "++",  "--",  "%=",  "&=", "|=", "^=", "&&", "||", "<<", ">>", "##",
        ";", "\\", "'", "~", ":", ";", "}", "{", "]", "[", "(", ")", "?", "`", "$", "@", ",", 
    );
    
    return @impl(p, kw);
    // This generates a giant @match that checks one character at a time until it doesn't match a punctuation token:
    // @switch(p[]) {
    //     @case("<".ascii()) => @switch(p.offset(1)[]) {
    //         @case("=".ascii()) => .@"<<";
    //         @default => .@"<";
    // Which is hella faster than for(kw, => if(p.slice(3).starts_with(it), => ...));
    // 50 lines of confusing code saves 90 lines of boring code. not great ratio. 
    impl :: fn(arg: FatExpr) FatExpr #macro = {
        E :: TokenKind;
        arg := arg&.items();
        
        // First convert the list to a tree. 
        Chars :: @rec @struct(x: HashMap(u8, *Chars));  // TODO: this should work without being wrapped in a struct
        prongs: Chars = (x = init(temp()));
        kw := const_eval([]Str)(arg[1]);
        for kw { kw |
            case := prongs&;
            for kw { c |
                ::?*Chars;
                case = or case.x&.get(c) {
                    next := temp().box_zeroed(Chars);
                    next[] = (x = init(temp()));
                    case.x&.insert(c, next);
                    next
                };
            };
        };
        
        // Then convert the tree to code.  
        s := u8.list(temp());
        return rec_case(arg[0], s&, prongs&);
        fn rec_case(arg: FatExpr, s: *List(u8), case: *Chars) FatExpr = {
            N := @literal s.len;
            get_val :: fn() => {
                y :: local_return;
                ::?E;
                if E.from_name(s.items()) { value | 
                    y @{ (@[N], @[@literal value]) };
                } else {
                    y @{ (@[N], E.TK_PUNCT) };
                };
                unreachable()
            };
            
            count := case.x.raw.len_including_tombstones;
            e := Ty(i64, FatExpr).list(count, ast_alloc());
            each case.x& { char, case |
                s.push(char);
                push(e&, (char.int(), rec_case(arg, s, case[])));
                s.pop();
            };
            make_switch(@{ @[arg].offset(@[N])[] }, get_val(), e)
        }
    };
}

fn read_escaped_char(c: *Ctx, new_pos: **u8, p: *u8) Ty(i64, bool) = {  // (ch, is unicode thingy)
    ::if(?i64);
    octal :: fn(ch: u8) ?i64 => 
        if("0".ascii() <= ch && ch <= "7".ascii(), => (Some = zext(ch - "0".ascii())), => .None);
    
    // Read an octal number.
    if octal(p[]) { ch |
        p = p.offset(1);
        if octal(p[]) { ch2 |
            ch = ch * 8 + ch2;
            p = p.offset(1);
            if octal(p[]) { ch2 |
                ch = ch * 8 + ch2;
                p = p.offset(1);
            };
        };
        new_pos[] = p;
        return(ch, false);
    };
    
    // Read a hexadecimal number.
    if p[] == "x".ascii() {
        p = p.offset(1);
        if p[].hex_digit().is_none() {
            @error_at(c, p, "invalid hex escape sequence");
        };
    
        ch := 0;
        while => hex_digit(p[]) { d |
            ch = ch * 16 + d;
            p = p.offset(1);
        };
        new_pos[] = p;
        return(ch, false);
    };
    
    // TODO: handle \U etc here as well instead of in a prepass but that requires the read_string_literal functions
    //       to expect multiple bytes here. 
    new_pos[] = p.offset(1);
    (zext(@switch(p[]) {
        @case("a".ascii()) => 0x07;
        @case("b".ascii()) => 0x08;
        @case("t".ascii()) => "\t".ascii();
        @case("n".ascii()) => "\n".ascii();
        @case("v".ascii()) => vertical_tab;
        @case("f".ascii()) => form_feed;
        @case("r".ascii()) => "\r".ascii();
        // [GNU] \e for the ASCII escape character is a GNU C extension.
        @case("e".ascii()) => 0x1B;
        @case("u".ascii()) => {
            ch: i64 = read_universal_char(new_pos[], 4).zext();
            new_pos[] = new_pos[].offset(4);
            return(ch, true)
        };
        @case("U".ascii()) => {
            ch: i64 = read_universal_char(new_pos[], 8).zext();
            new_pos[] = new_pos[].offset(8);
            return(ch, true)
        };
        @default => p[];
    }), false)
}

form_feed    :: 0x0C;
vertical_tab :: 0x0B;

fn read_string_literal(c: *Ctx, start: *u8, quote: *u8) *Token = {
    read_string_literal(c, start, quote, u8, ty_char) { p, len, buf |
        buf[len[]] = p[][];
        p[] = p[].offset(1);
        len[] += 1;
    }
}

// Read a UTF-8-encoded string literal and transcode it in UTF-16.
//
// UTF-16 is yet another variable-width encoding for Unicode. Code
// points smaller than U+10000 are encoded in 2 bytes. Code points
// equal to or larger than that are encoded in 4 bytes. Each 2 bytes
// in the 4 byte sequence is called "surrogate", and a 4 byte sequence
// is called a "surrogate pair".
fn read_utf16_string_literal(c: *Ctx, start: *u8, quote: *u8) *Token = {
    read_string_literal(c, start, quote, u16, ty_ushort) { p, len, buf |
        ch   := Unicode'decode_utf8(p, p[]);
        wide := ch >= 0x10000;
        if ch < 0x10000 {
            // Encode a code point in 2 bytes.
            buf[len[]] = ch.trunc();
        } else {
            // Encode a code point in 4 bytes.
            ch -= 0x10000;
            buf[len[]] = 0xd800 + ch.trunc().shift_right_logical(10).bit_and(0x3ff);
            buf[len[] + 1] = 0xdc00 + ch.trunc().bit_and(0x3ff);
        };
        len[] += 1 + int(wide);
    }
}

// Read a UTF-8-encoded string literal and transcode it in UTF-32.
//
// UTF-32 is a fixed-width encoding for Unicode. Each code point is
// encoded in 4 bytes.
fn read_utf32_string_literal(c: *Ctx, start: *u8, quote: *u8, ty: *CType) *Token = {
    read_string_literal(c, start, quote, u32, ty_uint) { p, len, buf |
        buf[len[]] = Unicode'decode_utf8(p, p[]);
        len[] += 1;
    }
}

// Find a closing double-quote.
fn string_literal_end(c: *Ctx, p: *u8) Ty(*u8, bool) = {
    start := p;
    had_escapes := false;
    while => p[] != "\"".ascii() {
        if p[] == "\n".ascii() || p[] == 0 {
            @error_at(c, start, "unclosed string literal");
        };
        if p[] == "\\".ascii() {
            p = p.offset(1);  // it might be \" so skip one extra  // TODO: memory unsafe if someone gives us an unterminated string with a \ at the end of the file
            had_escapes = true;
        };
        p = p.offset(1);
    };
    (p, had_escapes)
}

fn read_string_literal(c: *Ctx, start: *u8, quote: *u8, $T: Type, ty: *Types.CType, $read_char: @Fn(p: **u8, len: *i64, buf: []T) void #duplicated) *Token #generic = {
    p   := quote.offset(1);
    end, had_escapes := c.string_literal_end(p);
    buf := c.arena.alloc(T, ptr_diff(quote, end));  // :AuditQuotePointer TODO: chibicc used `start` here in read_utf16_string_literal but none of the others
    len := 0;
    is_bytes :: T == u8;
    @if(is_bytes) if !had_escapes {  // TODO: this makes it look confusing
        source := between(p, end);
        buf.slice(0, source.len).copy_from(source);
        len = source.len;
    };

    @if(len == 0)
    while => ptr_diff(p, end) > 0 {
        if p[] == "\\".ascii() {
            // TODO: ive made this stupid now
            ch, is_unicode := c.read_escaped_char(p&, p.offset(1));
            if is_unicode {
                @if(is_bytes, {
                    len += Unicode'encode_utf8(buf.rest(len), ch.trunc());
                }, {
                    small_buf := @uninitialized Array(u8, 16);
                    size := Unicode'encode_utf8(small_buf&.items(), ch.trunc());
                    q := small_buf&.as_ptr();
                    read_char(q&, len&, buf);
                });
            } else {
                buf[len] = ch.trunc();
                len += 1;
            };
        } else {
            read_char(p&, len&, buf);
        };
    };
    
    buf[len] = 0;
    @debug_assert_lt(len, buf.len, "overflow string");
    tok    := c.new_token(.TK_STR, start, end.offset(1));
    tok.ty  = c.array_of(ty, len + 1);
    tok.val.str_buf = ptr_cast_unchecked(T, u8, buf.ptr);
    tok
}

fn read_char_literal(c: *Ctx, start: *u8, quote: *u8, ty: *CType) *Token = {
    p := quote.offset(1);
    if(p[] == 0, => @error_at(c, start, "unclosed char literal"));
    
    ::if(u32);
    ch: u32 = if p[] == "\\".ascii() {
        ch, _ := c.read_escaped_char(p&, p.offset(1));
        ch.trunc()
    } else {
        Unicode'decode_utf8(p&, p)
    };
    
    end := p;
    while => end[] != "'".ascii() {
        if end[] == 0 {
            @error_at(c, p, "unclosed char literal");
        };
        end = end.offset(1);
    };
    
    tok := c.new_token(.TK_NUM, start, end.offset(1));
    tok.val.i = ch.zext();
    tok.ty = ty;
    tok
}

fn convert_pp_int(tok: *Token) bool = {
    p := tok.str().as_ptr();
    
    // Read a binary, octal, decimal or hexadecimal number.
    p0, p1, p2 := (p[], p.offset(1)[], p.offset(2)[]);
    base := if p2 != 0 && p0 == "0".ascii() {
        delta, base := @if_else {
            @if(p1 == "x".ascii() && hex_digit(p2).is_some()) => (2, 16);
            @if((p1 == "b".ascii() || p1 == "B".ascii()) && (p2 == "0".ascii() || p2 == "1".ascii())) => (2, 2);
            @else => (1, 8);
        };
        p = p.offset(delta);
        base
    } else {
        10
    };
    
    // 🤡🤡
    strtoul :: fn(str: *u8, end_out: **u8, base: i64) i64 #libc;  // TODO: can't be calling libc for stuff like this  
    val := strtoul(p, p&, base);
    
    startswith :: fn(p: *u8, needle: Str) bool = 
        p.slice(needle.len) == needle;
    // 🤡🤡 don't use libc for this
    strncasecmp :: fn(s: *u8, needle: CStr, size: i64) bool #libc; // TODO
        
    // Read U, L or LL suffixes. :UGLY
    delta, l, u := @if_else {
        @if(startswith(p, "LLU") || startswith(p, "LLu") || startswith(p, "llU") ||
            startswith(p, "llu") || startswith(p, "ULL") || startswith(p, "Ull") ||
            startswith(p, "uLL") || startswith(p, "ull"))         => (3, true, true);
        @if(!strncasecmp(p, "lu", 2) || !strncasecmp(p, "ul", 2)) => (2, true, true);
        @if(startswith(p, "LL") || startswith(p, "ll"))           => (2, true, false);
        @if(p[] == "L".ascii() || p[] == "l".ascii())             => (1, true, false);
        @if(p[] == "U".ascii() || p[] == "u".ascii())             => (1, false, true);
        @else => (0, false, false);
    };
    p = p.offset(delta);
    if(ptr_diff(tok.str().as_ptr(), p) != tok.len.intcast(), => return(false));
    
    hi :: fn(N) => shift_right_arithmetic(val, N) != 0; // TODO: make sure this what >> on int64_t does?.
    
    // Infer a type.
    ty := if (base == 10) {
        @if_else {
            @if(l && u) => ty_ulong;
            @if(l)      => ty_long;
            @if(u)      => @if(hi(32), ty_ulong, ty_uint);
            @else       => @if(hi(31), ty_long, ty_int);
        }
    } else {
        @if_else {
            @if(l && u) => ty_ulong;
            @if(l)      => @if(hi(63), ty_ulong, ty_long);
            @if(u)      => @if(hi(32), ty_ulong, ty_uint);
            @if(hi(63)) => ty_ulong;
            @if(hi(32)) => ty_long;
            @if(hi(31)) => ty_uint;
            @else       => ty_int;
        }
    };

    tok.kind = .TK_NUM;
    tok.val.i = val;
    tok.ty = ty;
    true
}

// The definition of the numeric literal at the preprocessing stage
// is more relaxed than the definition of that at the later stages.
// In order to handle that, a numeric literal is tokenized as a
// "pp-number" token first and then converted to a regular number
// token after preprocessing.
//
// This function converts a pp-number token to a regular number token.
fn convert_pp_number(c: *Ctx, tok: *Token) void = {
    // Try to parse as an integer constant.
    if(convert_pp_int(tok), => return());

    // If it's not an integer, it must be a floating point constant.
    // TODO: can't be calling libc for stuff like this 🤡🤡  
    strtod :: fn(str: CStr, end_out: **u8) f64 #libc;  
    end := @uninitialized *u8;
    s: CStr = (ptr = tok.str().as_ptr());
    val := strtod(s, end&);
    
    end_char := end[];
    ty := @if_else {
        @if(end_char == "f".ascii() || end_char == "F".ascii()) => {
            end = end.offset(1);
            val = val.to_single_precision_with_hi_zeroed();
            ty_float
        };
        @if(end_char == "l".ascii() || end_char == "L".ascii()) => {
            end = end.offset(1);
            ty_ldouble
        };
        @else => ty_double;
    };
    
    if ptr_diff(tok.str().as_ptr(), end) != tok.len.intcast() {
        @error_tok(c, tok, "invalid numeric constant '%'", between(tok.str().as_ptr(), end));
    };
    
    tok.kind = .TK_NUM;
    tok.val.i = val.bitcast();
    tok.ty = ty;
}

// backend `Con` only cares about bits, not types. 
// it needs 32 bit single precision floats as a 64 bit value with the high bits zeroed, 
// NOT as a 64 bit double precision number. 
fn to_single_precision_with_hi_zeroed(v: f64) f64 = {
    v: f32 = v.cast();
    v: u32 = v.bitcast();
    v: i64 = v.zext();
    v: f64 = v.bitcast();
    v
}

fn convert_pp_tokens(c: *Ctx, tok: *Token) void = {
    while => tok.kind != .TK_EOF {
        if tok.kind == .TK_PP_NUM {
            c.convert_pp_number(tok);
        };
        //update_kind(tok);  // done in new_token now
        tok = tok.next;
    };
}

fn update_kind(tok: *Token) void = {
    max :: max_enum_name_len(TokenKind);
    if(tok.len > max || !@is(tok.kind, .TK_IDENT, .TK_KEYWORD), => return());
    kw := TokenKind.from_name(tok.str()) || return();
    if(kw.raw() <= TokenKind.TK_ERROR.raw(), => return());
    tok.kind = kw;  // TODO: filter for the ones that aren't literal. ie. what if someone has a variable called `TK_EOF`
}

fn max_enum_name_len(E: Type) i64 #fold = {
    hi := 0;
    for get_enum_names(E) { n |
        hi = max(hi, n.len);
    };
    hi
}

// Tokenize a given string and returns new tokens.
fn tokenize(c: *Ctx, file: *File) *Token = {
    c.current_file = file;
    
    p := file.contents.ptr;
    head := Token.zeroed();
    cur := head&;
    
    c.at_bol    = true;
    c.has_space = false;
    line_no: i32 = 1;
    
    // track_blanks :: false;
    track_blanks := c.track_blanks;
    
    // recall :BoundsPadding, it's fine to look ahead a few characters without checking for the null terminator. 
    while => p[] != 0 { 
        continue :: local_return;
        continue_tok :: fn(tok) => {
            cur.next = tok;
            cur = cur.next;
            p = p.offset(cur.len.intcast());
            tok.line_no = line_no;
            continue();
        };
        continue_blank :: fn(start) => {
            @if(track_blanks) {
                tok := c.new_token(.TK_BLANK, start, p);
                cur.next = tok;
                cur = cur.next;
                tok.line_no = line_no;
            };
            continue();
        };
        if p[] == "/".ascii() {
            start := p;
            
            // Skip line comments.
            if p.offset(1)[] == "/".ascii() {
                while => p[] != "\n".ascii() && p[] != 0 {
                    if p[] == "\\".ascii() && p.offset(1)[] == "\n".ascii() {
                        p = p.offset(1);
                        line_no += 1;
                    };
                    
                    p = p.offset(1);
                };
                c.has_space = true;
                continue_blank(start);
            };
            
            // Skip block comments.
            if p.offset(1)[] == "*".ascii() {
                p = p.offset(2);  // required for `/*/ */` 
                // c doesn't allow nested block comments. 
                while => !(p[] == "*".ascii() && p.offset(1)[] == "/".ascii()) {
                    p = p.offset(1);
                    if p[] == 0 {
                        @error_at(c, p, "unclosed block comment");
                    };
                    if p[] == "\n".ascii() {
                        line_no += 1;
                    };
                };
                p = p.offset(2);
                c.has_space = true;
                continue_blank(start);
            };
            
            // fallthrough
        };
    
        if p[] == "\\".ascii() && p.offset(1)[] == "\n".ascii() {
            p = p.offset(2);
            line_no += 1;
            // pretend the next token is on the same line so don't set at_bol
            continue_blank(p.offset(-2));
        };
        
        // Skip newline.
        if p[] == "\n".ascii() {
            p = p.offset(1);
            c.has_space = false;
            line_no += 1;
            @if(track_blanks) @if(c.at_bol) continue_blank(p.offset(-1));
            c.at_bol = true;
            continue();
        };
    
        // Skip whitespace characters.
        if p[] == " ".ascii() || p[] == "\t".ascii() || p[] == form_feed || p[] == "\r".ascii() || p[] == vertical_tab {
            p = p.offset(1);
            c.has_space = true;
            continue_blank(p.offset(-1));
        };
    
        // Numeric literal
        if is_ascii_digit(p[]) || (p[] == ".".ascii() && is_ascii_digit(p.offset(1)[])) {
            q := p;
            p := p.offset(1); // not mutating outer `p` because continue_tok does it
            loop {
                a := is_ascii_alpha(p[]);
                if a || is_ascii_digit(p[]) || p[] == ".".ascii()  {
                    if a && "+-".contains(p.offset(1)[]) && "eEpP".contains(p[]) {
                        p = p.offset(1);
                    };
                    p = p.offset(1);
                } else {
                    continue_tok(c.new_token(.TK_PP_NUM, q, p));
                };
            };
        };
    
        // String literal
        if p[] == "\"".ascii() {
            continue_tok(c.read_string_literal(p, p));
        };
    
        if p.offset(1)[] == "\"".ascii() {
            @switch(p[]) {
                // TODO: this one was +2 but the others are +1? wrong? :AuditQuotePointer
                // UTF-16 string literal
                @case("u".ascii()) => continue_tok(c.read_utf16_string_literal(p, p.offset(1)));
                // Wide string literal
                @case("L".ascii()) => continue_tok(c.read_utf32_string_literal(p, p.offset(1), ty_int));
                // UTF-32 string literal
                @case("U".ascii()) => continue_tok(c.read_utf32_string_literal(p, p.offset(1), ty_uint));
                @default => (); // fallthrough
            };
        };
        // UTF-8 string literal
        if p[] == "u".ascii() && p.offset(1)[] == "8".ascii() && p.offset(2)[] == "\"".ascii() {
            continue_tok(c.read_string_literal(p, p.offset(2)));
        };
    
        // Character literal
        if p[] == "'".ascii() {
            tok := c.read_char_literal(p, p, ty_int);
            if tok.val.i > 255 {
                @error_tok(c, tok, "char literal too large. use a size prefix.");
            };
            sign_extend :: fn(c: i64) i64 #ir(.extsb, .Kl);
            tok.val.i = sign_extend(tok.val.i);
            continue_tok(tok);
        };
    
        if p.offset(1)[] == "'".ascii() {
            @switch(p[]) {
                // UTF-16 character literal
                @case("u".ascii()) => {
                    tok := c.read_char_literal(p, p.offset(1), ty_ushort);
                    tok.val.i = tok.val.i.bit_and(0xFFFF);  // TODO: is this supposed to be sign extended?
                    continue_tok(tok);
                };
                // Wide character literal
                @case("L".ascii()) => continue_tok(c.read_char_literal(p, p.offset(1), ty_int));
                // UTF-32 character literal
                @case("U".ascii()) => continue_tok(c.read_char_literal(p, p.offset(1), ty_uint));
                @default => (); // fallthrough
            };
        };
       
        // TODO: do update_kind here instead of always having to check the kind
        
        // Identifier or keyword
        len := read_ident(p);
        if p.offset(len)[] == "\\".ascii() && p.offset(len + 1)[] == "\n".ascii() {
            // if you use \ to split an identifier across a line: fuck you, we take quadratic time. 
            q := p.offset(len).slice(3);
            q[0] = q[2];
            q[1] = "\\".ascii();
            q[2] = "\n".ascii();
            // TODO: need to do that for other types of tokens as well. numbers. strings? punctuation. 
            continue();
        };
        if len != 0 {
            continue_tok(c.new_token(.TK_IDENT, p, p.offset(len)))
        };
        
        // Punctuators
        len, kind := read_punct(p);
        if len != 0 {
            continue_tok(c.new_token(kind, p, p.offset(len)))
        };
    
        @error_at(c, p, "invalid token");
    };
    @if(track_blanks) @if(c.at_bol) {
        c.at_bol = false;
        cur.next = c.new_token(.TK_BLANK, p.offset(-1), p);
        cur = cur.next;
    };
    
    cur.next = c.new_token(.TK_EOF, p, p);
    cur = cur.next;
    head.next
}

// TODO
// Replaces \r or \r\n with \n.
//fn canonicalize_newline(p: *u8) void = {

fn read_universal_char(p: *u8, len: i64) u32 = {
    ch := 0;
    range(0, len) { i |
        d := hex_digit(p[]) || return(0); // TODO: shouldn't this be an error? 
        ch = ch * 16 + d;
        p = p.offset(1);
    };
    ch.trunc()
}

fn new_file(c: *Ctx, name: Str, contents: Str) *File = {
    file := c.arena.box(File);
    file.name = name;
    file.display_name = name;
    
    // :BoundsPadding
    // we want it to be a c string, and if we add some extra zeros, the lexer doesn't 
    // have to worry about bounds checks when it looks a few characters ahead to match 
    // a specific one. 0 won't match anything. 
    // TODO: i had the great idea of not checking the length of the string and just stopping lexing when you hit a 0
    //       but since you also need to tokenize little slices sometimes it doesn't work with non-cstr
    // :SLOW
    file.contents = {
        dest := c.arena.alloc(u8, contents.len + 10);
        dest.slice(0, contents.len).copy_from(contents);
        dest.rest(contents.len).set_zeroed();
        dest
    };
    file
}

fn tokenize_file(c: *Ctx, path: Str) *Token = {
    prefix := Preprocess.HACK_BUILTIN_FOLDER_PREFIX;
    src := u8.list(c.arena);   // TODO: can probably be temp() since we copy string literals out
    if path.starts_with(prefix) {
        path = path.rest(prefix.len());
        src&.push_all(find_builtin_header(path).unwrap());
    } else {
        read_and_push(src&, path) || {
            @error_at(c, path.ptr, "Failed to open file: %", path)
        };
    };
    c.tokenize_string(path, src&.items())
}

fn tokenize_string(c: *Ctx, path: Str, src: Str) *Token = {
    // TODO: chibicc does some extra stuff here: 
    //       but we can't be doing like 17 passes over the file man, common. 
    //canonicalize_newline(p);
    
    //convert_universal_chars(p);
    
    file := c.new_file(path, src); 
    c.tokenize(file)
}

TokenKind :: @enum(u8) (
    TK_IDENT,   // Identifiers
    TK_PUNCT,   // Punctuators
    TK_KEYWORD, // Keywords
    TK_STR,     // String literals
    TK_NUM,     // Numeric literals
    TK_PP_NUM,  // Preprocessing numbers
    TK_EOF,     // End-of-file markers
    TK_ERROR,   // Only used for calling @error_tok
    TK_BLANK,
    // start update_kind
    
    // TK_KEYWORD and TK_PUNCT get converted to one of these:
    
    // start valid_macro_name 
    return,    if,         else,
    for,       while,      __attribute__,
    case,      default,    do,
    sizeof,    asm,        _Alignof,
    break,     continue,   switch,
    // start is_type_name
    short,     inline,     long,
    void,      typedef,    _Bool,
    enum,      static,     union,
    struct,    _Alignas,   extern,
    signed,    unsigned,   const,
    volatile,  auto,       register,
    restrict,  __restrict, __restrict__,
    _Noreturn, float,      double,
    typeof,    char,       _Thread_local,
    __thread,  _Atomic,    int,
    // end is_type_name
    __builtin_va_start, __builtin_va_arg, __builtin_types_compatible_p,
    goto,     _Generic, 
    // end valid_macro_name 
    
    @".", @",", @"(", @")", @":", @"?", @"{", @"}", @";",
    @"<<=", @">>=", @"...", @"==", @"!=", @"<=", @">=", @"->", @"+=", @"-=", @"*=", @"/=",
    @"++",  @"--",  @"%=",  @"&=", @"|=", @"^=", @"&&", @"||", @"<<", @">>", @"##",
    @"=", @"!", @"<", @">", @"-", @"+", @"*", @"/",
    @"%", @"&", @"|", @"^", @"#", @"[", @"]", @"~",
); 
