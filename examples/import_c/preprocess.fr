// Adapted from chibicc. MIT License. Copyright (c) 2019 Rui Ueyama
//
// The preprocessor takes a list of tokens as an input and returns a
// new list of tokens as an output.
//
// Macros are never recursive. Once we start expanding a macro, 
// it cannot be used again until the end of that expansion. 
// This is tracked in the `hide_stack`. 
//
// TODO: report error for recursive #include

#use("@/examples/import_c/lib.fr");
#use(Tokens);
#use("@/lib/sys/fs.fr"); // TODO: have the caller pass in a vtable?

MacroArg :: @struct {
    name: Str; 
    is_va_args: bool;
    tok: *Token;
};

MacroHandler :: @FnPtr(c: *Ctx, tmpl: *Token) *Token;

Macro :: @struct {
    name: Str;
    is_objlike: bool; // Object-like or function-like
    params: []Str;    // names in #define foo(param1, param2)
    // TODO: i assume most macros aren't variadic. 
    //       so this should be a flag and we just treat the last entry of params differently? 
    va_args_name: ?Str;  
    body: *Token;
    handler: ?MacroHandler;
    enabled: bool; // TODO: this means you can only run one thread at a time
};

// `#if` can be nested, so we use a stack to manage nested `#if`s.
CondIncl :: @rec @struct {
    next: ?*CondIncl;  // TODO: the Ctx should just have a List of these
    ctx: IfKind;
    tok: *Token;
    included: bool;
};

IfKind :: @enum(Then, Elif, Else);

fn is_hash(tok: *Token) bool #inline =
    tok.at_bol && equal(tok, "#");

// https://github.com/rui314/chibicc/issues/112

// Some preprocessor directives such as #include allow extraneous
// tokens before newline. This function skips such tokens.
fn skip_line(tok: *Token) *Token = {
    if(tok.at_bol, => return(tok));
    // warn_tok(tok, "extra token");  // TODO
    while => !tok.at_bol {
        tok = tok.next;
    };
    tok
}

fn copy_token(c: *Ctx, tok: *Token) *Token = {
    t := c.arena.boxed(Token, tok[]);
    t.next = zeroed(@type t.next);
    t
}

fn new_eof(c: *Ctx, tok: *Token) *Token = {
    t := c.copy_token(tok);
    t.kind = .TK_EOF;
    t.len = 0;
    t
}


// append tok2 to the end of (a copy of) tok1.
fn append(c: *Ctx, tok1: *Token, tok2: *Token) *Token = {
    if(tok1.kind == .TK_EOF, => return(tok2));
    head := Token.zeroed();
    cur  := head&;
    c.append_until_eof(cur&, tok1, true);
    cur.next = tok2;
    head.next
}

fn is(tok: *Token, $names: []Str) bool = {
    inline_for names { $name |
        if(equal(tok, name[]), => return(true));
    };
    false
}

// Skip until next `#else`, `#elif` or `#endif`.
// Nested `#if` and `#endif` are skipped.
fn skip_cond_incl(tok: *Token) *Token = {
    depth := 1;
    loop {
        if(tok.kind == .TK_EOF, => return(tok)); // error: unterminated conditional directive
        
        if is_hash(tok) {
            it := contextual_keyword(tok.next.str(), Directive);
            if depth == 1 && @is(it, .elif, .else, .endif) {
                return(tok)
            };
            depth -= int(@is(it, .endif));
            depth += int(@is(it, .if, .ifdef, .ifndef));
        };
        tok = tok.next;
    }
}

// TODO: this does not spark joy
// Double-quote a given string and returns it.
fn quote_string(c: *Ctx, str: Str) Str = {
    bufsize := 2;// + 5;
    for str { c | 
        bufsize += 1 + int(c == "\\".ascii() || c == "\"".ascii());
    };
    
    buf := c.arena.alloc_uninit(u8, bufsize);
    j := 0;
    buf[j] = "\"".ascii();
    j += 1;
    for str { c | 
        if c == "\\".ascii() || c == "\"".ascii() {
            buf[j] = "\\".ascii();
            j += 1;
        };
        buf[j] = c;
        j += 1;
    };
    buf[j] = "\"".ascii();
    j += 1;
    
    // :BoundsPadding
    // there's somewhere i forgot to do this so now i do it in create_file 
    // which is sad because then it happens maybe redundantly for the big input file
    // so TODO: maybe change it back or just accept the bounds check which would probably be faster than all this
    //range(0, 5) { _ |
    //    buf[j] = 0;
    //    j += 1;
    //};
    @debug_assert_eq(j, buf.len);
    buf
}

// note: wont work if there are new lines in there i think
fn new_str_token(c: *Ctx, str: Str, tmpl: *Token) *Token = {
    buf := c.quote_string(str);
    c.tokenize(c.new_file(tmpl.file.name, buf))
}

// Copy all tokens until the next newline, terminate them with
// an EOF token and then returns them. This function is used to
// create a new list of tokens for `#if` arguments.
fn copy_line(c: *Ctx, rest: **Token, tok: *Token) *Token = {
    head := Token.zeroed();
    cur  := head&;
    while => !tok.at_bol {
        c.append_one(cur&, tok, true);
        tok = tok.next;
    };
    cur.next = c.new_eof(tok);
    rest[] = tok;
    head.next
}

// needs to point to a string (not just set tok.val.i) in case it's used in paste() 
// and needs to be in a File because that's where str() looks. 
fn new_num_token(c: *Ctx, val: i64, tmpl: *Token) *Token = {
    ::if(*Token);
    t := if val == 0 || val == 1 {
        // fast path for eval_const_expr
        c.copy_token(c.cached_number_tokens&[val])
    } else {
        c.new_num_token(val, tmpl.file.name)
    };
    t.origin = tmpl;
    t
}

fn new_num_token(c: *Ctx, val: i64, filename: Str) *Token = {
    @debug_assert_ge(val, 0, "new_num_token negative");
    buf := @tfmt("%", val);
    tok := c.tokenize(c.new_file(filename, buf));
    @debug_assert_eq(tok.kind, .TK_PP_NUM);
    tok
}

fn valid_macro_name(tok: *Token) bool = {
    tok.kind == .TK_IDENT || tok.kind.valid_macro_name()
}

fn valid_macro_name(kind: Tokens.TokenKind) bool = 
    kind.raw() >= Tokens.TokenKind.return.raw() && kind.raw() <= Tokens.TokenKind._Generic.raw();

fn read_const_expr(c: *Ctx, rest: **Token, tok: *Token) *Token = {
    tok = c.copy_line(rest, tok);
    head := Token.zeroed();
    cur := head&;

    while => tok.kind != .TK_EOF {
        // "defined(foo)" or "defined foo" becomes "1" if macro "foo"
        // is defined. Otherwise "0".
        if equal(tok, "defined") {
            start := tok;
            has_paren := consume(tok&, tok.next, "(");

            if(!tok.valid_macro_name(), => @error_tok(c, start, "macro name must be an identifier"));
            m := c.find_macro(tok);
            tok = tok.next;
            if has_paren {
                tok = c.skip(tok, ")");
            };
            new := c.new_num_token(m.is_some().int(), start);
            c.append_one(cur&, new, false);
        } else {
            c.append_one(cur&, tok, false);
            tok = tok.next;
        };
    };

    cur.next = tok;
    head.next
}

// Read and evaluate a constant expression.
fn eval_const_expr(c: *Ctx, rest: **Token, tok: *Token) bool = {
    start := tok;
    expr := c.read_const_expr(rest, tok.next);
    expr = c.preprocess2(expr);

    if(expr.kind == .TK_EOF, => @error_tok(c, start, "no expression"));

    // [https://www.sigbus.info/n1570#6.10.1p4] The standard requires
    // we replace remaining non-macro identifiers with "0" before
    // evaluating a constant expression. For example, `#if foo` is
    // equivalent to `#if 0` if foo is not defined.
    head := Token.zeroed();
    cur := head&;
    t := expr;
    for_linked t { t |
        // TODO: if you get a "not a function" error because you tried to call it as a macro in an #if, 
        //       it's misleading because it says "while expanding" but the problem is really that the macro was not defined.
        new := @if(t.valid_macro_name(), c.new_num_token(0, t), t);
        c.append_one(cur&, new, false);
    };
    expr = head.next;

    // Convert pp-numbers to regular numbers
    c.convert_pp_tokens(expr);

    rest2 := zeroed(*Token);
    val   := c.const_expr(rest2&, expr);
    if(rest2.kind != .TK_EOF, => @error_tok(c, rest2, "extra token"));
    val != 0
}

fn push_cond_incl(c: *Ctx, tok: *Token, included: bool) *CondIncl = {
    ci := temp().boxed(CondIncl, (
        next = c.cond_incl,
        ctx = .Then,
        tok = tok,
        included = included,
    ));
    c.cond_incl = (Some = ci);
    ci
}

fn find_macro(c: *Ctx, tok: *Token) ?*Macro = {
    if(!tok.valid_macro_name(), => return(.None));
    c.macros&.get(tok.str())
}

fn add_macro(c: *Ctx, name: Str, is_objlike: bool, body: *Token, params: []Str, va_args_name: ?Str) *Macro ={
    m := c.arena.boxed(Macro, (
        name = name,
        is_objlike = is_objlike,
        body = body,
        params = params,
        va_args_name = va_args_name,
        handler = .None,
        enabled = true,
    ));
    c.macros&.insert(name, m);
    m
}

fn read_macro_params(c: *Ctx, rest: **Token, tok: *Token) Ty([]Str, ?Str) #once = {  // (params, va_args_name)
    rest[]  = tok;
    params := Str.list(c.arena);
    comma_sep(c, tok&, ")") {
        if equal(tok, "...") {
            rest[] = c.skip(tok.next, ")");
            return(params.items(), (Some = "__VA_ARGS__"));
        };

        if(!tok.valid_macro_name(), => @error_tok(c, tok, "expected an identifier"));

        name  := tok.str().shallow_copy(c.arena);
        
        if equal(tok.next, "...") {
            rest[] = c.skip(tok.next.next, ")");
            return(params.items(), (Some = name));
        };
        params&.push(name);
        tok = tok.next;
    };
    rest[] = tok;

    (params.items(), .None)
}

fn read_macro_definition(c: *Ctx, rest: **Token, tok: *Token) void #once = {
    if(!tok.valid_macro_name(), => @error_tok(c, tok, "macro name must be an identifier"));
    name := tok.str().shallow_copy(c.arena);
    tok = tok.next;

    if !tok.has_space && equal(tok, "(") {
        // Function-like macro
        params, va_args_name := c.read_macro_params(tok&, tok.next);

        m := c.add_macro(name, false, c.copy_line(rest, tok), params, va_args_name);
        m.params = params;
        m.va_args_name = va_args_name;
    } else {
        // Object-like macro
        c.add_macro(name, true, c.copy_line(rest, tok), empty(), .None);
    };
}

fn read_macro_arg_one(c: *Ctx, rest: **Token, tok: *Token, read_rest: bool, name: Str) MacroArg = {
    head  := zeroed(Token);
    cur   := head&;
    level := 0; // how many opening parens have we seen that need to be closed before we can stop. 
    
    // eat tokens until a comma or paren. if it's VAARGS, eat commas as well. eat well nested paren pairs. 
    while => level != 0 || (!equal(tok, ")") && (read_rest || !equal(tok, ","))) {
        if(tok.kind == .TK_EOF, => @error_tok(c, tok, "premature end of input"));

        level += int(equal(tok, "("));
        level -= int(equal(tok, ")"));
        
        cur.next = c.copy_token(tok);
        cur = cur.next;
        tok = tok.next;
    };

    cur.next = c.new_eof(tok);
    rest[]   = tok;
    (name = name, tok = head.next, is_va_args = read_rest)
}

fn read_macro_args(c: *Ctx, rest: **Token, tok: *Token, params: []Str, va_args_name: ?Str) []MacroArg = {
    start := tok;
    tok = tok.next.next;

    args  := MacroArg.list(params.len + int(va_args_name.is_some()), c.arena);
    first := true;
    for params { name | 
        if !first {
            tok = c.skip(tok, ",");
        };
        first = false;
        // TODO: catch `too few arguments`
        args&.push(c.read_macro_arg_one(tok&, tok, false, name));
    };

    if va_args_name { va_args_name |
        ::if(MacroArg);
        args&.push(if equal(tok, ")") {
            (name = va_args_name, is_va_args = true, tok = c.new_eof(tok))  // :VaArgsSentinal
        } else {
            //if (pp != params) :Audit
            if params.len > 0 {
                tok = c.skip(tok, ",");
            };
            c.read_macro_arg_one(tok&, tok, true, va_args_name)
        });
    } else {
        // TODO: they had: `else if (pp) error_tok(start, "too many arguments");`
        //       but i don't understand how that could happen since the loop above 
        //       was `for (; pp; pp = pp->next) {`, so you can't get out until pp is null? 
        //       im confused
        if !equal(tok, ")") {
            @error_tok(c, start, "too many arguments")
        };
    };
    
    c.skip(tok, ")");
    rest[] = tok;
    args.items()
}

fn find_arg(args: []MacroArg, tok: *Token) ?*MacroArg = {
    each args { a |
        if(a.name == tok.str(), => return(Some = a));
    };
    .None
}

// TODO: this is so similar to the strings one. sad
// Concatenates all tokens in `tok` and returns a new string.
fn join_tokens(tok: *Token, end: *Token) Str = {
    // Compute the length of the resulting token.
    len := 0;
    t := tok;
    while => !t.identical(end) && t.kind != .TK_EOF {
        len += int(!t.identical(tok) && t.has_space);
        len += t.len.intcast();
        t = t.next;
    };

    buf := temp().alloc_uninit(u8, len);
    // Copy token texts.
    pos := 0;
    t := tok;
    while => !t.identical(end) && t.kind != .TK_EOF {
        if !t.identical(tok) && t.has_space {
            buf[pos] = " ".ascii();
            pos += 1;
        };
        buf.subslice(pos, t.len.intcast()).copy_from(t.str());
        pos += t.len.intcast();
        t = t.next;
    };
    @debug_assert_eq(buf.len, pos);
    buf
}

// Concatenates all tokens in `arg` and returns a new string token.
// This function is used for the stringizing operator (#).
fn stringize(c: *Ctx, hash: *Token, arg: *Token) *Token = {
    // Create a new string token. We need to set some value to its
    // source location for error reporting function, so we use a macro
    // name token as a template.
    s := join_tokens(arg, zeroed(*Token));
    c.new_str_token(s, hash)
}

// Concatenate two tokens to create a new token.
fn paste(c: *Ctx, lhs: *Token, rhs: *Token) *Token = {
    // Paste the two tokens.
    buf := u8.list(intcast(lhs.len + rhs.len), c.arena);
    @fmt(buf&, "%%", lhs.str(), rhs.str());

    // Tokenize the resulting string.
    tok := c.tokenize(c.new_file(lhs.file.name, buf.items()));
    if tok.next.kind != .TK_EOF {
        @error_tok(c, lhs, "pasting forms '%', an invalid token", buf.items());
    };
    tok
}

fn has_varargs(args: []MacroArg) bool = {
    each args { a |
        if(a.name == "__VA_ARGS__", => return(a.tok.kind != .TK_EOF));  // :VaArgsSentinal
    };
    false
}

// Replace func-like macro parameters with given arguments.
fn subst(c: *Ctx, tok: *Token, args: []MacroArg) *Token #once = {
    head := Token.zeroed();
    cur := head&;

    while => tok.kind != .TK_EOF {
        continue :: local_return;
        
        // "#" followed by a parameter is replaced with stringized actuals.
        // https://gcc.gnu.org/onlinedocs/cpp/Stringizing.html
        if equal(tok, "#") {
            arg := find_arg(args, tok.next) || @error_tok(c, tok.next, "'#' is not followed by a macro parameter");
            c.append_one(cur&, c.stringize(tok, arg.tok), false);
            tok = tok.next.next;
            continue();
        };

        // [GNU] If __VA_ARG__ is empty, `,##__VA_ARGS__` is expanded
        // to the empty token list. Otherwise, its expaned to `,` and
        // __VA_ARGS__.
        if equal(tok, ",") && equal(tok.next, "##") {
            if find_arg(args, tok.next.next) { arg |
                if arg.is_va_args {
                    tok = if arg.tok.kind == .TK_EOF {
                        tok.next.next.next
                    } else {
                        c.append_one(cur&, tok, true);
                        tok.next.next
                    };
                    continue();
                };
            };
        };

        // ##arg
        if equal(tok, "##") {
            if(cur.identical(head&),     => @error_tok(c, tok, "'##' cannot appear at start of macro expansion"));
            if(tok.next.kind == .TK_EOF, => @error_tok(c, tok, "'##' cannot appear at end of macro expansion"));

            if find_arg(args, tok.next) { arg |
                if arg.tok.kind != .TK_EOF {
                    cur[] = c.paste(cur, arg.tok)[];
                    c.append_until_eof(cur&, arg.tok.next, true);
                };
                tok = tok.next.next;
                continue();
            };

            cur[] = c.paste(cur, tok.next)[];
            tok = tok.next.next;
            continue();
        };

        // arg##arg2  
        arg := find_arg(args, tok);
        if arg { arg |
            if equal(tok.next, "##") {
                rhs := tok.next.next;
                if arg.tok.kind == .TK_EOF {
                    if find_arg(args, rhs) { arg2 |
                        c.append_until_eof(cur&, arg2.tok, true);
                    } else {
                        c.append_one(cur&, rhs, true);
                    };
                    tok = rhs.next;
                    continue();
                };
    
                c.append_until_eof(cur&, arg.tok, true);
                tok = tok.next;
                continue();
            };
        };

        // If __VA_ARG__ is empty, __VA_OPT__(x) is expanded to the
        // empty token list. Otherwise, __VA_OPT__(x) is expanded to x.
        if equal(tok, "__VA_OPT__") && equal(tok.next, "(") {
            arg := c.read_macro_arg_one(tok&, tok.next.next, true, "");
            if has_varargs(args) {
                c.append_until_eof(cur&, arg.tok, false);
            };
            tok = c.skip(tok, ")");
            continue();
        };

        // Handle a macro token. Macro arguments are completely macro-expanded
        // before they are substituted into a macro body.
        if arg { arg |
            t := c.preprocess2(arg.tok);
            t.at_bol = tok.at_bol;
            t.has_space = tok.has_space;
            c.append_until_eof(cur&, t, true);
            tok = tok.next;
            continue();
        };

        // Handle a non-macro token.
        c.append_one(cur&, tok, true);
        tok = tok.next;
    };

    cur.next = tok;
    head.next
}

append_until_eof :: fn(c: *Ctx, cur: **Token, tok: *Token, $copy: bool) void = {
    until_eof tok { tok | 
        c.append_one(cur, tok, copy);
    };
};

append_one :: fn(c: *Ctx, cur: **Token, tok: *Token, $copy: bool) void = {
    cur.next = @if(copy, c.copy_token(tok), tok);
    cur[] = cur.next;
};

// If tok is a macro, expand it and return true.
// Otherwise, do nothing and return false.
fn expand_macro(c: *Ctx, rest: **Token, tok: *Token) bool #once = {
    m := c.find_macro(tok) || return(false);
    
    // If a funclike macro token is not followed by an argument list,
    // treat it as a normal identifier.
    if(!m.is_objlike && !equal(tok.next, "("),   => return(false));
    
    if !m.enabled || tok.no_macro {
        tok.no_macro = true;  // TODO: remove this field?
        return(false);
    };
    
    // Built-in dynamic macro application such as __LINE__
    if m.handler { handler | 
        rest[] = handler(c, tok);
        // note: this means a dynamic macro is never allowed to return multiple tokens. 
        rest.next = tok.next;
        return(true);
    };
    
    macro_token := tok;
    body := if m.is_objlike {
        if m.body.str() == tok.str() && m.body.next.kind == .TK_EOF {
            // dumb HACK for #define FOO FOO
            return(false);
        };
        
        m.body
    } else {  // Function-like macro application
        args   := c.read_macro_args(tok&, tok, m.params, m.va_args_name);
        c.subst(m.body, args)
    };
    end := tok.next;
    until_eof body { t |
        t.origin = macro_token;
    };
    rest[] = c.append(body, end);
    m.enabled = false;
    // TODO: make a simple test that needs this. lua/setobj2t does
    if !identical(end, rest[].next) {
        c.hide_stack&.push(@as(@type c.hide_stack[0]) (m, end));
    } else {
        c.check_hide(end);
        m.enabled = true;
    };
    rest.at_bol = macro_token.at_bol;
    rest.has_space = macro_token.has_space;
    true
}

fn until_eof(t: *Token, $body: @Fn(t: *Token) void) *Token = {
    while => t.kind != .TK_EOF {
        body(t);
        t = t.next;
    };
    t
}

fn search_include_paths(c: *Ctx, filename: Str) ?Str = {
    if(filename.len > 0 && filename[0] == "/".ascii(), => return(Some = filename));

    // The assumption being you'll include the same thing many times and it's slow to check if a file exists. 
    if c.filename_cache&.get(filename) { it |
        return(Some = it)  
    };

    // Search a file from the include paths.
    // TODO: have this be a vtable thing instead of a list of file paths. just provide this as the default implementation. 
    enumerate c.include_paths { i, include_path |
        path := u8.list(c.arena);
        @fmt(path&, "%/%", include_path, filename);
        if file_exists(path.items()) {
            c.filename_cache&.insert(filename, path.items());
            c.include_next_idx = i + 1;
            return(Some = path.items());
        };
    };
    
    @if(c.allow_builtin_headers || (c.m.goal.os == .linux && compiler_magic_headers.contains(filename)))
    if find_builtin_header(filename) { _ |
        return(Some = @tfmt("%%", HACK_BUILTIN_FOLDER_PREFIX, filename));
    };
    
    .None
}

fn search_include_next(c: *Ctx, filename: Str) ?Str = {
    for c.include_paths.items().rest(c.include_next_idx) { include_path |
        c.include_next_idx += 1;
        path := u8.list(c.arena);
        @fmt(path&, "%/%", include_path, filename);
        if file_exists(path.items()) {
            return(Some = path.items());
        };
    };
   
    @if(c.allow_builtin_headers || (c.m.goal.os == .linux && compiler_magic_headers.contains(filename)))
    if find_builtin_header(filename) { _ |
        return(Some = @tfmt("%%", HACK_BUILTIN_FOLDER_PREFIX, filename));
    };
    
    .None
}

// Read an #include argument.
fn read_include_filename(c: *Ctx, rest: **Token, tok: *Token) Ty(Str, bool) = @if_else {  // (_, is_dquote)
    // Pattern 1: #include "foo.h"
    @if(tok.kind == .TK_STR) => {
        // A double-quoted filename for #include is a special kind of
        // token, and we don't want to interpret any escape sequences in it.
        // For example, "\f" in "C:\foo" is not a formfeed character but
        // just two non-control characters, backslash and f.
        // So we don't want to use token.str.
        rest[] = skip_line(tok.next);
        s := tok.str().slice(1, tok.len.intcast() - 1);
        (s, true)
    };
    // Pattern 2: #include <foo.h>
    @if(equal(tok, "<")) => {
        // Reconstruct a filename from a sequence of tokens between
        // "<" and ">".
        start := tok;

        // Find closing ">".
        while => !equal(tok, ">") {
            if(tok.at_bol || tok.kind == .TK_EOF, => @error_tok(c, tok, "expected '>'"));
            tok = tok.next;
        };

        rest[] = skip_line(tok.next);
        s := join_tokens(start.next, tok);
        (s, false)
    };
    // Pattern 3: #include FOO
    // In this case FOO must be macro-expanded to either
    // a single string token or a sequence of "<" ... ">".
    @if(tok.valid_macro_name()) => {
        tok2 := c.preprocess2(c.copy_line(rest, tok));
        c.read_include_filename(tok2&, tok2)
    };
    @else => @error_tok(c, tok, "expected a filename");
};

// Detect the following "include guard" pattern.
//
//     #ifndef FOO_H
//     #define FOO_H
//     ...
//     #endif
fn detect_include_guard(c: *Ctx, tok: *Token) ?Str = {
    // Detect the first two lines.
    if(!is_hash(tok) || !equal(tok.next, "ifndef"), => return(.None));
    tok = tok.next.next;
    if(!tok.valid_macro_name(), => return(.None));
    macro := tok.str();
    tok    = tok.next;
    if !is_hash(tok) || !equal(tok.next, "define") || tok.next.next.str() != macro {
        return(.None);
    };

    // Read until the end of the file.
    while => tok.kind != .TK_EOF {
        continue :: local_return;
        if !is_hash(tok) {
            tok = tok.next;
            continue();
        };
        
        it := contextual_keyword(tok.next.str(), Directive);
        if it == .endif && tok.next.next.kind == .TK_EOF {
            return(Some = macro);
        };
        if @is(it, .if, .ifdef, .ifndef) {
            dowhile {
                tok = skip_cond_incl(tok.next);
                is_hash(tok) && @is(contextual_keyword(tok.next.str(), Directive), .elif, .else)
            };
        }
        tok = tok.next;
    };
    .None
}

fn include_file(c: *Ctx, tok: *Token, path: Str, filename_tok: *Token) ?*Token = {
    // Check for "#pragma once"
    if(c.pragma_once&.get(path).is_some(), => return(Some = tok));

    // If we read the same file before, and if the file was guarded
    // by the usual #ifndef ... #endif pattern, we may be able to
    // skip the file without opening it.
    if c.include_guards&.get(path) { guard_name |
        if(c.macros&.get(guard_name).is_some(), => return(Some = tok));
    };

    tok2 := c.tokenize_file(path, filename_tok) || return(.None);

    if detect_include_guard(c, tok2) { guard_name | 
        // detect_include_guard returns a borrow of the token but we need it to live past this file. 
        guard_name := guard_name.shallow_copy(c.arena);  
        c.include_guards&.insert(path, guard_name);
    };

    (Some = c.append(tok2, tok))
}

// Read #line arguments
fn read_line_marker(c: *Ctx, rest: **Token, tok: *Token) void = {
    start := tok;
    tok = c.preprocess(c.copy_line(rest, tok));

    if tok.kind != .TK_NUM || tok.ty.kind != .TY_INT {
        @error_tok(c, tok, "invalid line marker");
    };
    start.file.line_delta = tok.val.i.intcast() - start.line_no;

    tok = tok.next;
    if(tok.kind == .TK_EOF, => return());
    if(tok.kind != .TK_STR, => @error_tok(c, tok, "filename expected"));
    start.file.display_name = tok.val.str_buf.slice(tok.ty.size.intcast() - 1);  // no null terminator
}

fn read_warn_text(c: *Ctx, tok: **Token) Str = {
    tok := c.copy_line(tok, tok.next);
    tok := c.preprocess2(tok);
    c.join_adjacent_string_literals(tok);
    msg := @ref u8.list(temp());
    while => tok.kind != .TK_EOF {
        @fmt(msg, "% ", tok.string_value() || tok.str());
        tok = tok.next;
    };
    msg.items()
}

fn check_hide(c: *Ctx, tok: *Token) void = {
    if c.hide_stack&.last() { hide | 
        if identical(hide._1, tok) {
            hide._0.enabled = true;
            c.hide_stack&.pop();
            c.check_hide(tok);
        };
    };
}

Directive :: @enum(
    include, include_next, 
    define, undef, 
    if, ifdef, ifndef, elif, else, endif, 
    pragma, error, warning, line,
    add_include_path, // TODO: my extensions should probably be pragmas
    _,
);

// Visit all tokens in `tok` while evaluating preprocessing
// macros and directives.
fn preprocess2(c: *Ctx, tok: *Token) *Token = {
    head := Token.zeroed();
    cur := head&;

    while => tok.kind != .TK_EOF  {
        continue :: local_return;
        if c.expand_macro(tok&, tok) {
            c.check_hide(tok);
            continue();  
        };

        // Pass through if it is not a "#".
        if !is_hash(tok) {
            tok.line_no += tok.file.line_delta;
            c.append_one(cur&, tok, false);
            tok = tok.next;
            c.check_hide(tok);
            continue();
        };

        c.check_hide(tok);
        start := tok;
        tok = tok.next;
        
    start_kw := tok.next;
    @match(contextual_keyword(tok.str(), Directive)) {
        fn include() => {
            start := tok.next;
            filename, is_dquote := c.read_include_filename(tok&, tok.next);

            if filename[0] != "/".ascii() && is_dquote {
                // Treat it as relative to the folder of the file containing the include directive. 
                dirname :: fn(s: Str) Str = {
                    if(!s.contains("/"), => return("./"));
                    s.pop_path_segment()
                };
                // pop_path_segment has trailing slash
                path := @tfmt("%%", dirname(start.file.name), filename);
                if c.include_file(tok, path, start.next.next) { t |
                    tok = t;
                    continue();
                };
                // fallthrough
            };

            path := c.search_include_paths(filename) || filename;
            tok   = c.include_file(tok, path, start.next.next)
                || @error_tok(c, start, "Failed to open file: %", path);
        };
        fn include_next() => {
            start := tok.next;
            filename, _ := c.read_include_filename(tok&, tok.next);
            path := c.search_include_next(filename) || filename;
            tok = c.include_file(tok, path, start.next.next)
                || @error_tok(c, start, "Failed to open file: %", path);
        };
        fn define() => c.read_macro_definition(tok&, tok.next);
        fn undef() => {
            tok = tok.next;
            if(!tok.valid_macro_name(), => @error_tok(c, tok, "macro name must be an identifier"));
            c.undef_macro(tok.str());
            tok = skip_line(tok.next);
        };
        fn if() => {
            val := c.eval_const_expr(tok&, tok);
            c.push_cond_incl(start, val);
            if !val {
                tok = skip_cond_incl(tok);
            };
        };
        fn ifdef() => {
            defined := c.find_macro(tok.next).is_some();
            c.push_cond_incl(tok, defined);
            tok = skip_line(tok.next.next);
            if !defined {
                tok = skip_cond_incl(tok);
            };
        };
        fn ifndef() => {
            defined := c.find_macro(tok.next).is_some();
            c.push_cond_incl(tok, !defined);
            tok = skip_line(tok.next.next);
            if defined {
                tok = skip_cond_incl(tok);
            };
        };
        fn elif() => {
            cond_incl := c.move_cond_incl(start, true, .Elif);

            if !cond_incl.included && c.eval_const_expr(tok&, tok) {
                cond_incl.included = true;
            } else {
                tok = skip_cond_incl(tok);
            };
        };
        fn else() => {
            cond_incl := c.move_cond_incl(start, true, .Else);
            tok = skip_line(tok.next);

            if cond_incl.included {
                tok = skip_cond_incl(tok);
            };
        };
        fn endif() => {
            cond_incl := c.cond_incl || @error_tok(c, start, "stray #endif");
            c.cond_incl = cond_incl.next;
            tok = skip_line(tok.next);
        };
        fn line() => c.read_line_marker(tok&, tok.next);
        fn pragma() => {
            if equal(tok.next, "once") {
                c.pragma_once&.insert(tok.file.name, ());
                tok = skip_line(tok.next.next);
                continue();
            };

            // same as skip_line but no warning for extra tokens
            dowhile {
                tok = tok.next;
                !tok.at_bol
            };
        }
        fn error() => {
            msg := c.read_warn_text(tok&);
            @error_tok(c, start_kw, "error: %", msg);
        }
        fn warning() => {
            msg := c.read_warn_text(tok&);
            @warn_tok(c, start_kw, "warning: %", msg);
        };
        
        // TODO: maybe add_include_path should be `#pragma franca FOO` instead of `#FOO`
        // TODO: see if there's some common extension i should use for this instead. 
        // for convenience in caching i want to represent -Ifoo as something in source text 
        // so i don't have to add a new thing to .frc files. 
        fn add_include_path() => {
            t := tok.next;
            if t.kind != .TK_STR {
                @error_tok(c, t, "expected string");
            };
            tok = skip_line(t.next);
            s := t.str().slice(1, t.len.intcast() - 1);
            c.include_paths&.push(s);
        };
        fn _() => {
            if tok.kind == .TK_PP_NUM {
                c.read_line_marker(tok&, tok);
                continue();
            };

            // `#`-only line is legal. It's called a null directive.
            if !tok.at_bol {
                @error_tok(c, tok, "invalid preprocessor directive");
            }
        };
    };
    };

    cur.next = tok;
    head.next
}

fn move_cond_incl(c: *Ctx, start: *Token, require_non_else: bool, new_state: IfKind) *CondIncl = {
    cond_incl := c.cond_incl || @error_tok(c, start, "stray #%", new_state);
    if(require_non_else && cond_incl.ctx == .Else, => @error_tok(c, start, "stray #%", new_state));
    cond_incl.ctx = new_state;
    cond_incl
}
    
fn define_macro(c: *Ctx, name: Str, buf: Str) void = {
    //buf := @tfmt("%\0\0\0\0\0\0\0", buf); // :BoundsPadding
    tok := c.tokenize(c.new_file("<built-in>", buf));
    c.add_macro(name, true, tok, empty(), .None);
}

fn undef_macro(c: *Ctx, name: Str) void = {
    c.macros&.remove(name);
}

fn add_builtin(c: *Ctx, name: Str, f: MacroHandler) *Macro = {
    m := c.add_macro(name, true, zeroed(*Token) /*TODO*/, empty(), .None);
    m.handler = (Some = f);
    m
}

// this stuff gets added by init_macros()
builtins :: @struct {
    __STDC_VERSION__    :: "201112L";
    __STDC__            :: "1";
    __STDC_HOSTED__     :: "1";
    __STDC_NO_COMPLEX__ :: "1";
    __STDC_UTF_16__     :: "1";
    __STDC_UTF_32__     :: "1";
    __LP64__            :: "1";
 
    // TODO: remove this once i reimplement atomics!
    //       chibicc does them but my backend doesn't have a way to emit a CAS instruction yet. 
    __STDC_NO_ATOMICS__ :: "1";
    
    // TODO: i think all keywords are supposed to be allowed with double underscores. 
    //       do this consistantly. rn it's spread out everywhere as i find programs that need it.  
    __alignof__ :: "_Alignof";
    __typeof :: "typeof";
    __typeof__ :: "typeof";
    __SIZE_TYPE__ :: "unsigned long";
    
    // TODO: chibicc has a bunch more. do i need them? 
    // - __SIZEOF_*__
    // - __*__ for alignof typeof const signed volatile
    // - platform detection for unix linux x64 elf
    // - __USER_LABEL_PREFIX__ __C99_MACRO_WITH_VA_ARGS
    
    __FILE__ :: fn(c: *Ctx, tmpl: *Token) *Token = {
        while => !tmpl.origin.is_null() {
            tmpl = tmpl.origin;
        };
        c.new_str_token(tmpl.file.display_name, tmpl)
    };
    
    __LINE__ :: fn(c: *Ctx, tmpl: *Token) *Token = {
        while => !tmpl.origin.is_null() {
            tmpl = tmpl.origin;
        };
        i := tmpl.line_no + tmpl.file.line_delta;
        c.new_num_token(i.intcast(), tmpl)
    };

    // expanded to serial values starting from 0.
    __COUNTER__ :: fn(c: *Ctx, tmpl: *Token) *Token = {
        i := c.counter_macro_next_id;
        c.counter_macro_next_id += 1;
        c.new_num_token(i, tmpl)
    };
    
    // expanded to a string describing the last
    // modification time of the current file. E.g.
    // "Fri Jul 24 01:32:50 2020"
    __TIMESTAMP__ :: fn(c: *Ctx, tmpl: *Token) *Token = {
        //struct stat st;
        //if (stat(tmpl.file.name, &st) != 0)
        //    return new_str_token("??? ??? ?? ??:??:?? ????", tmpl);
    
        //char buf[30];
        //ctime_r(&st.st_mtime, buf);
        //buf[24] = '\0';
        buf := "??? ??? ?? ??:??:?? ????";  // TODO
        c.new_str_token(buf, tmpl)
    };
    
    __BASE_FILE__ :: fn(c: *Ctx, tmpl: *Token) *Token = {
        c.new_str_token(c.macro_base_file, tmpl)
    };
    
    // expanded to the current date as a string literal, e.g. "May 17 2020".
    __DATE__ :: fn(c: *Ctx, tmpl: *Token) *Token = {
        month :: @const_slice(
            "Jan", "Feb", "Mar", "Apr", "May", "Jun",
            "Jul", "Aug", "Sep", "Oct", "Nov", "Dec",
        );
        tm := c.macro_time&;
        s := @tfmt("\"% % %\"", month[tm.mon.zext()], tm.mday, tm.year + 1900);
        c.new_str_token(s, tmpl)
    };
    
    // expanded to the current time as a string literal, e.g. "13:34:03".
    __TIME__ :: fn(c: *Ctx, tmpl: *Token) *Token = {
        tm := c.macro_time&;
        s := @tfmt("\"%:%:%\"", tm.hour, tm.min, tm.sec);  // TODO: pad with zeros
        c.new_str_token(s, tmpl)
    };
};
Ctx :: Compile.Ctx;

fn init_macros(c: *Ctx) void = {
    s     :: scope_of(Type, builtins);
    names :: get_constants(s);
    inline_for names { $name |
        is_string :: { _, type := get_constant(s, name[]).unwrap(); type == Str };
        name_s    :: name[].str();
        @if(is_string, {
            value :: get_constant(Str, s, name[]).unwrap();
            c.define_macro(name_s, value);
        }, {
            handler :: get_constant(MacroHandler, s, name[]).unwrap();
            c.add_builtin(name_s, handler);
        });
    };
    
    c.macro_time = zeroed(BigTime);
    /* if you want __TIME__/__DATE__ to be real you could do this:  (but it breaks reproducible builds)
        now := time_t.zeroed();
        time(now&);
        localtime_r(now&, c.macro_time&);
    */
    
    // made up names i've been using
    c.define_macro(@tfmt("__%", c.m.goal.os), "1");
    c.define_macro(@tfmt("__%", c.m.goal.arch), "1");
    
    // the standard ones have two underscores. 
    // TODO: if i do this then tcc tries to rt_getcontext which i don't want to do the headers for. :NoDoubleUnderscoreArch
    //c.define_macro(@tfmt("__%__", c.m.goal.arch), "1");
    
    // #if defined(__unix__) || defined(__MACH__)
    //c.define_macro("__MACH__", "1");
}

HACK_BUILTIN_FOLDER_PREFIX :: "__builtin://";

// these don't live in the normal system include paths, 
// they're in clang/gcc version specific places, 
// so i guess i'm supposed to always provide my own. 
// which makes sense. 
compiler_magic_headers :: @const_slice("stddef.h", "stdarg.h", "stdbool.h");

fn find_builtin_header(filename: Str) ?Str = {
    if filename.ends_with(".h") {
        filename.len -= 2;
    };
    
    s :: import("@/examples/import_c/include.fr");
    headers :: @static(RawHashMap(Str, Str)) {
        h: HashMap(Str, Str) = init(ast_alloc());
        names := get_constants(s);
        for names { name |
            is_string := { _, type := get_constant(s, name).unwrap(); type == Str };
            if is_string {
                content := get_constant(Str, s, name).unwrap();
                h&.insert(str(name), content);
            } else {
                s2 := scope_of(Type, get_constant(Type, s, name).unwrap());
                names2 := get_constants(s2);
                for names2 { name2 | 
                    content := get_constant(Str, s2, name2).unwrap();
                    path := (@tfmt("%/%", name.str(), name2.str())).shallow_copy(ast_alloc());
                    h&.insert(path, content);
                };
            };
        };
        import("@/examples/import_c/ffi.fr")'gen_builtin_includes(h&);
        h.raw&.zero_unused_slots();
        h.raw
    };
    headers.get(filename)
}

StringKind :: @enum(STR_NONE, STR_UTF8, STR_UTF16, STR_UTF32, STR_WIDE);

fn string_kind(tok: *Token) StringKind = {
    s := tok.str();
    if(s.starts_with("u8"), => return(.STR_UTF8));
    @switch(tok.str().as_ptr()[]) {
        @case("\"".ascii()) => .STR_NONE;
        @case("u".ascii())  => .STR_UTF16;
        @case("U".ascii())  => .STR_UTF32;
        @case("L".ascii())  => .STR_WIDE;
        @default => unreachable();
    }
}

// TODO: this is a lot of code for something super boring. 
// Concatenate adjacent string literals into a single string literal
fn join_adjacent_string_literals(c: *Ctx, tok: *Token) void = {
    // TODO: pls. cache locality. do the two passes together. 
    //       and incrementally (but have to be careful of breaking ## if you do it too early)

    // First pass: If regular string literals are adjacent to wide
    // string literals, regular string literals are converted to a wide
    // type before concatenation. In this pass, we do the conversion.
    tok1 := tok;
    while => tok1.kind != .TK_EOF {
        continue :: local_return;
        if tok1.kind != .TK_STR || tok1.next.kind != .TK_STR {
            tok1 = tok1.next;
            continue();
        };

        kind   := string_kind(tok1);
        basety := tok1.ty.base;

        t := tok1.next;
        while => t.kind == .TK_STR {
            k := string_kind(t);
            if kind == .STR_NONE {
                kind = k;
                basety = t.ty.base;
            } else {
                if (k != .STR_NONE && kind != k) {
                    @error_tok(c, t, "unsupported non-standard concatenation of string literals");
                };
            };
            t = t.next;
        };

        if basety.size > 1 {
            t := tok1;
            while => t.kind == .TK_STR {
                if t.ty.base.size == 1 {
                    t[] = c.promote_to_wide_string_literal(t, basety)[];
                };
                t = t.next;
            };
        };

        while => tok1.kind == .TK_STR {
            tok1 = tok1.next;
        };
    };

    // Second pass: concatenate adjacent string literals.
    tok1 := tok;
    while => tok1.kind != .TK_EOF {
        continue :: local_return;
        if tok1.kind != .TK_STR || tok1.next.kind != .TK_STR {
            tok1 = tok1.next;
            continue();
        };
        one_null_terminator :: 1;
        char_size := tok1.ty.base.size.intcast();
        tok2 := tok1;
        len  := one_null_terminator;
        while => tok2.kind == .TK_STR {
            len += tok2.ty.array_len.intcast() - one_null_terminator;
            tok2 = tok2.next;
        };
        // TODO: is alignment real? we allocate this as bytes but may reintepret as wide later. 
        buf  := c.arena.alloc_uninit(u8, len * char_size); 
        tok2 := tok1;
        i := 0;
        while => tok2.kind == .TK_STR {
            @debug_assert_eq(tok2.ty.base.size.intcast(), char_size, "string element size mismatch");
            len := tok2.ty.array_len.intcast() - one_null_terminator;
            buf.subslice(i * char_size, len * char_size).copy_from(tok2.val.str_buf.slice(len * char_size));
            i += len;
            tok2 = tok2.next;
        };
        @debug_assert_eq(i, len - 1);
        buf.rest(i * char_size).set_zeroed();
        tok1[] = c.copy_token(tok1)[];  // TODO: why copy? 
        tok1.ty = c.array_of(tok1.ty.base, len);
        tok1.val.str_buf = buf.ptr;
        tok1.next = tok2;
        tok1 = tok2;
    };
}

fn promote_to_wide_string_literal(c: *Ctx, tok: *Token, basety: *Types.CType) *Token #once = {
    // can be called on a macro expanded from another file and new_token needs it to be in range for a 32 bit offset
    prev := c.current_file;
    c.current_file = tok.file;  

    t := if basety.size == 2 {
        c.read_utf16_string_literal(tok.str().as_ptr(), tok.str().as_ptr())
    } else {
        c.read_utf32_string_literal(tok.str().as_ptr(), tok.str().as_ptr(), basety)
    };
    c.current_file = prev;
    t.next = tok.next;
    t
}

// Entry point function of the preprocessor.
fn preprocess(c: *Ctx, tok: *Token) *Token = {
    tok = c.preprocess2(tok);
    if c.cond_incl { cond_incl |
        @error_tok(c, cond_incl.tok, "unterminated conditional directive");
    };
    c.convert_pp_tokens(tok);
    c.join_adjacent_string_literals(tok);
    tok
}
