// Adapted from chibi MIT License. Copyright (c) 2019 Rui Ueyama
#use("@/examples/import_c/lib.fr");
#use(Compile);

Tok :: Tokens.Token;  // TODO: i guess i need private so you can have this

CType :: @rec @struct(
    kind: TypeKind,
    size: i32,
    align: i32,
    is_unsigned: bool,
    is_atomic: bool,
    base: *CType,
    name: *Tok,
    name_pos: *Tok,
    array_len: i32,
    vla_len: Qbe.Ref,
    vla_size: Qbe.Ref,
    members: *Member,
    is_flexible: bool,
    is_packed: bool,
    return_ty: *CType,
    params: []*CType,
    is_variadic: bool,
    no_prototype: bool,
    ir_index: Qbe.Ref,
    franca: u32,
    // can contain a null pointer if it was a dclaration like `extern void f(int);` or similarly, a typedef
    param_names: []*import("@/examples/import_c/tokenize.fr").Token,
);
Member :: @rec @struct(
    next: *Member,
    ty: *CType,
    tok: *Tok,
    name: *Tok,
    idx: i32,
    align: i32,
    offset: i32,
    is_bitfield: bool,
    bit_offset: i32,
    bit_width: i32,
);

TypeKind :: @enum(i32) (
    TY_VOID,
    TY_BOOL,
    TY_CHAR,
    TY_SHORT,
    TY_INT,
    TY_LONG,
    TY_FLOAT,
    TY_DOUBLE,
    TY_LDOUBLE,
    TY_ENUM,
    TY_PTR,
    TY_FUNC,
    TY_ARRAY,
    TY_VLA, // variable-length array
    TY_STRUCT,
    TY_UNION,
);

fn fixed_type(c: *Ctx, tag: TypeKind, size: i64, unsigned: bool) *CType = {
    t := c.new_type(tag, size, size);
    t.is_unsigned = unsigned;
    t
}

Primitives :: @struct(
    ty_void: *CType,
    ty_bool: *CType,
    ty_char: *CType,
    ty_short: *CType,
    ty_int: *CType,
    ty_long: *CType,
    ty_uchar: *CType,
    ty_ushort: *CType,
    ty_uint: *CType,
    ty_ulong: *CType,
    ty_float: *CType,
    ty_double: *CType,
    ty_ldouble: *CType,
);

// ðŸ¤¡ These can't be static because the name field is mutated when parsing. 
//    (Need to allow multiple Ctx's on different threads)
fn fill_primitives(c: *Ctx) void = {
    c.prims = (
        ty_void = c.fixed_type(.TY_VOID, 1, false),
        ty_bool = c.fixed_type(.TY_BOOL, 1, false),
        ty_char = c.fixed_type(.TY_CHAR, 1, false),
        ty_short = c.fixed_type(.TY_SHORT, 2, false),
        ty_int = c.fixed_type(.TY_INT, 4, false),
        ty_long = c.fixed_type(.TY_LONG, 8, false),
        ty_uchar = c.fixed_type(.TY_CHAR, 1, true),
        ty_ushort = c.fixed_type(.TY_SHORT, 2, true),
        ty_uint = c.fixed_type(.TY_INT, 4, true),
        ty_ulong = c.fixed_type(.TY_LONG, 8, true),
        ty_float = c.fixed_type(.TY_FLOAT, 4, false),
        ty_double = c.fixed_type(.TY_DOUBLE, 8, false),
        ty_ldouble = c.fixed_type(.TY_LDOUBLE, 8, false),
    );
}

fn new_type(c: *Ctx, kind: TypeKind, size: i64, align: i64) *CType = {
    ty := c.arena.box_zeroed(CType);
    ty.kind = kind;
    ty.size = size.intcast();
    ty.align = align.intcast();
    ty
}

fn is_integer(ty: *CType) bool = 
    @is(ty.kind, .TY_BOOL, .TY_CHAR, .TY_SHORT, .TY_INT, .TY_LONG, .TY_ENUM);

fn is_flonum(ty: *CType) bool = 
    @is(ty.kind, .TY_FLOAT, .TY_DOUBLE, .TY_LDOUBLE);

fn is_numeric(ty: *CType) bool = 
    is_integer(ty) || is_flonum(ty);

fn is_void(ty: *CType) bool = 
    ty.kind == .TY_VOID;

fn is_compatible(t1: *CType, t2: *CType) bool = {
    if(t1.identical(t2),     => return(true));
    if(t1.kind != t2.kind,   => return(false));
    if(@is(t1.kind, .TY_CHAR, .TY_SHORT, .TY_INT, .TY_LONG), => return(t1.is_unsigned == t2.is_unsigned));
    if(@is(t1.kind, .TY_FLOAT, .TY_DOUBLE, .TY_LDOUBLE), => return(true));
    @match(t1.kind) {
        fn TY_PTR()  => is_compatible(t1.base, t2.base);
        fn TY_FUNC() => {
            if(!is_compatible(t1.return_ty, t2.return_ty), => return(false));
            if(!(t1.is_variadic == t2.is_variadic), => return(false));
            if(t1.params.len != t2.params.len, => return(false));
            range(0, t1.params.len) { i |
                if(!is_compatible(t1.params[i], t2.params[i]), => return(false));
            };
            true
        }
        fn TY_ARRAY() => {
            if(!is_compatible(t1.base, t2.base), => return(false));
            t1.array_len < 0 && t2.array_len < 0 && t1.array_len == t2.array_len
        }
        @default => false;
    }
}

fn copy_type(c: *Ctx, ty: *CType) *CType = {
    ret := c.arena.box_zeroed(CType);
    ret[] = ty[];
    ret
}

// TODO: this allocates every time! :SLOW
fn pointer_to(c: *Ctx, base: *CType) *CType = {
    ty := c.new_type(.TY_PTR, 8, 8);
    ty.base = base;
    ty.is_unsigned = true;
    ty
}

fn func_type(c: *Ctx, return_ty: *CType) *CType = {
    // The C spec disallows sizeof(<function type>), but
    // GCC allows that and the expression is evaluated to 1.
    ty := c.new_type(.TY_FUNC, 1, 1);
    ty.return_ty = return_ty;
    ty
}

fn array_of(c: *Ctx, base: *CType, len: i64) *CType = {
    ty := c.new_type(.TY_ARRAY, base.size.intcast() * len, base.align.intcast());
    ty.base = base;
    ty.array_len = len.intcast();
    ty
}

fn vla_of(c: *Ctx, base: *CType, len: *Node) *CType = {
    ty := c.new_type(.TY_VLA, 8, 8);
    ty.base = base;
    len = c.new_cast(len, c.ty_ulong);
    ty.vla_len = c.gen_expr(len);
    ty
}

fn get_common_type(c: *Ctx, ty1: *CType, ty2: *CType) *CType = {
    if(!ty1.base.is_null(), => return(c.pointer_to(ty1.base)));
    if(@is(ty1.kind, .TY_STRUCT, .TY_UNION), => return(ty1)); 
    
    k1, k2 := (ty1.kind, ty2.kind);
    if(k1 == .TY_FUNC, => return(c.pointer_to(ty1)));
    if(k2 == .TY_FUNC, => return(c.pointer_to(ty2)));
    
    if(k1 == .TY_LDOUBLE || k2 == .TY_LDOUBLE, => return(c.ty_ldouble));
    if(k1 == .TY_DOUBLE  || k2 == .TY_DOUBLE,  => return(c.ty_double));
    if(k1 == .TY_FLOAT   || k2 == .TY_FLOAT,   => return(c.ty_float));
    
    if ty1.size < 4 {
        ty1 = c.ty_int;
    };
    if ty2.size < 4 {
        ty2 = c.ty_int;
    };
    
    ::if(@type ty1);
    if(ty1.size != ty2.size, => return(if(ty1.size < ty2.size, => ty2, => ty1)));
    if(ty2.is_unsigned, => ty2, => ty1)
}

// For many binary operators, we implicitly promote operands so that
// both operands have the same type. Any integral type smaller than
// int is always promoted to int. If the type of one operand is larger
// than the other's (e.g. "long" vs. "int"), the smaller operand will
// be promoted to match with the other.
//
// This operation is called the "usual arithmetic conversion".
fn usual_arith_conv(c: *Ctx, lhs: **Node, rhs: **Node) void = {
    ty   := c.get_common_type(lhs.ty, rhs.ty);
    b := c.b;
    c.b = lhs.current_block;
    lhs[] = c.new_cast(lhs[], ty);
    c.b = lhs.current_block;
    rhs[] = c.new_cast(rhs[], ty);
    c.b = b;
}

Ctx :: Compile.Ctx;

fn add_type(c: *Ctx, node: *Compile.Node) void #inline = {
    ::ptr_utils(Compile.Node);
    ::ptr_utils(Types.CType);
    if(node.is_null() || !node.ty.is_null(), => return());
    if(@is(node.kind, .ND_NULL_EXPR, .ND_STMT), => return());
    add_type_inner(c, node);
}

fn add_type_inner(c: *Ctx, node: *Node) void = {
    c.add_type(node.lhs);
    c.add_type(node.rhs);
    k := node.kind;
    node.ty = @if_else {
        @if(@is(k, .ND_ADD, .ND_SUB, .ND_MUL, .ND_DIV)) => {
            c.usual_arith_conv(node.lhs&, node.rhs&);
            node.lhs.ty
        };
        @else => (@match(k) {
            //fn ND_CAS() => {
            //    c.add_type(node.cas_addr);
            //    c.add_type(node.cas_old);
            //    c.add_type(node.cas_new);
            //    if(node.cas_addr.ty.kind != .TY_PTR, => @error_tok(c, node.cas_addr.tok, "pointer expected"));
            //    if(node.cas_old.ty.kind  != .TY_PTR, => @error_tok(c, node.cas_old.tok, "pointer expected"));
            //    ty_bool
            //}
            //fn ND_EXCH() => {
            //    if(node.lhs.ty.kind != .TY_PTR, => @error_tok(c, node.cas_addr.tok, "pointer expected"));
            //    node.lhs.ty.base
            //}
            @default => @panic("% should have known type", node.kind);
        });
    };
}

fn add_type(c: *Ctx, k: NodeKind, lhs: **Node, rhs: **Node) *CType = {
    if lhs.ty.is_null() {
        @error_tok(c, lhs.tok, "unknown type for left of % (left is %)", k, lhs.kind);
    };
    if rhs.ty.is_null() {
        @error_tok(c, rhs.tok, "unknown type for right of %", k);
    };
    if lhs.ty.kind == .TY_VOID || rhs.ty.kind == .TY_VOID {
        return(c.ty_void);
    };
@if_else {
    @if(@is(k, .ND_COND, .ND_ADD, .ND_SUB, .ND_MUL, .ND_DIV, .ND_MOD, .ND_BITAND, .ND_BITOR, .ND_BITXOR)) => {
        c.usual_arith_conv(lhs, rhs);
        lhs.ty
    };
    @if(@is(k, .ND_EQ, .ND_NE, .ND_LT, .ND_LE)) => {
        c.usual_arith_conv(lhs, rhs);
        c.ty_int
    };
    @if(@is(k, .ND_SHL, .ND_SHR)) => {
        @if(lhs.ty.size < 4, c.ty_int, lhs.ty)
    };
    @else => (@match(k) {
        fn ND_NEG() => {
            ty := c.get_common_type(c.ty_int, lhs.ty);
            lhs[] = c.new_cast(lhs[], ty);
            ty
        }
        fn ND_ASSIGN() => {
            if(lhs.ty.kind == .TY_ARRAY, => @error_tok(c, lhs.tok, "not an lvalue"));
            if lhs.ty.kind != .TY_STRUCT {
                rhs[] = c.new_cast(rhs[], lhs.ty);
            };
            lhs.ty
        }
        fn ND_COND() => if lhs.ty.kind == .TY_VOID || rhs.ty.kind == .TY_VOID {
            c.ty_void
        } else {
            c.usual_arith_conv(lhs, rhs);
            lhs.ty
        };
        @default => panic("unhandled expression kind in new add_type");
    });
}
}

fn copy_struct_type(c: *Ctx, ty: *CType) *CType = {
    ty = c.copy_type(ty);

    head := Member.zeroed();
    cur  := head&;
    mem  := ty.members;
    for_linked mem { mem |
        m := c.arena.box_zeroed(Member);
        m[] = mem[];
        cur.next = m;
        cur = cur.next;
    };

    ty.members = head.next;
    ty
}

CPrimType :: @enum(B, I8, I16, I32, I64, U8, U16, U32, U64, F32, F64); // , F80);

fn get_type_id(ty: *CType) CPrimType = @match(ty.kind) {
    fn TY_BOOL()  => .B;
    fn TY_CHAR()  => @if(ty.is_unsigned,  .U8,  .I8);
    fn TY_SHORT() => @if(ty.is_unsigned, .U16, .I16);
    fn TY_INT()   => @if(ty.is_unsigned, .U32, .I32);
    fn TY_LONG()  => @if(ty.is_unsigned, .U64, .I64);
    fn TY_FLOAT()   => .F32;
    fn TY_DOUBLE()  => .F64;
    fn TY_LDOUBLE() => .F64;  // nothing special. spec says it can be the same as double. 
    fn TY_ENUM()    => .U32;
    @default => .U64;  // TODO: assert it's not a struct or something insane 
};

fn cls(ty: *CType) Qbe.Cls = {
    if(@is(ty.kind, .TY_STRUCT, .TY_UNION),   => return(.Kl)); // ehhh
    if(@is(ty.kind, .TY_DOUBLE, .TY_LDOUBLE), => return(.Kd));
    if(ty.kind == .TY_FLOAT,                  => return(.Ks));
    if(ty.size == 8 || ty.kind == .TY_ARRAY || ty.kind == .TY_VLA,  => return(.Kl));  // array decays to pointer
    @debug_assert(!@is(ty.kind, .TY_FUNC, .TY_VOID), "cls(%)", ty.kind);
    .Kw
}

fn ir_index(c: *Ctx, ty: *CType) Qbe.Ref = {
    @debug_assert(!ty.is_null(), "ir_index(null)");
    if(ty.ir_index != QbeNull || !@is(ty.kind, .TY_STRUCT, .TY_UNION), => return(ty.ir_index));
    type_info := Qbe.Typ.zeroed();
    out := u32.list(c.m.forever&.borrow()); out := out&;
    @if(Qbe.TRACK_IR_NAMES) if !ty.name.is_null() {
        type_info.name = ty.name.str();  // TODO: make a copy since we want to throw away the tokens?
    };
    @if(ty.size == -1) @error_tok(c, ty.name_pos, "ir_index(incomplete type)");
    @match(ty.kind) {
        fn TY_STRUCT() => {
            type_info.nunion = 1;
            off := 0;
            for_linked ty.members { mem |
                continue :: local_return;
                // TODO: the aarch64 abi pdf does have rules about how you're supposed to lay them out
                if mem.is_bitfield {
                    // the fields will just be FPad
                    continue();
                };
                add_padding(out, off&, mem.offset.intcast());
                c.push_as_fields(mem.ty, out);
                off += mem.ty.size.intcast();
            };
            add_padding(out, off&, ty.size.intcast());
            
            // HACK: amd64/sysv/retr doesn't like if all are FPad because all are bit fields (tcc/131_return_struct_in_reg)
            // TODO: decide what the rules are
            if out.len == 1 {
                f := out[0].unpack();
                if f.type == .FPad && f.len < field_by_size.len().trunc() {
                    out[0] = pack(type = field_by_size[f.len.zext()], len = f.len);
                };
            };
            
            push(out, pack(type = .FEnd, len = 0));
        }
        fn TY_UNION() => {
            mem := ty.members;
            type_info&.set_is_union(true);
            for_linked mem { mem | 
                @debug_assert(!mem.is_bitfield, "unions don't have bitfields");
                c.push_as_fields(mem.ty, out);
                push(out, pack(type = .FEnd, len = 0));
                type_info.nunion += 1;
            };
        }
        @default => unreachable();
    };
    type_info.fields = out.items();
    @debug_assert(ty.size >= 0);
    type_info.size = ty.size.bitcast();
    type_info.align_log2 = (@as(i64) ty.align.zext()).trailing_zeros().trunc();
    ty.ir_index = TYPE c.m.new_type(type_info);
    ty.ir_index
}

fn push_as_fields(c: *Ctx, ty: *CType, out: *List(u32)) void = {
    @debug_assert_ne(ty.kind, .TY_VLA, "cannot have vla in a struct");
    if ty.kind == .TY_ARRAY {
        if(ty.is_flexible, => return());
        // TODO: could be more efficient with nested arrays by making an ir_index
        //       here too, it just gets confusing because you'd need to carefully not use that when passing by value. 
        range(0, ty.array_len.intcast()) { _ |
            c.push_as_fields(ty.base, out);
        };
        return();
    };
    if @is(ty.kind, .TY_STRUCT, .TY_UNION) {
        push(out, pack(type = .FTyp, len = c.ir_index(ty).val().trunc()));
        return();
    };
    tag: Qbe.FieldType = @match(ty.kind) {
        fn TY_FLOAT()   => .Fs;
        fn TY_DOUBLE()  => .Fd;
        fn TY_LDOUBLE() => .Fd;
        @default => {
            it := field_by_size[ty.size.intcast()];
            @debug_assert_ne(it, .FPad);
            it
        };
    };
    push(out, pack(type = tag, len = ty.size.bitcast()));
}

field_by_size :: @const_slice(Qbe.FieldType.FPad, .Fb, .Fh, .FPad, .Fw, .FPad, .FPad, .FPad, .Fl);

#use("@/backend/lib.fr");
