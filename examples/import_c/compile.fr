// Adapted from chibicc. MIT License. Copyright (c) 2019 Rui Ueyama

// TODO: https://github.com/rui314/chibicc/issues/
//      #153 #141 #138 #110 #107 #99 #86 #84 more...
//      - https://github.com/fuhsnn/slimcc/issues?q=is%3Aissue+is%3Aclosed+label%3Aupstream-chibicc&page=2
// _Alignas needs more backend support
// TODO: __builtin_compare_and_swap, __builtin_atomic_exchange
// TODO: don't be copying types all the time? 

// TODO: want to let all the state (like Qbe.Fn) be allocated in Ctx.arena
//       so you can do all the c frontend stuff up front (because you kinda need 
//       to do preprocessor stuff in order) but defer actually compiling it until 
//       the function gets called (and still use temp() as scratch space). ie. a 
//       franca program using a c library should get dead code elimination the same 
//       as it would using a franca library. 

#use("@/examples/import_c/lib.fr");
#use(Tokens);

// TODO: i find the is_* fields more confusing than just using @tagged
Obj :: @struct(
    name: Str,
    ty: *CType,
    tok: *Token,
    align: i32,  // TODO
    stack_slot: Qbe.Ref, 
    is_function: bool,
    is_definition: bool,
    is_static: bool,
    is_tentative: bool,
    is_tls: bool,
    is_local: bool,
    is_inline: bool,
    yielded: bool,
    is_weak: bool,
    init_data: []u8,
    rel: []Dat2.Reloc,
    f: *Qbe.Fn,
    par_r: Qbe.Ref,
    global_symbol: ?Qbe.Sym,  // TODO: use this more
);
Node :: @rec @struct(
    kind: NodeKind,
    ty: *CType,
    tok: *Token,
    lhs: *Node,
    rhs: *Node,
    member: *Member,
    var: *Obj,
    r: Qbe.Ref,
    lvalue: Qbe.Ref,  // what would you get if you took the & of this expression
    current_block: *Qbe.Blk,   // TODO: remove
);

NodeKind :: @enum(i32) (
    ND_NULL_EXPR, // Do nothing
    ND_STMT,
    ND_ADD,       // +
    ND_SUB,       // -
    ND_MUL,       // *
    ND_DIV,       // /
    ND_NEG,       // unary -
    ND_MOD,       // %
    ND_BITAND,    // &
    ND_BITOR,     // |
    ND_BITXOR,    // ^
    ND_SHL,       // <<
    ND_SHR,       // >>
    ND_EQ,        // ==
    ND_NE,        // !=
    ND_LT,        // <
    ND_LE,        // <=
    ND_ASSIGN,    // =
    ND_COND,      // ?:
    ND_MEMBER,    // . (struct member access)
    ND_NOT,       // !
    ND_BITNOT,    // ~
    ND_VAR,       // Variable
    ND_CAST,      // Type cast
    //ND_ASM,       // "asm"
    //ND_CAS,       // Atomic compare-and-swap
    //ND_EXCH,      // Atomic exchange
    ND_INVALID,
);

// Scope for local variables, global variables, typedefs
// or enum constants
VarScope :: @struct {
    var: *Obj;
    type_def: *CType;
    enum_ty: *CType;
    enum_val: i64;
};

// Represents a block scope.
Scope :: @rec @struct {
    next: *Scope;

    // C has two block scopes; one is for variables/typedefs and
    // the other is for struct/union/enum tags.
    vars: HashMap(Str, *VarScope);
    tags: HashMap(Str, *CType);
};

// Variable attributes such as typedef or extern.
VarAttr :: @struct {
    is_typedef: bool;
    is_static:  bool;
    is_extern:  bool;
    is_inline:  bool;
    is_tls:     bool;
    align:       i32;
};

// This struct represents a variable initializer. Since initializers
// can be nested (e.g. `int x[2][2] = {{1, 2}, {3, 4}}`), this struct
// is a tree data structure.
Initializer :: @rec @struct {
    next: *Initializer;
    ty: *CType;
    tok: *Token;

    // If it's not an aggregate type and has an initializer,
    // `expr` has an initialization expression.
    expr: *Node;

    // If it's an initializer for an aggregate type (e.g. array or struct),
    // `children` has initializers for its children.
    children: RawList(*Initializer);

    // Only one member can be initialized for a union.
    // `mem` is used to clarify which member is initialized.
    mem: *Member;
    // TODO: the whole initilizer handling needs to get rewritten. 
    // this is a HACK that makes wuffs/gitplayer compile 30% faster by skipping useless write_gvar_data. 
    // it still allocates the initializers tho which is stupid. 
    all_zeros: bool;
    is_flexible: bool;
};

// For local variable initializer.
InitDesg :: @rec @struct {
    next: *InitDesg;
    idx: i64;
    member: *Member;
    var: *Obj;
};

#use(Preprocess);

Ctx :: @rec @struct {
    // All local variable instances created during parsing are
    // accumulated to this list.
    locals: *Obj;
    
    // Likewise, global variables are accumulated to this list.
    globals: *Obj;
    
    scope: *Scope;
    
    // Points to the function object the parser is currently parsing.
    current_fn: ?*Obj;
    
    m: *QbeModule;
    f: *Qbe.Fn;
    b: *Qbe.Blk;
    
    labels: HashMap(Str, *Qbe.Blk);
    brk_label: ?*Qbe.Blk;
    cont_label: ?*Qbe.Blk;
    
    // Points to a node representing a switch if we are parsing
    // a switch statement.
    current_switch: ?*Qbe.SwitchPayload;
    
    builtin_alloca: *Obj;
    
    arena: Alloc;
    arena_storage: Arena.Allocator;
    next_var_id: i64;
    scope_depth: i64;
    
    tentative: HashMap(Str, *Obj);
    prims: Primitives #use;
    
    consts: *HashMap(Qbe.Con, Qbe.Ref);
    cache_con01: Array(Qbe.Ref, 2);  // because eval_const_expr does true/false so many times
    
    // I'm probably going to regret this. 
    error_buf: List(u8);
    a_little_hidden_control_flow: import("@/lib/sys/jump.fr").JumpBuf;
    
    speculate: bool; // hack
    
    preserve_franca_env: bool;
    franca_env: Qbe.Ref;
    emitter: ?*CodegenShared;
    function_entry: ?*CodegenEntry;
    enqueue_task: @FnPtr(*CodegenShared, *CodegenEntry) void;
    
    /// Tokenize
    current_file: *File;
    at_bol: bool;  // True if the current position is at the beginning of a line
    has_space: bool;  // True if the current position follows a space character
    track_blanks: bool; // config
    
    /// Preprocess
    macros: HashMap(Str, *Macro);
    cond_incl: ?*CondIncl;
    pragma_once: HashMap(Str, void);
    include_guards: HashMap(Str, Str);  // path -> guard name
    include_next_idx: i64;
    counter_macro_next_id: i64;
    macro_time: BigTime;  // for __TIME__ and __DATE__, you can set this to something specific for reproducible builds. 
    filename_cache: HashMap(Str, Str);
    include_paths: List(Str);
    macro_base_file: Str;
    hide_stack: List(Ty(*Macro, *Token));
    allow_builtin_headers: bool;
    cached_number_tokens: Array(*Token, 2);
    import_type_cache: []Array(*CType, 2);
};

fn align_down(n: i64, align: i64) i64 = 
    align_to(n - align + 1, align);

:: {
    assert_eq(align_to(5, 8), 8);
    assert_eq(align_to(11, 8), 16);
    assert_eq(align_to(-1, 8), 0);
};

fn enter_scope(c: *Ctx) void = {
    sc := temp().box_zeroed(Scope);
    sc.next = c.scope;
    sc.vars = init(temp());
    sc.tags = init(temp());
    c.scope = sc;
    c.scope_depth += 1;
}

fn leave_scope(c: *Ctx) void = {
    c.scope = c.scope.next;
    c.scope_depth -= 1;
    @debug_assert_ge(c.scope_depth, 0);
}

fn find_var(c: *Ctx, tok: *Token) ?*VarScope = 
    c.find_var(tok.str());

fn find_var(c: *Ctx, name: Str) ?*VarScope = {
    ::ptr_utils(Scope);
    for_linked c.scope { sc |
        if sc.vars&.get(name) { sc2 |
            return(Some = sc2);
        };
    };
    .None
}

fn find_tag(c: *Ctx, tok: *Token) ?*CType = {
    for_linked c.scope { sc |
        if sc.tags&.get(tok.str()) { ty |
            return(Some = ty);
        };  
    };
    .None
}

fn push_scope(c: *Ctx, name: Str) *VarScope = {
    ::ptr_utils(Scope);
    @debug_assert(!c.scope.is_null(), "uninit Ctx.scope");
    sc := temp().box_zeroed(VarScope);
    insert(c.scope.vars&, name, sc);
    sc
}

fn new_node(c: *Ctx, kind: NodeKind, tok: *Token) *Node = {
    node := temp().box_zeroed(Node);
    node.kind = kind;
    node.tok = tok;
    node.current_block = c.b;
    node
}

fn new_binary(c: *Ctx, kind: NodeKind, lhs: *Node, rhs: *Node, tok: *Token) *Node = {
    node := c.new_node(kind, tok);
    node.lhs = lhs;
    node.rhs = rhs;
    node
}

fn new_deref(c: *Ctx, expr: *Node, tok: *Token) *Node = {
    // :CInferType
    c.add_type(expr);
    if(expr.ty.base.is_null(),        => @error_tok(c, tok, "invalid pointer dereference"));
    if(expr.ty.base.kind == .TY_VOID, => @error_tok(c, tok, "dereferencing a void pointer"));
    ty := expr.ty.base;
    
    r := QbeNull;
    if !c.speculate {
        addr := c.gen_expr(expr);
        r = c.gen_load(addr, ty);  // TODO: extra loads in &*&*&*& chains
    };
    c.ir_node(ty, r, expr.r, tok)
}

fn new_addr(c: *Ctx, expr: *Node, tok: *Token) *Node #once = {
    r := c.gen_addr(expr);
    // :CInferType
    ty := expr.ty;
    ty := c.pointer_to(if(ty.kind == .TY_ARRAY, => ty.base, => ty));
    c.ir_node(ty, r, QbeNull, tok)
}

fn new_num(c: *Ctx, val: i64, tok: *Token, ty: *CType) *Node = {
    @debug_assert(!c.f.is_null(), "no fun");
    c.ir_node(ty, c.getcon(val), QbeNull, tok)
}

fn new_num(c: *Ctx, val: i64, tok: *Token) *Node = 
    c.new_num(val, tok, c.ty_int);

fn new_long(c: *Ctx, val: i64, tok: *Token) *Node = 
    c.new_num(val, tok, c.ty_long);

fn new_ulong(c: *Ctx, val: i64, tok: *Token) *Node = 
    c.new_num(val, tok, c.ty_ulong);

fn new_var_node(c: *Ctx, var: *Obj, tok: *Token) *Node = {
    node := c.new_node(.ND_VAR, tok);
    node.var = var;
    node.ty = var.ty;
    
    node.lvalue = if node.var.is_local {
        node.var.stack_slot
    } else {
        c.getcon(node.var.global_symbol.expect("mangle"))
    };
    if node.var.is_function || var.ty.kind == .TY_ARRAY {
        // arrays decay to pointers: `array` === `&array` === `&array[0]`
        // functions are always a pointer to the code
        node.r = node.lvalue;
    };
    
    node
}

fn new_cast(c: *Ctx, expr: *Node, ty: *CType) *Node = {
    c.add_type(expr);
    check_types(c, expr.tok, expr.ty, ty);
    new_cast_force(c, expr, ty)
}

// TODO: get more serious about this. for now just catching some trivial mistakes. better than nothing. 
fn check_types(c: *Ctx, tok: *Token, lhs: *CType, rhs: *CType) void = {
    fail :: fn(cond) => @if(cond) @error_tok(c, tok, "incompatible % %", lhs.kind, rhs.kind);
    allow :: fn(cond) => @if(cond) return();

    allow(lhs.identical(rhs));
    fail(int(lhs.kind == .TY_STRUCT) != int(rhs.kind == .TY_STRUCT));
    fail(int(lhs.kind == .TY_UNION)  != int(rhs.kind == .TY_UNION));
    fail(int(lhs.kind == .TY_VOID)   != int(rhs.kind == .TY_VOID));
    fail((is_flonum(lhs) && !is_numeric(rhs)) || (is_flonum(rhs) && !is_numeric(lhs)));
}

fn new_cast_force(c: *Ctx, expr: *Node, ty: *CType) *Node = {
    c.add_type(expr);
    if(expr.ty.identical(ty), => return(expr));
    
    node := temp().box_zeroed(Node);
    node.kind = .ND_CAST;
    node.tok = expr.tok;
    node.lhs = expr;
    node.ty = ty; 
    node.current_block = expr.current_block; // HACK: this is super confusing, hopefully it will go away with asts
    
    //node.lvalue = expr.lvalue;  // :FrontendConstantFolding, TODO: but this is wrong, we're assuming its a noop cast but what if its a truncation
    
    source := c.gen_expr(node.lhs);
    from, to := (node.lhs.ty, node.ty);
    if(to.kind == .TY_VOID, => return(c.ir_node(c.ty_void, QbeNull, QbeNull, expr.tok)));  // explicit discard a value
    
    prev := c.b;
    c.b = expr.current_block;
    node.r = c.gen_cast(source, from, to, node.tok);
    c.b = prev;
    node
}

fn new_initializer(c: *Ctx, ty: *CType, is_flexible: bool) *Initializer =   
    new_initializer(ty, is_flexible);
    
fn new_initializer(ty: *CType, is_flexible: bool) *Initializer = {
    init := temp().box_zeroed(Initializer);
    init.ty = ty;

    if ty.kind == .TY_ARRAY {
        if is_flexible && ty.size <= 0 {
            init.is_flexible = true;
            return(init);
        };

        init.children = temp().alloc_init(*Initializer, ty.array_len.intcast(), 
            fn(_) => new_initializer(ty.base, false)).as_raw_list();
    };

    if ty.kind == .TY_STRUCT || ty.kind == .TY_UNION {
        // Count the number of struct members.
        len := 0;
        for_linked ty.members { mem |
            len += 1;
        };
        init.children = temp().alloc_uninit(*Initializer, len).as_raw_list();

        for_linked ty.members { mem |
            ::if(*Initializer);
            init[mem.idx.intcast()] = 
                if is_flexible && ty.is_flexible && mem.next.is_null() {
                    child := temp().box_zeroed(Initializer);
                    child.ty = mem.ty;
                    child.is_flexible = true;
                    child
                } else {
                    new_initializer(mem.ty, false)
                };
        };
    };

    init
}

fn new_var(c: *Ctx, name: Str, ty: *CType, a: Alloc) *Obj = {
    var := a.box_zeroed(Obj);
    var.name = name;  // TODO: this is bad if we reset temp!
    var.ty = ty;
    var.align = ty.align;
    var.global_symbol = .None;
    c.push_scope(name)[].var = var;
    
    var
}

fn new_lvar(c: *Ctx, name: Str, ty: *CType) *Obj = {
    var := c.new_var(name, ty, temp());
    var.is_local = true;
    c.locals = var;

    if c.current_fn { current_fn |
        if var.ty.size >= 0 {  // :StaticArrayOfUnknownLength
            if !c.f.start.is_null() {  // HACK: fix create_params_lvars instead of having an insane ordering where we delay making the start block so this knows to delay making variables for no reason
                c.create_stack_slot(var);
            };
        };
    };
    
    var
}

// fixed size allocs always go in the start block so they can be fast-locals. 
fn create_stack_slot(c: *Ctx, var: *Obj) void = {
    // :ZeroSizeTypes chibicc has empty structs with sizeof(0) but thats an extension
    // what if you tried to diy static_assert with that, now we broke your code?
    if var.ty.size < 0 {
        @error_tok(c, var.tok, "tried to create stack slot for a variable with negative size (%)", var.ty.size);
    };
    if var.stack_slot == QbeNull {
        var.stack_slot = c.f.newtmp(var.name, .Kl);
    };
    // TODO: use var.align, backend only supports up to 16
    push(c.f.start, make_ins(.alloc8, .Kl, var.stack_slot, c.getcon(var.ty.size.intcast()), QbeNull));  // TODO: smaller align stack slots
}

fn new_gvar(c: *Ctx, name: Str, ty: *CType, tok: *Token, is_static: bool) *Obj = {
    var := c.new_var(name, ty, c.arena);
    var.is_definition = true;
    var.is_static = is_static;
    var.tok = tok;
    var.global_symbol = (Some = c.m.mangle(var));
    c.globals = var;
    var
}

fn new_unique_name(c: *Ctx) Str = {
    s := u8.list(c.arena);
    @fmt(s&, ".L..%", c.next_var_id);
    c.next_var_id += 1;
    s.items()
}

fn new_anon_gvar(c: *Ctx, ty: *CType, tok: *Token) *Obj = 
    c.new_gvar(c.new_unique_name(), ty, tok, true);

fn new_string_literal(c: *Ctx, p: []u8, ty: *CType, tok: *Token) *Obj = {
    var := c.new_anon_gvar(ty, tok);
    var.init_data = p;
    if !c.speculate {
        c.yield(var);
    }
    var
}

fn get_ident(c: *Ctx, tok: *Token) Str = {
    if tok.kind != .TK_IDENT {
        @error_tok(c, tok, "expected an identifier");
    };
    tok.str()  // TODO: make sure we never mutate this (its not a copy!)
}

fn find_typedef(c: *Ctx, tok: *Token) ?*CType = {
    if tok.kind == .TK_IDENT {
        if c.find_var(tok) { sc |
            if !sc.type_def.is_null() {
                return(Some = sc.type_def);
            };
        };
    };
    .None
}

fn push_tag_scope(c: *Ctx, tok: *Token, ty: *CType) void = {
    c.scope.tags&.insert(tok.str(), ty);
}

// declspec = ("void" | "_Bool" | "char" | "short" | "int" | "long"
//                         | "typedef" | "static" | "extern" | "inline"
//                         | "_Thread_local" | "__thread"
//                         | "signed" | "unsigned"
//                         | struct-decl | union-decl | typedef-name
//                         | enum-specifier | typeof-specifier
//                         | "const" | "volatile" | "auto" | "register" | "restrict"
//                         | "__restrict" | "__restrict__" | "_Noreturn")+
//
// The order of typenames in a type-specifier doesn't matter. For
// example, `int long static` means the same as `static long int`.
// That can also be written as `static long` because you can omit
// `int` if `long` or `short` are specified. However, something like
// `char int` is not a valid type specifier. We have to accept only a
// limited combinations of the typenames.
//
// In this function, we count the number of occurrences of each typename
// while keeping the "current" type object that the typenames up
// until that point represent. When we reach a non-typename token,
// we return the current type object.
fn declspec(c: *Ctx, rest: **Token, tok: *Token, attr: ?*VarAttr) *CType = {
    // We use a single integer as counters for all typenames.
    // For example, bits 0 and 1 represents how many times we saw the
    // keyword "void" so far. With this, we can use a switch statement
    // as you can see below.
    S :: @enum(i64) (
        void     = 0,
        _Bool    = 2,
        char     = 4,
        short    = 6,
        int      = 8,
        long     = 10,
        float    = 12,
        double   = 14,
        // other = 16,
        signed   = 17,
        unsigned = 18,
    );  :: enum(S);
    Specifier_Other :: 16;
    
    ty        := c.ty_int;
    counter   := 0;
    is_atomic := false;

    if true {
        break :: local_return;
        while => c.is_type_name(tok) {
            continue :: local_return;
            
            if equal(tok, "__attribute__") {
                // :AttributesNotYetImplemented
                // TODO: these need to apply to the symbol. (see musl's #define hidden). 
                //       is it supposed to be broadcast accross commas like VarAttr is?
                _ := c.attribute_list(tok&, tok);
            };
            
            // Handle storage class specifiers.
            if @is(tok.kind, .typedef, .static, .extern, .inline, ._Thread_local, .__thread) {
                attr := attr || @error_tok(c, tok, "storage class specifier is not allowed in this context");
                field := @match(tok.kind) {
                    fn typedef() => attr.is_typedef&;
                    fn static()  => attr.is_static&;
                    fn extern()  => attr.is_extern&;
                    fn inline()  => attr.is_inline&;
                    @default     => attr.is_tls&;
                };
                field[] = true;
    
                disallow_typedef := attr.is_static || attr.is_extern || attr.is_inline || attr.is_tls;
                if attr.is_typedef && disallow_typedef {
                    @error_tok(c, tok, "typedef may not be used together with static, extern, inline, __thread or _Thread_local");
                };
                c.next(tok&, tok);
                continue();
            };
    
            // These keywords are recognized but ignored.
            !ignore(tok&, tok, @const_slice(
                "const", "volatile", "auto", "register", "restrict", "__restrict", "__restrict__", "_Noreturn", 
            )) || continue();
            
            if equal(tok, "_Atomic") {
                c.next(tok&, tok);
                if consume(tok&, tok , "(") {
                    ty = c.typename(tok&, tok);
                    tok = c.skip(tok, ")");
                };
                is_atomic = true;
                continue();
            };
    
            if (equal(tok, "_Alignas")) {
                attr := attr || @error_tok(c, tok, "_Alignas is not allowed in this context");
                c.next(tok&, tok);
                tok = c.skip(tok, "(");
    
                ::if(i32);
                attr.align = if c.is_type_name(tok) {
                    c.typename(tok&, tok)[].align
                } else {
                    c.const_expr(tok&, tok).intcast()
                };
                tok = c.skip(tok, ")");
                continue();
            };
    
            // Handle user-defined types.
            ty2 := c.find_typedef(tok);
            if ty2.is_some() || @is(tok.kind, .struct, .union, .enum, .typeof) {
                if(counter != 0, => break());
    
                start := tok;
                c.next(tok&, tok);
                ty = @match(start.kind) {
                    fn struct() => c.struct_decl(tok&, tok);
                    fn union()  => c.union_decl(tok&, tok);
                    fn enum()   => c.enum_specifier(tok&, tok);
                    fn typeof() => c.typeof_specifier(tok&, tok);
                    @default    => ty2.unwrap();
                };
    
                counter += 1.shift_left(Specifier_Other);
                continue();
            };
    
            // Handle built-in types.
            inline_for_enum S { $s |
                if equal(tok, s[].name_str()) {
                    if (:: @is(s[], .signed, .unsigned)) {
                        counter = counter.bit_or(:: 1.shift_left(s[].raw()));
                    } else {
                        counter += :: 1.shift_left(s[].raw());
                    };
                };
            };
            
            SS :: fn(e: FatExpr) FatExpr #macro = {
                i := 0;
                each e&.items() { e |
                    i += 1.shift_left(const_eval(S)(e[]).raw());
                };
                @literal i
            };
            
            // bleh
            ty = @switch(counter) {
                @case(@SS(.void))  => c.ty_void;
                @case(@SS(._Bool)) => c.ty_bool;
                @case(@SS(.char))          => c.ty_char;
                @case(@SS(.signed, .char)) => c.ty_char;
                @case(@SS(.unsigned, .char)) => c.ty_uchar;
                @case(@SS(.short))                => c.ty_short;
                @case(@SS(.short, .int))          => c.ty_short;
                @case(@SS(.short, .signed))       => c.ty_short;
                @case(@SS(.short, .signed, .int)) => c.ty_short;
                @case(@SS(.short, .unsigned))       => c.ty_ushort;
                @case(@SS(.short, .unsigned, .int)) => c.ty_ushort;
                @case(@SS(.int))          => c.ty_int;
                @case(@SS(.signed))       => c.ty_int;
                @case(@SS(.signed, .int)) => c.ty_int;
                @case(@SS(.unsigned))       => c.ty_uint;
                @case(@SS(.unsigned, .int)) => c.ty_uint;
                @case(@SS(.long))                       => c.ty_long;
                @case(@SS(.long, .int))                 => c.ty_long;
                @case(@SS(.long, .long))                => c.ty_long;
                @case(@SS(.long, .long, .int))          => c.ty_long;
                @case(@SS(.signed, .long))              => c.ty_long;
                @case(@SS(.signed, .long, .int))        => c.ty_long;
                @case(@SS(.signed, .long, .long))       => c.ty_long;
                @case(@SS(.signed, .long, .long, .int)) => c.ty_long;
                @case(@SS(.unsigned, .long))              => c.ty_ulong;
                @case(@SS(.unsigned, .long, .int))        => c.ty_ulong;
                @case(@SS(.unsigned, .long, .long))       => c.ty_ulong;
                @case(@SS(.unsigned, .long, .long, .int)) => c.ty_ulong;
                @case(@SS(.float)) => c.ty_float;
                @case(@SS(.double))        => c.ty_double;
                @case(@SS(.double, .long)) => c.ty_double;  // the spec says this is at least as precise as double, so there you go. 
                @default => @error_tok(c, tok, "invalid type");
            };
            c.next(tok&, tok);
        };
    };

    if is_atomic {
        // TODO!!!
        //panic("TODO :ParamTypeList");
        //ty = c.copy_type(ty);
        //ty.is_atomic = true;
    };

    rest[] = tok;
    ty
}

// func-params = ("void" | param ("," param)* ("," "...")?)? ")"
// param             = declspec declarator
// returns a function type
fn func_params(c: *Ctx, rest: **Token, tok: *Token, ret: *CType) *CType = {
    c.lookahead(tok, 1);
    if equal(tok, "void") && equal(tok.next, ")") {
        c.next(tok&, tok);
        c.next(rest, tok);
        return(c.func_type(ret));
    };

    params := list(*CType, c.arena);
    names  := list(*Token, c.arena);
    is_variadic := false;

    c.comma_sep(tok&, ")") {
        continue :: local_return;
        if consume(tok&, tok, "...") {
            is_variadic = true;
            if !equal(tok, ")") {
                @error_tok(c, tok, "expected ')' after '...'");
            }
            continue();
        };

            ty2 := c.declspec(tok&, tok, .None);
            ty2  = c.declarator(tok&, tok, ty2);
    
            name := ty2.name;
            @match(ty2.kind) {
                // "array of T" is converted to "pointer to T" only in the parameter
                // context. For example, *argv[] is converted to **argv by this.
                fn TY_ARRAY() => { 
                    ty2 = c.pointer_to(ty2.base);
                    ty2.name = name;
                }
                // Likewise, a function is converted to a pointer to a function
                // only in the parameter context.
                fn TY_FUNC() => {
                    ty2 = c.pointer_to(ty2);
                    ty2.name = name;
                }
                @default => ();
            };
            params&.push(ty2);
            names&.push(name);
    };
    
    ty := c.func_type(ret);
    ty.params = params.items();
    ty.param_names = names.items();
    ty.no_prototype = params.len == 0 && !is_variadic;
    ty.is_variadic = is_variadic;
    rest[] = tok;
    ty
}

// array-dimensions = ("static" | "restrict")* const-expr? "]" type-suffix
fn array_dimensions(c: *Ctx, rest: **Token, tok: *Token, ty: *CType) *CType #once = {
    dowhile {
        ignore(tok&, tok, @const_slice("static", "restrict"))
    };

    if consume(tok&, tok, "]") {
        ty = c.type_suffix(rest, tok, ty);
        // :StaticArrayOfUnknownLength
        // We don't know the length of the array until we parse the initializer list. 
        // Which is painful because we want to make the var at the beginning but now need to defer creating a stack slot for it. 
        // Should communicate this in a more clear way than just randomly having some sizes be negative. 
        return(c.array_of(ty, -1));  
    };

    expr := c.parse_expr(tok&, tok, .Conditional);
    tok   = c.skip(tok, "]");
    ty    = c.type_suffix(rest, tok, ty);

    ::if(*CType);
    if ty.kind == .TY_VLA || !c.is_const_expr(expr) {
        c.vla_of(ty, expr)
    } else {
        // :ZeroSizeTypes
        length := c.eval(expr);
        if length < 0 {
            @error_tok(c, expr.tok, "array length cannot be negative");
        };
        c.array_of(ty, length)
    }
}

// type-suffix = "(" func-params
//                         | "[" array-dimensions
//                         | Îµ
fn type_suffix(c: *Ctx, rest: **Token, tok: *Token, ty: *CType) *CType = {
    if(consume(tok&, tok, "("), => return(c.func_params(rest, tok, ty)));
    if(consume(tok&, tok, "["), => return(c.array_dimensions(rest, tok, ty)));
    rest[] = tok;
    ty
}

// pointers = ("*" ("const" | "volatile" | "restrict")*)*
fn pointers(c: *Ctx, rest: **Token, tok: *Token, ty: *CType) *CType = {
    while => consume(tok&, tok, "*") {
        ty = c.pointer_to(ty);
        dowhile {
            ignore(tok&, tok, @const_slice("const", "volatile", "restrict", "__restrict", "__restrict__"))
        };
    };
    rest[] = tok;
    ty
}

fn ignore(rest: **Token, tok: *Token, $ignored: []Str) bool #inline = {
    inline_for ignored { $kw |
        if(consume(rest, tok, ::kw[]), => return(true));
    };
    false
}

// declarator = pointers ("(" ident ")" | "(" declarator ")" | ident) type-suffix
fn declarator(c: *Ctx, rest: **Token, tok: *Token, ty: *CType) *CType = {
    ty = c.pointers(tok&, tok, ty);

    if consume(tok&, tok, "(") {
        // :RewalkTokens
        start := tok;
        dummy := CType.zeroed();
        c.declarator(tok&, start, dummy&);
        tok = c.skip(tok, ")");
        ty = c.type_suffix(rest, tok, ty);
        return(c.declarator(tok&, start, ty));
    };

    name := Token.ptr_from_int(0);
    name_pos := tok;

    if tok.kind == .TK_IDENT {
        name = tok;
        c.next(tok&, tok);
    };

    ty = c.type_suffix(rest, tok, ty);
    // TODO: this makes everything confusing
    //       we're stomping the name of the type with the name of the variable
    //       it works out because we only look at one variable at a time, 
    //       except for in func_params() where they need to be shuffled out into param_names
    ty.name = name;
    ty.name_pos = name_pos;
    ty
}

// abstract-declarator = pointers ("(" abstract-declarator ")")? type-suffix
fn abstract_declarator(c: *Ctx, rest: **Token, tok: *Token, ty: *CType) *CType = {
    ty = c.pointers(tok&, tok, ty);
    if consume(tok&, tok, "(") {
        // :RewalkTokens
        start := tok;
        dummy := CType.zeroed();
        c.abstract_declarator(tok&, start, dummy&);
        tok = c.skip(tok, ")");
        ty  = c.type_suffix(rest, tok, ty);
        c.abstract_declarator(tok&, start, ty)
    } else {
        c.type_suffix(rest, tok, ty)
    }
}

// type-name = declspec abstract-declarator
fn typename(c: *Ctx, rest: **Token, tok: *Token) *CType = {
    ty := c.declspec(tok&, tok, .None);
    c.abstract_declarator(rest, tok, ty)
}

fn is_end(c: *Ctx, tok: *Token) bool = {
    c.lookahead(tok, 1);
    equal(tok, "}") || (equal(tok, ",") && equal(tok.next, "}"))
}

// enum-specifier = ident? "{" enum-list? "}"
//                                | ident ("{" enum-list? "}")?
//
// enum-list            = ident ("=" num)? ("," ident ("=" num)?)* ","?
fn enum_specifier(c: *Ctx, rest: **Token, tok: *Token) *CType #once = {
    ty := c.new_type(.TY_ENUM, 4, 4);

    // Read a struct tag.
    tag: ?*Token = .None;
    if tok.kind == .TK_IDENT {
        tag = (Some = tok);
        c.next(tok&, tok);
    };

    if tag { tag |
        if !equal(tok, "{") {
            ty := c.find_tag(tag) || @error_tok(c, tag, "unknown enum type");
            if(ty.kind != .TY_ENUM, => @error_tok(c, tag, "not an enum tag"));
            rest[] = tok;
            return(ty);
        };
    };

    tok = c.skip(tok, "{");

    // Read an enum-list.
    val := 0;
    names := list(*Token, c.arena);
    comma_sep(c, tok&, "}") {
        names&.push(tok);
        name := c.get_ident(tok);
        c.next(tok&, tok);

        if consume(tok&, tok, "=") {
            val = c.const_expr(tok&, tok);
        };

        sc := c.push_scope(name);
        sc.enum_ty = ty;
        sc.enum_val = val;
        val += 1;
    };
    ty.param_names = names.items();  // The c compiler doesn't need this but we use it for exporting franca types. 
    rest[] = tok;

    if tag { tag |
        c.push_tag_scope(tag, ty);
    };
    ty
}

// typeof-specifier = "(" (expr | typename) ")"
fn typeof_specifier(c: *Ctx, rest: **Token, tok: *Token) *CType #once = {
    tok = c.skip(tok, "(");
    ty := if c.is_type_name(tok) {
        c.typename(tok&, tok)
    } else {
        node := c.speculate(tok&, tok, .None, false);
        c.add_type(node);
        node.ty
    };
    rest[] = c.skip(tok, ")");
    ty
}

// Generate code for computing a VLA size.
fn compute_vla_size(c: *Ctx, ty: *CType) Qbe.Ref = {
    if(ty.vla_size != QbeNull, => return(ty.vla_size));
    if !ty.base.is_null() {
        c.compute_vla_size(ty.base);
    };

    if(ty.kind != .TY_VLA, => return(QbeNull));

    base_sz := if ty.base.kind == .TY_VLA {
       ty.base.vla_size
    } else {
       c.getcon(ty.base.size.intcast())
    };

    @debug_assert_ne(ty.vla_len, QbeNull, "compute_vla_size with unknown length");
    // TODO: emit this up front when the type is created because otherwise the first sizeof() might not dominate cached uses. 
    ty.vla_size = c.emit(.mul, .Kl, ty.vla_len, base_sz);
    ty.vla_size
}

// TODO: sane error message for `, $body: @Fn(),`
fn declarators(c: *Ctx, tok: **Token, basety: *CType, first_declarator: *CType, $body: @Fn(decl: *CType) void #duplicated) void = {
    body(first_declarator); // TODO: only call once with do while
    while => !consume_end(tok, ";") {
        tok[] = c.skip(tok[], ",");
        ty := c.declarator(tok, tok[], basety);
        body(ty);
    };
}

// declaration = declspec (declarator ("=" expr)? ("," declarator ("=" expr)?)*)? ";"
fn declaration(c: *Ctx, tok: *Token, basety: *CType, attr: ?*VarAttr, first_declarator: *CType, expect_var: bool) *Token = {
    start := tok;
    declarators(c, tok&, basety, first_declarator) { ty |
        continue :: local_return;
        if(ty.kind == .TY_VOID, => @error_tok(c, tok, "variable declared void"));
        if ty.name.is_null() {
            @if(!expect_var) continue();
            @error_tok(c, ty.name_pos, "variable name omitted");
        };
        
        if attr { attr |
            if attr.is_static {
                // static locals are secretly globals
                var := c.new_anon_gvar(ty, start);
                c.push_scope(c.get_ident(ty.name))[].var = var;
                if consume(tok&, tok, "=") {
                    c.gvar_initializer(tok&, tok, var);
                };
                c.yield(var);
                continue();
            }
        };

        // Generate code for computing a VLA size. We need to do this
        // even if ty is not VLA because ty may be a pointer to VLA
        // (e.g. int (*foo)[n][m] where n and m are variables.)
        vla_size := c.compute_vla_size(ty);

        if ty.kind == .TY_VLA {
            if(equal(tok, "="), => @error_tok(c, tok, "variable-sized object must not be initialized"));

            // Variable length arrays (VLAs) are translated to alloca() calls.
            // For example, `int x[n+2]` is translated to `tmp = n + 2,
            // x = alloca(tmp)`.
            name := c.get_ident(ty.name);
            var := c.new_lvar(name, ty);
            var.stack_slot = c.f.newtmp(name, .Kl);
            c.emit(.alloc16, .Kl, var.stack_slot, vla_size, QbeNull);
            continue();
        };
        
        var := c.new_lvar(c.get_ident(ty.name), ty);
        if attr { attr |
            if attr.align != 0 {
                var.align = attr.align;  // TODO
            };
        };
        
        if consume(tok&, tok, "asm") {
            // :AsmNotYetImplemented
            // musl does like `register long x8 __asm__("x8") = n;` and passes that to inline asm block. 
            // for now just skip it.
            tok = c.skip(tok, "(");
            _constraint := tok.string_value()
                || @error_tok(c, tok, "expected string literal for asm template");
            c.next(tok&, tok);
            tok = c.skip(tok, ")");
        };

        if consume(tok&, tok, "=") {
            c.lvar_initializer(tok&, tok, var);
        };

        if(var.ty.size < 0,         => @error_tok(c, ty.name, "variable has incomplete type"));
        if(var.ty.kind == .TY_VOID, => @error_tok(c, ty.name, "variable declared void"));
    };
    
    tok  // already ate the semicolon
}

fn skip_excess_element(c: *Ctx, tok: *Token) *Token = {
    if consume(tok&, tok, "{") {
        tok = c.skip_excess_element(tok);
        tok = c.skip(tok, "}");
    } else {
        c.parse_expr(tok&, tok, .Assign);
    };
    tok
}

fn string_initializer(c: *Ctx, rest: **Token, tok: *Token, init: *Initializer) void #once = {
    @debug_assert(tok.kind == .TK_STR);
    if init.is_flexible {
        init[] = c.new_initializer(c.array_of(init.ty.base, tok.ty.array_len.intcast()), false)[];
    };

    len := min(init.ty.array_len, tok.ty.array_len);
    @debug_assert(len >= 0);

    // TODO: this is so garbage :SLOW
    slow :: fn($T) => {
        ::ptr_utils(T);
        str := ptr_cast_unchecked(u8, T, tok.val.str_buf);
        range(0, len.intcast()) { i |
            init[i].expr = c.new_num(str.offset(i)[].int(), tok);
        };
    };
    @switch(init.ty.base.size) {
        @case(1) => slow(u8);
        @case(2) => slow(u16);
        @case(4) => slow(u32);
        @default => unreachable();
    };
    
    c.next(rest, tok);
}

// array-designator = "[" const-expr "]"
//
// C99 added the designated initializer to the language, which allows
// programmers to move the "cursor" of an initializer to any element.
// The syntax looks like this:
//
//     int x[10] = { 1, 2, [5]=3, 4, 5, 6, 7 };
//
// `[5]` moves the cursor to the 5th element, so the 5th element of x
// is set to 3. Initialization then continues forward in order, so
// 6th, 7th, 8th and 9th elements are initialized with 4, 5, 6 and 7,
// respectively. Unspecified elements (in this case, 3rd and 4th
// elements) are initialized with zero.
//
// Nesting is allowed, so the following initializer is valid:
//
//     int x[5][10] = { [5][8]=1, 2, 3 };
//
// It sets x[5][8], x[5][9] and x[6][0] to 1, 2 and 3, respectively.
//
// Use `.fieldname` to move the cursor for a struct initializer. E.g.
//
//     struct { int a, b, c; } x = { .c=5 };
//
// The above initializer sets x.c to 5.
fn array_designator(c: *Ctx, rest: **Token, tok: *Token, ty: *CType, is_flexible: bool) Ty(i64, i64) = {  // (begin, end)
    c.next(tok&, tok);
    begin := c.const_expr(tok&, tok);
    if(begin >= ty.array_len.intcast() && !is_flexible, => @error_tok(c, tok, "array designator index (%) exceeds array bounds (%)", begin, ty.array_len));
    
    end := begin;
    if consume(tok&, tok, "...") {
        end = c.const_expr(tok&, tok);
        if(end >= ty.array_len.intcast() && !is_flexible, => @error_tok(c, tok, "array designator index exceeds array bounds"));
        if(end < begin, => @error_tok(c, tok, "array designator range [%d, %d] is empty", begin, end));
    };

    rest[] = c.skip(tok, "]");
    (begin, end)
}

// struct-designator = "." ident
fn struct_designator(c: *Ctx, rest: **Token, tok: *Token, ty: *CType) *Member = {
    start := tok;
    tok = c.skip(tok, ".");
    if(tok.kind != .TK_IDENT, => @error_tok(c, tok, "expected a field designator"));

    for_linked ty.members { mem |
        continue :: local_return;
        is_anon := (@is(mem.ty.kind, .TY_STRUCT, .TY_UNION)) && mem.name.is_null();
        if is_anon {
            if get_struct_member(mem.ty, tok) { _ |
                // :ReWalkTokens
                rest[] = start;
                return(mem);
            };
            continue();
        };

        // Regular struct member
        if mem.name.str() == tok.str() {
            c.next(rest, tok);
            return(mem);
        };
    };

    @error_tok(c, tok, "struct has no such member")
}

// designation = ("[" const-expr "]" | "." ident)* "="? initializer
fn designation(c: *Ctx, rest: **Token, tok: *Token, init: *Initializer) void = {
    if equal(tok, "[") {
        if(init.ty.kind != .TY_ARRAY, => @error_tok(c, tok, "array index in non-array initializer"));

        begin, end := c.array_designator(tok&, tok, init.ty, init.is_flexible);

        //tok2: *Token;  // TODO: sane error message for this!
        tok2 := Token.ptr_from_int(0);
        range(begin, end + 1) { i |
            // :ReWalkTokens
            c.designation(tok2&, tok, init[i]);
        };
        c.array_initializer2(rest, tok2, init, begin + 1);
        return();
    };

    @if(equal(tok, ".")) @match(init.ty.kind) {
        fn TY_STRUCT() => {
            mem := c.struct_designator(tok&, tok, init.ty);
            c.designation(tok&, tok, init.children[mem.idx.intcast()]);
            if equal(tok, ",") {  
                // this happens when they're nested like (T) { .a.b = 1, .c.d = 2, };
                // TODO: im not super confident i could explain why but this seems to work. 
                //       i think we're jsut saying the middle struct can't have other fields until after the comma (which is true syntactically)
                rest[] = tok;
                return()
            }
            init.expr = Node.ptr_from_int(0);
            c.struct_initializer2(rest, tok, init, mem.next);
            return();
        }
        fn TY_UNION() => {
            mem := c.struct_designator(tok&, tok, init.ty);
            init.mem = mem;
            c.designation(rest, tok, init.children[mem.idx.intcast()]);
            return();
        }
        @default => @error_tok(c, tok, "field name not in struct or union initializer"); 
    };
    _ := consume(tok&, tok, "=");
    c.initializer2(rest, tok, init);
}

fn comma_sep(c: *Ctx, tok: **Token, $end: Str, $body: @Fn() void) void = {
    first := true;
    while => !consume_end(tok, end) {
        if !first {
            tok[] = c.skip(tok[], ",");
        };
        first = false;
        body();
    };
}

// array-initializer1 = "{" initializer ("," initializer)* ","? "}"
fn array_initializer1(c: *Ctx, rest: **Token, tok: *Token, init: *Initializer) void = {
    tok = c.skip(tok, "{");

    // An array length can be omitted if an array has an initializer
    // (e.g. `int x[] = {1,2,3}`). If it's omitted, count the number
    // of initializer elements as we go. 
    if init.is_flexible {
        // not to be confused with :StaticArrayOfUnknownLength... this is a different thing, kinda
        init[] = c.new_initializer(c.array_of(init.ty.base, 0), true)[];   
    };

    i := 0;
    comma_sep(c, tok&, "}") {
        continue :: local_return;
        if equal(tok, "[") {
            begin, end := c.array_designator(tok&, tok, init.ty, init.is_flexible);

            tok2 := Token.ptr_from_int(0);
            range(begin, end + 1) { j |
                // :ReWalkTokens
                c.designation(tok2&, tok, init[j]);
            };
            tok = tok2;
            i = end + 1;
            if init.is_flexible {
                init.ty.array_len = max(init.ty.array_len, i.intcast());
            };
            continue();
        };

        if i < init.ty.array_len.intcast() || init.is_flexible {        
            c.initializer2(tok&, tok, init[i]);
        } else {
            tok = c.skip_excess_element(tok);
        };
        i += 1;
        if init.is_flexible {
            init.ty.array_len = max(init.ty.array_len, i.intcast());
        };
    };
    
    rest[] = tok;
}

fn index(self: *Initializer, i: i64) **Initializer = {
    if self.children.len > i {
        @debug_assert(i >= 0);
        return(self.children.index(i));
    };
    @debug_assert(self.ty.kind == .TY_ARRAY && self.is_flexible, "expected flex array");
    self.children&.reserve(i - self.children.len + 1, temp());
    range(self.children.len, i + 1) { _ |
        self.children&.push_assume_capacity(new_initializer(self.ty.base, false));
    };
    self.children.index(i)
}

// array-initializer2 = initializer ("," initializer)*
fn array_initializer2(c: *Ctx, rest: **Token, tok: *Token, init: *Initializer, i: i64) void = {
    first := tok;
    if init.is_flexible {
        // not to be confused with :StaticArrayOfUnknownLength... this is a different thing, kinda
        init[] = c.new_initializer(c.array_of(init.ty.base, 0), true)[];
    };

    while => { i < init.ty.array_len.intcast() || init.is_flexible } && !c.is_end(tok) {
        start := tok;
        if i > 0 {
            tok = c.skip(tok, ",");
        };
        if equal(tok, "[") || equal(tok, ".") {
            // :ReWalkTokens
            rest[] = start;
            if init.is_flexible {
                @debug_assert_eq(init.ty.kind, .TY_ARRAY);
                init.ty.size = init.ty.base.size * init.ty.array_len;
            }
            return();
        };

        c.initializer2(tok&, tok, init[i]);
        i += 1;
        if init.is_flexible {
            init.ty.array_len = max(init.ty.array_len, i.intcast());
        };
    };
    if init.is_flexible {
        @debug_assert_eq(init.ty.kind, .TY_ARRAY);
        init.ty.size = init.ty.base.size * init.ty.array_len;
    }
    rest[] = tok;
}

// struct-initializer1 = "{" initializer ("," initializer)* ","? "}"
fn struct_initializer1(c: *Ctx, rest: **Token, tok: *Token, init: *Initializer) void = {
    tok = c.skip(tok, "{");
    mem := init.ty.members;
    
    if equal(tok, "}") {
        init.all_zeros = true;
        c.next(rest, tok);
        return();
    };

    comma_sep(c, tok&, "}") {
        continue :: local_return;
        if equal(tok, ".") {
            mem = c.struct_designator(tok&, tok, init.ty);
            c.designation(tok&, tok, init[mem.idx.intcast()]);
            mem = mem.next;
            continue();
        };

        if !mem.is_null() {
            c.initializer2(tok&, tok, init[mem.idx.intcast()]);
            mem = mem.next;
        } else {
            tok = c.skip_excess_element(tok);
        }
    };
    rest[] = tok;
}

// struct-initializer2 = initializer ("," initializer)*
fn struct_initializer2(c: *Ctx, rest: **Token, tok: *Token, init: *Initializer, mem: *Member) void = {
    first := true;
    while => !mem.is_null() && !c.is_end(tok) {
        start := tok;
        if !first {
            tok = c.skip(tok, ",");
        };
        first = false;

        if equal(tok, "[") || equal(tok, ".") {
            // :ReWalkTokens
            rest[] = start;
            return();
        };

        c.initializer2(tok&, tok, init[mem.idx.intcast()]);
        mem = mem.next;
    };
    rest[] = tok;
}

fn union_initializer(c: *Ctx, rest: **Token, tok: *Token, init: *Initializer) void = {
    // Unlike structs, union initializers take only one initializer,
    // and that initializes the first union member by default.
    // You can initialize other member using a designated initializer.
    c.lookahead(tok, 1);
    if equal(tok, "{") && equal(tok.next, ".") {
        c.next(tok&, tok);
        mem := c.struct_designator(tok&, tok, init.ty);
        init.mem = mem;
        c.designation(tok&, tok, init[mem.idx.intcast()]);
        rest[] = c.skip(tok, "}");
        return();
    };

    init.mem = init.ty.members;

    if consume(tok&, tok, "{") {
        c.initializer2(tok&, tok, init[0]);
        _ := consume(tok&, tok, ",");
        rest[] = c.skip(tok, "}");
    } else {
        c.initializer2(rest, tok, init[0]);
    };
}

// initializer = string-initializer | array-initializer
//                         | struct-initializer | union-initializer
//                         | assign
fn initializer2(c: *Ctx, rest: **Token, tok: *Token, init: *Initializer) void = @match(init.ty.kind) {
    fn TY_ARRAY() => @if_else {
        @if(tok.kind == .TK_STR) => c.string_initializer(rest, tok, init);
        @if(equal(tok, "{")) => {
            c.lookahead(tok, 3);
            if equal(tok.next.next, "}") && tok.next.kind == .TK_NUM && tok.next.val.i == 0 {
                c.next(tok&, tok);
                c.next(tok&, tok);
                c.next(rest, tok);
                init.all_zeros = true;
                
                if init.ty.kind == .TY_ARRAY && init.ty.array_len == -1 {
                    // :StaticArrayOfUnknownLength 
                    init.ty.array_len = 1;
                }
            } else {
                c.array_initializer1(rest, tok, init);  
            };
        };
        @else => c.array_initializer2(rest, tok, init, 0);
    };
    fn TY_STRUCT() => if equal(tok, "{") {
        c.struct_initializer1(rest, tok, init);
    } else {
        // A struct can be initialized with another struct. E.g.
        // `struct T x = y;` where y is a variable of type `struct T`.
        // Handle that case first.
        expr := c.parse_expr(rest, tok, .Assign);
        c.add_type(expr);
        
        if expr.ty.kind == .TY_STRUCT {
            init.expr = expr;
        } else {
            // :ReWalkTokens
            c.struct_initializer2(rest, tok, init, init.ty.members);
        };
    };
    fn TY_UNION() => if equal(tok, "{") {
        c.union_initializer(rest, tok, init)
    } else {
        // a union initializer list with a single item initializes the first field,
        // but the initializer for a union object with automatic storage duration
        // may be a single expression that has compatible type instead of an initializer list. 
        // and that applies to nested designatied initionaizers like a struct field that's a union. 
        // TODO: only allow if coming from lvar_initializer
        expr := c.parse_expr(rest, tok, .Assign);
        c.add_type(expr);
        
        if expr.ty.kind == .TY_UNION {
            init.expr = expr;
        } else {
            // :ReWalkTokens
            c.union_initializer(rest, tok, init)
        };
    };
    @default => (if consume(tok&, tok, "{") {
        // An initializer for a scalar variable can be surrounded by
        // braces. E.g. `int x = {3};`. Handle that case.
        c.initializer2(tok&, tok, init);
        rest[] = c.skip(tok, "}");
    } else {
        init.expr = c.parse_expr(rest, tok, .Assign);
    }); // TODO: this shouldn't need the extra brackets?
};

fn initializer(c: *Ctx, rest: **Token, tok: *Token, ty: **CType) *Initializer = {
    c.lookahead(tok, 2);
    if ty.kind == .TY_ARRAY && ty.size > 0 && equal(tok, "{") && equal(tok.next.next, "}") && tok.next.kind == .TK_NUM && tok.next.val.i == 0 { 
        init := temp().box_zeroed(Initializer);
        init.ty = ty[];
        init.all_zeros = true;
        c.next(tok&, tok);
        c.next(tok&, tok);
        c.next(rest, tok);
        return(init);
    };
    init := c.new_initializer(ty[], true);
    c.initializer2(rest, tok, init);
    if init.ty.kind == .TY_ARRAY && init.is_flexible {
        init.ty.size = init.ty.base.size * init.ty.array_len;
    };
    // if there was a flexible array member chibicc makes a new type to track the exact size of this instantiation. 
    // but [https://www.sigbus.info/n1570#6.7.2.1p18] "In particular, the size of the structure is as if the flexible 
    // array member were omitted except that it may have more trailing padding than the omission would imply"
    ty[] = init.ty;
    init
}

#where(fn(T) => is_ptr(T) && has_field(Deref(T), @symbol next))
fn end_linked(head: ~T) T = {
    ::ptr_utils(Deref(T));
    while => !head.is_null() && !head.next.is_null() {
        head = head.next;
    };
    head
}

fn init_desg_expr(c: *Ctx, desg: *InitDesg, tok: *Token) *Node = {
    if(!desg.var.is_null(), => return(c.new_var_node(desg.var, tok)));
    
    if !desg.member.is_null() {
        return(c.access_member(c.init_desg_expr(desg.next, tok), desg.member, tok));
    };

    lhs := c.init_desg_expr(desg.next, tok);
    rhs := c.new_num(desg.idx, tok);
    c.new_add(lhs&, rhs&, tok);
    node := c.new_binary2(.ND_ADD, lhs, rhs, tok);
    c.new_deref(node, tok)
}

fn access_member(c: *Ctx, lhs: *Node, mem: *Member, tok: *Token) *Node = {
    node := c.new_node(.ND_MEMBER, tok);
    node.lhs = lhs;
    node.member = mem;
    node.ty = node.member.ty;
    node.lvalue = c.emit(.add, .Kl, node.lhs.lvalue, c.getcon(node.member.offset.intcast()));
    node
}

fn create_lvar_init(c: *Ctx, init: *Initializer, ty: *CType, desg: *InitDesg, tok: *Token) *Node = {
    if ty.kind == .TY_ARRAY {
        node := c.new_node(.ND_NULL_EXPR, tok);
        range(0, ty.array_len.intcast()) { i |
            desg2: InitDesg = (next = desg, idx = i, member = Member.ptr_from_int(0), var = Obj.ptr_from_int(0));
            rhs := c.create_lvar_init(init[i], ty.base, desg2&, tok);
            c.gen_expr(node);
            node = rhs;
        };
        return(node);
    };

    if ty.kind == .TY_STRUCT && init.expr.is_null() {
        node := c.new_node(.ND_NULL_EXPR, tok);

        for_linked ty.members { mem |
            desg2: InitDesg = (next = desg, idx = 0, member = mem, var = Obj.ptr_from_int(0));
            rhs := c.create_lvar_init(init[mem.idx.intcast()], mem.ty, desg2&, tok);
            c.gen_expr(node);
            node = rhs;
        };
        return(node);
    };

    if ty.kind == .TY_UNION && init.expr.is_null() {
        ::if(@type init.mem);
        mem := if(!init.mem.is_null(), => init.mem, => ty.members);
        desg2: InitDesg = (next = desg, idx = 0, member = mem, var = Obj.ptr_from_int(0));
        return(c.create_lvar_init(init[mem.idx.intcast()], mem.ty, desg2&, tok));
    };

    if(init.expr.is_null(), => return(c.new_node(.ND_NULL_EXPR, tok)));

    lhs := c.init_desg_expr(desg, tok);
    c.add_type(lhs);
    ty := c.add_type(.ND_ASSIGN, lhs&, init.expr&);
    c.gen_assign(lhs, c.gen_expr(init.expr), ty)
}

// A variable definition with an initializer is a shorthand notation
// for a variable definition followed by assignments. This function
// generates assignment expressions for an initializer. For example,
// `int x[2][2] = {{6, 7}, {8, 9}}` is converted to the following
// expressions:
//
//     x[0][0] = 6;
//     x[0][1] = 7;
//     x[1][0] = 8;
//     x[1][1] = 9;
fn lvar_initializer(c: *Ctx, rest: **Token, tok: *Token, var: *Obj) *Node = {
    loc := tok;
    init := c.initializer(rest, tok, var.ty&);
    desg := InitDesg.zeroed();
    desg.var = var;
    
    static_array_of_unknown_length := var.stack_slot == QbeNull;  // :StaticArrayOfUnknownLength
    if static_array_of_unknown_length {
        // This ref needs to exist because create_lvar_init will generate offsets from it to store the elements. 
        // (and can't be made in new_lvar like usual because size is unknown until parsing the initializer)
        c.create_stack_slot(var);
    };
    
    // TODO: wasteful in the common case! :SLOW giving the backend a bunch of extra dead stores to remove
    // If a partial initializer list is given, the standard requires
    // that unspecified elements are set to 0. Here, we simply
    // zero-initialize the entire memory region of a variable before
    // initializing it with user-supplied values.
    c.gen_zero_var(var, loc);
    node := c.ir_node(c.ty_void, QbeNull, QbeNull, loc);
    
    if !init.all_zeros {
        rhs := c.create_lvar_init(init, var.ty, desg&, loc);
        c.gen_expr(node);
        node = rhs;
    };
    c.gen_expr(node);
    node
}

// TODO: is alignment real? 
// TODO: if we always made sure the buffer was 8 aligned we could just read/write off the end and mask it because little endian. 
fn read_buf(buf: *u8, sz: i64) i64 = {
    @switch(sz) {
        @case(1) => buf[].zext();
        @case(2) => ptr_cast_unchecked(u8, u16, buf)[].zext();
        @case(4) => ptr_cast_unchecked(u8, u32, buf)[].zext();
        @case(8) => ptr_cast_unchecked(u8, i64, buf)[];
        @default => unreachable();
    }
}

fn write_buf(buf: *u8, val: i64, sz: i64) void = {
    @switch(sz) {
        @case(1) => { buf[] = val.trunc(); };
        @case(2) => { ptr_cast_unchecked(u8, u16, buf)[] = val.trunc(); };
        @case(4) => { ptr_cast_unchecked(u8, u32, buf)[] = val.trunc(); };
        @case(8) => { ptr_cast_unchecked(u8, i64, buf)[] = val; };
        @default => unreachable();
    };
}

fn write_gvar_data(c: *Ctx, cur: *List(Dat2.Reloc), init: *Initializer, ty: *CType, buf: []u8, off: i64) void = {
    ::enum(TypeKind);
    if ty.kind == .TY_ARRAY {
        sz := ty.base.size.intcast();
        @debug_assert_ge(sz, 0, "negative array in write_gvar_data");
        if(init.all_zeros, => return());
        range(0, ty.array_len.intcast()) { i |
            c.write_gvar_data(cur, init[i], ty.base, buf, off + sz * i);
        };
        return();
    };
    if ty.kind == .TY_STRUCT {
        if true {
            break :: local_return;
            for_linked ty.members { mem | 
                if mem.is_bitfield {
                    expr := init[mem.idx.intcast()].expr;
                    ::ptr_utils(Node);
                    if(expr.is_null(), => break());
                    loc      := buf.ptr.offset(off + mem.offset.intcast());
                    oldval   := read_buf(loc, mem.ty.size.intcast());
                    newval   := c.eval(expr);
                    mask     := 1.shift_left(mem.bit_width.intcast()) - 1;
                    combined := oldval.bit_or(newval.bit_and(mask).shift_left(mem.bit_offset.intcast()));
                    @debug_assert_ge(mem.ty.size, 0, "negative size in write_gvar_data");
                    write_buf(loc, combined, mem.ty.size.intcast());
                    @debug_assert_eq(combined, read_buf(loc, mem.ty.size.intcast()), "failed write_buf");
                } else {
                    c.write_gvar_data(cur, init[mem.idx.intcast()], mem.ty, buf, off + mem.offset.intcast());
                };
            };
        };
        if ty.has_flex() {
            child := init[init.children.len - 1];
            c.write_gvar_data(cur, child, child.ty, buf, off + ty.size.intcast());
        };
        
        return();
    };

    if ty.kind == .TY_UNION {
        if(init.mem.is_null(), => return());
        return(c.write_gvar_data(cur, init[init.mem.idx.intcast()], init.mem.ty, buf, off));
    };

    if(init.expr.is_null(), => return());

    if ty.kind == .TY_FLOAT {
        ptr_cast_unchecked(u8, f32, buf.ptr.offset(off))[] = c.eval_double(init.expr).cast();
        return();
    };

    if ty.kind == .TY_DOUBLE {
        ptr_cast_unchecked(u8, f64, buf.ptr.offset(off))[] = c.eval_double(init.expr);
        return();
    };

    val, label := c.eval2(init.expr);

    label := label || {
        @debug_assert_ge(ty.size, 0, "negative size scalar in write_gvar_data");
        write_buf(buf.ptr.offset(off), val, ty.size.intcast());
        return()
    };

    @debug_assert_lt(off, MAX_u32);
    cur.push(
        off = off.trunc(),
        id = label,
        addend = val,
    );
}

fn has_flex(ty: *CType) bool = 
    ty.is_flexible && @is(ty.kind, .TY_STRUCT, .TY_UNION);

// ty.size doesn't count the flexible array member because sizeof is not supposed to include it, 
// but we need to include it when allocating storage for static variables. 
fn size(init: *Initializer) i64 = 
    init.ty.size.intcast() + if(init.ty.has_flex(), => init[init.children.len - 1].size(), => 0);

// Initializers for global variables are evaluated at compile-time and
// embedded to .data section. This function serializes Initializer
// objects to a flat byte array. It is a compile error if an
// initializer list contains a non-constant expression.
fn gvar_initializer(c: *Ctx, rest: **Token, tok: *Token, var: *Obj) void = {
    init := c.initializer(rest, tok, var.ty&);
    if init.all_zeros {
        return();
    };
    
    buf := temp().alloc_zeroed(u8, init.size());
    rel := Dat2.Reloc.list(temp());
    c.write_gvar_data(rel&, init, var.ty, buf, 0);
    var.init_data = buf;
    var.rel = rel.items();
}

fn is_type_name(c: *Ctx, tok: *Token) bool #inline #use(Tokens) = {
    is_type_keyword := tok.kind.raw() >= TokenKind.short.raw() && tok.kind.raw() <= TokenKind.int.raw();
    is_type_keyword || equal(tok, "__attribute__") || c.find_typedef(tok).is_some()
}

fn push_loop(c: *Ctx, $body: @Fn(brk: *Qbe.Blk, cnt: *Qbe.Blk) void) Ty(*Qbe.Blk, *Qbe.Blk) = {
    brk  := c.brk_label;
    cont := c.cont_label;
    brk_label := c.new_block();
    cont_label := c.new_block();
    c.brk_label = (Some = brk_label);
    c.cont_label = (Some = cont_label);

    @must_return body(brk_label, cont_label);
    
    c.brk_label = brk;
    c.cont_label = cont;
    (brk_label, cont_label)
}

// compound-stmt = (typedef | declaration | stmt)* "}"
fn compound_stmt(c: *Ctx, rest: **Token, tok: *Token) *Node = {
    cur: ?*Node = .None;

    c.enter_scope();
    while => !equal(tok, "}") {
        c.lookahead(tok, 1);
        if c.is_type_name(tok) && !equal(tok.next, ":") {
            @if(SPAM) @println("type name! %", tok.str());
            attr   := VarAttr.zeroed();
            basety := c.declspec(tok&, tok, (Some = attr&));
            
            tok = if attr.is_typedef {
                c.parse_typedef(tok, basety)
            } else {
                expect_var := !equal(tok, ";");
                ty := c.declarator(tok&, tok, basety);
                @if_else {
                    // TODO: error if it has a body
                    @if(ty.kind == .TY_FUNC) => c.function(tok, basety, attr&, ty);
                    @if(attr.is_extern)   => c.global_variable(tok, basety, attr&, ty, expect_var);
                    @else => c.declaration(tok, basety, (Some = attr&), ty, expect_var);
                }
            };
        } else {
            cur = (Some = c.stmt(tok&, tok));
        };
        if cur { cur |
            c.add_type(cur);
            c.gen_expr(cur);
        };
    };

    c.leave_scope();

    c.next(rest, tok);
    cur || c.new_node(.ND_NULL_EXPR, tok)
}

// expr-stmt = expr? ";"
fn expr_stmt(c: *Ctx, rest: **Token, tok: *Token) *Node = if equal(tok, ";") {
    c.next(rest, tok);
    c.new_node(.ND_NULL_EXPR, tok)
} else {
    node := c.parse_expr(tok&, tok, .None);
    rest[] = c.skip(tok, ";");
    node
};

// struct-members = (declspec declarator (","    declarator)* ";")*
fn struct_members(c: *Ctx, rest: **Token, tok: *Token, ty: *CType) void = {
    head := Member.zeroed();
    cur  := head&;
    idx  := 0;

    while => !equal(tok, "}") {
        continue :: local_return;
        attr   := VarAttr.zeroed();
        basety := c.declspec(tok&, tok, (Some = attr&));

        is_anon := (@is(basety.kind, .TY_STRUCT, .TY_UNION)) && consume(tok&, tok, ";");
        if is_anon {
            mem := c.arena.box_zeroed(Member);
            mem.tok = tok;
            mem.ty  = basety;
            mem.idx = idx.intcast();
            idx += 1;
            mem.align = if(attr.align != 0, => attr.align, => mem.ty.align);
            cur.next = mem;
            cur = cur.next;
            continue();
        };

        // Regular struct members
        comma_sep(c, tok&, ";") {
            mem := c.arena.box_zeroed(Member);
            mem.tok = tok;
            mem.ty = c.declarator(tok&, tok, basety);
            mem.name = mem.ty.name;
            mem.idx = idx.intcast();
            idx += 1;
            mem.align = if(attr.align != 0, => attr.align, => mem.ty.align);

            if consume(tok&, tok, ":") {
                mem.is_bitfield = true;
                mem.bit_width = c.const_expr(tok&, tok).intcast();
            };
            cur.next = mem;
            cur = cur.next;
        };
    };

    // If the last element is an array of incomplete type, it's
    // called a "flexible array member". It should behave as if
    // if were a zero-sized array.
    ty.is_flexible = !cur.identical(head&) && cur.ty.kind == .TY_ARRAY && cur.ty.array_len < 0; 
    if ty.is_flexible {
        cur.ty = c.array_of(cur.ty.base, 0);
    };

    c.next(rest, tok);
    ty.members = head.next;
}

// struct-union-decl = attribute? ident? ("{" struct-members)?
fn struct_union_decl(c: *Ctx, rest: **Token, tok: *Token) *CType = {
    ty := c.new_type(.TY_STRUCT, 0, 1);
    tok = c.attribute_list(tok, ty);

    // Read a tag.
    tag: ?*Token = .None;
    if tok.kind == .TK_IDENT {
        tag = (Some = tok);
        c.next(tok&, tok);
    };

    if tag { tag |
        if !equal(tok, "{") {
            rest[] = tok;
            if c.find_tag(tag) { ty2 |
                // TODO: wastefully allocated `ty` every time you declare a struct variable
                // TODO: im not copying the attributes here. 
                //       can you have packed/aligned on a use of a type but not its declaration?
                return(ty2);
            };
            ty.size = -1;
            c.push_tag_scope(tag, ty);
            return(ty);
        }
    };

    tok = c.skip(tok, "{");

    // Construct a struct object.
    c.struct_members(tok&, tok, ty);
    rest[] = c.attribute_list(tok, ty);

    if tag { tag |
        // If this is a redefinition, overwrite a previous type.
        // Otherwise, register the struct type.
        if get(c.scope.tags&, tag.str()) { ty2 |
            ty2[] = ty[];
            return(ty2);
        };

        c.push_tag_scope(tag, ty);
    };

    ty
}

// struct-decl = struct-union-decl
fn struct_decl(c: *Ctx, rest: **Token, tok: *Token) *CType = {
    ty := c.struct_union_decl(rest, tok);
    ty.kind = .TY_STRUCT;
    // -1 means it's an incomplete forward declaration. 
    if(ty.size < 0, => return(ty));
    c.struct_layout(ty);
    ty
}

fn struct_layout(c: *Ctx, ty: *CType) void = {
    // Assign offsets within the struct to members.
    bits := 0;
    for_linked ty.members { mem |
        if mem.is_bitfield {
            if mem.ty.is_atomic {
                @error_tok(c, mem.tok, "the type backing a bitfield cannot be _Atomic");
            };
            if mem.bit_width == 0 {
                // [https://www.sigbus.info/n1570#6.7.2.1p12]
                // "As a special case, a bit-field structure member with a width of 0 indicates 
                // that no further bit-field is to be packed into the unit in which the previous 
                // bit-field, if any, was placed."
                bits = align_to(bits, mem.ty.size.intcast() * 8);
            } else {
                sz := mem.ty.size.intcast();
                unaligned := (bits / (sz * 8)) != (bits + mem.bit_width.intcast() - 1) / (sz * 8);
                if unaligned {
                    bits = align_to(bits, sz * 8);
                };
                mem.offset = align_down(bits / 8, sz).intcast();
                mem.bit_offset = bits.mod(sz * 8).intcast();
                bits += mem.bit_width.intcast();
            };
        } else {
            if !ty.is_packed {
                bits = align_to(bits, mem.align.intcast() * 8);
            };
            mem.offset = bits.intcast() / 8;
            bits += mem.ty.size.intcast() * 8;
        };

        if !ty.is_packed && ty.align < mem.align {
            ty.align = mem.align;
        };
    };

    ty.size = align_to(bits, ty.align.intcast() * 8).intcast() / 8;
}

// union-decl = struct-union-decl
fn union_decl(c: *Ctx, rest: **Token, tok: *Token) *CType = {
    ty := c.struct_union_decl(rest, tok);
    ty.kind = .TY_UNION;
    if(ty.size < 0, => return(ty));

    // If union, we don't have to assign offsets because they
    // are already initialized to zero. We need to compute the
    // alignment and the size though.
    for_linked ty.members { mem |
        ty.align = max(ty.align, mem.align);
        ty.size  = max(ty.size, mem.ty.size);
    };
    ty.size = align_to(ty.size.intcast(), ty.align.intcast()).intcast();
    ty
}

fn paren_typename(c: *Ctx, rest: **Token, tok: *Token) ?*CType = {
    c.lookahead(tok, 2);
    if equal(tok.next, "(") && c.is_type_name(tok.next.next) {
        c.next(tok&, tok);
        c.next(tok&, tok);
        ty := c.typename(tok&, tok);
        rest[] = c.skip(tok, ")");
        return(Some = ty);
    };
    .None
}

fn parse_typedef(c: *Ctx, tok: *Token, basety: *CType) *Token = {
    comma_sep(c, tok&, ";") {
        ty := c.declarator(tok&, tok, basety);
        if(ty.name.is_null(), => @error_tok(c, ty.name_pos, "typedef name omitted"));
        if !equal(tok, ";") && !equal(tok, ",") {
            @error_tok(c, ty.name_pos, "invalid type after 'typedef'");
        };
        c.push_scope(c.get_ident(ty.name))[].type_def = ty;
    };
    tok
}

Attributes :: @struct {
    packed := false;
    // TODO: needs backend support to put them in the magic elf section
    constructor := false;
    weak := false;
    hidden := false;  // TODO: do people use internal/protected visibility?
    align: ?i64 = .None;
    alias: ?*Token = .None;
};

fn attribute_list(c: *Ctx, tok: *Token, ty: *CType) *Token = {
    it := attribute_list(c, tok&, tok);
    c.apply(ty, it&);
    tok
}

fn apply(c: *Ctx, ty: *CType, it: *Attributes) void = {
    if it.packed {
        ty.is_packed = true;
    }
    if it.align { align |
        ty.align = align.intcast();
    }
    // TODO: is it an error to put symbol specific ones on a type? 
    //       or do they just fall over to the symbol if its a declaration?
}

AttrName :: @enum(
    packed,
    aligned,
    weak,
    alias,
    visibility,
    constructor,
    format, 
    const,
    noreturn, 
    deprecated,
    may_alias,
    _,
);

fn attribute(s: Str) AttrName = {
    if s.starts_with("__") && s.ends_with("__") && s.len > 4 {
        s = s.slice(2, s.len - 2); 
    }
    contextual_keyword(s, AttrName)
}

fn attribute_list(c: *Ctx, rest: **Token, tok: *Token) Attributes = {    
    result: Attributes = ();
    while => consume(tok&, tok, "__attribute__") {
        tok = c.skip(tok, "(");
        tok = c.skip(tok, "(");

        comma_sep(c, tok&, ")") {
            tok = c.one_attribute(tok, result&);
        };

        tok = c.skip(tok, ")");
    };

    rest[] = tok;
    result
}

fn one_attribute(c: *Ctx, tok: *Token, result: *Attributes) *Token #once = {
    ::enum(AttrName);
    kind := tok.str().attribute();
    
    str_arg :: fn($yield: @Fn(s: Str) void) => {
        tok = c.skip(tok, "(");
        yield(tok.string_value() 
            || @error_tok(c, tok, "expected string for %", kind));
        c.next(tok&, tok);
        tok = c.skip(tok, ")");
    };

    start := tok;
    c.next(tok&, tok);
    @match(kind) {
        fn _() => @error_tok(c, start, "unknown attribute");
        fn packed() => {
            result.packed = true;
        }
        fn weak() => {
            result.weak = true;
        }
        fn alias() => str_arg { _ |
            result.alias = (Some = tok);
        };
        fn visibility() => str_arg { vis |
            if vis == "hidden" {
                // :AttributesNotYetImplemented
                result.hidden = true;
            } else {
                @error_tok(c, tok, "unknown visibility attribute: %", vis);
            };
        };
        fn constructor() => {
            // :AttributesNotYetImplemented
            result.constructor = true;
        }
        fn aligned() => {
            tok = c.skip(tok, "(");
            result.align = (Some = c.const_expr(tok&, tok));
            tok = c.skip(tok, ")");
        }
        @default => {
            tok = c.skip_attribute(tok);
        };
    };
    tok
}

fn skip_attribute(c: *Ctx, tok: *Token) *Token #once = {
    if(equal(tok, ")"), => return(tok));
    if(equal(tok, ","), => return(tok));
    n := 0;
    dowhile {
        n -= int equal(tok, ")");
        n += int equal(tok, "(");
        c.next(tok&, tok);
        n > 0 && tok.kind != .TK_EOF
    };
    tok
}

fn parse_symbol_attributes(c: *Ctx, rest: **Token, tok: *Token, obj: *Obj) void = {
    if consume(tok&, tok, "asm") {
        tok = c.asm_alias(tok, obj);
    };
    
    if equal(tok, "__attribute__") {
        // TODO: clearly you're allowed it before the type as well, so like it has to be part of VarAttr,
        //      but idk if its supposed to be inherited when you have multiple declarations with commas.
        //      and idk how you decide if it does on the symbol or the type, 
        //      maybe the attrs that apply to them just never overlap so it's not ambigous, you just can't give an error message when something doesn't make sense. 
        it := c.attribute_list(tok&, tok);
        
        obj.is_weak = it.weak;
        if it.alias { target_tok |
            target_name := target_tok.string_value().unwrap();
            target := c.find_var(target_name) 
                || @error_tok(c, target_tok, "alias to undefined var %", target_name);
            target := target.var;
            
            @debug_assert(!obj.yielded);
            obj.yielded = true;
            if c.emitter { ctx |
                // TODO: not using the vtable thing (c'enqueue_task) makes this compile slower.
                enter_task ctx { entry | 
                    lnk := temp().boxed(Qbe.Lnk, (
                        id = obj.global_symbol.unwrap(),
                        export = !obj.is_static,
                    ));
                    entry.task = (Bounce = (lnk = lnk, target = target.global_symbol.unwrap()));
                };
            };
        };
    };
    
    // :XXXX otherwise linker doesn't get them from the static archive...
    use_symbol(c.m, obj.global_symbol.unwrap()) { s |
        s.strong = !obj.is_weak;
    };
    
    rest[] = tok;
}

// these are different:
// - asm alias: the symbol name does not match the source name but there's only one symbol. 
// - attribute alias: two symbols are made that point to the same place. 
//      - clang doesn't allow on macos?
fn asm_alias(c: *Ctx, tok: *Token, obj: *Obj) *Token = {
    // `asm("foo")` after a forward declaration means `#[link_name = "foo"]`. 
    tok = c.skip(tok, "(");
    alias := tok.string_value() 
        || @error_tok(c, tok, "expected a string (treating asm keyword after function as symbol alias)");
    c.next(tok&, tok);
    tok = c.skip(tok, ")");
    obj.global_symbol = (Some = c.m.intern(alias));
    tok
}

fn find_func(c: *Ctx, tok: *Token) ?*Obj = {
    it := c.find_var(tok) || return(.None);
    @debug_assert(!it.var.is_null(), tok.str());
    (Some = it.var)
}

fn function(c: *Ctx, tok: *Token, basety: *CType, attr: *VarAttr, ty: *CType) *Token = {
    t := ty.name_pos;
    if(ty.name.is_null(), => @error_tok(c, tok, "function name omitted"));
    name_str := c.get_ident(ty.name);
    
    @debug_assert(identical(ty.name, ty.name_pos));  // todo: confusing to have two things
    f := if c.find_func(ty.name) { f |
        if(!f.is_function,                     => @error_tok(c, t, "redeclared as a different kind of symbol"));
        if(f.is_definition && equal(tok, "{"), => @error_tok(c, t, "redefinition of function '%'", name_str));
        // note: the other way around is legal. forward declare as static and then define without saying static again will be treated as static. 
        if(!f.is_static && attr.is_static,     => @error_tok(c, t, "static declaration follows a non-static declaration"));
        f
    } else {
        is_static := attr.is_static || (attr.is_inline && !attr.is_extern);
        f := c.new_gvar(name_str, ty, t, is_static);
        f.is_function = true;
        f.is_inline = attr.is_inline;
        f
    };
    
    c.parse_symbol_attributes(tok&, tok, f);
    
    if consume(tok&, tok, ";") {
        f.is_definition = false;
        return(tok);
    };

    if equal(tok, ",") {
        f.is_definition = false;
        tok = c.skip(tok, ",");
        ty := c.declarator(tok&, tok, basety);
        return c.global_variable(tok, basety, attr, ty, true);
    };
    depth := c.scope_depth;
    // TODO: hoist this from emit_one()
//    ctx := c.emitter.unwrap();
//    entry := bouba_acquire(ctx);
//    c.function_entry = (Some = entry);
//push_dynamic_context {
//        set_temporary_allocator entry.arena&;
    f.is_definition = true;
    c.current_fn = (Some = f);
    
    c.init_function(temp());
    c.f.lnk.id = f.global_symbol.expect("mangle");
    c.f.lnk.export = !f.is_static;
    //c.speculate = false;
    c.f.rpo = new(1);
    c.b = c.f.start;
    
    c.labels = init(temp());
    c.locals = ptr_from_int(@type c.locals[], 0);
    c.enter_scope();
    c.f.vararg = ty.is_variadic;
    rty := ty.return_ty;
    c.f.retty = c.ir_index(rty);
    if rty.kind != .TY_VOID {
        c.f.ret_cls = @if(c.f.retty != Qbe.Null, .Ke, rty.cls());
    };
    
    tok = c.skip(tok, "{");

    f_name := str(as_cstr f.name);  // TODO: SLOW LSOW SLOW :SLOW 
    f_name.len += 1;  // null terminator
    
    // TODO: this `ty` is not the same as `obj.ty` because it `obj.ty` might be from a forward declaration
    //       with different parameter names, and we store those names in the type, which is silly. 
    //       TODO: make a simpler test for this than the lua interpreter
    c.gen_par(ty);
    
    // TODO: we are doing extra work for every single function to support a feature that is rarely used. that's not what you want. 
    //       detect it after failing a name lookup instead and just add it then? 
    
    // [https://www.sigbus.info/n1570#6.4.2.2p1] "__func__" is
    // automatically defined as a local variable containing the
    // current function name.
    name_var := c.new_string_literal(f_name, c.array_of(c.ty_char, f_name.len), tok);
    c.push_scope("__func__")[].var = name_var;
    
    // [GNU] __FUNCTION__ is yet another name of __func__.
    c.push_scope("__FUNCTION__")[].var = name_var;
    
    _ := c.compound_stmt(tok&, tok);
    if c.b.jmp.type == .Jxxx {
        c.b.jmp = @if_else {
            // void functions are allowed to just fall off the end
            @if(rty.is_void())    => (type = .ret0, arg = QbeNull);
            // for main() falling off the end is legal and means returning 0
            @if(f.name == "main") => (type = .retw, arg = QbeConZero);
            // it would be nice to give an error otherwise but it's non-trivial to decide if this codepath is reachable. 
            // TODO: does the spec say i have to just give you garbage or is it ub that lets me crash?
            @else                 => (type = .hlt, arg = QbeNull);
        };
    };
    
    c.f.set_link_from_rpo();
    f.f = c.f;
    
    c.leave_scope();
    c.current_fn = .None;
    c.franca_env = QbeNull;
    c.f = Qbe.Fn.ptr_from_int(0);
    c.yield(f);
//};
    @debug_assert_eq(depth, c.scope_depth);
    tok
}

fn init_function(c: *Ctx, a: Alloc) void = {
    c.f = a.box_uninit(Qbe.Fn);
    c.f.default_init(c.m);
    // todo: f.con is still in tmp which is kinda not what you want for the toplevel one
    
    c.consts = a.box_zeroed(@type c.consts[]);
    c.consts[] = init(a);
    c.cache_con01&[0] = Qbe.ConZero;
    c.cache_con01&[1] = c.f.getcon(1);
    ::if false {  // garbage garbage garbage. enabling import_module caching changes the order and im not order independent
        getcon(zeroed(*Ctx), zeroed Qbe.Con);
    }
    for c.f.con.slice(0, c.f.ncon.zext()) { cc |
        c.consts.insert(cc, c.f.newcon(cc&));
    };
    c.f.track_ir_names = c.m.debug != 0;
}

fn global_variable(c: *Ctx, tok: *Token, basety: *CType, attr: *VarAttr, first_declarator: *CType, expect_var: bool) *Token = {
    declarators(c, tok&, basety, first_declarator) { ty |
        continue :: local_return;
        if ty.name.is_null() {
            @if(!expect_var) continue();
            @error_tok(c, ty.name_pos, "variable name omitted");
        };
        
        prev_is_tentative   := false;
        prev_is_definition := false;
        prev := c.find_var(ty.name_pos);
        prev_var := Obj.ptr_from_int(0);
        if prev { prev |
            ::ptr_utils(@type prev.var[]);
            if !prev.var.is_null() {
                prev_var = prev.var;
                prev_is_tentative = prev.var.is_tentative;
                prev_is_definition = prev.var.is_definition;
            }
        }
        
        var := prev_var;
        if var.is_null() {
            var = c.new_gvar(c.get_ident(ty.name), ty, ty.name_pos, attr.is_static);
        } else {
            if var.is_static != attr.is_static {
                @warn_tok(c, var.tok, "forward declared here");
                @error_tok(c, ty.name_pos, "static-ness must match forward declaration");
            };
        };
        var.is_definition = !attr.is_extern;
        var.is_tls = attr.is_tls;
        if attr.align > 0 {
            var.align = attr.align;  // TODO: needs backend support
        };
        
        c.parse_symbol_attributes(tok&, tok, var);
        
        if equal(tok, "=") {
            if(attr.is_extern, => @error_tok(c, tok, "extern symbol with a value doesn't make any sense?"));
            if(ty.kind == .TY_FUNC, => @error_tok(c, tok, "function can't be declared with '='"));
            c.next(tok&, tok);
            c.gvar_initializer(tok&, tok, var);
        } else {
            var.is_definition = false;
            if ty.kind == .TY_FUNC {
                var.is_function = true;
                continue();
            };
            var.is_tentative = var.is_tentative || (!attr.is_extern && !attr.is_tls);
        };
        
        if var.is_tentative {
            if prev_is_definition || prev_is_tentative {
                continue(); 
            };
            if !prev_is_tentative {  // might be filled later
                c.tentative&.insert(var.name, var);  
            };
        } else {
            if prev_is_tentative {  // the old definition refers to the new variable
                c.tentative&.remove(var.name);
            };
            @if(!attr.is_extern) c.yield(var);
        };
    };
    tok
}

fn declare_builtin_functions(c: *Ctx) void = {
    ty := c.func_type(c.pointer_to(c.ty_void));
    ty.params = c.arena.alloc_init(*CType, 1, fn(_) => c.ty_int);
    c.builtin_alloca = c.new_gvar("alloca", ty, zeroed(*Token), false); // TODO: this is trash
    c.builtin_alloca.is_definition = false;
    c.builtin_alloca.is_function = true;
}

discard_static_scope :: fn(c: *Ctx) void = {
    hack := c.scope;
    sc := hack.end_linked();
    retain sc.vars.raw& { k, v |
        v.var.is_null() || !v.var.is_static
    };
}

// program = (typedef | function-definition | global-variable)*
fn parse(c: *Ctx, tok: *Token) *Obj = {
    c.declare_builtin_functions();
    //c.speculate = true;
    ::if(*Token);
    while => tok.kind != .TK_EOF {
        continue :: local_return;
        @match(tok.kind) {
        fn TK_discard_static_scope() => {
            c.discard_static_scope();
            c.next(tok&, tok);
            continue();
        };
        fn TK_FRC() => {
            f :: import("@/examples/import_c/ffi.fr").import_cache_file;
            c.f(tok);
            c.next(tok&, tok);
            continue();
        };
        fn _Static_assert() => {
            tok = c.static_assert(tok);
            continue();
        }
        fn asm() => {
            // :AsmNotYetImplemented
            c.next(tok&, tok);
            tok = c.skip(tok, "(");
            tok = c.skip(tok, "TK_STR");
            tok = c.skip(tok, ")");
            continue();
        }
        @default => ();
        };
        
        attr := VarAttr.zeroed();
        basety := c.declspec(tok&, tok, (Some = attr&));
        tok = if attr.is_typedef {
            c.parse_typedef(tok, basety)
        } else {
            expect_var := !equal(tok, ";");
            ty := c.declarator(tok&, tok, basety);
            ::enum(@type ty.kind);
            if ty.kind == .TY_FUNC {
                prev_c := c.consts;
                prev := c.f;   // :TopLevelFunction
                tok := c.function(tok, basety, attr&, ty);
                c.f = prev;
                c.consts = prev_c;
                c.b = c.f.start; // HACK
                tok
            } else {
                c.global_variable(tok, basety, attr&, ty, expect_var)
            }
        };
        
        // TODO: reset temp() here? but then if want to delay adding functions to the module, 
        //       need to have them not in temp(), or copy them out at the end. 
    };

    each c.tentative& { name, var |
        c.yield(var[]);
    };
    c.tentative&.clear();
    
    c.globals
}

fn static_assert(c: *Ctx, tok: *Token) *Token = {
    c.next(tok&, tok);
    tok = c.skip(tok, "(");
    cond := c.const_expr(tok&, tok);
    msg := "";
    if consume(tok&, tok, ",") {
        msg = tok.string_value() || tok.str();
        c.next(tok&, tok);
    };
    if cond == 0 {
        @error_tok(c, tok, "static assertion failed %", msg);
    };
    tok = c.skip(tok, ")");
    tok
}

/**************************
*   Parsing Expressions   *
**************************/

Prec :: @enum(i32) (
    Invalid,
    Stmt,
    None, 
    Comma,
    Assign, 
    Conditional,  // ?:
    LogOr, LogAnd, 
    BitOr, BitXor, BitAnd, 
    Equality, Relational, 
    Shift, Term, Factor, 
    Unary, PostFix, Primary,
);

N1: ParseFn1 : fn(c, b, t) = @error_tok(c, t, "unexpected (prefix) token %", t.str()); 
N2: ParseFn2 : fn(c, b, t, d) = @error_tok(c, t, "unexpected (infix) token %", t.str()); 
ParseFn1   :: @FnPtr(c: *Ctx, rest: **Token, tok: *Token) *Node;
ParseFn2   :: @FnPtr(c: *Ctx, rest: **Token, tok: *Token, node: *Node) *Node;
ParseRule :: @struct(prefix: ParseFn1 = N1, infix: ParseFn2 = N2, prec := Prec.Invalid, op := NodeKind.ND_INVALID);

RulesTable :: import("@/lib/collections/enum_map.fr")'EnumMap(Tokens.TokenKind, ParseRule);
rules :: @static RulesTable;

// not just a '::' here because it needs to happen after the dylib is initilized or we think there are missing functions. 
fn comptime_init_rules_table() void #use(Tokens) = {
    h := rules;
    each h { k, v |
        v[] = ();
    };
    
    ::if(*Node);
    ::enum(NodeKind);
    ::enum(Prec);
    ::enum(TypeKind);
    ::ptr_utils(Scope);
    ::if(*CType); 
    
    binary := @slice(@as(Ty(TokenKind, Prec, NodeKind))
        (.@"+", .Term,   .ND_INVALID),
        (.@"-", .Term,   .ND_INVALID),
        (.@"*", .Factor, .ND_MUL),
        (.@"/", .Factor, .ND_DIV),
        (.@"%", .Factor, .ND_MOD),
        (.@"|", .BitOr,  .ND_BITOR),
        (.@"^", .BitXor, .ND_BITXOR),
        (.@"&", .BitAnd, .ND_BITAND),
        (.@">>", .Shift, .ND_SHR),
        (.@"<<", .Shift, .ND_SHL),
        
        (.@"+=", .Assign,  .ND_INVALID),
        (.@"-=", .Assign,  .ND_INVALID),
        (.@"*=", .Assign,  .ND_MUL),
        (.@"/=", .Assign,  .ND_DIV),
        (.@"%=", .Assign,  .ND_MOD),
        (.@"|=", .Assign,  .ND_BITOR),
        (.@"^=", .Assign,  .ND_BITXOR),
        (.@"&=", .Assign,  .ND_BITAND),
        (.@">>=", .Assign, .ND_SHR),
        (.@"<<=", .Assign, .ND_SHL),
        
        (.@"==", .Equality,   .ND_EQ),
        (.@"!=", .Equality,   .ND_NE),
        (.@">=", .Relational, .ND_LE), // ND_GE
        (.@">", .Relational,  .ND_LT), // ND_GT
        (.@"<=", .Relational, .ND_LE),
        (.@"<", .Relational,  .ND_LT),
        
        (.@",", .Comma,  .ND_INVALID),
        (.@"=", .Assign, .ND_ASSIGN),
    );
    each binary { it |
        h[it._0] = (infix = parse_binary, prec = it._1, op = it._2);
    };
    
    s := scope_of(Type, parsers);
    names := get_constants(s);
    for names { name |
        fid := get_constant(FuncId, s, name).unwrap();
        func := get_function_ast(fid, true, false, false, false);
        each func.annotations { ann |
            continue :: local_return;
            args := ann.args&.items();
            keyword := const_eval(TokenKind)(args[0]);
            rule := h[keyword]&;
            ::?ParseFn2; ::?ParseFn1;
            op_index := @switch(ann.name) {
                @case(@symbol prefix) => {
                    rule.prefix = get_constant(ParseFn1, s, name).unwrap();
                    1
                };
                @case(@symbol infix) => {
                    rule.infix = get_constant(ParseFn2, s, name).unwrap();
                    new := const_eval(Prec)(args[1]);
                    @assert(rule.prec == .Invalid, "multiple precedences for % (% vs %)", keyword, rule.prec, new);
                    rule.prec = new;
                    2
                };
                @default => continue();
            };
            if args.len > op_index {
                new := const_eval(NodeKind)(args[op_index]);
                @assert(rule.op == .ND_INVALID, "multiple operations for % (% vs %)", keyword, rule.op, new);
                rule.op = new;
            };
        };
    };
};

fn parse_expr(c: *Ctx, rest: **Token, tok: *Token, prec: Prec) *Node = {
    @if(SPAM) @println("Prefix: % %", tok.str(), tok.kind);

    ::comptime_init_rules_table();
    rules := rules;  // TODO: shouldn't need to do this but otherwise if can't call the function ?? 
    rule := rules.index(tok.kind);
    node := (rule.prefix)(c, tok&, tok);
    c.gen_expr(node);
    ::enum(@type prec);
    rule := rules.index(tok.kind);
    while => prec.raw() <= rule.prec.raw() {
        @if(SPAM) @println("Infix: % %", tok.str(), tok.kind);
        hack := tok.kind == .@":";
        node = (rule.infix)(c, tok&, tok, node);
        if hack {
            prec = .Primary; // HACK
        };
        rule = rules.index(tok.kind);
        c.gen_expr(node);
    };
    rest[] = tok;
    @if(SPAM) @println("End Expression: % % %", tok.str(), tok.kind, node.kind);
    c.gen_expr(node);
    node
}

fn parse_binary(c: *Ctx, rest: **Token, tok: *Token, lhs: *Node) *Node = {
    node := c.parse_binary_inner(rest, tok, lhs);
    c.gen_expr(node);
    node
}

fn parse_binary_inner(c: *Ctx, rest: **Token, tok: *Token, lhs: *Node) *Node = {
    rule := rules.index(tok.kind);
    prec := rule.prec;
    
    // assignment is right associative. everything else is left. 
    // you can work out why this works on a whiteboard. or you can just trust that this trick works. 
    if prec != .Assign {
        prec = @as(Prec) @as(i32) prec.raw() + 1;  
    }; 
    
    c.lookahead(tok, 1);
    rhs  := parse_expr(c, rest, tok.next, prec);
    @match(tok.kind) {
        fn @"+="()  => {
            c.new_add(lhs&, rhs&, tok);
            node := c.to_assign(.ND_ADD, lhs, rhs, tok);
            return(node);
        }
        fn @"-="()  => {
            node := c.new_sub(lhs, rhs, tok);
            if node.lhs.kind == .ND_CAST {
                node.lhs = node.lhs.lhs;  // HACK. fixes short x[1]; x[0] -= 1; 
            };
            node := c.to_assign(node.kind, node.lhs, node.rhs, node.tok);
            return(node);
        }
        fn @"+"()   => {
            c.new_add(lhs&, rhs&, tok);
            return(c.new_binary2(.ND_ADD, lhs, rhs, tok));
        }
        fn @"-"()   => return(c.new_sub(lhs, rhs, tok));
        @default    => ();
    };
    
    needs_flip := @is(tok.kind, .@">=", .@">");
    if needs_flip { // TODO: just have ops for this. 
        t := lhs; lhs = rhs; rhs = t; 
    };
    is_update_assign := @is(tok.kind, .@"*=", .@"/=", .@"%=", .@"&=", .@"|=", .@"^=", .@"<<=", .@">>=");
    node := if is_update_assign {
        c.to_assign(rule.op, lhs, rhs, tok)
    } else {
        if tok.kind == .@"=" {
            c.add_type(lhs);
            c.add_type(rhs);
            check_types(c, tok, lhs.ty, rhs.ty);
            ty := c.add_type(.ND_ASSIGN, lhs&, rhs&);
            val := c.gen_expr(rhs);
            return(c.gen_assign(lhs, val, ty));
        };
        if tok.kind != .@"," {
            c.new_binary2(rule.op, lhs, rhs, tok)
        } else {
            c.gen_expr(lhs);
            rhs
        }
    };
    node
}

::if(*Node);

// if immediately jumping on a value that's already <= 32 bits, don't insert an extra comparison. 
fn cast_cond(c: *Ctx, cond: *Node) *Node = {
    small := @is(cond.ty.kind, .TY_BOOL, .TY_CHAR, .TY_SHORT, .TY_INT, .TY_ENUM);
    if !small {
        // jnz only looks at low 32 bits but we might be jumping on a long 
        // (or a float)
        cond = c.new_cast(cond, c.ty_bool);
    } else {
        @debug_assert_le(cond.ty.size, 4);
    }
    cond
}

fn lookahead(c: *Ctx, tok: *Token, n: i64) void = {
    
}

fn next(c: *Ctx, rest: **Token, tok: *Token) void = {
    c.lookahead(tok, 1);
    rest[] = tok.next;
}

parsers :: @struct {
// TODO: less dumb ir for if conditions
// short-circuiting, output is always 0 or 1
#infix(.@"||", .LogOr, .ND_BITOR) #infix(.@"&&", .LogAnd, .ND_BITAND) 
parse_logical :: fn(c, rest, tok, cond) = {
    rule := rules.index(tok.kind);
    fold_op := rule.op;
    cond := c.cast_cond(cond);
    
    else_block := c.new_block();
    join_block := c.new_block();
    
    prev_block := c.b;
    ::enum(Qbe.J);
    need_jump := prev_block.jmp.type == .Jxxx && !c.speculate;
    if need_jump {
        r := c.gen_expr(cond);
        prev_block.jmp = (type = .jnz, arg = r);
    };
    
    c.b = else_block; 
    c.lookahead(tok, 1);
    rhs  := parse_expr(c, rest, tok.next, @as(Prec) @as(i32) rule.prec.raw() + 1);
    rhs  := c.new_cast(rhs, c.ty_bool);  // not cast_cond (need to force the value to be 0/1)
    else_block_end := c.b;
    then, else, s1, s2, phi1, phi2 := @match(tok.kind) {
        fn @"&&"() => (rhs, c.new_num(0, tok), else_block, join_block, else_block_end, prev_block);
        fn @"||"() => (c.new_num(1, tok), rhs, join_block, else_block, prev_block, else_block_end);
        @default   => unreachable();
    };
    
    c.jmp_if_unterminated(join_block);
    if need_jump {
        prev_block.s1 = s1;
        prev_block.s2 = s2;
    };
    
    c.b = join_block;

    r := if rtype(cond.r) == .RCon && rtype(rhs.r) == .RCon {
        cond := c.new_cast(cond, c.ty_bool);  // not cast_cond
        // :FrontendConstantFolding 
        c.gen_binary(fold_op, cond.r, rhs.r, c.ty_bool, c.ty_bool, tok)
    } else {
        if !c.speculate {
            p := new_phi(c.f, join_block, .Kw, 2);
            p.push(phi1, then.r);
            p.push(phi2, else.r);
            p.to
        } else {
            QbeNull
        }
    };
    
    // not ty_bool, _Generic can observe the difference
    c.ir_node(c.ty_int, r, QbeNull, tok)
};

// the ternary operator
conditional :: fn(c, rest, tok, cond) #infix(.@"?", .Conditional) = {
    // note: the [GNU] case below still uses the old `cond` node without this cast. 
    original_cond := c.gen_expr(cond);
    cond_r := c.gen_expr(c.cast_cond(cond));
    if(!c.speculate && cond_r == QbeNull, => @error_tok(c, cond.tok, "ICE: failed to compile condition"));
    
    cond_block := c.b;
    then_block := c.new_block();
    else_block := c.new_block();
    join_block := c.new_block();
    
    ::if(Ty(*CType, *Qbe.Blk, Qbe.Ref, Qbe.Ref));
    c.next(tok&, tok);
    ty, then_phi_src, then_r, else_r := if consume(tok&, tok, ":") {
        // [GNU] Compile `a ?: b` as `tmp = a, tmp ? tmp : b`.
        then_block = join_block;
        then := c.ir_node(cond.ty, original_cond, QbeNull, tok);
        c.b = else_block;
        else := c.parse_expr(rest, tok, .Conditional);
        ty := c.add_type(.ND_COND, then&, else&);
        (ty, cond_block, then.r, else.r)
    } else {
        c.b = then_block;
        then := c.parse_expr(tok&, tok, .None);
        then_phi_src := c.b;
        c.jmp_if_unterminated(join_block);
        tok = c.skip(tok, ":");
        c.b = else_block;
        else := c.parse_expr(rest, tok, .Conditional);
        ty   := c.add_type(.ND_COND, then&, else&);
        (ty, then_phi_src, then.r, else.r)
    };
    else_phi_src := c.b;
    c.jmp_if_unterminated(join_block);
    c.b = cond_block;
    c.jnz_if_unterminated(cond_r, then_block, else_block);
    c.b = join_block;
    
    r := if rtype(cond_r) == .RCon {  
        // :FrontendConstantFolding (only matters if the values are RCon too)
        is_false := iscon(c.f.get_constant(cond_r), false, 0);
        if cond_block.jmp.type == .jnz {
            cond_block.jmp = (type = .jmp, arg = Qbe.Null);
            if is_false {
                cond_block.s1 = cond_block.s2;
            };
            cond_block.s2 = Qbe.Blk.ptr_from_int(0);
        };
        if(is_false, => else_r, => then_r)
    } else {
        if !c.speculate {
            p := new_phi(c.f, join_block, ty.cls(), 2);
            p.push(then_phi_src, then_r);
            p.push(else_phi_src, else_r);
            p.to
        } else {
            QbeNull
        }
    };
    lvalue := if(@is(ty.kind, .TY_STRUCT, .TY_UNION), => r, => QbeNull);
    node := c.ir_node(ty, r, lvalue, tok);
    node.current_block = join_block; // this makes a cast from the result go to the right place (when gen_expr gets called again by our caller)
    node
};

parse_bracketed :: fn(c, rest, tok) #prefix(.@"(") = {
    start := tok;
    tok = c.skip(tok, "(");
    node := if c.is_type_name(tok) {
        ty := c.typename(tok&, tok);
        tok = c.skip(tok, ")");

        is_compound_literal := equal(tok, "{");
        if is_compound_literal {
            if c.scope.next.is_null() {  // global
                var := c.new_anon_gvar(ty, tok);
                c.gvar_initializer(rest, tok, var);
                c.yield(var);
                c.new_var_node(var, start)
            } else {  // local
                var := c.new_lvar("", ty);
                lhs := c.lvar_initializer(rest, tok, var);
                rhs := c.new_var_node(var, tok);
                c.gen_expr(lhs);
                rhs
            }
        } else {  // type cast
            node := parse_expr(c, rest, tok, .Unary);
            node := c.new_cast_force(node, ty);
            node.tok = start;
            node
        }
    } else {
        node := if consume(tok&, tok, "{") {
            // This is a [GNU] statement expresssion.
            node := c.compound_stmt(tok&, tok);
            ::ptr_utils(@type node.ty[]);
            //@if(node.ty.is_null() || node.ty.kind == .TY_VOID)
            //@error_tok(c, node.tok, "statement expression returning void is not supported");
            node
        } else {
            // just a braketed expression like in math
            parse_expr(c, tok&, tok, .None)
        };
        rest[] = c.skip(tok, ")");
        node
    };
    c.gen_expr(node);
    node
};

label :: fn(c, rest, tok, prev) #infix(.@":", .Stmt) = {
    // :LabelAsInfix
    if !@is(prev.kind, .ND_VAR, .ND_STMT) {
        @error_tok(c, tok, "treating infix ':' as a label but the expression on the left was not an indentifier");
    };
    unique_label := c.get_block(prev.tok.str());
    c.jmp_if_unterminated(unique_label);
    c.b = unique_label;
    c.next(tok&, tok);
    c.stmt(rest, tok)
};

parse_ident :: fn(c, rest, tok) #prefix(.TK_IDENT) = {
    // Variable or enum constant
    sc := c.find_var(tok);
    start := tok;
    c.next(rest, tok);
    // For "static inline" function  // TODO: what? explain
    ::ptr_utils(Obj);
    ::?*Obj;
    if sc { sc |
        if !sc.var.is_null() {
            var := sc.var;
            node := c.new_var_node(var, start);
            node.ty = var.ty;
            return(node);
        };
        ::ptr_utils(@type sc.enum_ty[]);
        if(!sc.enum_ty.is_null(), => return(c.new_num(sc.enum_val, start)));
    };

    tok = rest[];
    if(equal(tok, "("), => @error_tok(c, start, "implicit declaration of a function (%)", start.str()));
    if equal(tok, ":") {
        // :LabelAsInfix
        // might be a label: the colon will be treated as an infix operator
        // this case can't skip the var lookup tho because of `a?b:c;`, from here we can't tell that b is not a label.
        node := c.new_node(.ND_STMT, start);
        // Undef makes sure gen_expr/gen_addr skip it
        node.r = QbeUndef;
        node.lvalue = QbeUndef;
        node.ty = c.ty_int;  // HACK: without this, it crashes on `"" + a` when a is undeclared 
        return(node);
    };  
    @error_tok(c, start, "undefined variable: '%'", start.str())
};

parse_string :: fn(c, rest, tok) #prefix(.TK_STR) = {
    s := tok.c_string_value().unwrap();
    var := c.new_string_literal(s, tok.ty, tok);
    node := c.new_var_node(var, tok);
    c.gen_expr(node);
    c.next(rest, tok);
    node
};

parse_number :: fn(c, rest, tok) #prefix(.TK_NUM) = {
    // could be a float or an int. backend just cares about the bits. 
    node := c.new_num(tok.val.i, tok, tok.ty);
    c.next(rest, tok);
    node
};

unary_plus :: fn(c, rest, tok) #prefix(.@"+") = {
    c.next(tok&, tok);
    c.parse_expr(rest, tok, .Unary)
}

unary_amp :: fn(c, rest, tok) #prefix(.@"&") = {
    start := tok;
    c.next(tok&, tok);
    lhs := c.parse_expr(rest, tok, .Unary);
    if lhs.kind == .ND_MEMBER && lhs.member.is_bitfield {
        @error_tok(c, start, "cannot take address of bitfield");
    };
    c.new_addr(lhs, start)
};

unary_star :: fn(c, rest, tok) #prefix(.@"*") = {
    start := tok;
    c.next(tok&, tok);
    // TODO: im not totally convinced this is right. 
    //       but it makes `*&""` work (which is something TCC does)
    if consume(tok&, tok, "&") {
        return(c.parse_expr(rest, tok, .Unary));
    };
    
    // [https://www.sigbus.info/n1570#6.5.3.2p4] This is an oddity
    // in the C spec, but dereferencing a function shouldn't do
    // anything. If foo is a function, `*foo`, `**foo` or `*****foo`
    // are all equivalent to just `foo`.
    node := c.parse_expr(rest, tok, .Unary);
    node := if(node.ty.kind == .TY_FUNC, => node, => c.new_deref(node, start));
    c.gen_expr(node);
    node
};

#prefix(.@"-", .ND_NEG) #prefix(.@"~", .ND_BITNOT) #prefix(.@"!", .ND_NOT) 
parse_unary :: fn(c, rest, tok) = {
    rule := rules.index(tok.kind);
    start := tok;
    c.next(tok&, tok);
    lhs := c.parse_expr(rest, tok, .Unary);
    ty := @match(rule.op) {
        fn ND_NEG() => {
            ty := c.get_common_type(c.ty_int, lhs.ty);
            lhs = c.new_cast(lhs, ty);
            ty
        }
        fn ND_BITNOT() => @if(lhs.ty.size < 4, c.ty_int, lhs.ty);
        fn ND_NOT()    => c.ty_int;
        @default => lhs.ty;
    };
    arg := c.gen_expr(lhs);
    r := @match(rule.op) {
        fn ND_NEG()    => c.emit(.neg, ty.cls(), arg, QbeNull);
        fn ND_BITNOT() => c.emit(.xor, ty.cls(), arg, c.getcon(-1));
        fn ND_NOT()    => {  // TODO: do the trick with redirecting jump targets to emit better code when this is in an if condition. 
            // not just xor with 1 bit. it might not be a _Bool. 
            op_eq := cmp_base(lhs.ty.cls());
            c.emit(op_eq, .Kw, arg, QbeConZero)
        }
        @default => unreachable();
    };
    c.ir_node(ty, r, QbeNull, start)
};

pre_inc :: fn(c, rest, tok) #prefix(.@"++") = { // Read ++i as i+=1
    rhs := c.new_num(1, tok);
    c.next(tok&, tok);
    lhs := c.parse_expr(rest, tok, .Unary);
    c.new_add(lhs&, rhs&, rhs.tok);
    node := c.to_assign(.ND_ADD, lhs, rhs, rhs.tok);
    c.gen_expr(node);
    node
};

pre_dec :: fn(c, rest, tok) #prefix(.@"--") = { // Read --i as i-=1
    c.next(tok&, tok);
    node := c.new_sub(c.parse_expr(rest, tok, .Unary), c.new_num(1, tok), tok);
    if node.lhs.kind == .ND_CAST {
        node.lhs = node.lhs.lhs;  // HACK. 
    };
    node := c.to_assign(node.kind, node.lhs, node.rhs, node.tok);
    c.gen_expr(node);
    node
};

// generic-selection = "(" assign "," generic-assoc ("," generic-assoc)* ")"
//
// generic-assoc = type-name ":" assign
//                             | "default" ":" assign
//
// This is just a switch statement over types. 
// A branch is chosen based on the ~type~ of the first expression. 
generic_selection :: fn(c, rest, tok) #prefix(._Generic) = {
    start := tok;
    c.next(tok&, tok);
    tok = c.skip(tok, "(");

    ctrl := c.speculate(tok&, tok, .Assign, false);
    c.add_type(ctrl);

    t1 := ctrl.ty;
    t1 := @match(t1.kind) {
        fn TY_FUNC()  => c.pointer_to(t1);
        fn TY_ARRAY() => c.pointer_to(t1.base);
        @default => t1;
    };
    
    // Now choose one of the branches to use based on that type. 
    ret: ?*Node = .None;
    use_default := false; 
    while => !consume(tok&, tok, ")") {
        tok = c.skip(tok, ",");

        if consume(tok&, tok, "default") {
            tok = c.skip(tok, ":");
            node := c.speculate(tok&, tok, .Assign, false);
            if ret.is_none() {
                ret = (Some = node);
                use_default = true;
            };
        } else {
            t2 := c.typename(tok&, tok);
            tok = c.skip(tok, ":");
            done := ret.is_some() && !use_default;
            if is_compatible(t1, t2) && /* wrong */ !done {
                if done {
                    // :BrokenCGeneric
                    // TODO: this should be an error but cosmo wants to do `signed long` and `signed long long` in stdchdint.h
                    //       and i don't track those as seperate types currently. 
                    // @error_tok(c, tok, "conflicting branches for generic association type");  
                };
                node := c.parse_expr(tok&, tok, .Assign);
                ret = (Some = node);
                use_default = false;
            } else {
                _ := c.speculate(tok&, tok, .Assign, false);
            };
        };
    };
    node := ret || @error_tok(c, start, "controlling expression type not compatible with any generic association type");
    if use_default {
        // HACK: because default might not be the last case. 
        // this relies on gen_expr recursing. better would be to 
        // emit default into a different branch and discard the other one
        c.gen_expr(node);
    };
    rest[] = tok;
    node
};

sizeof :: fn(c, rest, tok) #prefix(.sizeof) = {
    start := tok;
    ty := c.paren_typename(rest, tok) || {
        c.next(tok&, tok);
        node := c.speculate(rest, tok, .Unary, false);
        if(node.kind == .ND_MEMBER && node.member.is_bitfield, => @error_tok(c, tok, "sizeof(bitfield) is illegal"));
        node.ty
    };
    r := if(ty.kind == .TY_VLA, => c.compute_vla_size(ty), => c.getcon(ty.size.intcast()));
    c.ir_node(c.ty_ulong, r, QbeNull, start)
};

alignof :: fn(c, rest, tok) #prefix(._Alignof) = {
    start := tok;
    ty := c.paren_typename(rest, tok) || {
        c.next(tok&, tok);
        c.speculate(rest, tok, .Unary, false)[].ty
    };
    c.new_ulong(ty.align.intcast(), start)
};

prefix_ampamp :: fn(c, rest, tok) #prefix(.@"&&") = {
    c.next(tok&, tok);
    label := c.get_ident(tok);
    @error_tok(c, tok, "[GNU] labels-as-values is not supported (name = %)", label);
};

// funcall = (assign ("," assign)*)? ")"
funcall :: fn(c, rest, tok, f) #infix(.@"(", .PostFix) = {
    start := tok;
    c.next(tok&, tok);
    c.add_type(f);

    if (f.ty.kind != .TY_FUNC && (f.ty.kind != .TY_PTR || f.ty.base.kind != .TY_FUNC)) {
        @error_tok(c, f.tok, "not a function");
    };

    ty := if(f.ty.kind == .TY_FUNC, => f.ty, => f.ty.base);

    param_i := 0;
    args := list(*Node, temp());
    comma_sep(c, tok&, ")") {
        arg := c.parse_expr(tok&, tok, .Assign);
        
        if param_i < ty.params.len {
            param_ty := ty.params[param_i];
            param_i += 1;
            if !@is(param_ty.kind, .TY_STRUCT, .TY_UNION) {
                arg = c.new_cast(arg, param_ty);
            };
        } else {
            if !ty.is_variadic {
                if ty.no_prototype {
                    // not an error because musl's __syscall_cp_c does this. -- Oct 5
                    // not the same as variadic! ub if callee is actually variadic. 
                    @warn_tok(c, tok, "too many arguments (callee does not have a prototype)");
                } else {
                    @error_tok(c, tok, "too many arguments");
                }
            };
            // "default argument promotions" when parameter type is omitted (e.g. in "..."). 
            // These are defined by the C spec, not the individual abis. 
            if arg.ty.kind == .TY_FLOAT {
                arg = c.new_cast(arg, c.ty_double);
            };
            if @is(arg.ty.kind, .TY_BOOL, .TY_CHAR, .TY_SHORT) {
                arg = c.new_cast(arg, c.ty_int);
            }
        };
        args&.push(arg);
    };

    if(param_i < ty.params.len, => @error_tok(c, tok, "too few arguments"));
    rest[] = tok;

    c.gen_call(f, ty, args.items(), start)
};

square :: fn(c, rest, tok, node) #infix(.@"[", .PostFix) = {
    // x[y] is short for *(x+y)
    start := tok;
    c.next(tok&, tok);
    idx := c.parse_expr(tok&, tok, .None);
    c.new_add(node&, idx&, start);
    node := c.new_binary2(.ND_ADD, node, idx, start);
    c.gen_expr(node);
    node := c.new_deref(node, start);
    set_rest_and_gen(c, rest, c.skip(tok, "]"), node)
};
dot :: fn(c, rest, tok, node) #infix(.@".", .PostFix) = {
    c.next(tok&, tok);
    node := c.struct_ref(node, tok);
    c.next(tok&, tok);
    set_rest_and_gen(c, rest, tok, node)
};
arrow :: fn(c, rest, tok, node) #infix(.@"->", .PostFix) = {
    // x->y is short for (*x).y
    node := c.new_deref(node, tok);
    c.next(tok&, tok);
    node := c.struct_ref(node, tok);
    c.next(tok&, tok);
    set_rest_and_gen(c, rest, tok, node)
};
post_inc :: fn(c, rest, tok, node) #infix(.@"++", .PostFix) = {
    node := c.new_inc_dec(node, tok, 1);
    c.next(tok&, tok);
    set_rest_and_gen(c, rest, tok, node)
};
post_dec :: fn(c, rest, tok, node) #infix(.@"--", .PostFix) = {
    node := c.new_inc_dec(node, tok, -1);
    c.next(tok&, tok);
    set_rest_and_gen(c, rest, tok, node)
};

va_start :: fn(c, rest, tok) #prefix(.__builtin_va_start) = {
    start := tok;
    c.next(tok&, tok);
    tok = c.skip(tok, "(");
    ap := c.parse_expr(tok&, tok, .Assign);
    ap := c.new_addr(ap, tok);
    if consume(tok&, tok, ",") {
        // for compatibility, allow a second argument (last named parameter)
        tok = c.skip(tok, "TK_IDENT");
    }
    rest[] = c.skip(tok, ")");
    r := c.gen_expr(ap);
    c.emit(.vastart, .Kw, QbeNull, r, QbeNull);
    c.ir_node(c.ty_int, QbeConZero, QbeNull, start)
};
va_arg :: fn(c, rest, tok) #prefix(.__builtin_va_arg) = {
    start := tok;
    c.next(tok&, tok);
    tok = c.skip(tok, "(");
    ap := c.parse_expr(tok&, tok, .Assign);
    ap := c.new_addr(ap, tok);
    tok = c.skip(tok, ",");
    type := c.typename(tok&, tok);
    rest[] = c.skip(tok, ")");
    ap := c.gen_expr(ap);
    r := c.emit(.vaarg, type.cls(), ap, QbeNull);
    c.ir_node(type, r, QbeNull, start)
};
compatible :: fn(c, rest, tok) #prefix(.__builtin_types_compatible_p) = {
    start := tok;
    c.next(tok&, tok);
    tok = c.skip(tok, "(");
    t1 := c.typename(tok&, tok);
    tok = c.skip(tok, ",");
    t2 := c.typename(tok&, tok);
    rest[] = c.skip(tok, ")");
    c.new_num(is_compatible(t1, t2).int(), start)
};

return :: fn(c, rest, tok) #prefix(.return, .ND_STMT) = {
    current_fn := c.current_fn || @error_tok(c, tok, "stray return");
    ty := current_fn.ty.return_ty;
    ::if(Ty(Qbe.Ref, Qbe.J));
    c.next(tok&, tok);
    r, j := if !consume(rest, tok, ";") {
        exp := c.parse_expr(tok&, tok, .None);
        rest[] = c.skip(tok, ";");
    
        c.add_type(exp);
        
        if !@is(ty.kind, .TY_STRUCT, .TY_UNION) {
            exp = c.new_cast(exp, ty);
        };
        r := c.assert_gen_expr(exp);
          
        ::enum(Qbe.J);
        k := ty.cls(); // TODO: retc
        j := k.retk(); // TODO: also sb,etc.
        if c.f.retty != QbeNull {
            j = .retc;
        };
        (r, j)
    } else {
        (QbeNull, Qbe.J.ret0)
    };
    if c.b.jmp.type == .Jxxx && !c.speculate {
        c.b.jmp = (type = j, arg = r);
    };
    c.new_node(.ND_STMT, tok)
};
if_ :: fn(c, rest, tok) #prefix(.if, .ND_STMT) = {
    c.next(tok&, tok);
    tok = c.skip(tok, "(");
    cond := c.parse_expr(tok&, tok, .None);
    cond := c.assert_gen_expr(c.cast_cond(cond));
    tok = c.skip(tok, ")");
    
        then_block := c.new_block();
        else_block := c.new_block();
        join_block := c.new_block();

        c.jnz_if_unterminated(cond, then_block, else_block);
        
        c.b = then_block;
        c.stmt(tok&, tok);
        c.jmp_if_unterminated(join_block);
        
        c.b = else_block;
        if consume(tok&, tok, "else") {
            c.stmt(tok&, tok);
        };
        c.jmp_if_unterminated(join_block);
        
        c.b = join_block;

    rest[] = tok;
    c.new_node(.ND_STMT, tok)
};
switch_ :: fn(c, rest, tok) #prefix(.switch, .ND_STMT) = {
    payload := temp().box_zeroed(Qbe.SwitchPayload);
    c.next(tok&, tok);
    tok = c.skip(tok, "(");
    cond := c.parse_expr(tok&, tok, .None);
    tok = c.skip(tok, ")");
    //cond := c.new_cast(cond, ty_long);
    payload.inspect = c.assert_gen_expr(cond);
    // TODO :WrongSwitchCast
    // there should be no conversion here and the constant case values should be cast to cond.ty
    // but the backend needs 64 bits
    if cond.ty.cls() != .Kl && !c.speculate {
        r := c.f.newtmp("c", .Kl);
        c.emit(.extsw, .Kl, r, payload.inspect, QbeNull);
        payload.inspect = r;
    };
    payload.src = c.b;
    payload.cases = new(0);
    
    ::enum(Qbe.J);
    if payload.src.jmp.type == .Jxxx && !c.speculate {
        payload.src.jmp.type = .switch;
    };

    sw := c.current_switch;
    c.current_switch = (Some = payload);
    brk := c.brk_label;
    brk_label := c.new_block(); 
    c.brk_label = (Some = brk_label);

    c.b = c.new_block();  // TODO: should be redundant
    c.stmt(rest, tok);
    c.jmp_if_unterminated(brk_label);
    c.current_switch = sw;
    c.brk_label = brk;
    c.b = brk_label;
    ::ptr_utils(@type payload.default[]);
    if payload.default.is_null() {
        payload.default = brk_label;
    };
    
    if payload.src.jmp.type == .switch {
        payload.src.jmp.arg = INT(c.f.switch_count.zext());
        if c.f.switch_count == 0 {
            c.f.switches = new(1);
        };
        push(c.f.switches&, c.f.switch_count&, payload[]);
    };
    c.new_node(.ND_STMT, tok)
};
case :: fn(c, rest, tok) #prefix(.case, .ND_STMT) = {
    unique_label := c.new_block();
    c.jmp_if_unterminated(unique_label);
    c.b = unique_label;
    current_switch := c.current_switch || @error_tok(c, tok, "stray case");
    
    // TODO :WrongSwitchCast
    c.next(tok&, tok);
    begin := c.const_expr(tok&, tok);
    begin: u32 = begin.trunc();
    begin: i32 = begin.bitcast();
    begin: i64 = begin.intcast();

    if consume(tok&, tok, "...") {
        end := c.const_expr(tok&, tok);
        if(end < begin, => @error_tok(c, tok, "empty case range specified"));
        @error_tok(c, tok, "[GNU] Case ranges are not supported (% ... %)", begin, end);
    };

    tok = c.skip(tok, ":");
    c.stmt(rest, tok);
    push(current_switch.cases&, current_switch.case_count&, (unique_label, begin));
    
    next_block := c.new_block();  // TODO: wasteful, empty block for consecutive cases. 
    c.jmp_if_unterminated(next_block);
    c.b = next_block;
    c.new_node(.ND_STMT, tok)
};
default :: fn(c, rest, tok) #prefix(.default, .ND_STMT) = {
    unique_label := c.new_block();
    c.jmp_if_unterminated(unique_label);
    c.b = unique_label;
    current_switch := c.current_switch || @error_tok(c, tok, "stray default");
    
    c.next(tok&, tok);
    tok = c.skip(tok, ":");
    c.stmt(rest, tok);
    current_switch.default = unique_label;
    
    next_block := c.new_block();
    c.jmp_if_unterminated(next_block);
    c.b = next_block;
    c.new_node(.ND_STMT, tok)
};
for_ :: fn(c, rest, tok) #prefix(.for, .ND_STMT) = {
    _, _ := push_loop c { brk_label, cont_label |
        cond_block := c.new_block();
        body_block := c.new_block();
        
        c.enter_scope();
        c.next(tok&, tok);
        tok = c.skip(tok, "(");
        if c.is_type_name(tok) {
            basety := c.declspec(tok&, tok, .None);
            expect_var := !equal(tok, ";");
            ty := c.declarator(tok&, tok, basety);
            tok = c.declaration(tok, basety, .None, ty, expect_var);
        } else {
            c.expr_stmt(tok&, tok);
        };
        c.jmp_if_unterminated(cond_block);

        c.b = cond_block;
        cond := if !equal(tok, ";") {
            c.cast_cond(c.parse_expr(tok&, tok, .None))
        } else {
            c.new_num(1, tok)  // wasteful to rely on folding for this 
        };
        cond := c.assert_gen_expr(cond);
        tok = c.skip(tok, ";");
        
        c.jnz_if_unterminated(cond, body_block, brk_label);

        c.b = cont_label;
        inc := if !equal(tok, ")") {
            c.parse_expr(tok&, tok, .None)
        } else {
            c.new_num(0, tok)  // nop
        };
        tok = c.skip(tok, ")");
        c.jmp_if_unterminated(cond_block);

        c.b = body_block;
        c.stmt(rest, tok);
        c.jmp_if_unterminated(cont_label);

        c.leave_scope();
        c.b = brk_label;
    };
    c.new_node(.ND_STMT, tok)
};
while_ :: fn(c, rest, tok) #prefix(.while, .ND_STMT) = {
    push_loop c { brk_label, cont_label |
        c.jmp_if_unterminated(cont_label);
        c.b = cont_label;
        c.next(tok&, tok);
        tok = c.skip(tok, "(");
        cond := c.cast_cond(c.parse_expr(tok&, tok, .None));
        cond := c.assert_gen_expr(cond);
        tok = c.skip(tok, ")");
        body_block := c.new_block();

        c.jnz_if_unterminated(cond, body_block, brk_label);
        
        c.b = body_block;
        c.stmt(rest, tok);
        c.jmp_if_unterminated(cont_label);
        c.b = brk_label;
    };
    c.new_node(.ND_STMT, tok)
};
do :: fn(c, rest, tok) #prefix(.do, .ND_STMT) = {
    body_block := c.new_block();
    c.jmp_if_unterminated(body_block);
    brk_label, cont_label := push_loop c { _, _ |
        c.b = body_block;
        tok = c.skip(tok, "do");
        c.stmt(tok&, tok);
    };
    c.jmp_if_unterminated(cont_label);  // goto condition
    
    c.b = cont_label;  
    tok = c.skip(tok, "while");
    tok = c.skip(tok, "(");
    cond := c.new_cast(c.parse_expr(tok&, tok, .None), c.ty_bool);
    cond := c.assert_gen_expr(cond);
    tok = c.skip(tok, ")");
    rest[] = c.skip(tok, ";");
    
    c.jnz_if_unterminated(cond, body_block, brk_label);
    c.b = brk_label;
    c.new_node(.ND_STMT, tok)
};
asm :: fn(c, rest, tok) #prefix(.asm, .ND_STMT) = {
    // :AsmNotYetImplemented
    // for now just parse it and hope the function isn't actually called. 
    c.next(tok&, tok);
    dowhile {
        ignore(tok&, tok, @const_slice("volatile", "inline"))
    };
    tok = c.skip(tok, "(");
    template := tok.string_value()
        || @error_tok(c, tok, "expected string literal for asm template");
    c.next(tok&, tok);
    
    // eat gnu extended assembly 
    while => consume(tok&, tok, ":") {
        dowhile {
            if tok.string_value() { _constraint |
                c.next(tok&, tok);
                if consume(tok&, tok, "(") {
                    c.speculate(tok&, tok, .None, false);
                    tok = c.skip(tok, ")");
                }
            };
            consume(tok&, tok, ",")
        }
    };
    
    rest[] = c.skip(tok, ")");
    if template != "" {
        @warn_tok(c, tok, "asm stmt is not supported");
        if !c.f.is_null() {
            c.b.jmp.type = .hlt;
            c.b = c.new_block();
        };
    }
    // TODO: else when its just used as a memory barrier, should insert a no_inline=true call to keep that semantic
    c.new_node(.ND_STMT, tok)
    
};
goto :: fn(c, rest, tok) #prefix(.goto, .ND_STMT) = {
    c.next(tok&, tok);
    if consume(tok&, tok, "*") {
        _dest := c.parse_expr(tok&, tok, .None);
        @error_tok(c, tok, "[GNU] labels-as-values is not supported (goto *ptr)");
    };

    unique_label := c.get_block(c.get_ident(tok));
    c.jmp_if_unterminated(unique_label);
    c.next(tok&, tok);
    rest[] = c.skip(tok, ";");
    c.b = c.new_block();
    c.new_node(.ND_STMT, tok)
};
break :: fn(c, rest, tok) #prefix(.break, .ND_STMT) = {
    brk_label := c.brk_label || @error_tok(c, tok, "stray break");
    unique_label := brk_label;
    c.next(tok&, tok);
    rest[] = c.skip(tok, ";");
    c.jmp_if_unterminated(brk_label);
    c.b = c.new_block();
    c.new_node(.ND_STMT, tok)
};
continue :: fn(c, rest, tok) #prefix(.continue, .ND_STMT) = {
    cont_label := c.cont_label || @error_tok(c, tok, "stray continue");
    unique_label := cont_label;
    c.next(tok&, tok);
    rest[] = c.skip(tok, ";");
    c.jmp_if_unterminated(cont_label);
    c.b = c.new_block();
    c.new_node(.ND_STMT, tok)
};
block :: fn(c, rest, tok) #prefix(.@"{", .ND_STMT) = {
    c.next(tok&, tok);
    c.compound_stmt(rest, tok);
    c.new_node(.ND_STMT, tok)
};
empty_stmt :: fn(c, rest, tok) #prefix(.@";", .ND_STMT) = {
    c.next(rest, tok);
    c.new_node(.ND_STMT, tok)
};
_Static_assert :: fn(c, rest, tok) #prefix(._Static_assert, .ND_STMT) = {
    rest[] = c.static_assert(tok);
    c.new_node(.ND_STMT, tok)
};

};

fn set_rest_and_gen(c: *Ctx, rest: **Token, tok: *Token, node: *Node) *Node = {
    rest[] = tok;
    c.gen_expr(node);
    node
}

fn stmt(c: *Ctx, rest: **Token, tok: *Token) *Node = {
    rule := rules.index(tok.kind);
    if rule.op == .ND_STMT {
        node := (rule.prefix)(c, rest, tok);
        @debug_assert(node.rhs.is_null() && node.lhs.is_null() && node.member.is_null());
        node.tok = tok;
        node
    } else {
        node := c.parse_expr(rest, tok, .Stmt);
        _ := consume(rest, rest[], ";");
        node
    }
}

// In C, `+` operator is overloaded to perform the pointer arithmetic.
// If p is a pointer, p+n adds not n but sizeof(*p)*n to the value of p,
// so that p+n points to the location n elements (not bytes) ahead of p.
// In other words, we need to scale an integer value before adding to a
// pointer value. This function takes care of the scaling.
// 
// This coerces the arguments. You still have to actually create the add later. 
fn new_add(c: *Ctx, lhs: **Node, rhs: **Node, tok: *Token) void = {
    //c.add_type(lhs);
    //c.add_type(rhs);
    c.gen_expr(lhs[]);
    c.gen_expr(rhs[]);

    // num + num
    if is_numeric(lhs.ty) && is_numeric(rhs.ty) {
        return();
    };

    if !lhs.ty.base.is_null() && !rhs.ty.base.is_null() {
        @error_tok(c, tok, "invalid operands");
    };

    // Canonicalize `num + ptr` to `ptr + num`.
    if lhs.ty.base.is_null() && !rhs.ty.base.is_null() {
        t := lhs[]; lhs[] = rhs[]; rhs[] = t;
    };

    if lhs.ty.base.is_null() {
        @error_tok(c, tok, "neither side of subscript is a pointer or array");
    };
    
    // VLA + num
    if lhs.ty.base.kind == .TY_VLA {
        vla_size := c.ir_node(c.ty_ulong, lhs.ty.base.vla_size, QbeNull, tok);
        rhs[] = c.new_binary2(.ND_MUL, rhs[], vla_size, tok);
        return();
    };

    // ptr + num
    rhs[] = c.new_binary2(.ND_MUL, rhs[], c.new_long(lhs.ty.base.size.intcast(), tok), tok);
}

fn new_binary2(c: *Ctx, kind: NodeKind, lhs: *Node, rhs: *Node, tok: *Token) *Node = {
    out_ty := c.add_type(kind, lhs&, rhs&);
    if c.speculate {
        node := c.new_binary(kind, lhs, rhs, tok);
        node.ty = out_ty;
        return(node);
    };
    c.gen_expr(lhs);
    c.gen_expr(rhs);
    @debug_assert(lhs.r != QbeNull && rhs.r != QbeNull, "new_binary missing evaluated args");
    r := c.gen_binary(kind, lhs.r, rhs.r, out_ty, lhs.ty, tok);
    c.ir_node(out_ty, r, QbeNull, tok)
}

// Like `+`, `-` is overloaded for the pointer type.
fn new_sub(c: *Ctx, lhs: *Node, rhs: *Node, tok: *Token) *Node = {
    @if_else {
        // num - num
        @if(is_numeric(lhs.ty) && is_numeric(rhs.ty)) => {
            node := c.new_binary(.ND_SUB, lhs, rhs, tok);
            c.gen_expr(node);
            node
        };
        // VLA - num
        @if(lhs.ty.base.kind == .TY_VLA) => {
            vla_size := c.ir_node(c.ty_ulong, lhs.ty.base.vla_size, QbeNull, tok);
            rhs = c.new_binary2(.ND_MUL, rhs, vla_size, tok);
            node := c.new_binary(.ND_SUB, lhs, rhs, tok);
            node.ty = lhs.ty;
            c.gen_expr(node);
            node
        };
        // ptr - num
        @if(!lhs.ty.base.is_null() && is_integer(rhs.ty)) => {
            rhs = c.new_binary2(.ND_MUL, rhs, c.new_long(lhs.ty.base.size.intcast(), tok), tok);
            node := c.new_binary(.ND_SUB, lhs, rhs, tok);
            node.ty = lhs.ty;
            c.gen_expr(node);
            node
        };
        // ptr - ptr, which returns how many elements are between the two.
        @if(!lhs.ty.base.is_null() && !rhs.ty.base.is_null()) => {
            node := c.new_binary(.ND_SUB, lhs, rhs, tok);
            node.ty = c.ty_long;
            node := c.new_binary(.ND_DIV, node, c.new_num(lhs.ty.base.size.intcast(), tok), tok);
            c.gen_expr(node);
            node
        };
        @else => @error_tok(c, tok, "invalid operands");
    }
};

fn get_struct_member(ty: *CType, name: *Token) ?*Member = {
    for_linked ty.members { mem |
        is_anon := (@is(mem.ty.kind, .TY_STRUCT, .TY_UNION)) && mem.name.is_null();
        if is_anon {
            if get_struct_member(mem.ty, name) { _ |
                return(Some = mem);
            };
        } else {
            if(mem.name.str() == name.str(), => return(Some = mem));
        };
    };
    .None
}

// Create a node representing a struct member access, such as foo.bar
// where foo is a struct and bar is a member name.
//
// C has a feature called "anonymous struct" which allows a struct to
// have another unnamed struct as a member like this:
//
//     struct { struct { int a; }; int b; } x;
//
// The members of an anonymous struct belong to the outer struct's
// member namespace. Therefore, in the above example, you can access
// member "a" of the anonymous struct as "x.a".
//
// This function takes care of anonymous structs.
fn struct_ref(c: *Ctx, node: *Node, tok: *Token) *Node = {
    c.add_type(node);
    ty := node.ty;
    has_fields := @is(ty.kind, .TY_STRUCT, .TY_UNION);
    if(!has_fields, => @error_tok(c, node.tok, "not a struct nor a union (%, %)", node.kind, ty.kind));
    loop {
        mem := get_struct_member(ty, tok) || @error_tok(c, tok, "no such member");
        node = c.access_member(node, mem, tok);
        if(!mem.name.is_null(), => return(node));
        ty = mem.ty;
    }
}

// Convert A++ to `(typeof A)((A += 1) - 1)`
fn new_inc_dec(c: *Ctx, node: *Node, tok: *Token, addend: i64) *Node = {
    c.add_type(node);
    rhs := c.new_num(addend, tok);
    c.new_add(node&, rhs&, tok);
    nn := c.to_assign(.ND_ADD, node, rhs, tok);
    nnn := c.new_num(-addend, tok);
    c.new_add(nn&, nnn&, tok);
    nnnn := c.new_binary2(.ND_ADD, nn, nnn, tok);
    c.new_cast(nnnn, node.ty)
}

// for expressions that don't get evaluated (like sizeof, alignof, typeof),
// we just mask out all the emitted instructions/jumps. 
fn speculate(c: *Ctx, rest: **Token, tok: *Token, prec: Prec, is_stmt: bool) *Node = {
    old_block := c.b;
    prev := c.speculate;
    c.speculate = true;
    c.b = c.new_block();
    node := if is_stmt {
        c.stmt(rest, tok)
    } else {
        c.parse_expr(rest, tok, prec)
    };
    c.speculate = prev;
    c.b = old_block;
    c.add_type(node);
    node
}

fn eval(c: *Ctx, node: *Node) i64 = {
    off, label := c.eval2(node);
    if label.is_some() {
        @error_tok(c, node.tok, "expected a numeric constant");
    };
    off
}

// Evaluate a given node as a constant expression.
//
// A constant expression is either just a number or ptr+n where ptr
// is a pointer to a global variable and n is a postiive/negative
// number. The latter form is accepted only as an initialization
// expression for a global variable.
fn eval2(c: *Ctx, node: *Node) Ty(i64, ?Qbe.Sym) = {  // (off, label)
    if !c.is_const_expr(node) {
        @error_tok(c, node.tok, "expected a constant expression");
    };
    
    // verbose sign extension:
    if node.ty.is_integer() && node.ty.size != 8 && !node.ty.is_unsigned {
        prev := c.speculate; // HACK
        c.speculate = false;
        //@println("% %", node.r, c.speculate);
        node = c.new_cast(node, c.ty_long);
        c.speculate = prev;
        //@println("%", node.r);
    };
    
    r := node.r;
    if rtype(r) != .RCon {
        @error_tok(c, node.tok, "ICE: unevaluated constant");
    };
    con := c.f.get_constant(r);
    ::enum(Qbe.ConType);
    label: ?Qbe.Sym = @if(con.type() == .CAddr, (Some = con.sym), .None);
    (con.bits(), label)
}

fn is_const_expr(c: *Ctx, node: *Node) bool = { 
    rtype(node.r) == .RCon
}

fn const_expr(c: *Ctx, rest: **Token, tok: *Token) i64 = {
    prev := c.speculate;
    c.speculate = false;
    node := c.parse_expr(rest, tok, .Conditional);
    c.speculate = prev;
    c.eval(node)
}

fn eval_double(c: *Ctx, node: *Node) f64 = { 
    // verbose extension:
    {
        prev := c.speculate; // HACK
        c.speculate = false;
        node = c.new_cast(node, c.ty_double);
        c.speculate = prev;
    };
    
    if rtype(node.r) != .RCon {
        @error_tok(c, node.tok, "ICE: unevaluated constant");
    };
    con := c.f.get_constant(node.r);
    ::enum(@type con.type());
    @debug_assert_eq(con.type(), .CBits);
    con.bits().bitcast()
}

// Convert op= operators to expressions containing an assignment.
//
// In general, `A op= C` is converted to ``tmp = &A, *tmp = *tmp op B`.
// However, if a given expression is of form `A.x op= C`, the input is
// converted to `tmp = &A, (*tmp).x = (*tmp).x op C` to handle assignments
// to bitfields.
fn to_assign(c: *Ctx, kind: NodeKind, lhs: *Node, rhs: *Node, tok: *Token) *Node = {
    if c.speculate {
        return(lhs);
    };
    //c.add_type(lhs);
    //c.add_type(rhs);
    
    is_bitfield := lhs.kind == .ND_MEMBER && lhs.member.is_bitfield;

    // If A is an atomic type, Convert `A op= B` to
    //
    // ({
    //     T1 *addr = &A; T2 val = (B); T1 old = *addr; T1 new;
    //     do {
    //        new = old op val;
    //     } while (!atomic_compare_exchange_strong(addr, &old, new));
    //     new;
    // })
    if lhs.ty.is_atomic && !is_bitfield {
        @error_tok(c, tok, "TODO: to_assign for _Atomic types");
    };

    // n1570#6.5.16p3: An assignment expression has the value of the left operand after the assignment, but is not an lvalue. 
    // Convert `A op= B` to ``tmp = &A, *tmp = *tmp op B`.
    // Bitfields need special handling because their address can't be taken. 

    //@match(kind) {
    //    fn ND_ADD() => c.new_add();
    //    fn ND_SUB() => c.new_sub();
    //    @default => ();
    //};
    
    addr  := c.gen_addr(lhs);
    delta := c.gen_cast(c.gen_expr(rhs), rhs.ty, lhs.ty, tok);
    start := if is_bitfield {
        c.gen_load_bitfield(addr, lhs.member)
    } else {
        c.gen_load(addr, lhs.ty)
    };
    final := c.gen_binary(kind, start, delta, lhs.ty, lhs.ty, tok);
    if is_bitfield {
        // this generates silly code that loads the other fields with the same storage again even though we already did that, but whatever
        c.gen_store_bitfield(addr, final, lhs.member);
    } else {
        c.gen_store(addr, final, lhs.ty);
    };
    
    c.ir_node(lhs.ty, final, QbeNull, tok)
}

fn ir_node(c: *Ctx, ty: *CType, r: Qbe.Ref, lvalue: Qbe.Ref, tok: *Token) *Node = {
    n := c.new_node(.ND_NULL_EXPR, tok);
    n.r = r;
    n.lvalue = lvalue;
    n.ty = ty;
    n
}

/*******************
*   Ir-ish Stuff   *
********************/

fn new_block(c: *Ctx) *Qbe.Blk = {
    @if(c.speculate) return(@static(Qbe.Blk));
    
    f := c.f;
    b := newblk();
    push(f.rpo&, f.nblk&, b);
    b.id = f.nblk - 1;
    b
}

fn get_block(c: *Ctx, name: Str) *Qbe.Blk = {
    c.labels&.get_or_insert(name, => c.new_block())[]
}

fn jmp_if_unterminated(c: *Ctx, dest: *Qbe.Blk) void = {
    if c.b.jmp.type == .Jxxx && !c.speculate {
        c.b.s1 = dest;
        c.b.jmp.type = .jmp;
    };
}

fn jnz_if_unterminated(c: *Ctx, cond: Qbe.Ref, then: *Qbe.Blk, else: *Qbe.Blk) void = {
    if c.b.jmp.type == .Jxxx && !c.speculate {
        c.b.jmp = (type = .jnz, arg = cond);
        c.b.s1 = then;
        c.b.s2 = else;
    };
}

fn emit(c: *Ctx, op: Qbe.O, k: Qbe.Cls, to: Qbe.Ref, arg0: Qbe.Ref, arg1: Qbe.Ref) void = {
    @if(SPAM) @println("O % =% % % %", to, k, op, arg0, arg1);
    @if(c.speculate) return();
    push(c.b, make_ins(op, k, to, arg0, arg1));
}

fn gen_par(c: *Ctx, ty: *CType) void = {
    obj := c.current_fn.expect("gen_par() in function context");
    if ty.params.len > ty.param_names.len {    
        // TODO: this is probably at the wrong place now since we alias types?
        @error_tok(c, ty.params[ty.param_names.len].name_pos, "parameter name omitted")
    }
    obj_params := temp().alloc_init(*Obj, ty.params.len) { i |
        c.new_lvar(c.get_ident(ty.param_names[i]), ty.params[i])
    };
    
    f := c.f; 
    f.start = c.new_block();
    c.b = f.start;
    
    if c.preserve_franca_env {
        c.franca_env = f.newtmp("env", .Kl);
        c.emit(.pare, .Kl, c.franca_env, QbeNull, QbeNull);
    }
    
    for obj_params { loc |
        k := loc.ty.cls();
        loc.par_r = f.newtmp(loc.name, k);
        i := c.ir_index(loc.ty);
        o: Qbe.O = @if(i == QbeNull, .par, .parc);
        emit(c, o, k, loc.par_r, i, QbeNull); 
    };
    // all the allocs have to be after all the pars
    for obj_params { loc |
        if c.ir_index(loc.ty) == QbeNull {
            c.create_stack_slot(loc);
        } else {
            loc.stack_slot = loc.par_r;
        };
    };
    // some instructions (par/alloc) will always go in f.start, real code goes in its own block. 
    // but since all vars get stack slots, we need to store any scalar arguments. 
    body := c.new_block();
    c.jmp_if_unterminated(body);
    for obj_params { loc |
        if c.ir_index(loc.ty) == QbeNull {
            c.gen_store(loc.stack_slot, loc.par_r, loc.ty);
        };
    };
    c.b = body;
}

fn assert_gen_expr(c: *Ctx, node: *Node) Qbe.Ref = {
    @debug_assert(node.r != QbeNull || c.speculate, "assert_gen_expr");    
    node.r
}

fn gen_expr(c: *Ctx, node: *Node) Qbe.Ref = {
    if(node.r != QbeNull, => return(node.r));
    c.add_type(node);
    ::ptr_utils(@type c.f[]);
    if(c.f.is_null() || c.speculate, => return(node.r));
    node.r = c.gen_expr_inner(node);
    node.r
}

fn gen_expr_inner(c: *Ctx, node: *Node) Qbe.Ref = {
    ::enum(NodeKind);
    @if(SPAM) @println("E % %; %", node.kind, Node.int_from_ptr(node), node.tok.str());
    @match(node.kind) {
        fn ND_NULL_EXPR() => QbeUndef;
        fn ND_STMT() => QbeUndef;
        fn ND_VAR() => {
            addr := c.gen_addr(node); 
            c.gen_load(addr, node.ty)
        }
        fn ND_MEMBER() => {
            addr := c.gen_addr(node); 
            r := if node.member.is_bitfield {
                c.gen_load_bitfield(addr, node.member)
            } else {
                c.gen_load(addr, node.ty)
            };
            r
        }
        @default => {
            if node.lhs.is_null() || node.rhs.is_null() || node.ty.is_null() {
                @error_tok(c, node.tok, "gen_binary invalid arg for %", node.kind);
            };
            lhs_r := c.gen_expr(node.lhs);
            rhs_r := c.gen_expr(node.rhs);
            c.gen_binary(node.kind, lhs_r, rhs_r, node.ty, node.lhs.ty, node.tok)
        };
    }
}

fn gen_assign(c: *Ctx, addr_node: *Node, value: Qbe.Ref, ty: *CType) *Node = {
    addr  := c.gen_addr(addr_node);
    if !c.speculate {
        if addr_node.kind == .ND_MEMBER && addr_node.member.is_bitfield {
            c.gen_store_bitfield(addr, value, addr_node.member);
        } else {
            c.gen_store(addr, value, ty);
        };
    };
    lvalue := if(@is(ty.kind, .TY_STRUCT, .TY_UNION), => value, => QbeNull);
    node := c.ir_node(ty, value, lvalue, addr_node.tok);
    node
}

fn gen_zero_var(c: *Ctx, var: *Obj, tok: *Token) void = {
    if(c.speculate, => return());
    dest := var.stack_slot;
    if dest == QbeNull {
        @error_tok(c, tok, "ICE: gen_zero_var missing slot for %", var.name);
    };
    size: i64 = var.ty.size.intcast();
    off := 0;
    each Qbe.Simplify.blit_op_table { o |
        while => size >= o.size {
            d := if off == 0 {
                dest 
            } else {
                d := c.f.newtmp("c", .Kl);
                c.emit(.add, .Kl, d, dest, c.getcon(off));
                d
            };
            c.emit(o.store, .Kw, QbeNull, QbeConZero, d);
            size -= o.size;
            off  += o.size;
        };
    };
}

// Read the current value from memory and merge it with a new value.
fn gen_store_bitfield(c: *Ctx, addr: Qbe.Ref, value: Qbe.Ref, mem: *Member) void = {
    @debug_assert(mem.is_bitfield);
    k := mem.ty.cls();
    r := @uninitialized Array(Qbe.Ref, 4); r := r&;
    each r { it |
        it[] = c.f.newtmp("c", k);
    };
    
    prev := c.gen_load(addr, mem.ty);
    mask := 1.shift_left(mem.bit_width.intcast()) - 1;
    c.emit(.and, k, r[0], value, c.getcon(mask));
    c.emit(.shl, k, r[1], r[0], c.getcon(mem.bit_offset.intcast()));
    mask := mask.shift_left(mem.bit_offset.intcast()).bit_not();
    c.emit(.and, k, r[2], prev, c.getcon(mask));
    c.emit(.or, k, r[3], r[2], r[1]);
    
    c.gen_store(addr, r[3], mem.ty);
}

// TODO: you'd think gen_store_bitfield should call this
fn gen_load_bitfield(c: *Ctx, addr: Qbe.Ref, mem: *Member) Qbe.Ref = {
    @debug_assert(mem.is_bitfield);
    r := c.gen_load(addr, mem.ty);
    k := mem.ty.cls();
    r1, r2 := (c.f.newtmp("c", k), c.f.newtmp("c", k));
    c.emit(.shl, k, r1, r, c.getcon(64 - mem.bit_width.intcast() - mem.bit_offset.intcast()));
    o: Qbe.O = @if(mem.ty.is_unsigned, .shr, .sar);
    c.emit(o, k, r2, r1, c.getcon(64 - mem.bit_width.intcast()));
    r2
}

fn gen_binary(c: *Ctx, kind: NodeKind, lhs_r: Qbe.Ref, rhs_r: Qbe.Ref, out_ty: *CType, ctrl_ty: *CType, tok: *Token) Qbe.Ref = {
    o: Qbe.O = @match(kind) {
        fn ND_ADD()      => .add;
        fn ND_SUB()      => .sub;
        fn ND_MUL()      => .mul;
        fn ND_DIV()      => if(out_ty.is_unsigned, => .udiv, => .div);
        fn ND_MOD()      => if(out_ty.is_unsigned, => .urem, => .rem);
        fn ND_BITAND()   => .and;
        fn ND_BITOR()    => .or;
        fn ND_BITXOR()   => .xor;
        fn ND_SHL()      => .shl;
        fn ND_SHR()      => if(out_ty.is_unsigned, => .shr, => .sar);
        fn ND_EQ()       => ctrl_ty.cls().cmp_base();
        fn ND_NE()       => ctrl_ty.cls().cmp_ne();
        fn ND_LT()       => @match(ctrl_ty.cls()) {
            fn Kw() => if(ctrl_ty.is_unsigned, => .cultw, => .csltw);
            fn Kl() => if(ctrl_ty.is_unsigned, => .cultl, => .csltl);
            fn Ks() => .clts;
            fn Kd() => .cltd;
            @default => panic("bad cls");
        };
        fn ND_LE()       => @match(ctrl_ty.cls()){
            fn Kw() => if(ctrl_ty.is_unsigned, => .culew, => .cslew);
            fn Kl() => if(ctrl_ty.is_unsigned, => .culel, => .cslel);
            fn Ks() => .cles;
            fn Kd() => .cled;
            @default => panic("bad cls");
        };
        @default => @panic("unexpected binary expression but found: %", kind);
    };
    c.emit(o, out_ty.cls(), lhs_r, rhs_r)
}

fn emit(c: *Ctx, o: Qbe.O, k: Qbe.Cls, a0: Qbe.Ref, a1: Qbe.Ref) Qbe.Ref = {
    // :FrontendConstantFolding
    // The backend will do more aggressive constant folding later, 
    // but there are some language constructs that require 
    // known constants in the frontend (ie. array types). 
    if OpTab'get(o, .can_fold) && rtype(a0) == .RCon && (@is(rtype(a1), .RCon, .RNull)) {
        ::if(Qbe.Ref);
        a1 := if(a1 == QbeNull, => QbeConZero, => a1);
        lhs_c, rhs_c := (c.f.get_constant(a0), c.f.get_constant(a1));
        f :: Qbe.backend.try_fold_op;
        if f(o, k, lhs_c, rhs_c) { result |
            return(c.getcon(result));
        };
    };
    
    if(c.speculate, => return(QbeNull));
    r := c.f.newtmp("c", k);
    c.emit(o, k, r, a0, a1);
    r
}
#use(Types);

// TODO: audit this. chibicc has a big table of x64 mnemonics to compare to. 
fn gen_cast(c: *Ctx, src: Qbe.Ref, from: *CType, to: *CType, tok: *Token) Qbe.Ref = {
    // array types know thier size for sizeof but when we look at size below we want to have decayed to a pointer. 
    // sizeof(function)==1 is what clang and chibicc do so thats what i do Â¯\_(ã)_/Â¯ but also need to allow casting it like a pointer
    from := @if(from.kind == .TY_ARRAY || from.kind == .TY_FUNC, c.ty_ulong, from);
    to   := @if(to.kind == .TY_ARRAY || from.kind == .TY_FUNC, c.ty_ulong, to);
    
    k_from, k_to := (from.cls(), to.cls());
    p_from, p_to := (from.get_type_id(), to.get_type_id());
    ::enum(@type p_from);
    @if(SPAM) @println("cast % % % -> %", src, from.kind, p_from, p_to);
    if !c.speculate && src == QbeNull {
        @error_tok(c, tok, "ICE: tried to cast Null ref");
    };
    if(p_from == p_to, => return(src));
    if p_to == .B {  
        return(c.emit(Simplify'cmp_ne(k_from), k_to, src, QbeConZero))
    };
    ::if(Qbe.O);
    o: Qbe.O = if !k_to.is_int() {
        @match(p_from) {
            fn U64() => .ultof;
            fn I64() => .sltof;
            fn U32() => .uwtof;
            fn I32() => .swtof;
            fn F32() => .exts;
            fn F64() => .truncd;
            @default => {
                //  bool/byte/short to float/double cast
                src = c.gen_cast(src, from, c.ty_int, tok);
                .swtof
            };
        }
    } else {  // k_to is integer
        if(to.size == from.size && k_to == k_from, => return(src));  // if sizes are equal, it's a signedness cast which does nothing 
        if k_from.is_int() && to.size < from.size {
            // `(char) 256` needs to truncate
            mask := 1.shift_left(to.size.intcast() * 8) - 1;
            return(c.emit(.and, k_to, src, c.getcon(mask)));
        };
        ::enum(Qbe.Cls);
        @match(p_from) {
            fn B()   => {
                @if(k_to == .Kw) return(src);
                .extub
            }
            fn U8()  => .extub;
            fn I8()  => .extsb;
            fn U16() => .extuh;
            fn I16() => .extsh;
            fn U32() => .extuw;
            fn I32() => .extsw;
            fn F32() => @if(to.is_unsigned, .stoui, .stosi);
            fn F64() => @if(to.is_unsigned, .dtoui, .dtosi);
            @default => @panic("bad type! % % % to % % %", p_from, k_from, from.kind, p_to, k_to, to.kind);  // *u64 is just a signedness cast
        }
    };

    c.emit(o, k_to, src, QbeNull)
}

fn gen_call(c: *Ctx, callee: *Node, function_ty: *CType, arg: []*Node, tok: *Token) *Node #once = {
    // TODO: don't just take random variable names!
    //       call this __builtin_alloca and provide alloca.h
    if callee.kind == .ND_VAR && callee.var.name == "alloca" {
        @if(arg.len != 1) @error_tok(c, tok, "alloca arity error");
        size := c.gen_expr(arg[0]);
        r := c.f.newtmp("alloca", .Kl);
        c.emit(.alloc16, .Kl, r, size, QbeNull);
        return(c.ir_node(function_ty.return_ty, r, r, tok));
    };
    
    while => function_ty.kind == .TY_PTR {
        function_ty = function_ty.base;
    };

    variadic_marker_index := if(function_ty.is_variadic, => function_ty.params.len, => -1);
    arguments := list(Qbe.Ins, arg.len, temp());
    for arg { arg |
        if variadic_marker_index == 0 {
            arguments&.push(make_ins(.argv, .Kw, QbeNull, QbeNull, QbeNull));
        };
        variadic_marker_index -= 1;
        
        // TODO: b/h arg/par
        r := c.gen_expr(arg);
        arguments&.push(arg_ins(r, arg.ty.cls(), c.ir_index(arg.ty)));
    };
    
    @if(c.speculate) return c.ir_node(function_ty.return_ty, QbeNull, QbeNull, tok);
    
    // tell the backend that it's variadic even if we're not passing any va-args (needed for wasm). 
    // TODO: make sure the franca frontend does this too 
    if variadic_marker_index == 0 {
        arguments&.push(make_ins(.argv, .Kw, QbeNull, QbeNull, QbeNull));
    };
    
    ::ptr_utils(Obj);
    
    // TODO: compiler bug: if you get a compile error here when jitting, 
    //       you fault in the jit shim (stack overflow maybe?).  -- Mar 11, 2025
    if c.preserve_franca_env {
        c.emit(.arge, .Kl, QbeNull, c.franca_env, QbeNull);
    }
    for arguments { i |    
        c.b.push(i);
    };
    
    callee := c.gen_expr(callee);
    k := function_ty.return_ty.cls();
    is_void := function_ty.return_ty.kind == .TY_VOID;
    r := if(is_void, => QbeNull, => c.f.newtmp("c", k)); 
    i := c.ir_index(function_ty.return_ty);
    c.emit(.call, k, r, callee, i);
    // TODO: it seems like just returning QbeNull for void would work but fails wuffs/lzma.c :FUCKED
    r := if(is_void, => QbeConZero, => r); 
    lvalue := if(i != QbeNull, => r, => QbeNull); // for gen_addr so you can do `foo().field`
    c.ir_node(function_ty.return_ty, r, lvalue, tok)
}

// TODO: move these to util and use them elsewhere
fn arg_ins(r: Qbe.Ref, k: Qbe.Cls, type_index: Qbe.Ref) Qbe.Ins = {
    ::if(Qbe.Ins);
    if type_index == QbeNull {
        make_ins(.arg, k, QbeNull, r, QbeNull)
    } else {
        make_ins(.argc, .Kl, QbeNull, type_index, r)
    }
}

fn gen_store(c: *Ctx, addr: Qbe.Ref, value: Qbe.Ref, ty: *CType) void = {
    @debug_assert(!ty.is_null(), "gen_store unknown type");
    if @is(ty.kind, .TY_STRUCT, .TY_UNION) {
        c.emit(.blit0, .Kw, QbeNull, value, addr);  // src, dest because we hate ourselves
        c.emit(.blit1, .Kw, QbeNull, INT(ty.size.intcast()), QbeNull);
        return();
    };
    o: Qbe.O = @if_else {
        @if(@is(ty.kind, .TY_DOUBLE, .TY_LDOUBLE)) => .stored;
        @if(@is(ty.kind, .TY_FLOAT)) => .stores;
        @else => import("@/backend/opt/mem.fr")'store_by_size[ty.size.zext()];
    };
    c.emit(o, .Kw, QbeNull, value, addr);
}

fn gen_load(c: *Ctx, addr: Qbe.Ref, type: *CType) Qbe.Ref = {
    if @is(type.kind, .TY_ARRAY, .TY_STRUCT, .TY_UNION, .TY_FUNC, .TY_VLA) {
        return(addr);  // really?
    };
    k := type.cls();
    r := c.f.newtmp("c", k);
    if @is(type.kind, .TY_DOUBLE, .TY_LDOUBLE, .TY_FLOAT) {
        c.emit(.load, k, r, addr, QbeNull);
        return(r);
    };
    o: Qbe.O = @switch(type.size) {
        @case(1) => @if(type.is_unsigned, .loadub, .loadsb);
        @case(2) => @if(type.is_unsigned, .loaduh, .loadsh);
        @case(4) => @if(type.is_unsigned, .loaduw, .loadsw);
        @case(8) => .load;
        @default => panic("invalid int size");
    };
    c.emit(o, k, r, addr, QbeNull);
    r
}

fn gen_addr(c: *Ctx, node: *Node) Qbe.Ref = {
    if node.lvalue == QbeNull && !c.speculate {
        @error_tok(c, node.tok, "expected lvalue");
    };
    node.lvalue
}

fn getcon(c: *Ctx, s: Qbe.Sym) Qbe.Ref = 
    c.getcon(con(s, 0));
    
fn getcon(c: *Ctx, i: i64) Qbe.Ref = 
    c.getcon(con(Qbe.no_symbol_S, i));

// the map makes it not suck for giant array literals
fn getcon(c: *Ctx, c0: Qbe.Con) Qbe.Ref = {
    ::enum(Qbe.ConType);
    // profile compiling musl before deciding this is dumb!
    if c0&.type() == .CBits {
        n := c0&.bits();
        @if(n.ule(1)) return(c.cache_con01&[n]);
    };
    //@println("xxx % %", c0&.bits(), c0.sym.id);
    ::AutoHash(Qbe.Con, TrivialHasher);
    ::AutoHash(Qbe.Sym, TrivialHasher);
    ::AutoHash(Ty(u32, u32), TrivialHasher);
    ::AutoEq(Qbe.Con);
    ::AutoEq(Qbe.Sym);
    ::AutoEq(Ty(u32, u32));
    c.consts.get_or_insert(c0, => {
        c.f.newcon_unchecked(c0&)
    })[]
}

#use("@/backend/opt/fold.fr");
#use("@/backend/lib.fr");
