write :: fn(fd: i64, buf: i64, len: i64) i64 #n(64) = {
    kprint(u8.ptr_from_int(buf).slice(len));
    len
}

read :: fn(fd: i64, buf: i64, len: i64) i64 #n(63) = {
    @if(fd != 0) return(-1);
    dest := u8.ptr_from_int(buf).slice(len);
    count := 0;
    // TODO
    count
}

mmap :: fn(kernel: *Kernel, addr: i64, len: i64, prot: i64, flags: i64, fd: i64, offset: i64) i64 #n(222) = {
    pages := len.ualign_to(PAGE_SIZE).udiv(PAGE_SIZE);
    result_addr := vmap_empty_any(kernel, kernel.tasks&[0].mem&, pages);
    barrier();  // TODO: theres an instruction to kill the tlb or something
    result_addr
}

mprotect :: fn(addr: i64, len: i64, prot: i64) i64 #n(226) = {
    // TODO: do the protection. for now everything is RWX so it doesn't matter. 
    barrier(); // TODO: theres an instruction to kill the tlb or something
    0
}

exit :: fn(task: *Task) i64 #n(94) = {
    kprint("called exit\n");
    // TODO: deallocate its pages and stuff
    task.active = false;
    0
}

spawn :: fn(kernel: *Kernel, buf: i64, len: i64) i64 #n(0xFFFF0001) = {
    //elf_bytes := u8.ptr_from_int(buf).slice(len);
    
    task := kernel.alloc_task();
    tt := kernel.idle_task.mem.root;
    init_task(task, user_exec, tt);
    task.mcontext.gpr&[0] = buf;
    task.mcontext.gpr&[1] = len;
    
    0
}

yield :: fn(task: *Task) i64 #n(0xFFFF0002) = {
    0
}

generate :: fn() []Ty(@FnPtr(task: *Task) void, i64) = {
    results := Ty(@FnPtr(task: *Task) void, i64).list(ast_alloc());
    s := import("@/examples/os/kernel/syscalls.fr");
    for get_constants(s) { name |
        continue :: local_return;
        impl_fid := get_constant(FuncId, s, name).unwrap();
        impl_func := get_function_ast(impl_fid, true, true, true, false);
        loc := impl_func.loc;
        
        i := impl_func.annotations&.index_of(fn(it) => it.name == @symbol n)
            || continue();
        syscall_number := const_eval(i64)(impl_func.annotations[i].args);
        
        fr := current_compiler_context();
        func := empty_fn(impl_func.name, loc);
        func.resolve_scope = s; // :WhatScope
        fill_bindings(func&, fr, @slice(*Task));
        wrapper_fid := fr.intern_func(func&);
        func := get_function_ast(wrapper_fid, true, true, false, false);
        
        the_task := func.arg.bindings[0].name.Var;
        the_task: FatExpr = (expr = (GetVar = the_task), ty = UnknownType, done = false, loc = loc);
        args := FatExpr.list(ast_alloc());
        i := 0;  // choosing this index gets more complicated once its not just for arm
        each impl_func.arg.bindings& { it |
            @switch(it.ty.Finished) {
                @case(*Task) => args&.push(the_task);
                @case(*Kernel) => args&.push(@{ kernel() });
                @case(i64) => {
                    args&.push(@{ @[the_task].mcontext.gpr&[@[@literal i]] });
                    i += 1;
                };
                @default => panic("invalid syscall argument type");
            };
        };
        @debug_assert_le(i, 8, "too many syscall arguments");
        
        args: FatExpr = if args.len == 1 {
            args[0]
        } else {
            (expr = (Tuple = args.as_raw()), ty = UnknownType, done = false, loc = loc)
        };
        func.body = (Normal = @{ 
            x0: i64 = @[@literal impl_fid](@[args]);
            @[the_task].mcontext.gpr&[0] = x0;
        });
        
        callee := fr.get_jitted(wrapper_fid);
        callee := bit_cast_unchecked(rawptr, @FnPtr(task: *Task) void, callee);
        push(results&, (callee, syscall_number));
    };
    results.items()
}
