
#use("@/examples/os/kernel/pages.fr");

Kernel :: @struct {
    physical: Physical;
    // for now i always increase the virtual addresses being handed out 
    // so you can tell which address space a pointer is in for debugging. 
    next_vaddr: i64;
    tasks: Array(Task, 16);
    next_task_to_run: i64;
    next_task_id: i64;
    env: rawptr;
    interrupt_stack: []u8;
    timer_counter: u64;
    idle_task: Task;
    pages_reserved: i64;
    pages_committed: i64;
    pages_reserved_freed: i64;
    pages_committed_freed: i64;
    device_tree: []u8;
};

fn kernel() *Kernel = {
    // when the mmu is off, all memory is treated as device memory and doesn't allow unaligned access. 
    // (and my flat_link doesn't align the data segment)
    k :: @static(Array(u8, Kernel.size_of()*2));
    kernel := align_the_thing(k, 8, size_of(Kernel));
    kernel := Kernel.ptr_from_raw(kernel);
    kernel
}

DT :: import("@/examples/dump_devicetree.fr");

// this is called by emit_entry's _start
main :: fn(device_tree: i64, _sp: i64, kernel_image_base: i64) void = {
    link_image_base: i64 = 0x40100000;
    kernel_image_size := -1;
    if device_tree == 0 || kernel_image_base == -4 {
        // qemu running as elf instead of as linux image
        device_tree = 0x40000000;
        kernel_image_base = link_image_base;
        kernel_image_size = 1.shift_left(23);  // TODO: tighter bound. 
    } else {
        kernel_image_size = i64.ptr_from_int(kernel_image_base + 16)[].align_to(PAGE_SIZE);
    };
    kprint_label("main ", int_from_rawptr(main));
    kprint_label("image_base ", kernel_image_base);
    kprint_label("device_tree ", device_tree);
    
    dt := DT.Header.ptr_from_int(device_tree)[];
    DT.Header.byte_swap_fields(dt&);
    if dt.magic != DT.MAGIC {
        kprint("bad dt magic");  // yolo
        poweroff();
    };
    device_tree_bytes := u8.ptr_from_int(device_tree).slice(dt.totalsize.zext());
    
    _, c := create_and_set_unsafe_environment();
    //c.panic_hook = kpanic;
    c.panic_hook = bit_cast_unchecked(i64, @type c.panic_hook, 0xABABABAB);
    kprint("Hi\n");
    
    el := i64.sys_get(.CurrentEL).shift_right_logical(2);
    if el != 1 {
        kprint_label("el ", el);
        kpanic("expected to run in el1");
    };
    if i64.sys_get(.ID_AA64ISAR0_EL1).shift_right_logical(20).bit_and(0b1111) == 0 {
        kprint("WARNING: atomic instructions are not implemented on this cpu (qemu: try -cpu cortex-a76)\n");
    };
    if i64.sys_get(.ICC_SRE_EL1).bit_and(1) == 0 {
        kprint("WARNING: ICC_SRE_EL1 (system register interface for GIC) is disabled\n");
    };
    
    kernel := kernel();
    
    ram_size: i64 = 1.shift_left(29) - 0x00100000; // TODO: get this from device tree
    kernel.physical.remaining = (
         ptr = u8.ptr_from_int(kernel_image_base + kernel_image_size), 
         len = ram_size - kernel_image_size,
    );
    kernel.next_vaddr = (512*1024*1024) * 4;
    kernel.env = get_dynamic_context();
    kernel.device_tree = device_tree_bytes;
    
    // TODO: maybe better to use this to only save on interrupt if they're actually being used by that process
    cpacr := i64.sys_get(.CPACR_EL1);
    i64.sys_set(.CPACR_EL1, cpacr.bit_or(0b11.shift_left(20)));  // FPEN
    
    // EL0PCTEN: allow userspace to read CNTPCT_EL0 and CNTFRQ_EL0
    cntctl := i64.sys_get(.CNTKCTL_EL1);
    i64.sys_set(.CNTKCTL_EL1, cntctl.bit_or(1));

    //setup_interrupts();
    //tt := setup_virtual_memory();
    tt := zeroed(*TranslationTable);

    //a := Arena'stack_alloc(100000);
    //out := u8.list(a);
    //DT'dump(out&, device_tree_bytes);
    //kprint(out.items());
    
    //franca examples/os/build.fr && qemu-system-aarch64 -machine virt,gic-version=3 -global virtio-mmio.force-legacy=false \
    //        -cpu cortex-a76 -kernel target/kernel.out -serial stdio -display none -m 512M \
    //        -device virtio-serial-pci,id=virtio-serial0 \
    //        -device virtconsole,chardev=vc02 \
    //        -chardev file,path=a.txt,id=vc02  && ls -l a.txt && cat a.txt && rm a.txt
    
    // TODO: annoying avoiding unaligned read so it works without mmu. only works because backend is dumb. 
    pop_int :: fn(in) i64 => 
        in.pop_type(u32)[].zext().bit_or(in.pop_type(u32)[].zext().shift_left(32)).byte_swap();
    
    legal_pci_addr := 0;
    prev := "";
    
    self := DT'iter(device_tree_bytes);
    dowhile {
        continue :: local_return;
        it := self&.next();
        
        if it.name == "ranges" && prev.starts_with("pci") {
            // TODO: check that various size/address cells count is 2/3
            while => it.data.len > 7*4 {
                kprint("PCI RANGE\n");
                flags: i64 = it.data&.pop_type(u32)[].zext();
                pci_addr := pop_int(it.data&);
                cpu_addr := pop_int(it.data&);
                pci_size := pop_int(it.data&);
                kprint_label("flags ", flags);
                kprint_label("pci_addr ", pci_addr);
                kprint_label("cpu_addr ", cpu_addr);
                kprint_label("pci_size ", pci_size);
                kprint_label("cpu_addr[0] ", u32.volatile(cpu_addr).zext());
                
                if pci_addr == cpu_addr {
                    legal_pci_addr = pci_addr;
                    kprint_label("legal_pci_addr ", legal_pci_addr);
                }
            };
        };
        
        
        if it.tag == .BEGIN_NODE {
            prev = it.name;
        };
        
        it.tag != .END
    };
    self := DT'iter(device_tree_bytes);
    dowhile {
        continue :: local_return;
        it := self&.next();
        // device tree pci.reg replaces ACPI 'MCFG' table and lets you find the config space. 
        // "The PCI Express bus extends the Configuration Space from 256 bytes to 4096 bytes."
        //    so maybe i need prev.starts_with("pcie") or else step by 256?
        // vendorid = 0xffff means non existant device
        //
        if it.name == "reg" && prev.starts_with("pci") {
            addr := pop_int(it.data&);  // i think this is the "configuration space"
            size := pop_int(it.data&);
            kprint("PCI REG\n");
            kprint_label("addr ", addr);
            kprint_label("size ", size);
            
            range(0, size / 4096) { i |
                a := addr + i*4096;
                vendorid := u32.volatile(a).bit_and(0xFFFF);
                //if vendorid != 0xFFFF {
                if vendorid == 0x1AF4 {
                    header_type := u32.volatile(a + 12).shift_right_logical(16).bit_and(0xFF);
                    command := u32.volatile(a + 4).bit_and(0xFFFF);

                    deviceid := u32.volatile(a).shift_right_logical(16).bit_and(0xFFFF);
                    //virtio_id := deviceid - 0x1040;  // TODO: 0x1040 apple or 0x1000 qemu
                    if deviceid == 0x1043 || deviceid == 0x1003 {
                            //u32.volatile(addr + 0x100 + 8, 67);
                        kprint_label("found at ", i);
                        //kprint_label("virtio_id ", virtio_id.zext());
                        kprint_label("header_type ", header_type.zext());
                        kprint_label("command ", command.zext());
                        
                        u32.volatile(a + 4, 0b110);  // command. enable memory space
                        
                        //bars: Array(u32, 6) = (
                        //    u32.volatile(a + 0x10),
                        //    u32.volatile(a + 0x14),
                        //    u32.volatile(a + 0x18),
                        //    u32.volatile(a + 0x1c),
                        //    u32.volatile(a + 0x20),
                        //    u32.volatile(a + 0x24),
                        //);
                        //kprint_label("bar4 ", bars&[4].zext());
                        
                        
                        //cap_ptr: i64 = u16.volatile(a + 0x34).bit_and(0b11111111111100).zext();
                        cap_ptr: i64 = u8.volatile(a + 0x34).zext();
                        kprint_label("cap_ptr ", cap_ptr);
                        
                        // 4.1.4 Virtio Structure PCI Capabilities
                        cap := a + cap_ptr;
                        dowhile {
                            cap_vndr: i64 = u8.volatile(cap).zext();
                            kprint_label("cap_vndr ", cap_vndr);
                            
                            if cap_vndr == 9 {
                                cfg_type := u8.volatile(cap + 3);
                                bar := u8.volatile(cap + 4);
                                off := u32.volatile(cap + 8);
                                len := u32.volatile(cap + 12);
                                kprint_label("cfg_type ", cfg_type.zext());
                                kprint_label("bar ", bar.zext());
                                kprint_label("off ", off.zext());
                                kprint_label("len ", len.zext());
                                
                                //if cfg_type == 5 {   // VIRTIO_PCI_CAP_PCI_CFG. crashes qemu. doesn't exist in avf. 
                                //    kprint_label("caplen ", u8.volatile(cap + 2).zext());
                                //    u8.volatile(cap + 4, 4);  // bar
                                //    u32.volatile(cap + 8, 8192 + 8);  // off
                                //    u32.volatile(cap + 12, 4);  // len
                                //    u32.volatile(cap + 16, 67);
                                //};
                                kprint_label("bar val ",  u32.volatile(a + 0x10 + (bar.zext() * 4)).zext());
                                if cfg_type == 4 {  // 4=VIRTIO_PCI_CAP_DEVICE_CFG
                                    //if bars&[bar.zext()].bit_and(0b110) == 0b100 {
                                    //  // 64 bit memory space
                                    //};
                                    
                                    //X :: @struct(a: u32, b: u32, c: u32);
                                    //my_addr: X = (a = 0, b = 0, c = 0);
                                    //my_addr := X.int_from_ptr(my_addr&);
                                    //u32.volatile(a + 0x10 + (bar.zext() * 4), my_addr.trunc());
                                    //u32.volatile(a + 0x10 + (bar.zext() * 4) + 4, my_addr.shift_right_logical(32).trunc());
                                    //my_addr := my_addr + 8 + off.zext();
                                    
                                    read_int :: fn(it: i64) i64 = 
                                        u32.volatile(it).zext().bit_or(u32.volatile(it + 4).zext().shift_left(32));
                                    
                                    write_int :: fn(addr: i64, val: i64) void = {
                                        u32.volatile(addr, val.trunc());
                                        u32.volatile(addr + 4, val.shift_right_logical(32).trunc());
                                    };
                                    

                                    bar_addr := a + 0x10 + (bar.zext() * 4);
                                    base := read_int(bar_addr).bit_and(bit_not(0xF));
                                    kprint_label("OLD_BASE ", base);
                                    write_int(bar_addr, -1);
                                    size_mask := read_int(bar_addr).bit_and(bit_not(0xF));
                                    size := size_mask.bit_not().add(1);
                                    
                                    base: i64 = legal_pci_addr;
                                    write_int(bar_addr, base);
                                    //base := read_int(bar_addr).bit_and(bit_not(0xF));
                                    
                                    kprint_label("BASE ", base);
                                    kprint_label("SIZE_MASK ", size_mask);
                                    kprint_label("SIZE ", size);
                                    emerg_wr := base + 8 + off.zext();

                                    u32.volatile(emerg_wr, 67);
                                    u32.volatile(emerg_wr, 10);
                                    u32.volatile(emerg_wr, 67);
                                    u32.volatile(emerg_wr, 10);
                                    dopoweroff();
                                    //dohang();
                                }
                            };
                            cap_next: i64 = u8.volatile(cap + 1).zext();
                            kprint_label("cap_next ", cap_next);
                            cap = a + cap_next;
                            cap_next != 0
                        };
                        
                    };
                }
            };
            
            //kprint_label("addr[0] ", u32.volatile(addr).zext());
            //kprint_label("addr[1] ", u32.volatile(addr + 4).zext());
            //kprint_label("addr[2] ", u32.volatile(addr + 8).zext());
            //kprint_label("addr[3] ", u32.volatile(addr + 12).zext());
            //kprint_label("addr[4] ", u32.volatile(addr + 16).zext());
            
            //range(0, 256) { bus |
            //    range(0, 64) { device |
            //        function := 0;
            //        pci_get(addr, bus, device, function)
            //    };
            //};
            
        };
        if it.name == "reg" && it.data.len == 16 && prev != "memory" {
            addr := pop_int(it.data&);
            size := pop_int(it.data&);
            kprint("REG\n");
            kprint_label("addr ", addr);
            kprint_label("size ", size);
            
            if size >= 0x100 {
                init_virt_device(addr, prev);
            };
            continue(true);
        };
        
        if it.tag == .BEGIN_NODE {
            prev = it.name;
            //kprint(prev);
            //kprint("\n");
            //prefix := "virtio_mmio@";
            //if it.name.starts_with(prefix) && it.name.len > prefix.len {
            //    if hex(it.name.rest(prefix.len)) { addr |
            //        init_virt_device(addr, prev);
            //    };
            //}
        };
        it.tag != .END
    };
    dopoweroff();
    
    stack_size_pages := 16;
    kstack := kernel.physical&.map(stack_size_pages);  // TODO: its hacky to assume this will be contiguous
    ksize := stack_size_pages*PAGE_SIZE;
    kernel.interrupt_stack = bit_cast_unchecked(*Physical.Free, *u8, kstack).slice(ksize);

    ::[]Task;
    task := kernel.idle_task&;
    task.slice(1).set_zeroed();
    task.mem.root = tt;
    task.kernel_sp = kernel.interrupt_stack.end_pointer();
    init_task(task, spin);

    kernel.next_task_id = 1;
    task := kernel.alloc_task(tt);
    init_task(task, user_exec);
    elf_bytes := root_task_elf_bytes;
    task.mcontext.gpr&[0] = launder_to_user_pointer(u8.raw_from_ptr(elf_bytes.ptr));
    task.mcontext.gpr&[1] = elf_bytes.len;
    
    kprint("kernel ready\n");
    return_to_scheduler();
}

pci_get :: fn(base: i64, bus: i64, slot: i64, func: i64, offs: i64) u32 = 
    u32.volatile(base + (((bus * 256) + (slot * 8) + func) * 4096) + offs);

dopoweroff :: fn() void #noinline = {
    poweroff();
};
dohang :: fn() void #noinline = {
    loop {
    
    };
};

init_virt_device :: fn(addr: i64, msg: Str) void = {
    MAGIC :: 0x74726976;
    magic: i64 = u32.volatile(addr + 0).zext();
    version: i64 = u32.volatile(addr + 4).zext();
    if magic == MAGIC && version == 2 {
        id: i64 = u32.volatile(addr + 8).zext();
        if id != 0 {
            kprint_label("virtio_mmio at ", addr);
            kprint_label("magic ", magic);
            kprint_label("version ", version);
            kprint_label("DeviceID ", id);
            
            if id == 3 {
                status := addr + 0x070;
                u32.volatile(status, 0);  // reset
                u32.volatile(status, u32.volatile(status).bit_or(1));  // ACKNOWLEDGE
                u32.volatile(status, u32.volatile(status).bit_or(2));  // DRIVER
                feature_flags := u32.volatile(addr + 0x10);
                kprint_label("flags ", feature_flags.zext());
                u32.volatile(addr + 0x020, feature_flags);
                u32.volatile(status, u32.volatile(status).bit_or(8));  // FEATURES_OK
                features_ok := u32.volatile(status).bit_and(8) != 0;
                u32.volatile(status, u32.volatile(status).bit_or(4));  // DRIVER_OK
                
                emerg_wr := addr + 0x100 + 8;
                range(0, 26) { i |
                    u32.volatile(emerg_wr, 65 + i.trunc());
                };
                u32.volatile(emerg_wr, 10);
                for msg { c |
                    u32.volatile(emerg_wr, c.zext());
                };
                u32.volatile(emerg_wr, 10);
            }
        }
    };
};

root_task_elf_bytes :: {
    franca := get_executable_path(temp());
    o := "target/userspaceprogram.out";
    // TODO: this needs to be cacheable (rn -syscalls isn't but it shouldn't be hard to fix since thats not foldable)
    //       but also only the driver gets cached, not the program you're compiling, so need to fix that too. 
    import("@/examples/testing.fr")'sh(@slice(
        franca, "examples/default_driver.fr", "build", 
        "examples/os/user/init.fr", 
        "-os", "linux", "-arch", "aarch64", 
        //"-syscalls",
        "-keep-names",
        "-o", o,
    ));
    read_entire_file_or_crash(ast_alloc(), o)
};

alloc_task :: fn(kernel: *Kernel, tt: *TranslationTable) *Task = {
    each kernel.tasks& { it |
        if !it.active {
            it.slice(1).set_zeroed();
            it.active = true;
            it.thread_id = kernel.next_task_id;
            kernel.next_task_id += 1;
            // TODO: its dumb to store this on every task but it makes it easy for the interrupt handler to get it. 
            // TODO: really it needs to be local to the core if multiple threads are allowed to be in the kernel at once. 
            it.kernel_sp = kernel.interrupt_stack.end_pointer();
            it.mem.root = tt;
            return it;
        };
    };
    kpanic("too many tasks running")
}

init_task :: fn(task: *Task, callee: rawptr) void = {
    kernel := kernel();
    stack_size_pages := 10;
    user_stack := vmap_reserve(kernel, task.mem&, stack_size_pages);
    // stack grows left, so start at the right of the allocation. 
    user_stack += stack_size_pages * PAGE_SIZE; 
    
    task.mcontext.gpr&[31] = user_stack;
    // TODO: remove the remapping hack, just copy the bytes. 
    task.mcontext.elr = launder_to_user_pointer(callee);
}

fn kill_task(task: *Task) void = {
    // TODO: deallocate its pages and stuff
    //       (but for now everything is thread-like not process-like)
    // TODO: fix race. need to make it non-schedulable, then free pages, then make the task slot reusable. 
    task.active = false;
    if task.thread_id == 1 {
        kprint("init task exited\n");
        stop();
    };
    if task.thread_id == 0 {
        kpanic("tried to kill idle_task");
    };
}

setup_interrupts :: fn() void = {
    init_interrupt_vector();
    init_gic();
    init_timer();
    init_uart();
    barrier();
}

init_interrupt_vector :: fn() void #use(Arm) = {
    InterruptVector :: Array(Array(u32, 32), 16);
    interrupt_handlers := @static(Array(u8, size_of(InterruptVector) * 2));
    interrupt_base := align_the_thing(interrupt_handlers, 2048, size_of(InterruptVector));
    interrupt_handlers := InterruptVector.ptr_from_raw(interrupt_base);
    // TODO: have a way to ask for the global to have the right alignment
    // TODO: have a more official way to ask for it to be in executable memory
    
    // this assumes we're starting in el1 and don't have to set any interrupt masks, etc.
    
    // TODO: idk if i have to enable the caches somehow but i figure this can't hurt
    cc :: import("@/lib/sys/process.fr").aarch64_clear_instruction_cache;
    clear_cache :: AsmFunctionArmOnly(fn(beg: rawptr, end: rawptr) void = (), cc);
    
    // this is a pain because AsmFunction doesn't have a way to do relocations.
    // but since this runs before memory protection is set up, its fine to patch the jump offsets. 
    
    // each slot of the InterruptVector is limited to 32 instructions, 
    // just branch to a seperate function where the size doesn't matter. 
    int_callee := @as(rawptr) interrupt_trampoline;
    each interrupt_handlers { it |
        // TODO: tell it which one this is somehow
        src := u32.raw_from_ptr(it.index(0));
        it[0] = b(ptr_diff(src, int_callee) / 4, 0);
        clear_cache(src, src.offset(128));
    };
    
    // :patch interrupt_trampoline calls syscall_func
    i := @run interrupt_trampoline_code.index_of(arm_nop).unwrap();
    i += 1;  // TODO: really shouldn't force a bti because this super error prone
    src := u32.ptr_from_raw(int_callee).offset(i);
    dest := u32.ptr_from_raw(@as(rawptr) syscall_func);
    // with_link=0, the handler is expected to call return_to_user
    src[] = b(ptr_diff(src, dest), 0);
    clear_cache(int_callee, int_callee.offset(128));
    
    sys_set(*InterruptVector, .VBAR_EL1, interrupt_handlers);
    @run assert_eq(size_of(InterruptVector), 0x800);
}

// generic interrupt controller
// TODO: get these numbers from devicetree.intc@<whatever>.reg (addr, size) pairs
gicd :: 0x08000000;
gicr :: 0x080a0000;
init_gic :: fn() void = {
    // ignore interrupts with lower priority than PMR 
    // (but 255 is low, 0 is high, so this means allow all). 
    i64.sys_set(.ICC_PMR_EL1, 255);  
    i64.sys_set(.ICC_IGRPEN1_EL1, 1);  // enable group 1 interrupts
    
    u32.volatile(gicd + 0x0000, 0b10);  // CTLR.EnableGrp1NS=1
    // there's a whole thing about waking up the redistributor with GICR_WAKER (rd_lpi + 0x0014) 
    // but it seems fine. (maybe a problem once i have more cores)
}

// EL1 Physical Timer. INTID defined by the Server Base System Architecture (doesn't show in device tree?)
timer_irq :: 30;
init_timer :: fn() void = {
    // one per core but i only have one core
    rd_sgi: i64 = gicr + 0x10000;

    // timer is private so its enabled in ---R only. 
    // any priority/ICFGR is fine.
    set_field(timer_irq, rd_sgi + 0x80, 1, 1);  // IGROUPR0 set to group 1
    set_field(timer_irq, rd_sgi + 0x100, 1, 1); // ISENABLER0 
    
    reset_countdown();
    i64.sys_set(.CNTP_CTL_EL0, 1);  // turn it on
}

reset_countdown :: fn() void = {
    frequency := i64.sys_get(.CNTFRQ_EL0);
    i64.sys_set(.CNTP_TVAL_EL0, frequency / 200);
}

// TODO: the 1 is the middle number in devicetree.pl011@<whatever>.interrupts
irq_uart :: 32 + 1;
init_uart :: fn() void = {
    // any priority/ICFGR is fine. IROUTER doesn't matter because i only have one core.
    set_field(irq_uart, gicd + 0x80, 1, 1);  // IGROUPR set to group 1
    set_field(irq_uart, gicd + 0x100, 1, 1); // ISENABLER 
    
    // RSR,LCR_H,DMACR seem to be fine as reset=0.
    // strangely so are IBRD,FBRD (you're supposed to compute them from clock-frequency in device tree and desired baudrate)
    
    // ask for interrupt when it recieves something
    u32.volatile(uart + 0x038, 0b10000);  // IMSC
    // TODO: some bits are "reserved do not modify"
    // enable and allow transmit + recieve
    u32.volatile(uart + 0x030, 0b1100000001);  // CR  
};

set_field :: fn(interrupt_id: i64, addr: i64, bit_width: i64, value: u32) void #inline = {
    mask: u32 = 1.shift_left(bit_width) - 1;
    value := value.bit_and(mask);
    count_per_word := 32.udiv(bit_width);
    shift := interrupt_id.umod(count_per_word) * bit_width;
    idx := interrupt_id.udiv(count_per_word);
    addr += idx * 4;
    old := u32.volatile(addr);
    new := old.bit_and(mask.shift_left(shift).bit_not()).bit_or(value.shift_left(shift));
    u32.volatile(addr, new);
}

Arm :: import("@/backend/arm64/bits.fr");
// - don't need to save sp here, sp=SP_EL1 already, have to explicitly access SP_EL0 to get the userspace one. 
interrupt_trampoline :: AsmFunctionArmOnly(fn() void = (), interrupt_trampoline_code);
interrupt_trampoline_code :: {
    #use(Arm);
    out := u32.list(64, ast_alloc());
    emit :: fn(inst) => out&.push(inst);
    
    // briefly save x0 so i can use it to save the rest 
    // TODO: this is not ok if its el1 code being interrupted. its fine if its el0 because that uses a different sp. 
    emit(str_uo(.X64, x0, sp, 0));  
    emit(mrs(x0, .TPIDR_EL1));
    
    @debug_assert_eq(SavedRegisters.offset_of(.gpr), 0);
    range(0, 16) { r |
        a, b := (r*2, r*2+1);
        off := r * 2;
        emit(stp_so(.X64, a, b, x0, @as(i7) off));
    };
    emit(ldr_uo(.X64, x1, sp, 0));  // move the saved x0 to gpr[0]
    emit(str_uo(.X64, x1, x0, 0));  // ^
    
    // since syscall_func never returns, it never unwinds its stack frame, so manually reset sp at the beginning. 
    off := Task.offset_of(.kernel_sp) / 8;
    @debug_assert_lt(off, 1.shift_left(12));
    emit(ldr_uo(.X64, x1, x0, off));
    emit(add_im(.X64, sp, x1, 0, 0));
    
    @assert_lt(SavedRegisters.offset_of(.fpr) / 16 + 32, 1.shift_left(6));
    range(0, 16) { r |
        a, b := (r*2, r*2+1);
        off := r * 2 + SavedRegisters.offset_of(.fpr) / 16;
        emit(f_stp_so(FType.Q128, a, b, x0, @as(i7) off));
    };
    
    // call syscall_func(task = x0)
    // (which will save some special registers to task.mcontext itself)
    emit(arm_nop);  // :patch
    @debug_assert_eq(out.items().index_of(arm_nop).unwrap(), out.len - 1, "patch must be first nop");
    out.items()
};

// read SavedRegisters
return_to_user :: AsmFunctionArmOnly(fn(task_x0: *Task) Never = (), {
    #use(Arm);
    out := u32.list(64, ast_alloc());
    emit :: fn(inst) => out&.push(inst);
    
    // restore special registers
    off := SavedRegisters.offset_of(.elr);
    @debug_assert_eq(off, SavedRegisters.offset_of(.spsr) - 8);
    off /= 8;
    emit(ldp_so(.X64, x1, x2, x0, @as(i7) off));
    emit(msr(.ELR_EL1, x1)); 
    emit(msr(.SPSR_EL1, x2)); 
    @debug_assert_eq(SavedRegisters.offset_of(.gpr), 0);
    emit(ldr_uo(.X64, x1, x0, @as(i7) sp));
    emit(msr(.SP_EL0, x1)); 
    emit(msr(.TPIDR_EL1, x0)); 
    // TODO: set TTBR0_EL1
    // (because each task should have its own address space)
    
    range(0, 16) { r |
        a, b := (r*2, r*2+1);
        off := r * 2 + SavedRegisters.offset_of(.fpr) / 16;
        emit(f_ldp_so(FType.Q128, a, b, x0, @as(i7) off));
    };
    
    // restore general registers. 
    // rev so x0 is last to be restored so it can be used as indexer
    // note: x31 here is xzr not sp.
    range_rev(0, 16) { r |
        a, b := (r*2, r*2+1);
        off := r * 2;
        emit(ldp_so(.X64, a, b, x0, @as(i7) off));
    };
    
    // jump to ELR_EL1 = task.mcontext.elr
    emit(eret);  
    
    out.items()
});

return_to_scheduler :: fn() Never = {
    barrier();
    kernel := kernel();
    cap := size_of(@type kernel.tasks) / size_of(Task);
    i := kernel.next_task_to_run&;
    range(0, cap) { _ |
        task := kernel.tasks&[i[]]&;
        i[] = i[].add(1).mod(cap);
        if task.active && task.futex_wait == 0 {
            // TODO: doing this means i can't use it for actual timer
            // if the guy before you used most of their time slice and then did a syscall that yielded,
            // the next guy should still get a full time slice, 
            // otherwise you could starve people by controlling the order processes get spawned. 
            reset_countdown();
            
            return_to_user(task);
        };
    };
    reset_countdown();
    return_to_user(kernel.idle_task&)
}

stop :: fn() Never = {
    dump_page_stats();
    kprint("goodbye!\n");
    poweroff()
}

align_the_thing :: fn(it: ~T, need_align: i64, need_size: i64) rawptr #where = {
    tt := int_from_ptr(@type it[], it);
    start := tt; 
    end := start + size_of(@type it[]);
    tt := tt.ualign_to(need_align);
    if tt + need_size > end {
        kprint("fucked\n!!!\n");
    };
    rawptr_from_int(tt)
}

// all the barriers for good luck
barrier :: @AsmFunctionArmOnly(fn() void = ()) => (
    @bits(0b11010101000000110011, 0b1111, 0b101, 0b11111),  // DMB SY
    @bits(0b11010101000000110011, 0b1111, 0b100, 0b11111),  // DSB SY
    @bits(0b11010101000000110011, 0b1111, 0b110, 0b11111),  // ISB SY
    ret(),
);

user_exec :: fn(elf_bytes: []u8) void = {
    _, c := create_and_set_unsafe_environment();
    c.panic_hook = print_and_exit1;
    c.prefer_syscalls = true;
    c.current_os = 1;
    c.temporary_allocator_i = Arena'stack_alloc(1.shift_left(15));
    // TODO: its sad that i have to commit new pages for the bytes copied 
    //       for Load commands but not accessed by the running program.
    import("@/examples/elf_loader.fr")'load_elf_file(elf_bytes);
}

Task :: @struct {
    // mcontext must be the first field because the interrupt handler starts saving at TPIDR_EL1
    mcontext: SavedRegisters;  
    mem: AddressSpace;
    kernel_sp: *u8;
    signal_handler: i64;  // @FnPtr(task: *Task) void;
    signal_stack: i64;
    signal_stack_left: i64;
    thread_id: i64;
    futex_wait: i64;  // *u32
    active: bool;
};

SavedRegisters :: MContext;
tracing :: false; 
// for now im using the same handler for every slot of the InterruptVector
syscall_func :: fn(task: *Task) void = {
    return :: ();  // must do it via return_to_user
    
    kernel := kernel();
    set_dynamic_context(kernel.env);
    args := task.mcontext&;
    
    if tracing {
    kprint("=== inside syscall_func ===\n");
    }; 
    
    // these are restored by return_to_user
    args.elr = i64.sys_get(.ELR_EL1);
    args.spsr = i64.sys_get(.SPSR_EL1);
    args.gpr&[31] = i64.sys_get(.SP_EL0);
    
    // these being in SavedRegisters isn't important because i don't restore them 
    // but it seems convient to have one context thing you can pass around.
    // TODO: if i keep these do it in the assembly part instead of as a bunch of calls here. 
    args.esr = i64.sys_get(.ESR_EL1);
    args.far = i64.sys_get(.FAR_EL1);
    args.intid = i64.sys_get(.ICC_IAR1_EL1).bit_and(0xfff);
    
    intid: u32 = args.intid.trunc();
    intid0 := i64.sys_get(.ICC_IAR0_EL1).bit_and(0xfff);
    if intid0 != 1023 {
        kpanic("intid0");
    };
    if tracing {
    kprint_label("thread pointer: ", SavedRegisters.int_from_ptr(args));
    kprint_label("SP_EL0: ", i64.sys_get(.SP_EL0));
    kprint_label("saved fp: ", args.gpr&[29]);
    kprint_label("intid: ", intid.zext());
    };
    
    if intid == irq_uart {
        //                     TMIS           RXMIS
        if u32.volatile(uart + 0x040).bit_and(0b10000) == 0 {
            kpanic("got uart interrupt but not ready to receive");
        };
        byte := getchar();  // the read clears the bit  ^
        
        // always the init task! not whatever task was interrupted. 
        init := kernel.tasks&[0]&;
        @if(init.signal_handler == 0) kpanic("got input before init signal handler");
        push_signal_context(init);
        init.mcontext.gpr&[1] = intid.zext();
        init.mcontext.gpr&[2] = byte.zext();  // HACK
        return_to_user(init);
    };
    
    exception_class := args.esr.shift_right_logical(26).bit_and(0b111111);
    
    if intid == 1023 {
        if exception_class == 0b100100 {
            vaddr := args.far.align_back(PAGE_SIZE);
            
            if vaddr.bit_and(1.shift_left(42).sub(1).bit_not()) != 0 {
                kprint("data abort from el0\n");
                kprint_label("fault address: ", args.far);
                kprint_label("ip: ", args.elr);
                send_signal(task);
            };
            
            // TODO: don't create a L2 table for it if its just a junk pointer 
            pte := index_page_table(kernel, task.mem&, vaddr);
            if pte.res.get(.tag) == 0b00 && pte.res.get(.reserved) == 0b1 {
                pte.res.repr = 0;  // TODO: store permissions there and pass them to vmap_one
                vmap_one(kernel, task.mem&, vaddr, kernel.physical&.map(1));
                return_to_user(task);
            };
            
            kprint("data abort from el0\n");
            kprint_label("fault address: ", args.far);
            kprint_label("ip: ", args.elr);
            send_signal(task);  // give userspace a chance to print a stack trace
        };
        
        if exception_class == 0b100101 {
            // TODO: its fine for user to pass pointer to memory they haven't touched yet (implicitly zeroed)
            //       to a syscall, so should do the auto commit here as well.  
            kpanic("data abort from el1");
        };
        
        if exception_class == 0b011000 {
            inst := u32.ptr_from_int(args.elr)[];
            kprint("trapped system instruction\n");
            kprint_label("instruction: ", inst.zext());
            send_signal(task);
        };
        
        if exception_class == 0b111100 {
            inst := u32.ptr_from_int(args.elr)[];
            context := inst.shift_right_logical(5).bit_and(0xFFFF);
            kprint_label("executed brk: ", context.zext());
            send_signal(task);
        };
    
        is_svc := exception_class == 0b010101;
        if is_svc {
            syscall_number := args.gpr&[8];
            if syscall_number != args.gpr&[16] {
                tpanic("perform_syscall always uses both x8 and x16");
            };
            // note: not iterating over the array at runtime so it doesn't need data relocations so the kernel is PIC
            calls :: @run import("@/examples/os/kernel/syscalls.fr")'generate();
            inline_for calls { $it |
                callee, n := @run it[];
                if syscall_number == n {
                    callee(task);
                    return_to_user(task);
                }
            };
            // unknown syscall
            send_signal(task);
        };
        
        kprint_label("FAR_EL1: ", args.far);
        kprint_label("ESR_EL1: ", args.esr);
        kprint_label("SPSR_EL1: ", args.spsr);
        kprint_label("ELR_EL1: ", args.elr);
            kprint_label("exception class: ", exception_class);
            if exception_class == 0 {
                inst := u32.ptr_from_int(args.elr)[];
                kprint_label("instruction: ", inst.zext());
            };
            
        send_signal(task);
    };
    
    if intid == timer_irq {
        kernel.timer_counter += 1;
        i64.sys_set(.ICC_EOIR1_EL1, intid.zext());
        return_to_scheduler();  // this does reset_countdown
    };
    
    if intid != timer_irq && intid != irq_uart { 
        kprint_label("intid: ", intid.zext());
        kpanic("unknown interrupt");
    };
    
    return_to_scheduler();
};

dump_page_stats :: fn() void = {
    kernel := kernel();
    kprint_label("pages_remaining: ", kernel.physical.remaining.len / PAGE_SIZE);
    kprint_label("pages_reserved : ", kernel.pages_reserved);
    kprint_label("pages_committed: ", kernel.pages_committed);
    kprint_label("pages_reserved_freed : ", kernel.pages_reserved_freed);
    kprint_label("pages_committed_freed: ", kernel.pages_committed_freed);
    kprint_label("next_vaddr: ", kernel.next_vaddr);
}

push_signal_context :: fn(task: *Task) void = {
    task.futex_wait = 0;
    if task.signal_handler != 0 {
        ctx := task.mcontext&;
        // TODO: this is still fucked if its interrupted while pushing or popping 
        //       the frame for the signal handler in userspace
        @if(task.signal_stack == ctx.gpr&[31]) kpanic("todo: interrupted before pushing stack frame");
        if ctx.gpr&[31] > task.signal_stack_left && ctx.gpr&[31] < task.signal_stack {
            // when sending a nested signal, update for whatever stack frames have been pushed in user space. 
            task.signal_stack = ctx.gpr&[31];
        };
        
        task.signal_stack -= size_of(SavedRegisters);
        saved := SavedRegisters.ptr_from_int(task.signal_stack);
        saved[] = ctx[];
        ctx.elr = task.signal_handler;
        ctx.gpr&[0] = task.signal_stack;
        ctx.gpr&[1] = ctx.intid;
        ctx.gpr&[2] = 0;
        ctx.gpr&[31] = task.signal_stack;
        ctx.gpr&[30] = launder_to_user_pointer(user_unwind_signal);
        
        if task.signal_stack < task.signal_stack_left {
            tpanic(task, "too many nested signals");
        };
    } else {
        tpanic(task, "no signal handler")
    };
}

send_signal :: fn(task: *Task) Never = {
    push_signal_context(task);
    return_to_scheduler()
}

launder_to_user_pointer :: fn(a: rawptr) i64 #noinline = a.int_from_rawptr() + 512*1024*1024;

user_unwind_signal :: @AsmFunctionArmOnly(fn(intid_x0: i64) Never = ()) => (
    add_im(.X64, x1, sp, 0, 0),
    movz(.X64, x16, 0xFFFF, Hw.Left16),
    movk(.X64, x16, 0x0004, Hw.Left0),
    mov(.X64, x8, x16),
    svc,  // sig_return
    // :end_user_unwind_signal
);

Crash :: import("@/lib/crash_report.fr");

poweroff :: fn() Never = {
    hypervisor_call :: @AsmFunctionArmOnly(fn(n: i64) Never = ()) => (
        hvc,
        ret(), 
    );
    // not listed in the devicetree's psci section which is strange (cpu_off is there but doesn't do what i want). 
    // Arm Power State Coordination Interface. Version 1.3 issue F.b
    SYSTEM_OFF :: 0x84000008;
    hypervisor_call(SYSTEM_OFF)
}

fn tpanic(msg: Str) Never = 
    tpanic(sys_get(*Task, .TPIDR_EL1), msg);

fn tpanic(task: *Task, msg: Str) Never = {
    kprint("killed ");
    kscary_log(task.thread_id);
    kprint(": ");
    kprint(msg);
    kprint("\n");
    kill_task(task);
    return_to_scheduler()
}

kpanic :: fn(msg: Str) Never = {
    kprint("we're so fucked\n===\n");
    kprint(msg);
    kprint("\n===\ni repeat, we're so fucked\n");
    poweroff()
};

kprint_label :: fn(msg: Str, value: i64) void = {
    kprint(msg);
    kscary_log(value);
    kprint("\n");
}

spin :: fn() Never = {
    loop {
        (@AsmFunctionArmOnly(fn() void = ()) => (
            wfi,
            ret(), 
        ))();
    };
}

kprint :: fn(s: Str) void = {
    for s { c |
        //u32.volatile(uart, c.zext());
    };
}

// TODO: read the magic number from the device tree thingy?
// https://developer.arm.com/documentation/ddi0183/g/programmers-model/summary-of-registers?lang=en
uart :: 0x09000000;

getchar :: fn() u8 = {
    u32.volatile(uart).trunc()
}

// TODO: can't decide if this is where i want to go with this
SerialPort :: @struct {
    addr: i64;
    intid: i64;
    interrupt: @FnPtr(ctx: *MContext) void;
    putchar: @FnPtr(c: u8) void;
    getchar: @FnPtr() u8;
};

// TODO: can't let it try to bake the junk address or it crashes in bake_relocatable_constant :compilerbug
fn volatile($T: Type, addr: i64, value: T) void #noinline #generic = {
    bit_cast_unchecked(i64, *T, addr)[] = value;
}

fn volatile($T: Type, addr: i64) T #noinline #generic = {
    bit_cast_unchecked(i64, *T, addr)[]
}

fn kscary_log(i: i64) void = {
    buf := @uninitialized Array(u8, 24);
    buf := buf&.items();
    len := write_int_to_buffer(buf, i);
    kprint(buf.slice(0, len));
}

// TODO: this is a neat demo but it would be more simple to just make the syntax such that it doesn't resolve
//       eagarly which might just mean using `fn() = {}` instead of `fn() => ()` but then its annoying to get 
//       the tuple out of the block... idk this whole operation is kinda dumb anyway. 
// this is convoluted to trick it into resolving the expression in the context of #use(arm/bits)
fn AsmFunctionArmOnly(signeture: FatExpr, code: FatExpr) FatExpr #macro = {
    signeture := FuncId.const_eval(signeture);
    code_fid := FuncId.const_eval(code);
    code := get_function_ast(code_fid, false, false, false, false);
    ::tagged(@type code.body);
    @debug_assert(code.body&.is(.Normal));

    code.body.Normal = @{ @const_slice(@[code.body.Normal]) };
    unresolve_scopes(code.body.Normal&);
    
    code.resolve_scope = FuncId.scope_of(fn() = {
        // the body of `code` will be able to see any constants declared here.
        #use(Arm);
    });
    // TODO: makes sense that you need this,
    //       but you shouldn't panic without it, should be an error instead of 
    //       `panic! Unreachable unless you set the load factor to 100%`
    code.unset_flag(.ResolvedBody);
    
    code := Slice(u32).const_eval(@{ @[@literal code_fid]() });
    @literal AsmFunctionArmOnly(signeture, code)
}

// time to do some sketchy shit do da do da
fn unresolve_scopes(expr: *FatExpr) void = {
    #use("@/compiler/walk_ast.fr");
    #use("@/compiler/ast_external.fr");
    UnResolve :: @struct();
    ::WalkAst(UnResolve, void);
    
    // TODO: `@ref(@as(UnResolve) ())` ambigous overload for FatExpr -> FatExpr. :compilerbug?
    unresolve: UnResolve = ();  
    walk_expr(unresolve&, expr);

    fn handle_expr(self: *UnResolve, expr: *FatExpr) Result(DoMore, void) = {
        @match(expr.expr&) {
            fn GetVar(it) => {
                expr.expr = (GetNamed = it.name);
            }
            fn UndeclaredVar(it) => {
                expr.expr = (GetNamed = it.name);
            }
            fn Block(it) => {
                it.flags = it.flags.bit_and(bit_not(1.shift_left(@as(i64) BlockFlags.Resolved)));
                it.scope = NOSCOPE;
            }
            @default => ();
        };
        (Ok = .Continue)
    }
    fn handle_stmt(self: *UnResolve, stmt: *FatStmt) Result(DoMore, void) = (Ok = .Continue);
    fn handle_type(self: *UnResolve, type: *LazyType) Result(DoMore, void) = (Ok = .Continue);
    fn handle_func(self: *UnResolve, func: *Func) Result(DoMore, void) = (Ok = .Continue);
    fn handle_pattern(self: *UnResolve, pattern: *Pattern) Result(DoMore, void) = (Ok = .Continue);
}

#use("@/examples/os/libkernel.fr");
#use("@/lib/sys/process.fr");  // TODO: maybe sys_get/sys_set should go somewhere else
