// https://docs.oasis-open.org/virtio/virtio/v1.3/virtio-v1.3.html
// i only support the pci transport mechanism, split virtqueues. 

pci_vendor_id :: 0x1AF4;

// 4.1.4.3 Common configuration structure layout
PciCommonCfg :: @struct {
    device_feature: Features;
    driver_feature: Features;
    config_msix_vector: u16;
    num_queues: u16;
    status: u8;
    config_generation: u8;
    
    queue_select: u16;
    queue_size: u16;
    queue_msix_vector: u16;
    queue_enable: u16;
    queue_notify_off: u16;
    queue_desc: *Desc;          // physical!
    queue_driver: *Queue.Head;  // physical!
    queue_device: *Queue.Head;  // physical!
    queue_notif_config_data: u16;
    queue_reset: u16;

    admin_queue_index: u16;
    admin_queue_num: u16;
};

Features :: @struct {
    select: u32;
    value: u32;
};

// 4.1.4 Virtio Structure PCI Capabilities
PciCap :: @struct {
    cap_vndr: u8;
    cap_next: u8;
    cap_len: u8;
    cfg_type: PciCapTag;
    bar: u8;  // which base-address-register from pci header
    id: u8;
    _: Array(u8, 2);
    // slice of bar
    offset: u32;
    length: u32;
};

PciCapTag :: @enum(u8) (_0, COMMON, NOTIFY, ISR, DEVICE, PCI, _6, _7, SHARED_MEMORY, VENDOR);

// when we get an interrupt, need to look through all the queues to find which one changed. 
Device :: @struct {
    queues: []Queue;
    // intid and interupt_status are important for usage. 
    // the other fields are needed only when creating queues. 
    handle: *DeviceHandle #use;
    label := zeroed Array(u8, 40);  // for syscalls.virtq_create
};

// call sequence: init_features -> init_queue xN -> publish_queues -> notify_device
Queue :: @struct {
    desc: []Desc;
    driver: @struct {  // avail  VIRTQ_AVAIL_F_NO_INTERRUPT(1)
        head: *Head #use;
        ring: []u16;
        tail: *Tail #use;
    };
    device: @struct {  // used  VIRTQ_USED_F_NO_NOTIFY(1)
        head: *Head #use;
        ring: []UsedElem;
        tail: *Tail #use;
    };
    notify: *u16;
    
    Head :: @struct(flags: u16, idx: u16);
    Tail :: @struct(event: u16); /* Only if VIRTIO_F_EVENT_IDX */ 
    
    buf: []u8;  // all the physical memory backing this queue
    this_queue_index: u16;
    // next thing we'll write to driver.head.idx 
    // (to allow delaying making a change public until a whole chain is ready)
    driver_idx: u16;  
    driver_chain_start: ?u16;
    driver_next_desc: u16;
    // last thing we read from device.head.idx
    // (so we don't miss anything)
    device_idx: u16;  
    
    user: ?*UQueue;  // need to be able to find this to wake it on interrupt
};

// TODO: unclear if i need to align `device` to 4096
memory_needed :: fn(s: i64) i64 = {
    size_of(Desc)*s + size_of(Queue.Head)*2 + size_of(Queue.Tail)*2 + size_of(u16)*2*s
}

fn init_queue(cfg: *PciCommonCfg, q: *Queue, q_index: u16, buf: *[]u8, size: i64, notify: ?NotifyStep) void = {
    init_pipe :: fn(it, $T) => {
        it.head = buf.pop_type(Queue.Head);
        it.ring = buf.pop_slice(T, size);
        it.tail = buf.pop_type(Queue.Tail);
    };
    start := buf[];
    q.this_queue_index = q_index;
    q.user = .None;
    q.desc = buf.pop_slice(Desc, size);
    init_pipe(q.driver&, u16);
    init_pipe(q.device&, UsedElem);
    q.buf = (ptr = start.ptr, len = start.len - buf.len);
    
    cfg.queue_select&.vol(q_index);
    // TODO: check that it accepts our `size`
    max_queue_size := cfg.queue_size&.vol();
    @if(max_queue_size == 0) kpanic("invalid queue");
    @if(size > max_queue_size.zext()) kpanic("queue size too large");
    cfg.queue_size&.vol(size.trunc());  
    @if(cfg.queue_size&.vol() != size.trunc()) kpanic("queue size not accepted");
    cfg.queue_desc&.vol(q.desc.index(0));
    cfg.queue_driver&.vol(q.driver.head);
    cfg.queue_device&.vol(q.device.head);
    cfg.queue_enable&.vol(1);
    
    if notify { notify |
        notify := bit_cast_unchecked(*u8, i64, notify.bar.ptr)
            + notify.base + cfg.queue_notify_off&.vol().zext() * notify.off_multiplier;
        q.notify = u16.ptr_from_int(notify);
    };
    
    q.driver_chain_start = .None;
}

fn publish_queues(cfg: *PciCommonCfg) void = {
    barrier();
    cfg.status&.vol(cfg.status&.vol().bit_or(4));  // DRIVER_OK
    status := cfg.status&.vol();  // READING SOMETHING IS IMPORTANT on avf ??
    @if(status != 15) kpanic("driver failed to init");  // TODO: don't crash
}

NotifyStep :: @struct {
    bar: []u8;
    base: i64;
    off_multiplier: i64;
};

fn notify_device(q: *Queue) void = {
    barrier();
    @if(q.notify.is_null()) return();
    q.notify.vol(q.this_queue_index);
    barrier();
}

fn push_virt(q: *Queue, virtual: []u8, flags: u16) void = {
    // the addresses in Virt.Desc are physical, so step through each page of the message 
    // and manually translate the addresses before pushing them to the queue. 
    // (because physical memory is only contiguous at page granularity)
    mem: AddressSpace = (root = sys_get(*TranslationTable, .TTBR0_EL1));
    v := u8.int_from_ptr(virtual.ptr);
    len := virtual.len;
    while => len > 0 {  
        // TODO: check memory permissions and commit the pages here
        p := v_to_p(mem&, v);
        space := p.align_to(kernel.page_size) - p;
        if space == 0 {
            space = kernel.page_size;
        }
        space := min(space, len);
        q.push_phys(u8.ptr_from_int(p).slice(space), flags);
        len -= space;
        v += space;
    };
}

// don't forget to publish_chain() after!
fn push_phys(self: *Queue, physical: []u8, flags: u16) void = {
    @debug_assert_eq(physical.len.bit_and(MAX_u32), physical.len);
    id := self.driver_next_desc;
    next: u16 = id.zext().add(1).umod(self.desc.len).trunc();
    self.driver_next_desc = next;
    flags = flags.bit_or(DESC_F_NEXT);
    it := self.desc[id.zext()]&;
    it.addr = physical.ptr;
    it.len = physical.len.trunc();
    it.flags = flags;
    it.next = next;
    if self.driver_chain_start.is_none() {
        self.driver_chain_start = (Some = id);
    };
}

fn publish_chain(self: *Queue) void = {
    chain_start := self.driver_chain_start&.take()
        || return();

    // push_phys automatically chains sequential descriptors, 
    // now that we're done, mark the previous one as the end of the chain. 
    last: i64 = self.driver_next_desc.zext() - 1;
    if last < 0 {
        last = self.desc.len - 1;
    };
    desc := self.desc[last]&;
    desc.flags = desc.flags.bit_and(DESC_F_NEXT.bit_not().trunc());
    desc.next = 0;
    
    i: i64 = self.driver_idx.zext().umod(self.desc.len);
    self.driver.ring[i] = chain_start;
    barrier();
    self.driver_idx += 1;  // free running until wrap
    self.driver.head.idx&.vol(self.driver_idx);
    self.notify_device();
}

DESC_F_NEXT :: 1;
DESC_F_WRITE :: 2;
Desc :: @struct {
    addr: *u8;  // physical!
    len: u32;
    flags: u16; 
    next: u16;  // valid if VIRTQ_DESC_F_NEXT
};

UsedElem :: @struct { 
    id: u32; 
    len: u32; 
};
 
// TODO: error if they don't agree on features
// TODO: allow optional features
fn init_features(self: *PciCommonCfg, required: i64) i64 = {
    self.status&.vol(0);  // reset
    // todo: don't hang if the device never responds
    dowhile(=> self.status&.vol() != 0);  
    self.status&.vol(self.status&.vol().bit_or(1));  // ACKNOWLEDGE
    self.status&.vol(self.status&.vol().bit_or(2));  // DRIVER
    offered := self.device_feature&.get();
    agree := required.bit_and(offered);
    self.driver_feature&.set(agree);
    self.status&.vol(self.status&.vol().bit_or(8));  // FEATURES_OK
    features_ok := self.status&.vol().bit_and(8) != 0;
    if !features_ok {
        agree = 0;
    };
    agree
}

fn check_interrupt(self: *Virt.Device, intid: i64) void = {
    @if(intid != self.intid) return();
    @if(self.interrupt_status.is_null()) return();
    @if(self.handle.interrupt_status.vol().bit_and(1) == 0) return();
    // interrupt_status is reset to zero by reading it
    
    each self.queues { q |
        if q.user { user |
            if q.device.head.idx&.vol() != q.device_idx {
                #use("@/examples/os/kernel/syscalls.fr");
                _ := do_virtq_poll(user);
            };
        };
    };
}

fn set(self: *Features, it: i64) void = {
    self.select&.vol(1);
    self.value&.vol(it.shift_right_logical(32).trunc());
    self.select&.vol(0);
    self.value&.vol(it.trunc());
}

fn get(self: *Features) i64 = {
    self.select&.vol(1);
    hi := self.value&.vol();
    self.select&.vol(0);
    lo := self.value&.vol();
    hi.zext().shift_left(32).bit_or(lo.zext())
}

fn find_pci_cap(h: *Pci.Header, want: PciCapTag) ?*PciCap = {
    for_cap h { c |
        ::enum(@type want);
        if c.cap_vndr&.vol() == 9 && c.cfg_type&.vol() == want {
            return(Some = c);
        };
    };
    .None
}

DeviceHandle :: @struct {
    cfg: *Virt.PciCommonCfg;
    note: ?Virt.NotifyStep;
    interrupt_status: *u8;
    intid: i64;
    device_config: ?[]u8;
    kind: *KnownDevice;
};

discover_all :: fn(pci: *Pci.MemoryRegion) void = {
    range(0, pci.config.len / 4096) { i |
        continue :: local_return;
        h := bit_cast_unchecked(*u8, *Pci.Header, pci.config.index(i*4096));
        vendorid := h.vendor_id&.vol();
        if(vendorid == 0xFFFF, => continue());
        
        if(vendorid != Virt.pci_vendor_id, => continue());
        id := h.device_id&.vol();
        if implemented.find(fn(it) => id == 0x1040 + it.id || id == 0x1000 + it.id) { kind |
            handle := discover_one(pci, i*4096, h, kind);
            kernel.handles&.push(handle);
        }
    };
}

discover_one :: fn(pci: *Pci.MemoryRegion, a: i64, h: *Pci.Header, kind: *KnownDevice) DeviceHandle = {
    intid := find_interrupt(pci[], h) || -1;
    
    h.command&.vol(0b110);  // enable memory space
    
    c := h.find_pci_cap(.COMMON).unwrap();
    bar_index := c.bar&.volatile();
    
    legal_pci_addr := u8.int_from_ptr(pci.bar.ptr) + pci.bar_offset;  
    bar := Pci'set_bar64(h, bar_index, legal_pci_addr, false);
    if u8.int_from_ptr(bar.mem.ptr) == legal_pci_addr {
        pci.bar_offset += bar.size;
    };
    cfg := bit_cast_unchecked(*u8, *Virt.PciCommonCfg, bar.mem.index(c.offset&.vol().zext()));
    
    note: ?Virt.NotifyStep = .None;
    if h.find_pci_cap(.NOTIFY) { c | 
        @if(bar_index != c.bar&.vol()) kpanic("TODO: can this happen?");
        note = (Some = (
            off_multiplier = u32.vol(int_from_ptr(@type c[], c) + size_of(@type c[])).zext(),
            base = c.offset&.vol().zext(),
            bar = bar.mem,
        ));
    };
    config: ?[]u8 = .None;
    if h.find_pci_cap(.DEVICE) { c |
        @if(bar_index != c.bar&.vol()) kpanic("TODO: can this happen?");
        config = (Some = bar.mem.subslice(c.offset&.vol().zext(), c.length&.vol().zext()));
    };
    status: *u8 = zeroed(*u8);
    if h.find_pci_cap(.ISR) { c |
        @if(bar_index != c.bar&.vol()) kpanic("TODO: can this happen?");
        status = bar.mem.index(c.offset&.vol().zext());
    };
    (
        cfg = cfg, note = note, device_config = config, 
        interrupt_status = status, intid = intid,
        kind = kind,
    )
}

fn init(it: *DeviceHandle) ?Device = {
    feat := it.kind.features;
    agree := it.cfg.init_features(feat);
    @if(agree != feat) kpanic("didn't agree on device features");
    
    // TODO: this is dumb
    buf := kernel.physical&.map_contiguous(1.shift_left(16), 1);
    each buf { it |
        it[] = 0;
    };
    
    hi := 0;
    for it.kind.queue_indices& { i |
        hi = max(hi, i);
    };
    
    qs := buf&.pop_slice(Virt.Queue, hi + 1);
    self: Device = (queues = qs, handle = it);
    for it.kind.queue_indices& { i |
        if i >= 0 {
            // TODO: better way of choosing the buffer size
            init_queue(it.cfg, qs.index(i), i.trunc(), buf&, 128, it.note);
        }
    };
    it.cfg.publish_queues();
    (Some = self)
}

Pci :: import("@/examples/os/drivers/pci.fr");

// TODO: relocations for name and queue_indices (make it a []i64)
KnownDevice :: @struct {
    id: u16;
    //name: Str;
    features: i64;
    queue_indices: Array(i64, 10);
};

VIRTIO_F_VERSION_1 :: 1.shift_left(32);

implemented :: @const_slice(@as(KnownDevice) (
    // Virtio Console (read/write a stream of bytes to a terminal)
    id = 3,
    //name = "console",
    features = VIRTIO_F_VERSION_1,
    // [RECEIVE, TRANSMIT]
    queue_indices = (0, 1, ..(-1)),
    // TODO: the spread ..-1 doesn't work without the extra brackets :compilerbug
), (
    // Virtio File System Device (FUSE, mounting a shared directory from the host)
    id = 26,
    //name = "fs",
    features = VIRTIO_F_VERSION_1,
    // [HIPRIO, REQUEST] (note: no VIRTIO_FS_F_NOTIFICATION)
    queue_indices = (0, 1, ..(-1)),
),
);

FsConfig :: @struct {
    tag: Array(u8, 36);
    num_request_queues: u32;
    // note: no VIRTIO_FS_F_NOTIFICATION
    // notify_buf_size: u32;
};

// note: this is only used for kernel logging (before setting up the UQueue)
fn console_write(self: *Virt.Device, virtual: []u8) void = {
    @if(virtual.len == 0) return();
    TRANSMIT :: 1;
    q := self.queues.index(TRANSMIT);
    self_dropped_write :: @static(i64);  // HACK
    if q.device_idx != q.driver_idx {
        // TODO: its kinda fucked to drop writes. 
        //       but without this, if you try to log while its being used by UQueue.poll,
        //       you hang everything. 
        self_dropped_write[] += 1;
        return();
    };
    q.push_virt(virtual, 0);
    
    // TODO: this needs to be nonblocking eventually but then the lifetime of the message gets complicated
    q.publish_chain();
    i := q.driver_idx;
    while => q.device.head.idx&.vol() != i {
        barrier();  // spin
    };
    q.device_idx = i;
    
    // TODO: sketchy
    if q.user { user |
        user.pipe.work&.set_all(q.device_idx.zext());
        user.pipe.done&.set_all(q.driver_idx.zext());
    };
    
    if self_dropped_write[] > 0 {
        self_dropped_write[] = MIN_i64;
        console_write(self, "\nWARNING: DROPPED A LOG MESSAGE\n");
        self_dropped_write[] = 0;
    }
}
