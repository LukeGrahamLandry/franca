
// stores just the compiled code, can be instantiated multiple times
Module :: @rec @struct {
    loader: import("@/examples/import_wasm/convert.fr").Loaded;
    w: WasmModule;
    counts: Counts;
    // function pointers from runtime.fr 
    // (only the ones reachable from this module)
    runtime: []rawptr;  
    
    // instead of always getting them from the *Qbe.Module,
    // this makes it more sane to compile() at comptime and then bake the whole thing. 
    functions: []rawptr;
    datas: [][]u8;
    m: ?*Qbe.Module;
    trace: ?*Crash.LocationResolverNode;
};

// the code linked with imports and storage for globals/tables
// this is passed as the first parameter to every wasm function.
Instance :: @struct {  // !Sized
    memory: *SaneRawList(u8);
    gpa: Alloc;
    counts: Counts;
    exports := zeroed RawHashMap(Str, Export);
    ordered_exports: []Export = empty();
    // unsized: View #inline;
    
    fn size(self: *Instance) i64 = {
        last := @as(Fields(View)) @as(i64) Fields(View).enum_count() - 1;
        compute_offset(self.counts&, last, self.counts&[last])
    }
    
    fn view(self: *Instance) View = {
        result := zeroed Array(Ty(i64, i64), Fields(View).enum_count());
        enumerate result& { i, it |
            field := @as(Fields(View)) i;
            it[] = (
                Instance.int_from_ptr(self) + compute_offset(self.counts&, field, 0),
                self.counts&.get(field),
            );
        };
        bit_cast_unchecked(@type result, View, result)
    }
    
    compute_offset :: fn(counts: *Counts, field: Fields(View), i: i64) i64 = {
        off := size_of(Instance);
        inline_for_enum Fields(View) { $it |
            T :: FieldType(View, it[]).Element;
            xxx := it[];
            xxx := (@as(i64) xxx) < (@as(i64) field);
            if xxx {
                off += size_of(T) * counts[it[]];
            };
            ::enum(@type field);
            if it[] == field {
                off += size_of(T) * i;
            };
        };
        off
    }
};

Counts :: EnumMap(Fields(View), i64);

// this data is stored inline after the fields of Instance
View :: @struct {
    local_globals: []GlobalValue;
    local_tables: []Table;
    globals: []*GlobalValue;
    tables: []*Table;
    imports: []Callable;  // functions only
    runtime: []rawptr;  // function pointers from runtime.fr
};

GlobalValue :: @union(i64: i64, i32: i32, f64: f64, f32: f32);
Table :: SaneRawList(Callable);

Callable :: @struct {
    callee: rawptr;
    context: rawptr;
};

// order must match ImportType
Export :: @tagged(
    Function: Callable,
    Table: *Table,
    Memory: *SaneRawList(u8),
    Global: *GlobalValue,
);

Engine :: @rec @struct {
    // TODO: could do much better than this if most modules are [large, of unique length, instantiated once]  
    //       if i just hash the length instead of needing to look at all the bytes. 
    modules: HashMap([]u8, @tagged(Ready: *Module, Compiling));
    debug: Str;
    lock := zeroed Mutex;
    target: Qbe.QbeTargetEnv;
    gpa: Alloc;
    generation: u32 = 0;
    storage: *Arena.Allocator;
    memories := zeroed RawList([]u8);
    instances := zeroed RawList(*Instance);
};

fn init_for_jit(a: Alloc, debug: Str) Engine = 
    init(a, (type = .JitOnly, os = query_current_os(), arch = query_current_arch()), debug);

fn init(a: Alloc, target: Qbe.QbeTargetEnv, debug: Str) Engine = {
    arena: Arena.Allocator = init(a, 1.shift_left(16));
    aa := arena&.borrow().box_uninit(@type arena);
    aa[] = arena;
    arena := aa;
    locked := arena.borrow().boxed(LockedAlloc, (parent = arena.borrow()));
(
    modules = init(locked.borrow()), 
    target = target,
    debug = debug,
    gpa = locked.borrow(),
    storage = arena,
)
}

// - don't want to hold the lock while compiling because that's slow
// - don't want multiple threads to compile the same module redundantly
fn compile(self: *Engine, wasm: []u8) *Module = {
    self.lock&.lock();
    if self.modules&.get(wasm) { it |
        ::tagged(@type it);
        while => it&.is(.Compiling) {
            value := self.generation;
            self.lock&.unlock();
            Futex'wait(self.generation&, value);
            self.lock&.lock();
            it = self.modules&.get(wasm).unwrap();
        };
        self.lock&.unlock();
        return it.Ready;
    };
    wasm = wasm.shallow_copy(self.gpa);
    // TODO: sad to refind the bucket here when it can't have changed
    _ := self.modules&.insert(wasm, .Compiling);
    self.lock&.unlock();
    mod := self.compile_uncached(wasm);
    self.lock&.lock();
    _ := self.modules&.insert(wasm, (Ready = mod));
    self.generation += 1;
    Futex'wake(self.generation&, MAX_i32);
    self.lock&.unlock();
    mod
}

fn compile_uncached(self: *Engine, wasm: []u8) *Module = {
    a := self.gpa;
    mod := a.box_zeroed(Module);
    mod.trace = .None;
    m := a.box_uninit(Qbe.Module);
    Qbe'backend'init_module(m, self.target);
    mod.m = (Some = m);
    m.set_debug_types(self.debug, true);
    mod.w = empty(a);
    p: ParseWasm = (w = mod.w&, src = wasm);
    or parse_wasm(p&) { e |
        @panic("% (at byte index %)", e, p.cursor);
    };
    
    mod.loader = load(m, mod.w&, a);
    mod.counts = mod.loader.counts;
    m.Qbe'backend'compile_suspended();
    ::enum(@type m.goal.type);
    if m.goal.type == .JitOnly {
        m.make_exec();
        mod.trace = (Some = Crash'push_resolver(Qbe.Module, m, Qbe.find_ip_in_module));
        
        mod.datas = a.alloc_uninit([]u8, mod.loader.datas.len);
        enumerate mod.loader.datas { i, it |
            use_symbol(m, it.id) { s |
                mod.datas[i] = m.segments&[s.segment].mmapped.subslice(s.offset, s.size.zext());
            };
        };
        mod.functions = a.alloc_zeroed(rawptr, mod.loader.functions.len);
        enumerate mod.loader.functions { i, it |
            if it[] != Qbe.no_symbol_S {
                f, _ := m.get_addr(it[]).unwrap();
                mod.functions[i] = f;
            };
        };
    };
    
    // this copy step means if you compile at comptime and then bake the module, 
    // you'll only get the parts of the runtime you need. 
    mod.runtime = a.alloc_zeroed(rawptr, collect_runtime_calls().len());
    calls := collect_runtime_calls();
    for mod.loader.rt_needed& { i |
        mod.runtime[i] = calls[i].callee;
    };
    // TODO: most of the stuff in *Qbe.Module should be dropped. 
    //       just need the active part of code and data segments. 
    
    mod
}

fn instantiate(engine: *Engine, mod: *Module, imports: *ExportsEnv) *Instance = {
    a := engine.gpa;
    instance := {
        it: Instance = (
            memory = zeroed(*SaneRawList(u8)),
            gpa = general_allocator(),
            counts = mod.counts,
        );
        r := a.alloc_zeroed(i64, it&.size() / size_of(i64));
        r := bit_cast_unchecked(*i64, *Instance, r.ptr);
        r[] = it;
        r
    };
    view := instance.view();
    view.runtime.copy_from(mod.runtime);
    
    @assert_le(mod.w.memories.len, 1, "TODO: multiple memories");
    for mod.w.memories { it |
        // max=MAX_u32 means no max was specified, clamp to 2^16 pages = 4gb
        len, cap := (it.min.zext() * wasm_page_size, it.max.zext().min(wasm_page_size) * wasm_page_size);
        buf := page_allocator.alloc_uninit(u8, cap);  // page allocator always gives zeros
        engine.memories&.push(buf, a);
        buf := a.boxed(SaneRawList(u8), (ptr = buf.ptr, cap = buf.len, len = len));
        instance.memory = buf;
    };

    found := zeroed Instance.Counts;
    missing := 0;
    enumerate mod.w.imports& { i, it |
        continue :: local_return;
        module_s, name_s := (it.module.items(), it.name.items());
        value := imports.get(module_s, name_s) || {
            if module_s != "webgpu" {
                @eprintln("tried to import % from %", name_s, module_s);
                missing += 1;
                continue()
            };
            // HACK: it's not ok to file_exists("target/franca/webgpu.g.fr") because it tricks the caching :(
            crash :: fn() void = {
                @panic("TODO: import_wasm does not support webgpu");
            };
            f: rawptr = crash;
            @as(Export) (Function = (callee = f, context = zeroed(rawptr)))
        };
        @if(missing != 0) continue();
        
        // TODO: be able to say it's an @tagged with tag ImportType
        ::tagged(@type it.desc);
        ::tagged(@type value);
        a := value&.tag();
        b := it.desc&.tag();
        @assert_eq(@as(i64) a, @as(i64) b, "wrong import type % %", module_s, name_s);
        
        @match(it.desc) {
            fn Function() => {
                i := found&[.imports]&;
                view.imports[i[]] = value.Function;
                i[] += 1;
            }
            fn Table() => {
                i := found&[.tables]&;
                view.tables[i[]] = value.Table;
                i[] += 1;
            }
            fn Memory() => {
                ::ptr_utils(@type instance.memory[]);
                @assert(instance.memory.is_null(), "TODO: multiple memories");
                instance.memory = value.Memory;
            }
            fn Global() => {
                i := found&[.globals]&;
                view.globals[i[]] = value.Global;
                i[] += 1;
            }
        };
    };
    @assert_eq(missing, 0, "had missing imports");
    ::ptr_utils(@type instance.memory[]);
    
    view.local_globals.copy_from(mod.loader.init_global_values);
    enumerate view.local_globals { i, it |
        view.globals[found&[.globals] + i] = it;
    };
    enumerate mod.loader.init_table_sizes { i, it |
        it := instance.gpa.alloc_zeroed(Callable, it[]);
        view.local_tables[i] = (ptr = it.ptr, len = it.len, cap = it.len);
        view.tables[found&[.tables] + i] = view.local_tables[i]&;
    };
    
    instance.ordered_exports = a.alloc_init(Export, mod.w.exports.len) { i |
        it := mod.w.exports.index(i);
        ::?Callable;
        e: Export = @match(it.type) {
            fn Func() => (Function = get_callable(instance, mod, it.id.zext()) 
                || @panic("uncompiled export %", it.name.items()));
            fn Global() => (Global = view.globals[it.id.zext()]);
            fn Table() => (Table = view.tables[it.id.zext()]);
            fn Memory() => (Memory = instance.memory);
        };
        instance.exports&.insert(it.name.items(), e, a);
        e
    };
    
    instance.run_initializers(mod);
    
    engine.instances&.push(instance, a);
    instance
}

fn run_initializers(self: *Instance, mod: *Module) void = {
    // it would work if you just did this part at comptime but you don't want to 
    // bake the whole memory if theres a bunch of zero padding in there. 
    // better to keep it in the split form like in the wasm module. 
    @debug_assert_eq(mod.loader.datas.len, mod.datas.len, "TODO: delay run_initializers when not jitting");
    
    enumerate mod.loader.datas { i, it |
        if it.active_at { off |
            src := mod.datas[i];
            self.memory.len = max(self.memory.len, off + src.len);
            self.memory_init(src.ptr, self.memory, off.trunc(), 0, src.len.trunc());
        };
    };
    
    view := self.view();
    each mod.loader.elems { it |
        if it.active_at { active_at |
            table := view.tables[active_at.table][].from_sane().items();
            dest := table.subslice(active_at.offset, it.functions.len);
            enumerate dest { i, dest |
                dest[] = self.get_callable(mod, it.functions[i]) 
                    || @panic("failed to get callable for active elem");
            };
        };
    };
}

fn get_callable(self: *Instance, mod: *Module, global_i: i64) ?Callable = {
    @debug_assert_ne(mod.functions.len, 0, "when not jitted you have to manually copy functions/datas");
    view := self.view();
    if global_i < view.imports.len {
        return(Some = view.imports[global_i]);
    };
    f := mod.functions[global_i];
    (Some = (callee = f, context = Instance.raw_from_ptr(self)))
}

ExportsEnv :: @struct(_: HashMap(Str, RawHashMap(Str, Export)));

fn insert(self: *ExportsEnv, module: Str, name: Str, value: Export) void = {
    exports := self._&.get_or_insert(module, => init());
    exports.insert(name, value, self._.alloc);
}

fn insert(self: *ExportsEnv, module: Str, name: Str, callee: rawptr, context: ~T) void #where = {
    it: Export = (Function = (
        callee = callee, 
        context = bit_cast_unchecked(T, rawptr, context),
    ));
    self.insert(module, name, it);
}

fn get(self: *ExportsEnv, module: Str, name: Str) ?Export = {
    m := self._&.get_ptr(module) || return(.None);
    m.get(name)
}

UserContext :: @struct(memory: *SaneRawList(u8), env: rawptr);
fn new_memory(engine: *Engine, initial: i64, max_bytes: i64) Ty(Export, *UserContext) = {
    buf := page_allocator.alloc_uninit(u8, max_bytes);  // page allocator always gives zeros
    a := engine.gpa;
    engine.memories&.push(buf, a);
    buf := a.boxed(SaneRawList(u8), (ptr = buf.ptr, cap = buf.len, len = initial));
    ctx := a.boxed(UserContext, (memory = buf, env = zeroed(rawptr)));
    ((Memory = buf), ctx)
}

fn drop(self: *Engine) void = {
    self.lock&.lock();
    for self.instances { it |
        view := it.view();
        for view.local_tables { t |
            t := t.from_sane();
            drop(t&, it.gpa);
        };
    };
    for self.memories { it |
        page_allocator.dealloc(u8, it);
    };
    each self.modules& { k, v |
        @if_let(v) fn Ready(mod) => {
            if mod.m { m |
                drop(m);
            };
        };
    };
    arena := self.storage[];
    arena&.deinit();
}

fn SaneRawList($T: Type) Type = {
    Self :: @struct(ptr: *T, len: i64, cap: i64, Element :: T);
    
    fn bake_relocatable_value(self: *Self) Slice(BakedEntry) = {
        ptr_len := bake_relocatable_slice_erased(T.raw_from_ptr(self.ptr), self.len, T);
        @slice(ptr_len[0], ptr_len[1], ptr_len[1]) ast_alloc()
    }
    
    fn to_sane(self: RawList(T)) Self = 
        (ptr = self.ptr, len = self.len, cap = self.cap);
    
    fn from_sane(self: Self) RawList(T) = 
        (ptr = self.ptr, len = self.len, cap = self.cap);
    
    fn maybe_uninit(self: *Self) []T = 
        self[].from_sane().maybe_uninit();
    
    fn items(self: *Self) []T = 
        self[].from_sane().items();
    
    Self
}

// some wasm instructions don't map directly to native instructions 
// and do heavy weight things that don't need super tight code generation. 
// see convert.fr/choose_runtime_call

#wasm(0xFC, 0x0F, .table)
table_grow :: fn(ctx: *Instance, table_in: *SaneRawList(Instance.Callable), fill: *Callable, delta: i32) i32 = {
    fill := fill[];
    table := table_in[].from_sane();
    if delta < 0 || table.len + delta.intcast() > MAX_i32 {
        return(-1);
    };
    
    table&.reserve(delta.intcast(), ctx.gpa);
    range(0, delta.intcast()) { _ |
        table&.push_assume_capacity(fill);
    };
    
    table_in[] = table.to_sane(); 
    table.len.intcast() - delta
}

#wasm(0xFE, 0x00, .memarg)
atomic_notify :: fn(ctx: *Instance, addr: *u32, count: u32) i32 = {
    _ := Futex'wake(addr, count);
    
    // TODO: return the number that waiters that were woken
    0
};

#wasm(0xFE, 0x01, .memarg)
atomic_wait32 :: fn(ctx: *Instance, addr: *u32, expect: u32, timeout_ns: i64) Futex.WasmWaitResult = {
    forever := timeout_ns < 0;
    @assert(forever, "TODO(import_wasm): atomic.wait with timeout");
    _ := Futex'wait(addr, expect);
    // TODO: return the correct reason for waking
    .Ok
}

#wasm(0xFE, 0x03, 0x00) 
atomic_fence :: fn(ctx: *Instance) void = {
    fence();
}

// i always preallocate the whole memory so it doesn't have to resize, 
// but keep track of a smaller "length" value so user code can use memory_grow as the page allocator.
#wasm(0x40, .memory)
memory_grow :: fn(ctx: *Instance, memory: *SaneRawList(u8), delta_pages: i32) i32 = {
    delta := delta_pages.intcast().shift_left(16);
    old := i64.cas(memory.len&) { old |
        new := old + delta;
        @if(new > memory.cap) return(-1);
        new
    };
    old.intcast().shift_right_arithmetic(16)
}

#wasm(0xFC, 0x08, .data, .memory)
memory_init :: fn(ctx: *Instance, data_start: *u8, _: *SaneRawList(u8), dest: u32, src_offset: u32, size: u32) void = {
    ctx := ctx.memory.ptr;
    src := data_start.offset(src_offset.zext()).slice(size.zext());
    dest := ctx.offset(dest.zext()).slice(size.zext());
    dest.copy_from(src);
}

Futex :: import("@/lib/sys/sync/futex.fr");
#use("@/lib/sys/threads.fr");
#use("@/lib/sys/sync/mutex.fr");
#use("@/examples/import_wasm/parse.fr");
#use("@/lib/collections/map.fr");
Qbe :: import("@/backend/ir.fr");
Crash :: import("@/lib/crash_report.fr");
wasm_page_size :: 65536;

fn bake_relocatable_value(self: *Module) []BakedEntry = {
    msg :: "you can't bake a jitted Module. see import_wasm/ffi.fr";
    @assert(self.m.is_none()/* || self.m.Some.goal.type != .JitOnly*/, msg);

    // HACK: because you can't bake the ast_alloc
    // TODO: really i should deal with that more generally
    inline_for WasmModule.get_fields() { $f |
        @if(@run IsCollection(List)(f.ty)) {
            it := WasmModule.get_field_ptr(self.w&, f);
            it.gpa = zeroed(Alloc);
        }
    };
    
    dyn_bake_relocatable_value(Module.cast_to_bytes(self), Module, true)
}
