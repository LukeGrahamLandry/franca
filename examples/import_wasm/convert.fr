//! === WARNING === This is not a sandbox! === WARNING ===

#use("@/backend/lib.fr");
#use("@/examples/import_wasm/parse.fr");

// TODO: this could be hella faster: 
//       - there's a wasteful prepass that splits up bits of the module into a big data structure. 
//       - the parser+wasm->ir could be on a different thread from the ir->asm 
//         (i have the machinery to do this already because the Franca compiler works that way)
//         + you could compile multiple functions in parallel (but that would need more work).
//       - the number of bounds checks the parser does per byte is a bit sad. 
//       - the way i deal with adjusting indexes for imports is silly. 
//       - could inline more if we pre-sorted based on callgraph,
//         but maybe the expectation with wasm is that the first compiler did that already?

// TODO: validation
// TODO: tables, vector ops, call_indirect, br_table, br_if, drop, select, memory grow/init/size/copy/fill, data drop,
//       T.eqz, abs, ceil, floor, trunc, nearest, copysign, trunc_sat, some other conversions
//       multiple return values, ref.*
//       more atomic ops. 
// TODO: provide standard c api so could run other people's tests? https://github.com/WebAssembly/wasm-c-api/blob/main/include/wasm.h

fn init(m: *QbeModule, w: *WasmModule, a: Alloc) LoadWasm = (
    m = m,
    w = w,
    stack = list(temp()),
    locals = empty(),
    blocks = list(temp()),
    preserve_franca_env = true,
    alloc = a,
);

fn fill_imports(self: *LoadWasm, imports: *RawHashMap(Str, rawptr)) void = {
    each self.w.imports& { it |
        name := @tfmt("%$%", it.name.items(), it.module.items());  // :leak
        if imports.get(name) { addr |
            self.m.put_jit_addr(self.m.intern(name), addr);
        } else {
            @panic("ERROR: missing import '%'", name);
        }
    };
}

fn collect_exports(self: *LoadWasm, a: Alloc) []Qbe.Sym = {
    count := 0;
    each self.w.exports& { it |
        ::enum(@type it.type);
        count += int(it.type == .Func);
    };
    e := a.alloc_uninit(Qbe.Sym, count);
    i := 0;
    each self.w.exports& { it |
        if it.type == .Func {
            e[i] = self.functions[it.id.zext()];
            i += 1;
        };
    };
    @debug_assert_eq(e.len, i);
    e
}

// Take a struct like { Module :: { Func :: fn(); } } and create a map [func$module -> fnptr]
fn comptime_exports($Exports: Type) *RawHashMap(Str, rawptr) = {
    // TODO: it would be great if these could just be normal for loops since we can just be running in comptime anyway. 
    //       but calling get_constant to get a rawptr from a closure literal doesn't bake it properly. 
    //       and `fid` needs to be const for @as(rawptr) to work (maybe we should just allow that for free at comptime).
    // TODO: sane error message if you try to have this be the whole HashMap that includes ast_alloc as a rawptr
    //       but it wont have been baked before so you cant bake it now and don't know why but the error makes it sound like its a rawptr value in the map. 
    exports :: @static(RawHashMap(Str, rawptr)) { // TODO: make this := after ^
        exports: HashMap(Str, rawptr) = init(ast_alloc());
        s :: scope_of(Type, Exports);
        inline_for get_constants(s) { $module_name |
            s2 :: scope_of(Type, get_constant(Type, s, module_name[]).unwrap());
            func_names :: get_constants(s2);
            inline_for func_names { $func_name | 
                addr :: get_constant(FuncId, s2, func_name[]).unwrap();
                mangled_name :: (@tfmt("%$%", func_name[].str(), module_name[].str())).shallow_copy(ast_alloc());
                exports&.insert(mangled_name, @as(rawptr) addr);
            }
        }
        exports.raw&.zero_unused_slots();
        exports.raw
    }
    exports
} 

fn const_eval_wasm_expr(expr: []u8) Ty(i64, Qbe.Cls) = {
    o := @as(Wasm.Inst) expr[0];
    ::enum(Wasm.Inst);
    @assert(@is(o, .I32_Const, .I64_Const), "TODO: complex expr");
    v, _, ok := read_leb128_signed(expr.rest(1));
    @debug_assert(ok, "bad constant expression");
    (v, @match(o) {
        fn I32_Const() => .Kw;
        fn I64_Const() => .Kl;
        fn F32_Const() => .Ks;
        fn F64_Const() => .Kd;
        @default => @panic("unhandled op in const_eval_wasm_expr");
    })
} 

LoadWasm :: @struct(
    m: *QbeModule,
    w: *WasmModule,
    src := "",
    cursor := 0,
    module_name := "module",
    global_names: []Qbe.Sym = empty(),
    global_cls: []Qbe.Cls = empty(),
    tables: []Qbe.Sym = empty(),
    functions: []Qbe.Sym = empty(),  // [...imports, ...exports]
    function_types: []Wasm.TypeIdx = empty(),
    preserve_franca_env: bool,
    
    stack: List(Qbe.Ref),
    blocks: List(BlockEntry),
    locals: []Qbe.Ref,  // TODO: we can't store a 128 bit vector in a temporary 
    f := zeroed(*Qbe.Fn),
    base_pointer := QbeNull,
    return_types: []Wasm.ValType = empty(),
    link := zeroed(**Qbe.Blk),
    franca_env := QbeNull,
    alloc: Alloc,
);

fn create_init_func(self: *LoadWasm) Qbe.Sym = {
    f := Qbe.Fn.zeroed(); f := f&;
    f.default_init(self.m);
    f.lnk.id = self.m.intern(@tfmt("init$%$", self.module_name));
    f.lnk.export = true;
    f.start = newblk();
    f.start.jmp = (type = .ret0, arg = QbeNull);
    f.nblk = 1;
    // TODO: i think i need to keep the data symbols for passive segments and then need to do this at the beginning before the other functions. 
    base := f.newtmp("base", .Kl);
    f.emit(.par, .Kl, base, QbeNull, QbeNull);
    enumerate self.w.data { i, data |
        expr := data.active_offset_expr;
        @assert_ne(expr.len, 0, "TODO: passive data");
        off, k := const_eval_wasm_expr(expr.items());
        @debug_assert_eq(k, .Kw, "offset expression");
        id := self.m.intern(@tfmt("data%$%$", i, self.module_name));
        self.m.emit_data(template = (Bytes = data.bytes.items()), id = id, relocations = empty());
        dest := f.newtmp("dat", .Kl);
        // :ThisSureIsABigBlit I AM BAD AT MY JOB
        // TODO: this sucks really really bad if we actually emit all the instructions for large blits 
        f.emit(.add, .Kl, dest, base, f.getcon(off));
        f.emit(.blit0, .Kw, QbeNull, f.symcon(id), dest);
        f.emit(.blit1, .Kw, QbeNull, INT(data.bytes.len), QbeNull);
    };
    f.copy_instructions_from_scratch_reversed_which_means_forwards(f.start);
    run_qbe_passes(f);  // :ThisIsWhereWeEmit
    f.lnk.id
}

preleb :: import("@/backend/wasm/isel.fr").wasm_type_preleb;

fn load_module(self: *LoadWasm) void = {
    self.create_globals();
    
    range(0, self.w.code.len) { i |
        mark := mark_temporary_storage();
        f := Qbe.Fn.zeroed();
        self.translate_func(i, f&);
        run_qbe_passes(f&);  // :ThisIsWhereWeEmit
        reset_temporary_storage(mark);
    };
};

fn translate_func(self: *LoadWasm, local_func_i: i64, f: *Qbe.Fn) void = {
    code := self.w.code.index(local_func_i);
    global_func_i := local_func_i + self.w.imported_function_count;
    self.f = f;
    self.f.default_init(self.m);
    
    f.lnk.id = self.functions[global_func_i];
    
    type_index := self.function_types[global_func_i];
    
    signature := self.w.types[type_index.id.zext()]&;
    self.locals = temp().alloc_uninit(Qbe.Ref, code.total_local_count + signature.arg.len);
    self.blocks = list(temp());
    self.stack = list(temp());
    self.base_pointer = self.f.newtmp("wasm_globals", .Kl);
    if self.preserve_franca_env {
        self.franca_env = self.f.newtmp("env", .Kl);
        self.f.emit(.pare, .Kl, self.franca_env, QbeNull, QbeNull);
    }
    self.f.emit(.par, .Kl, self.base_pointer, QbeNull, QbeNull);
    
    // parameters come in as locals not on the stack
    range(0, signature.arg.len) { i |
        k := signature.arg[i].cls();
        self.locals[i] = self.f.newtmp(@tfmt("L%", i), k);
        self.f.emit(.par, k, self.locals[i], QbeNull, QbeNull);
    };
    
    {
        i := signature.arg.len;
        for code.locals& { local |
            k := local.type.cls();
            range(0, local.count) { _ |
                self.locals[i] = self.f.newtmp(@tfmt("L%", i), k);
                i += 1;
            };
        };
        @debug_assert_eq(self.locals.len, i);
    };
    
    self.src = code.insts.items();
    self.cursor = 0;
    
    self.link = self.f.start&;
    // you can't br targtting the outer scope of the function so only `current` matters. 
    self.blocks&.push(current = self.link_new_block(), continue = Qbe.Blk.ptr_from_int(0), break = Qbe.Blk.ptr_from_int(0), loop = false);
    self.push_block(preleb(.EmptyBlock).intcast(), false);
    
    self.return_types = signature.ret.items();
    self.emit_the_code();
    
    self.f.lnk.export = true; // TODO: kind depends if this is the final thing. if it's aot into a franca program, you want to to TOFKALTO
}

// choose names for functions, globals, tables
fn create_globals(self: *LoadWasm) void = {
    a := self.alloc;
    count := self.w.functions.len + self.w.imported_function_count;
    self.functions = a.alloc_uninit(Qbe.Sym, count); // :Leak
    self.function_types = a.alloc_uninit(Wasm.TypeIdx, count);
    f_i := 0;
    each self.w.imports& { import |
        @if_let(import.desc&) fn Function(id) => {
            self.functions[f_i] = self.m.intern(@tfmt("%$%", import.name.items(), import.module.items()));
            self.function_types[f_i] = id[];
            f_i += 1;
        };
    };
    @debug_assert_eq(f_i, self.w.imported_function_count);
    range(0, self.w.functions.len) { i |
        self.functions[f_i] = self.m.intern(@tfmt("F%$%", f_i, self.module_name));
        self.function_types[f_i] = self.w.functions[i];
        f_i += 1;
    };
    @debug_assert_eq(count, f_i);    
    
    // actually, if it's an export it's nicer to use the real names. TODO: same thing for globals
    each self.w.exports& { it |
        ::enum(@type it.type);
        if it.type == .Func {
            self.functions[it.id.zext()] = self.m.intern(@tfmt("%$%", it.name.items(), self.module_name));
        };
    };
    
    self.global_names = a.alloc_uninit(Qbe.Sym, self.w.globals.len); // :Leak
    self.global_cls = a.alloc_uninit(Qbe.Cls, self.w.globals.len); // :Leak
    enumerate self.w.globals& { local_global_i, global | 
        // TODO: offset the index by number of imported globals
        id := self.m.intern(@tfmt("G%$%", local_global_i, self.module_name));
        self.global_names[local_global_i] = id;
        
        value, k := const_eval_wasm_expr(global.init_expr.items());  // TODO: is this k always the same as global.type?
        self.global_cls[local_global_i] = k;
        self.m.emit_data(
            id = id, 
            template = (Bytes = (ptr = ptr_cast_unchecked(i64, u8, value&), len = 4 + 4 * int(k.is_wide()))), 
            relocations = empty(),
        );
    };
    
    // :Leak
    self.tables = a.alloc_init(Qbe.Sym, self.w.tables.len) { table_i | 
        table := self.w.tables.index(table_i);
        name := @tfmt("T%$%", table_i, self.module_name);
        table_pointer := self.m.intern(name);
        table_initial := self.m.intern(@tfmt("init__%", name));
        
        ::enum(@type table.type);
        @assert(table.type == .FuncRef, "TODO: non-func tables");
        
        // Reserve some memory for the starting values in the table. 
        found := false;
        each self.w.elements { elem | 
            if elem.table.id.zext() == table_i {
                @assert(!found, "TODO: init multiple parts of a table");
                found = true;
                off, k := const_eval_wasm_expr(elem.active_offset_expr.items());
                @assert_eq(off, 0, "TODO: init table offset non-zero");
                @assert_ge(elem.funcs.len, table.limits.min.zext(), "TODO: init table < table.min");
                r := temp().alloc_init(Dat2.Reloc, elem.funcs.len) { i |
                    f_id := elem.funcs[i];
                    (off = trunc(off + i * size_of(rawptr)), id = self.functions[f_id.id.zext()])
                };
                self.m.emit_data(
                    id = table_initial, 
                    template = (Zeroes = r.len * size_of(rawptr)), 
                    relocations = r,
                );
            };
        };
        @assert(found, "TODO: uninit table");
        
        // Reserve a symbol to hold the address of the table since we want to be able to resize it later
        self.m.emit_data(
            id = table_pointer, 
            template = (Zeroes = size_of(rawptr)), 
            relocations = @slice(@as(Dat2.Reloc) (off = 0, id = table_initial)),
        );
        
        table_pointer
    };
    
}   

BlockEntry :: @struct(continue: *Qbe.Blk, break: *Qbe.Blk, current: *Qbe.Blk, loop: bool);

fn emit_the_code(self: *LoadWasm) void = {
    IfNode :: @struct(src: *Qbe.Blk, block_type: i64 /* needed for op else */, stack: []Qbe.Ref);
    if_stack := list(IfNode, temp());
    while => self.cursor < self.src.len {
        continue :: local_return;
        
        b := self.src[self.cursor];
        self.cursor += 1;
        inst := @as(Wasm.Inst) b;
        ::enum(Wasm.Inst);
        
        ::enum(Qbe.J);
        if self.get_blk()[].jmp.type != .Jxxx && !@is(inst, .End, .Unreachable, .Nop) {
            printfn(self.f, self.f.globals.debug_out);
            @panic("more instructions @% which has already been terminated. (TODO: this happens when there is unreachable code after a BR instruction but that is likely not what you wanted anyway)", self.get_blk()[].id);
        };
        
        // Single byte unary/binary instructions are found in the table. 
        encoding := lookup_wasm_encoding(b);
        
        ::enum(@type encoding.kind);
        if encoding.kind != .other {
            a0, a1, r := (QbeNull, QbeNull, QbeNull);
            @match(encoding.kind) {
                fn other() => unreachable();
                fn unary() => {
                    ::enum(Qbe.O);
                    if encoding.op == .truncl {
                        encoding.op = .copy;
                    };
                    r = self.f.newtmp("wasm", encoding.cls);
                    a := self.stack[self.stack.len - 1]&;
                    a0 = a[];
                    a[] = r;
                };
                fn binary() => {
                    r = self.f.newtmp("wasm", encoding.cls);
                    a1 = self.stack[self.stack.len - 1];
                    b := self.stack[self.stack.len - 2]&;
                    self.stack.len -= 1;
                    a0 = b[];
                    b[] = r;
                };
                fn load() => {
                    align := self.read_u();
                    offset := self.read_u();
                    addr := self.stack&.pop().expect("stack for load addr");
                    addr := self.compute_address(addr, offset.bitcast());
                    
                    result := self.f.newtmp("load", encoding.cls);
                    self.stack&.push(result);
                    a0 = addr; a1 = QbeNull; r = result; 
                };
                fn store() => {
                    align := self.read_u();
                    offset := self.read_u();
                    value := self.stack&.pop().expect("stack for store value");
                    addr := self.stack&.pop().expect("stack for store addr");
                    addr := self.compute_address(addr, offset.bitcast());
                    a0 = value; a1 = addr; r = QbeNull; 
                };
            };
            
            self.f.emit(encoding.op, encoding.cls, r, a0, a1);
            continue();
        }; // Otherwise it's a more complicated instruction. 
        
        @match(inst) {
            fn I32_Const() => self.stack&.push(self.f.getcon(self.read_s()));
            fn I64_Const() => self.stack&.push(self.f.getcon(self.read_s()));
            fn F64_Const() => self.push_float(8);
            fn F32_Const() => self.push_float(4);
            fn LocalGet()  => self.local_inst(1);
            fn LocalSet()  => self.local_inst(-1);
            fn LocalTee()  => self.local_inst(0);
            // TODO: this is unfortunate code to generate but i don't know how you do better without knowing that tables are immutable. 
            //       if max=min then at least you know they don't resize and you could save an indirection. 
            fn CallIndirect() => {
                type_index       := self.read_u();
                table_index      := self.read_u();
                index_in_table_W := self.stack&.pop().expect("call index on stack");
                table_var        := self.tables[table_index.bitcast()];
                table_var        := self.f.symcon(table_var);
                callee           := self.f.newtmp("Icallee", .Kl);
                index_in_table_L := self.f.newtmp("Iindex", .Kl);
                table_slot       := self.f.newtmp("Islot", .Kl);
                table_offset     := self.f.newtmp("Ioff", .Kl);
                table_base       := self.f.newtmp("Ibase", .Kl);
                
                self.f.emit(.load, .Kl, table_base, table_var, QbeNull);
                self.f.emit(.extuw, .Kl, index_in_table_L, index_in_table_W, QbeNull);
                self.f.emit(.mul, .Kl, table_offset, index_in_table_L, self.f.getcon(8));
                self.f.emit(.add, .Kl, table_slot, table_base, table_offset);
                self.f.emit(.load, .Kl, callee, table_slot, QbeNull);
                
                self.emit_call_from_stack(callee, (id = type_index.trunc()));
            }
            fn Call() => {
                callee := self.read_index(Wasm.FuncIdx);
                type_index := self.function_types[callee.id.zext()];
                callee := self.f.symcon(self.functions[callee.id.zext()]);
                self.emit_call_from_stack(callee, type_index);
            }
            fn Return() => self.emit_return();
            fn GlobalSet() => {
                i: i64 = self.read_u().bitcast();
                g := self.f.symcon(self.global_names[i]);
                val := self.stack&.pop().expect("enough stack");
                k := self.global_cls[i];
                self.f.emit(k.store_op(), .Kw, QbeNull, val, g); 
            }
            fn GlobalGet() => {
                i: i64 = self.read_u().bitcast();
                g := self.f.symcon(self.global_names[i]);
                k := self.global_cls[i];
                val := self.f.newtmp("global_get", k);
                self.stack&.push(val);
                self.f.emit(.load, k, val, g, QbeNull);
            }
            fn VectorPrefix() => panic("Vector instructions are not supported (0xFD prefix)");
            fn Nop() => ();
            fn Unreachable() => if self.get_blk()[].jmp.type == .Jxxx {
                self.get_blk()[].jmp.type = .hlt;
            };
            fn Loop()  => self.push_block(self.read_s(),  true);
            fn Block() => self.push_block(self.read_s(), false);
            fn End()   => self.end_block(true);
            fn If() => {
                block_type := self.read_s();
                old := self.get_blk();
                old.jmp = (type = .jnz, arg = self.stack&.pop().expect("arg on stack for If"));
                stack := self.stack.items().clone(temp()).items();
                if_stack&.push(src = old, block_type = block_type, stack = stack); 
                self.push_block(block_type, false);
                old.s1 = self.get_blk();
            }
            fn Else() => {
                self.end_block(false);
                if_node := if_stack&.pop().expect("Else only inside If");
                self.stack = assume_owned(if_node.stack, temp());
                self.push_block(if_node.block_type, false);   // TODO: feels like this wont work. i just don't generate if/else yet
                if_node.src.s2 = self.get_blk();
            }
            fn Br() => {
                src := self.get_blk();
                src.jmp.type = .jmp;
                src.s1 = self.parse_branch_target();
                self.stack_to_phi(src, src.s1);
            }
            fn BrIf() => {
                src := self.get_blk();
                src.jmp = (type = .jnz, arg = self.stack&.pop().expect("arg on stack for BrIf"));
                // TODO: only clone the part that gets popped. 
                stack := self.stack.items().clone(temp());
                src.s1 = self.parse_branch_target();
                self.stack_to_phi(src, src.s1);
                
                // If the condition is false, fallthrough and keep parsing instructions into a new block 
                // (without consuming anything from the stack). don't need phis since this is the only entry point. 
                src.s2 = self.link_new_block();
                current := self.blocks[self.blocks.len - 1].current&;
                self.f.copy_instructions_from_scratch_reversed_which_means_forwards(current[]);
                current[] = src.s2;
                self.stack = stack;
            }
            fn Drop() => {
                self.stack&.pop().expect("stack for store drop");
            }
            fn Select() => {
                count := self.read_u();
                @assert_eq(count, 1, "TODO: multi-value");
                k := cls(@as(Wasm.ValType) @as(u8) self.src[self.cursor]);
                self.cursor += 1;
                @assert(k.is_int(), "TODO: select on floats");

                result := self.f.newtmp("select", k);
                cond := self.stack&.pop().expect("stack for sel-cond");
                f := self.stack&.pop().expect("stack for sel-false");
                t := self.stack&.pop().expect("stack for sel-true");
                self.f.emit(.sel0, .Kw, QbeNull, cond, QbeNull);
                self.f.emit(.sel1, k, result, t, f);
                self.stack&.push(result);
            }
            fn AtomicPrefix() => {
                opcode := self.read_u();
                k: Qbe.Cls = @switch(opcode) {
                    @case(72) => .Kw;
                    @case(73) => .Kl;
                    @default => @panic("TODO: support more atomic ops (%)", opcode);
                };
                align := self.read_u();
                offset := self.read_u();
                
                new := self.stack&.pop().expect("stack for cas-new");
                old := self.stack&.pop().expect("stack for cas-old");
                p := self.stack&.pop().expect("stack for cas-p");
                p := self.compute_address(p, offset.bitcast());
                prev := self.f.newtmp("cas-prev", k);
                
                self.f.emit(.cas0, .Kw, QbeNull, p, QbeNull);
                self.f.emit(.cas1, k, prev, old, new);
                self.stack&.push(prev);
            }
            @default => @panic("unhandled unstruction %", self.src[self.cursor - 1]);
        }
    }
}

fn parse_branch_target(self: *LoadWasm) *Qbe.Blk = {
    depth: i64 = self.read_u().bitcast();
    it := self.blocks[self.blocks.len - depth - 1];
    @if(it.loop, it.continue, it.break)
}

fn push_float(self: *LoadWasm, $size: i64) void = {
    v := IntType(size * 8, false).cast_front_unaligned(self.src.rest(self.cursor));
    value: i64 = @if(size == 4, v.zext(), @if(size == 8, v.bitcast(), unreachable()));
    self.cursor += size;
    self.stack&.push(self.f.getcon(value));
}

fn stack_to_phi(self: *LoadWasm, src: *Qbe.Blk, dest: *Qbe.Blk) void = {
    for_phi dest { p |
        p.push(src, self.stack&.pop() || @panic("missing value for phi % -> % %", src.id, dest.id, { printfn(self.f, self.f.globals.debug_out); ""}));
    }
}

fn decode_block_type(self: *LoadWasm, block_type: i64) Ty([]Wasm.ValType, []Wasm.ValType) = {
    if block_type >= 0 {
        ty := self.w.types[block_type]&;
        return(ty.arg.items(), ty.ret.items());
    };
    if block_type == preleb(.EmptyBlock).intcast() {
        return(empty(), empty());
    };
    
    // :SLOW
    values :: get_cases(Wasm.ValType);
    each values { it |
        if block_type == preleb(it[]).intcast() {
            return(empty(), (ptr = it, len = 1));
        };
    };
    
    @panic("invalid block type %", block_type)
}

fn get_blk(self: *LoadWasm) *Qbe.Blk =
    self.blocks[self.blocks.len - 1].current;

fn push_block(self: *LoadWasm, block_type: i64, loop: bool) void = {
    arg, ret := self.decode_block_type(block_type);
    ::enum(Wasm.ValType);  ::DerefEq(Wasm.ValType);
    
    old := self.blocks[self.blocks.len - 1]&;
    new := self.link_new_block();
    init_empty_phis(self.f, new, arg);
    self.stack_to_phi(old.current, new);
    self.f.copy_instructions_from_scratch_reversed_which_means_forwards(old.current);
    continuation := self.link_new_block();
    init_empty_phis(self.f, continuation, ret);  // break's inputs are the new block's outputs
    if old.current.jmp.type == .Jxxx {
        old.current.jmp.type = .jmp;
        old.current.s1 = new;
    }
    old.current = continuation;
    self.phi_to_stack(new);
    self.blocks&.push(continue = new, break = continuation, current = new, loop = loop);
    
    init_empty_phis :: fn(f: *Qbe.Fn, b: *Qbe.Blk, arg_types: []Wasm.ValType) void = 
        for(arg_types, fn(ty) => new_phi(f, b, ty.cls(), 1));
}

fn end_block(self: *LoadWasm, fallthrough: bool) void = {
    it := self.blocks&.pop().expect("well nested End instructions");
    self.f.copy_instructions_from_scratch_reversed_which_means_forwards(it.current);
    if it.current.jmp.type == .Jxxx {
        self.stack_to_phi(it.current, it.break);
        it.current.jmp.type = .jmp;
        it.current.s1 = it.break;
    }
    it.current = zeroed(*Qbe.Blk);
    self.blocks[self.blocks.len - 1].current = it.break;
    if fallthrough {
        self.phi_to_stack(it.break);
    }
}

fn phi_to_stack(self: *LoadWasm, b: *Qbe.Blk) void = {
    for_phi_rev_TODOSLOW b { p |
        self.stack&.push(p.to);
    }
}

fn link_new_block(self: *LoadWasm) *Qbe.Blk = {
    b := newblk();
    b.id = self.f.nblk;
    self.f.nblk += 1;
    self.link[] = b; 
    self.link = b.link&;
    b
}

fn compute_address(self: *LoadWasm, addr: Qbe.Ref, offset: i64) Qbe.Ref = {
    f := self.f;
    r0 := f.newtmp("a", .Kl);
    r1 := f.newtmp("a", .Kl);
    f.emit(.extuw, .Kl, r0, addr, QbeNull);
    f.emit(.add, .Kl, r1, self.base_pointer, r0);
    if(offset == 0, => return(r1));
    r2 := f.newtmp("a", .Kl);
    f.emit(.add, .Kl, r2, r1, f.getcon(offset));
    r2
}

fn local_inst(self: *LoadWasm, delta: i64) void = {
    i    := self.read_u();
    var  := self.locals[i.bitcast()];
    k := self.f.get_temporary(var)[].cls;
    ::if(Qbe.Ref);
    dest := if(delta == 1, => self.f.newtmp(@tfmt("getL%", i), k), => var);
    src  := if(delta == 1, => var, => self.stack[self.stack.len - 1]);
    self.stack&.reserve(abs(delta));
    self.stack.len += delta;
    if delta == 1 {
        @debug_assert(self.stack.len > 0, "tried to access empty stack in local_inst");
        self.stack[self.stack.len - 1] = dest;
    };
    self.f.emit(.copy, k, dest, src, QbeNull);
}

fn emit_return(self: *LoadWasm) void = {
    @debug_assert(self.get_blk()[].jmp.type == .Jxxx, "tried to return from terminated block");
    @switch(self.return_types.len) {
        @case(0) => {
            self.get_blk()[].jmp.type = .ret0;
        };
        @case(1) => {
            r := self.return_types[0].cls().retk();
            self.get_blk()[].jmp = (type = r, arg = self.stack[self.stack.len - 1]);
            self.stack.len -= 1;
        };
        @default => panic("TODO: handle multiple returns");
    };
}

fn emit_call_from_stack(self: *LoadWasm, callee: Qbe.Ref, type: Wasm.TypeIdx) void = {
    type := self.w.types[type.id.zext()]&;
    @assert_le(
        type.arg.len, self.stack.len, 
        "not enough stack for call to % %", callee, 
        @if(rtype(callee) == .RCon, self.m.str(self.f.get_constant(callee)[].sym), ""),
    );
    if self.preserve_franca_env {
        self.f.emit(.arge, .Kl, QbeNull, self.franca_env, QbeNull);
    }
    
    self.f.emit(.arg, .Kl, QbeNull, self.base_pointer, QbeNull);
    range(0, type.arg.len) { i |
        ref := self.stack[self.stack.len - type.arg.len + i];
        k := type.arg[i].cls();
        self.f.emit(.arg, k, QbeNull, ref, QbeNull);
    };
    self.stack.len -= type.arg.len;
    
    @switch(type.ret.len) {
        @case(0) => {
            self.f.emit(.call, .Kw, QbeNull, callee, QbeNull);
        };
        @case(1) => {
            k := type.ret[0].cls();
            ref := self.f.newtmp("ret", k);
            self.f.emit(.call, k, ref, callee, QbeNull);
            self.stack&.push(ref);
        };
        @default => panic("TODO: handle multiple returns");
    };
}

// (dest_offset, src_offset_in_data, size_to_copy)  // TODO: make sure those arguments are right
fn emit_memory_init(self: *WasmModule, data_id: i64) void = {
    todo()
}
