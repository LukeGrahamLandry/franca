// I'm not super thrilled about writing it this way but its really annoying to do the boring stack manipulation every time. 
//
// Also this always calls through the vtable because I want you to be able to load this in your driver and write your own backends.
// So it shouldn't directly access compiler internals. See examples/qbe.fr + examples/default_driver.fr for usage. 


// IMPORTANT: your setup+inst+finished run inside a temp allocator reset after each function. 
// TODO: traits
/*
Backend :: @trait fn($B: Type) = {
    // B.Val needs to be Copy.
    :: assert_eq(@type :: B.Val, Type); // TODO: better syntax for associated types? 
    
    fn new(comp: CompCtx, alloc: Alloc, arch: Arch, os: Os, userdata: rawptr) B; 
    fn inst_call(self: *B, args: Slice(B.Val), sig: PrimSig, f: FuncId, tail: bool, loc: ?Span) Slice(B.Val);
    fn inst_trap(self: *B) void;
    fn inst_call_ptr(self: *B, args: Slice(B.Val), sig: PrimSig, ptr: B.Val, loc: ?Span, context: bool) Slice(B.Val);
    fn inst_offset(self: *B, ptr: B.Val, bytes: i64) B.Val;
    fn inst_literal(self: *B, value: i64, ty: Prim) B.Val;
    fn inst_load(self: *B, addr: B.Val, ty: Prim) B.Val;
    fn inst_store(self: *B, addr: B.Val, value: B.Val, ty: Prim) void;
    fn inst_copy(self: *B, from: B.Val, to: B.Val, bytes: u16) void;
    fn inst_func_ref(self: *B, fid: FuncId) B.Val;
    fn inst_global(self: *B, id: BakedVarId) B.Val;
    fn inst_jump_if(self: *B, cond: B.Val, true: BbId, false: BbId, args: Slice(B.Val)) void;
    fn inst_jump(self: *B, always: BbId, args: Slice(B.Val)) void;
    fn inst_return(self: *B, args: Slice(B.Val)) void;
    fn move_to_block(self: *B, block: *BasicBlock, ip: BbId) Slice(B.Val);
    // - declare basic blocks
    // - declare stack slots for local variables
    fn setup(self: *B, body: *FnBody, vars_out: *List(B.Val)) void;
    fn inst_intrinsic(self: *B, op: Intrinsic, args: Slice(B.Val)) Slice(B.Val);
    fn inst_switch(self: *B, info: *RawList(SwitchPayload), inspected: B.Val, uid: i64) void;
    fn finished(self: *B, fid: FuncId) void;
};
*/

fn walk_block();
fn emit_current_function();
fn add_pending_callees();
fn finished();
fn loop_emit_constants();

// Note: B.Val is the example usecase for const struct fields. 
fn CodeGen($B: Type) Type = {
    MAX_BLOCKS :: 512;
    Self :: @struct(
        program: CompCtx,
        body: *FnBody,
        vars: List(B.Val),
        stack: List(B.Val),
        blocks_done: BitSet = empty(),
        funcs_done: BitSet = empty(),
        constants_needed: BitSet = empty(),
        max_const_id: i64 = 0,
        pending: List(FuncId),
        static_context_var: ?BakedVarId,
        did_constants := false,
        backend: B,
        bc: *BcBackend,
        $emit := emit_program,
    );
    
    // :TooManyArgsX64
    emit_program :: fn(comp: CompCtx, fns: [] FuncId, entry: ProgramEntry, target: *TargetEnv, userdata: rawptr) BucketArray(u8) = {
        alloc := comp.get_alloc();
        env := comp.get_comptime_env();
        gen: Self = (
            program = comp,
            body = zeroed(*FnBody), // EVIL
            vars = list(temp()),
            stack = list(temp()),
            pending = fns.clone(libc_allocator),
            static_context_var = env.static_context_var,
            backend = new(comp, alloc, target.arch, target.os, userdata),
            bc = create(comp),
        );
        @assert(comp.get_build_options()[].implicit_context_runtime == gen.static_context_var.is_none(), "should have baked the static context location already iff no implicit context");
        work_stack := FuncId.list(temp());
        if entry == .WrapMain || entry == .TestRunnerMain {
            env := comp.get_comptime_env();
            work_stack&.push(env.runtime_init.expect("declaration of franca_runtime_init"));
        };
        work_stack&.push_all(fns);
        emitted_functions := 0;
        while(=> work_stack.len.ne(0)){
            continue :: local_return;
            fid := work_stack&.last().unwrap()[];
            if gen.funcs_done&.get(fid.to_index().zext()) {
                work_stack&.pop();
                continue();
            }; // might have been added multiple times
            
            {comp.vtable.report_aot_progress}(comp.data, fid, true, 2);
            func := comp.get_function(fid);
            // Note: compile before checking callees! // TODO: return error instead
            xx := {comp.vtable.compile_func}(comp.data, fid, .Aot);  // TODO: fix parsing to allow this as a quick expr
            or xx { err | 
                @println("failed compile %", comp.get_string(func.name));
                comp.report_error(err)
            };  // TODO: return error instead
            
            // sort the functions to make sure we can inline calls to intrinsics
            not_done_count := 0;
            for func.callees { f |  
                if !gen.funcs_done&.get(f.to_index().zext()) && !work_stack.items().contains(f&) {
                    not_done_count += 1;
                    work_stack&.push(f);
                };
            };
            if not_done_count > 0 {
                // no pop
                continue();
            };
            
            xx := emit_bc(comp, gen.bc, fid, .Aot);
            body := or xx { err |
                @println("failed emit_bc for %", comp.get_string(func.name));
                comp.report_error(err)
            }; // TODO: return error instead
            
            @if_let(func.body) fn Bytecode(b) => {
                body = FnBody.ptr_from_int(b);
            };
            
            if body.func != fid {
                // We just noticed its a duplicate.
                //work_stack&.push(body.func);
                // TODO: it would be nice if we could just skip and always emit calls to the target, 
                //       but i think we might have already generated some so make a forwarding shim. 
                //       also now i don't call follow_redirects all the time because i have to rewrite that to use vtable.  -- Sep 21
                //continue(); 
                ::tagged(FuncImpl);
                @debug_assert(func.body&.is(.Redirect), "expected redirect");
            };
            
            gen.body = body;
            if body.blocks.len.eq(0) || func.body&.is(.Redirect) {
                success := gen.backend&.emit_special(fid, func.body&, func, body, gen.pending&); 
                if !success {
                    success = gen.backend&.emit_special_asm(func.body&, func, body, target); 
                };
                if !success {
                    // TODO: should assert but debug_tag_corruption is confused. -- Jun 27
                    real_name := comp.get_string(func.name);
                    @eprintln("!!!! failed to emit speciai function: %", real_name);
                };
                //assert(success, "failed to emit speciai function");
            } else {
                gen.backend&.emit_function_husk(fid, body.signeture) {
                    gen&.emit_current_function();
                };
                emitted_functions += 1;
            };
            
            {comp.vtable.report_aot_progress}(comp.data, fid, false, 2);
            current := work_stack&.pop().unwrap();
            @assert_eq(current, fid, "order messed up");
            gen.funcs_done&.set(fid.to_index().zext(), alloc);
            for func.mutual_callees { c |
                if !gen.funcs_done&.get(c.to_index().zext()) && !work_stack.items().contains(c&)  {
                    work_stack&.push(c);
                };
            };
            if body.func != fid {
                // We just noticed its a duplicate.
                work_stack&.push(body.func);
            };
            if gen.pending.len != 0 {
                for gen.pending& { c | 
                    if !gen.funcs_done&.get(c.to_index().zext()) && !work_stack.items().contains(c&) {
                        work_stack&.push(c);
                    };
                };
                gen.pending&.clear();
            }
        };
        
        if env.static_context_var { context | 
            gen&.add_constant(context);
        };
        
        gen&.emit_entry_points_and_debug_info(comp, fns, entry); // note: qbe hack needs this to be last
        @debug_assert(gen.did_constants, "forgot to call loop_emit_constants");
       
        gen.constants_needed&.drop();
        gen.funcs_done&.drop();
        gen.pending&.drop();
        // TODO: if alloc != temp { temp.reset(mark ? no but that wouldn't catch if they derived a new one from temp
        gen.backend.out
    };
    
    fn loop_emit_constants(gen: *Self) void = {
        constants := 0;
        range(0, gen.max_const_id + 1) {i|
            if gen.constants_needed&.get(i) {
                gen.backend&.emit_constant((id = i.trunc()));
                constants += 1;
            };
        };
        gen.did_constants = true;
    }

    fn emit_current_function(self: *Self) void = {
        mark := mark_temporary_storage();
        s := self.body.blocks.items();
        self.vars = list(temp());
        self.stack = list(temp());
        self.blocks_done = empty();
        self.backend&.setup(self.body, self.vars&);
        self.walk_block((id = 0));
        self.backend&.finished(self.body.func);
        reset_temporary_storage(mark);
    }
    
    fn walk_block(self: *Self, b: BbId) void = {
        // TODO: you cant call pop unless its been instantiated but it cant be instantiated if the type doesn't exist.
        :: ?B.Val; ::?Slice(B.Val);
        block_index: i64 = b.id.zext();
        break :: return;
        if(self.blocks_done&.get(block_index), => break());
        self.blocks_done&.set(block_index, temp());
        
        block := self.body.blocks.items()[block_index]&;
        args := self.backend&.move_to_block(block, b);
        assert(args.len.ge(block.arg_prims.len), "missing block args");
        self.stack&.push_all(args);
        enumerate (block.insts.items()){ i, inst |  
            continue :: local_return;
            inst := inst[];
            @match(inst){
                (fn Nop() => ());
                (fn SaveSsa(slot) => {
                    v := self.stack&.pop().expect("stack for SaveSsa");
                    self.vars[slot.id.zext()] = v;
                });
                (fn LoadSsa(slot) => {
                    v := self.vars[slot.id.zext()];
                    self.stack&.push(v);
                });
                (fn Intrinsic(op) => {
                    arg_count := op.arg_count();
                    args := self.stack.items().slice_last(arg_count).expect("enough args on stack for intrinsic");
                    
                    @match(op) {
                        fn GetContext() => {
                            if self.static_context_var { context | 
                                context := self.backend&.inst_global(context);
                                args[0] = self.backend&.inst_load(context, .P64);
                                continue();
                            };
                        }
                        fn SetContext() => {
                            if self.static_context_var { context | 
                                context := self.backend&.inst_global(context);
                                self.backend&.inst_store(context, args[0], .P64);
                                args[0] = self.backend&.inst_literal(0, .I64);
                                continue();
                            };
                        }
                        @default => ();
                    };
                    
                    ret := self.backend&.inst_intrinsic(args, op);
                    self.stack.len -= arg_count;
                    self.stack&.push_all(ret);
                });
                (fn CallDirect(call) => { //  f, tail, sig
                    f := call.f; // TODO: is this ok? i think i need v if i don't do as many husks
                    //f := self.comp.follow_redirects(call.f); // HACK to fix redirects added by deduplication
                    self.pending&.push(f); // TODO: callees list from compiler should make this redundant but im afraid.
                   
                    sig := self.body.decode_sig(call.sig); 
                    arg_count: i64 = sig.arg_slots();
                    args := self.stack.items().slice_last(arg_count).expect("enough args on stack for call");
                    
                    loc := block.get_debug_loc(i);
                    ret := self.backend&.inst_call(args, sig[], f, call.tail, loc, call.context);
                    self.stack.len -= arg_count;
                    if sig.no_return {
                        self.backend&.inst_trap();
                        break();
                    };
                    if call.tail {
                        // TODO: do this properly
                        self.backend&.inst_return(ret);
                        break();
                    };
                    self.stack&.push_all(ret);
                });
                (fn CallFnPtr(call) => {
                    sig := self.body.decode_sig(call.sig);
                    // TODO: better error message if you don't put the type annotation here. 
                    arg_count: i64 = sig.arg_slots();
                    ptr := self.stack.items()[self.stack.len.sub(arg_count).sub(1)];
                    args := self.stack.items().slice_last(arg_count).expect("enough args on stack for call");
                    loc := block.get_debug_loc(i);
                    ret := self.backend&.inst_call_ptr(args, sig[], ptr, loc, call.context);
                    self.stack.len -= arg_count;
                    self.stack.len -= 1;
                    self.stack&.push_all(ret);
                });
                (fn RotateForImmediateCallPtr() => { // first it just has to work 
                    next := block.insts[i + 1];
                    assert(next&.is(.CallFnPtr), "bad RotateForImmediateCallPtr");
                    sig := self.body.decode_sig(next.CallFnPtr.sig);
                    arg_count: i64 = sig.arg_slots();
                    stack := self.stack&;
                    callee := stack.pop().unwrap();
                    stack.insert(stack.len - arg_count, callee); 
                });
                (fn PushConstant(c) => {
                    v := self.backend&.inst_literal(c.value, c.ty);
                    self.stack&.push(v);
                });
                (fn PushGlobalAddr(id) => {
                    self.add_constant(id);
                    v := self.backend&.inst_global(id);
                    self.stack&.push(v);
                });
                (fn JumpIf(jump) => { //  { true_ip, false_ip, slots }
                    cond := self.stack&.pop().expect("stack for jumpif");
                    args := self.stack.items().slice_last(jump.slots.zext()).expect("enough args on stack for JumpIf");
                    self.backend&.inst_jump_if(cond, jump.true_ip, jump.false_ip, args);
                    self.stack.len -= jump.slots.zext();
                    stack := self.stack.items().clone(temp());
                    self.walk_block(jump.true_ip);
                    self.stack = stack;
                    self.walk_block(jump.false_ip);
                    break();
                });
                (fn Goto(jump) => { // { ip, slots }
                    args := self.stack.items().slice_last(jump.slots.zext()).expect("enough args on stack for Jump");
                    @debug_assert_eq(args.len, self.body.blocks[jump.ip.id.zext()].arg_prims.len(), "expected enough args for block");
                    self.backend&.inst_jump(jump.ip, args);
                    self.stack.len -= jump.slots.zext();
                    self.walk_block(jump.ip);
                    break();
                });
                (fn Ret0() => {
                    self.backend&.inst_return(empty());
                    break();
                });
                (fn Ret1(_) => {
                    args := self.stack.items().slice_last(1).expect("stack for ret1");
                    self.backend&.inst_return(args);
                    self.stack.len -= 1;
                    break();
                });
                (fn Ret2(_) => {
                    args := self.stack.items().slice_last(2).expect("stack for ret2");
                    self.backend&.inst_return(args);
                    self.stack.len -= 2;
                    break();
                });
                (fn GetNativeFnPtr(f) => {
                    //f = self.comp.follow_redirects(f);  // TODO: is not doing this ok? i think i need it if i don't do as many husks
                    self.pending&.push(f); // TODO: callees list from compiler should make this redundant but im afraid
                    v := self.backend&.inst_func_ref(f);
                    self.stack&.push(v);
                });
                (fn Load(ty) => {
                    addr := self.stack&.pop().unwrap();
                    v    := self.backend&.inst_load(addr, ty);
                    self.stack&.push(v);
                });
                (fn StorePost(ty) => {
                    assert(self.stack.len.ge(2), "StorePost: not enough args");
                    addr := self.stack&.pop().unwrap();
                    v    := self.stack&.pop().unwrap();
                    self.backend&.inst_store(addr, v, ty);
                });
                (fn StorePre(ty) => {
                    assert(self.stack.len.ge(2), "StorePre: not enough args");
                    v    := self.stack&.pop().unwrap();
                    addr := self.stack&.pop().unwrap();
                    self.backend&.inst_store(addr, v, ty);
                });
                (fn AddrVar(slot) => {
                    ptr := self.vars[slot.id.zext()];
                    self.stack&.push(ptr);
                });
                (fn IncPtrBytes(bytes) => {
                    ptr := self.stack&.pop().unwrap();
                    res := self.backend&.inst_offset(ptr, bytes);
                    self.stack&.push(res);
                }); // TODO: better error message if you forget this semi-colon
                (fn Unreachable() => {
                    self.backend&.inst_trap();
                    break();
                });
                (fn NoCompile() => {
                    panic("ICE: NoCompile");
                });
                (fn LastUse(_) => ());
                (fn PeekDup(skip) => {
                    i := self.stack.len().sub(skip.zext()).sub(1);
                    v := self.stack[i];
                    self.stack&.push(v);
                });
                (fn Snipe(skip) => {
                    index := self.stack.len().sub(skip.zext()).sub(1);
                    self.stack&.ordered_remove(index);
                });
                (fn CopyBytesToFrom(bytes) => {
                    from := self.stack&.pop().unwrap();
                    to := self.stack&.pop().unwrap();
                    self.backend&.inst_copy(from, to, bytes);
                });
                fn Switch(idx) => {
                    info := self.body.switch_payloads.index(idx.zext());
                    value := self.stack&.pop().unwrap();
                    self.backend&.inst_switch(info, value, idx.zext());
                    for info { case |
                        stack := self.stack.items().clone(temp());
                        self.walk_block(case.block);
                        self.stack = stack;
                    };
                    break();
                }
            }; // continues
        };
    }
    
    // TODO: super dumb that i have to walk twice. 
    fn add_constant(self: *Self, id: BakedVarId) void = {
        index: i64 = id.id.zext();
        if(self.constants_needed&.get(index), => return());
        
        self.constants_needed&.set(index, libc_allocator);
        self.max_const_id = self.max_const_id.max(index);
        value := {self.program.vtable.get_baked}(self.program.data, id)[]._1&;
        
        @match(value) {
            (fn VoidPtrArray(parts) => {
                for(parts[].items()){inner|
                    @match(inner) {
                        (fn FnPtr(f) => self.pending&.push(f));
                        (fn AddrOf(v) => self.add_constant(v));
                        (fn Num(_) => ());
                    };
                };
            });
            @default => ();
        }
    }

    Self
}

fn arg_count(i: Intrinsic) i64 #inline = {
    if(i.raw() >= @run Intrinsic.BitNot.raw(), => 1, => 2)
}

fn get_debug_loc(block: *BasicBlock, inst_index: i64) ?Span = {
    if(block.debug.len <= inst_index, => return(.None)); // len=0 when debug info is disabled. 
    loc := block.debug[inst_index];
    if(loc.low == 0 && loc.high == 0, => return(.None));
    (Some = loc)
}

#include_std("compiler/ast_external.fr");
