// trying to debug __temp_alloc base size being wrong
// - emit_relocatable_constant_body had to dump_dirty/__clear_cache
// that wasn't the problem i'm looking for tho.
#test fn bus_error_baking_constant() = {
    MeArena :: @struct {
        Inner :: @struct {
            parent: Alloc;
            base_size: i64;
        };
        i: Inner;
    };
    
    fn bake_relocatable_value(self: *MeArena) Slice(BakedEntry) = {
        bytes := MeArena.cast_to_bytes(self);
        entries := dyn_bake_relocatable_value(bytes, MeArena.Inner, true);
        entries
    }
    
    constant :: @static(MeArena) (i = (parent = page_allocator, base_size = 1234)); 
    x := constant[].i.base_size;
    assert_eq(x, 1234);
}

// This was the __temp_alloc problem.
// I just wasn't adding the padding for voids in .None (and other tagged things),
// so the thing was too short and you were reading off the end or getting later fields.
// but only if the payload had pointers because otherwise you'd just emit the bytes. 
#test fn baked_constant_tagged_padding() = {
    MeArena :: @struct {
        Inner :: @struct {
            chunk: ?*i64;
            base_size: i64;
        };
        i: Inner;
    };
    
    fn bake_relocatable_value(self: *MeArena) Slice(BakedEntry) = {
        bytes := MeArena.cast_to_bytes(self);
        entries := dyn_bake_relocatable_value(bytes, MeArena.Inner, true);
        entries
    }

    constant :: @static(MeArena) (i = (chunk = .None, base_size = 1234)); 
    x := constant[].i.base_size;
    assert_eq(x, 1234);
}

// this was about letting Never fall through with early returns? really need to fix that...
// TODO: make a test for the actual problem hopefully before i forget
#test fn derive_eq_doesnt_even_work() = {
    Bc :: @tagged(
        Snipe: u16,
    );

    :: {
        tagged(Bc);
        AutoEq(Bc);
    };
    
    a := 0xFFFF;
    b := 0xFFFF;
    ::assert_eq(u16);
    assert_eq(a, b); // this works...

    a: Bc = (Snipe = 123);
    b: Bc = (Snipe = 123);
    same := a& == b&;
    assert_eq(true, same);
}

#test fn derive_eq_segfaults() = {
    FuncId :: @struct(f: u32);
    Bc :: @tagged(
        CallDirect: @struct(sig: PrimSig, f: FuncId, tail: bool),     // <args:m> -> <ret:n>
        CallFnPtr: @struct(sig: PrimSig),                             // <ptr:1> <args:m> -> <ret:n>
        PushConstant: @struct(value: i64, ty: Prim),                  // _ -> <v:1>
        JumpIf: @struct(true_ip: BbId, false_ip: BbId, slots: u16),   // <args:slots> <cond:1> -> !
        Goto: @struct(ip: BbId, slots: u16),                          // <args:slots> -> !
        GetNativeFnPtr: FuncId,                                       // _ -> <ptr:1>
        Load: Prim,                                                   // <ptr:1> -> <?:n>
        StorePost: Prim,                                              // <?:n> <ptr:1> -> _
        StorePre: Prim,                                               // <ptr:1> <?:n> -> _
        AddrVar: @struct(id: u16),                                    // _ -> <ptr:1>
        SaveSsa: @struct(id: u16, ty: Prim),                          // <p:1> -> _
        LoadSsa: @struct(id: u16),                                    // _ -> <p:1>
        IncPtrBytes: u16,                                             // <ptr:1> -> <ptr:1>
        PeekDup: u16,                                                 // <x:1> <skip:n> -> <x:1> <skip:n> <x:1>,
        CopyBytesToFrom: u16,                                         // <to_ptr:1> <from_ptr:1> -> _
        LastUse: @struct(id: u16),                                    // _ -> _
        Unreachable,                                                  // _ -> !
        GetCompCtx,                                                   // _ -> <ptr:1>
        NoCompile,
        PushGlobalAddr: BakedVarId,
        Snipe: u16,
        Ret0, // big return uses this too because code has already written to indirect return address.
        Ret1: Prim,
        Ret2: Ty(Prim, Prim),
        Nop,
    );
    
    PrimSig :: @struct(
        args: Slice(Prim) = empty(),
        ret1: ?Prim,
        ret2: ?Prim,
        return_value_bytes: u16 = 0,
        first_arg_is_indirect_return: bool = false,
        no_return: bool = false,
        arg_int_count: u8 = 0,
    );
    
    FnBody :: @struct(
        blocks: RawList(BasicBlock),
        // TODO: would be nice if i could sort these so less alignment padding on my backends. 
        //       but thats a pain because then you need to map indexes.
        vars: RawList(VarSlotType),
        alloc: Alloc,
        hash: i64 = 0,
        signeture: PrimSig,
        func: FuncId,
        name: Symbol,
        current_block: BbId,  // TODO: remove. only needed while building
        clock: u16,           // TODO: remove. only needed while building
        want_log: bool,       // TODO: remove. only needed while building
    );
    VarSlotType :: @struct(size: u16, align: u16);
        
    BbId :: @struct(id: u16);
    BasicBlock :: @struct(
        insts: RawList(Bc),
        arg_prims: Slice(Prim),
        incoming_jumps: u16,
        clock: u16,
    );
    
    fn eq(lhs: **FnBody, rhs: **FnBody) bool = {
        if(lhs.blocks&.items() != rhs.blocks&.items(), => return(false));
        if(lhs.vars&.items() != rhs.vars&.items(), => return(false));
        true
    }
    
    Prim :: @enum(i64) (I8, I16, I32, I64, F64, F32, P64);
    
    :: {
        tagged(Bc);
        enum(Prim);
        AutoEq(Bc);
        AutoEq(PrimSig);
        DerefEq(Prim);
        AutoEq(?Prim);
        AutoEq(BbId);
        AutoEq(BakedVarId);
        AutoEq(BasicBlock);
        AutoEq(VarSlotType);
        DerefEq(FuncId);
        fn eq(a: FuncId, b: FuncId) bool #redirect(Ty(u32, u32), bool);
        AutoEq(get_variant_type(Bc, Bc.Tag().CallDirect));
        AutoEq(get_variant_type(Bc, Bc.Tag().CallFnPtr));
        AutoEq(get_variant_type(Bc, Bc.Tag().PushConstant));
        AutoEq(get_variant_type(Bc, Bc.Tag().JumpIf));
        AutoEq(get_variant_type(Bc, Bc.Tag().Goto));
        AutoEq(get_variant_type(Bc, Bc.Tag().AddrVar));
        AutoEq(get_variant_type(Bc, Bc.Tag().SaveSsa));
        AutoEq(get_variant_type(Bc, Bc.Tag().LoadSsa));
        AutoEq(get_variant_type(Bc, Bc.Tag().LastUse));
        AutoEq(get_variant_type(Bc, Bc.Tag().Ret2));
    };
    
    a: Bc = (AddrVar = (id = 123));
    b: Bc = (AddrVar = (id = 123));
    assert_eq(true, a& == b&);
    
    garbage := FnBody.zeroed();
    garbage_ref := garbage&;
    assert_eq(true, garbage_ref& == garbage_ref&);
}

// Fixed by having compiler.rs/compile_expr/Block use the requested type if the result expr was Never. 
// Previously you'd inline thing3, decide its type was Never, so result was Never, so you didn't bother returning the right thing. 
// This solution is kinda a hack, should instead fix in emit_bc to never do garbage stuff. 
// It ended up returning the address of result instead of loading it because that happened to be on top of the stack when it got bored of compiling. 
#test fn early_return_fallthrough_never() = { // :early_return_fallthrough_never
    fn thing11() i64 = {
        result := thing55();
        result
    }
    
    fn thing55() i64 #inline = {
        return(123);
        // 123 // this works
        unreachable() // this doesn't
    }
    
    result := thing11();
    assert_eq(result, 123);
}

// Here the problem was not discarding the old result location after pushing a new one for a large early return. 
#test fn early_return_big() = { // :early_return_big
    Big :: @struct(a: i64, b: i64, c: i64);
    
    fn thing111() Big = {
        result := thing555();
        result
    }
    
    fn thing555() Big #inline = {
        return(a = 1, b = 2, c = 3) // this doesn't work
        //(a = 4, b = 5, c = 6) // this alone works 
    }
    
    result := thing111();
    // If you did this instead, you got these instead of garbage. so its not writting to the right place
    //result: Big = (a = 255, b = 255, c = 255);
    //result = thing111();
    
    assert_eq(result.a, 1);
    assert_eq(result.b, 2);
    assert_eq(result.c, 3);
}

#test fn early_return_big_non_never() = {
    Big :: @struct(a: i64, b: i64, c: i64);
    
    get1 :: fn() Big = {
        x := get2();
        x
    };
    
    get2 :: fn() Big #inline = {
        return(a = 1, b = 2, c = 3);
        (a = 0, b = 0, c = 0)
    };
    
    result := get1();
    assert_eq(result.a, 1);
}

#test fn early_return_big_skipped() = {
    Big :: @struct(a: i64, b: i64, c: i64);
    
    get1 :: fn() Big = {
        pls :: fn() Big #inline = {
            s := if true {
                if(false, => return(Big.zeroed()));
                5
            } else {
                6
            };
            
            (a = 1, b = 2, c = 3)
        };
        x := pls();
        x
    };
    
    result := get1();
    
    assert_eq(result.a, 1); 
    assert_eq(result.b, 2); 
    assert_eq(result.c, 3);
}

#test fn enum_names_constant() = {
    A :: @enum(i64) (hello, world);
    names :: A.get_enum_names();
    assert_eq(names[0], "hello");
    assert_eq(names[1], "world");
}

fn baked_align_padding() #test = {
    Outer :: @struct {
        inner: Inner = ();
        // 4 bytes of padding here
        eight: *i64;
    };
    Inner :: @struct {
        a: u32 = 1;
        b: u32 = 2;
        c: u32 = 3;
    };
    
    constant := @static(Outer) (eight = @static(i64) 19);
    assert_eq(constant[].eight[] + constant[].inner.a.zext(), 20);
}

fn let_me_panic() #test = {
    a :: fn(cond: bool) i64 #noinline = {
        if cond {
            crash();
        };
        123
    };
    crash :: fn() i64 #noinline = {
        panic("This can't happen")
    };
    
    a(false);
}

/*
this is a situation where we need to call created_jit_fn_ptr_value on the shim's address. 

the address of `func` is never created as a int/Value in sema. 
it hasn't been jitted yet when it gets to took_pointer_value so that's just recorded as a flag. 
since func() is in mutual_callees of init_data(), a shim is created in shallow_jit_func and put in the GOT.  
an Expr::FnPtr gets to emit_ir and func_ref() makes a Con without creating the address. 
since comptime uses got_indirection_instead_of_patches, it becomes a GOT lookup. 
so when init_data runs to create the constant, you get the address of that shim, 
and when you go to bake that constant, we need to be able to track it back to func(). 
but notice that get_fn_callable was never called for func(), so create_jit_shim needs to know about TookPointerValue. 
-- Mar 23, 2025 
*/
fn tracking_shims_in_data() void #test = {
    F         :: @FnPtr() i64;
    Callable  :: @struct(callee: F);
    func      :: fn() i64 = int_from_ptr(Callable, data);
    data      :: init_data();
    init_data :: fn() *Callable = {  // inlined @static so you can tell what's going on
        d := box_zeroed(ast_alloc(), Callable);
        d[] = (callee = func);
        d
    };
    
    x := data[]'callee();
    y := Callable.ptr_from_int(x);
    @assert_eq(x, y'callee());
}

// the field order/counts are important for reproducing the bug
// see devlog :ByteOffsetUninitRootCause -- Apr 3, 2025
fn field_init_reorder() #test = {
    #use("@/lib/collections/enum_map.fr");
    
    Iterator :: @struct {
        point: *i64;
        gps: *i64;
        rgb: *i64;
        has: EnumMap(ItemRecord.Kind, bool);
        stream: Stream;
    }
    Stream :: @struct {
        input: []u8;
        i: i64;
        value: u32;
        length: u32;
    }
    ItemRecord :: @struct {
        Kind :: @enum(u16) (
            Byte, _Short, _Integer, _Long, _Float, _Double, 
            Point10, GPSTime11, RGB12, Wavepacket13, 
            Point14, RGB14, RGBNIR14, Wavepacket14, Byte14,
        );
        type: Kind;
        size: u16;
        version: u16;
    }
    
    a, b, c := (0, 1, 2);
    self: Iterator = (point = a&, gps = b&, rgb = c&, stream = zeroed Stream, has = zeroed(EnumMap(ItemRecord.Kind, bool)));
    each self.has.data& { it |
        @assert(!it[]);
    };
}

fn cycles() #test = {
    main :: fn() void = {
        new_sema_fill_export_ffi();
    }
    
    call_main: rawptr : fn() void = {
        main();
    };
    
    new_sema_fill_export_ffi :: fn() void = {
        out: List(u8) = list(temp());
        @fmt(out&, "%", call_main);
        escape(out.items());
    }
    
    escape :: fn(_: []u8) void #noinline = ();
    
    main();
}
