// #requires(raw_ptr);
// #import(lib/codegen/aarch64/instructions); #import(lib/collections);

const BoxMmap = VoidPtr;
const CodePtr = VoidPtr;
fn copy_to_mmap_exec(insts: Slice(u32)) (BoxMmap, CodePtr);

fn call_jit(input: i64, code: Slice(u32)) i64 = {
    var map_and_ptr = copy_to_mmap_exec(code);
    let ptr: Ptr(CodePtr) = raw_slice(map_and_ptr!addr, size_of(VoidPtr), mul(size_of(VoidPtr), 2));
    let f: FnPtr(i64, i64) = ptr[];
    f(input)
}

fn heap(ops: Slice(u32)) Slice(u32) = {
    var out: List(u32) = list(ops.len[]);
    push_all(out!addr, ops);
    var out: Slice(u32) = items(out!addr);
    out
}

fn main(canary: i64) i64 = {
    // TODO: fix typecheck. 
    // { let a: u5 = 0b10101010101010; }!assert_compile_error;
    // ((fn(a: u1) u1 = 0x1)(0b11))!assert_compile_error;
    add_sr(Bits.X64[], x0, x1, x0, Shift.LSL[], 0x0000)!assert_compile_error;  // TODO: why does this one work but not the above? 
    
    let code = (
        movz(Bits.X64[], x1, 0b0000000000001010, Hw.Left0[]), 
        add_sr(Bits.X64[], x0, x1, x0, Shift.LSL[], 0), 
        ret()
    )!slice;
    assert_eq(call_jit(90, code), 100);
    
    // Decimal literals auto cast to any bit size. 
    // TODO: bounds checking for constants. 
    let code = (
        movz(Bits.X64[], x1, 120, Hw.Left0[]), 
        add_sr(Bits.X64[], x0, x0, x1, Shift.LSL[], 0), 
        ret()
    )!slice;
    assert_eq(call_jit(80, code), 200);
    
    @c_call
    fn add_by_asm(a: i64, b: i64) i64 = heap((
        add_sr(Bits.X64[], x0, x0, x1, Shift.LSL[], 0),
        ret(),
    )!slice)!asm;
    
    let three = add_by_asm(1, 2);
    assert_eq(three, 3);
    
    @c_call
    fn add_one(a: i64) i64 = heap((
        add_im(Bits.X64[], x0, x0, 1, 0),
        ret(),
    )!slice)!asm;
    assert_eq(add_one(9), 10);
    
    @c_call
    fn sub_one(a: i64) i64 = heap((
        sub_im(Bits.X64[], x0, x0, 1, 0),
        ret(),
    )!slice)!asm;
    assert_eq(sub_one(10), 9);

    @c_call
    fn use_stack(a: i64) i64 = heap((
        sub_im(Bits.X64[], sp, sp, 16, 0),
        str_uo(Bits.X64[], x0, sp, 1),
        movz(Bits.X64[], x0, 10, Hw.Left0[]), 
        ldr_uo(Bits.X64[], x1, sp, 1),
        add_sr(Bits.X64[], x0, x0, x1, Shift.LSL[], 0),
        ret(),
    )!slice)!asm;
    assert_eq(use_stack(15), 25);

    @c_call
    fn read_pair(a: i64, b: i64) i64 = heap((
        sub_im(Bits.X64[], sp, sp, 16, 0),
        str_uo(Bits.X64[], x0, sp, 1),
        str_uo(Bits.X64[], x1, sp, 2),
        ldp_so(Bits.X64[], x2, x3, sp, 1),
        sub_sr(Bits.X64[], x0, x2, x3, Shift.LSL[], 0),
        ret(),
    )!slice)!asm;
    assert_eq(read_pair(30, 20), 10);

    @c_call
    fn write_pair(a: i64, b: i64) i64 = heap((
        sub_im(Bits.X64[], sp, sp, 16, 0),
        stp_so(Bits.X64[], x0, x1, sp, 1),
        ldr_uo(Bits.X64[], x2, sp, 1),
        ldr_uo(Bits.X64[], x3, sp, 2),
        sub_sr(Bits.X64[], x0, x2, x3, Shift.LSL[], 0),
        ret(),
    )!slice)!asm;
    assert_eq(write_pair(30, 20), 10);

    @c_call
    fn both_pair(a: i64, b: i64) i64 = heap((
        sub_im(Bits.X64[], sp, sp, 16, 0),
        stp_so(Bits.X64[], x0, x1, sp, 1),
        ldp_so(Bits.X64[], x2, x3, sp, 1),
        sub_sr(Bits.X64[], x0, x2, x3, Shift.LSL[], 0),  // sub means order matters, so you can catch if flipped in encoding.
        ret(),
    )!slice)!asm;
    assert_eq(both_pair(30, 20), 10);
    
    canary
}
