//! TODO: utf8

Token :: @struct(type: TokenType, span: Span);

BinNum :: @struct(bit_count: u8, value: u64); // TODO: use this struct in the FromBitLiteral ast node? 
TokenType :: @tagged(
    Number: i64,
    // TODO: if this is below, it gets shadowed by the varient
    Quoted: @struct(s: Symbol, escapes: bool),
    Symbol: Symbol,
    Op: Operator, 
    Error: LexErr,
    Float: f64,
    // Bit count means leading zeros are observable.
    BinaryNum: BinNum,
    LeftSquiggle, RightSquiggle, LeftParen, RightParen, LeftSquare, RightSquare,
    Dot, At, Comma, Colon, Semicolon, DoubleSquare, Hash, FatRightArrow, DoubleColon, 
    Amp, Question, Pipe, Equals, Dollar, Eof, Squiggle, 
    Fn, // TODO: if i could remove this i'd have no keywords which would be kinda pleasing.
    Tick, DotDot,
);
:: tagged(TokenType);

::enum(Operator);
Operator :: @enum(i64) (Plus, Minus, Star, Slash, Less, Greater, Bang, PlusEq, MinusEq, StarEq, SlashEq, LessEq, GreaterEq, BangEq, EqEq, AmpAmp, PipePipe);

LexErr :: @tagged(
    Unexpected: i64,
    UnterminatedStr,
    /// C has it mean octal which I don't really like but I don't want to accept the same syntax and mean something different.
    DenyLeadingZero,
    TooManyBits,
    UnterminatedComment,
    IdentifiersCannotUseUnicodeSorry,
    TodoEscapesInRawIdent,
    // TODO: ThatsNotANormalQuoteDidYouCopyPasteFromAPdf,
);

Lexer :: @struct(
    pool: *StringPool,
    root: Span,
    src: Str,
    start := 0,
    current := 0,
    // TODO: can't put `()!uninitialized` here as default value because c backend sees its an enum and thinks it might have a pointer in there and can't deal with it. 
    //       need to be smarter about how constants get emitted. 
    token: Token,
    line := 0,
    old_line := 0,
);

// TODO: need be be able to find the ResAddr cause it might not be on top of the stack. (early return from flat_call: big ret/arg value )
fn peek(self: *Lexer) *Token = self.token&;

fn pop(self: *Lexer) *Token = {
    self.old_line = self.line;
    if(self.eat_white_space_hit_end(), => return(self.token&));
    self.start = self.current;
    
    // TODO: fancier switch statements. 
    @switch(self.peek_c()) {
        @inclusive("a".ascii(), "z".ascii()) => self.lex_ident();
        @inclusive("A".ascii(), "Z".ascii()) => self.lex_ident();
        @case("_".ascii()) => self.lex_ident();
        @case(";".ascii()) => self.one(.Semicolon);
        @case(":".ascii()) => self.pair(":".ascii(), .Colon, .DoubleColon);
        @case(".".ascii()) => self.pair(".".ascii(), .Dot, .DotDot);
        @case("(".ascii()) => self.one(.LeftParen);
        @case(")".ascii()) => self.one(.RightParen);
        @case("{".ascii()) => self.one(.LeftSquiggle);
        @case("}".ascii()) => self.one(.RightSquiggle);
        @case(",".ascii()) => self.one(.Comma);
        @case("$".ascii()) => self.one(.Dollar);
        @case("+".ascii()) => self.pair("=".ascii(), (Op = .Plus), (Op = .PlusEq));
        @case("-".ascii()) => self.pair("=".ascii(), (Op = .Minus), (Op = .MinusEq));
        @case("*".ascii()) => self.pair("=".ascii(), (Op = .Star), (Op = .StarEq));
        @case("/".ascii()) => self.pair("=".ascii(), (Op = .Slash), (Op = .SlashEq));
        @case("<".ascii()) => self.pair("=".ascii(), (Op = .Less), (Op = .LessEq));
        @case(">".ascii()) => self.pair("=".ascii(), (Op = .Greater), (Op = .GreaterEq));
        @case("!".ascii()) => self.pair("=".ascii(), (Op = .Bang), (Op = .BangEq));
        @case("~".ascii()) => self.one(.Squiggle);
        @case("=".ascii()) => {
            found := @switch(self.peek_c(1)) {
                @case("=".ascii()) => {
                    self.current += 1;
                    @as(TokenType) (Op = .EqEq)
                };
                @case(">".ascii()) => {
                    self.current += 1;
                    TokenType.FatRightArrow
                };
                @default => TokenType.Equals;
            };
            self.one(found)
        };
        @case("@".ascii()) => {
            self.current += 1;
            if self.peek_c() == "\"".ascii() {
                self.start += 1;  // lex_string will skip the " but we have to skip the @
                if self.lex_string() {
                    s := self.token.type&;
                    if s.Quoted.escapes {
                        // TODO: expand_string_escapes
                        self.error(.TodoEscapesInRawIdent);
                    } else {
                        s[] = (Symbol = s.Quoted.s);
                    };
                };
                self.token.span.low -= 1;
            } else {
                self.put_token(.At);
            };
        };
        @case("&".ascii()) => self.pair("&".ascii(), .Amp, (Op = .AmpAmp));
        @case("#".ascii()) => {
            if self.peek_c(1) == "!".ascii() {
                dowhile() {
                    self.current += 1;
                    self.peek_c() != "\n".ascii() && self.peek_c() != 0
                };
                return(self.pop());
            };
            self.one(.Hash)
        };
        @case("?".ascii()) => self.one(.Question);
        @case("|".ascii()) => self.pair("|".ascii(), .Pipe, (Op = .PipePipe));
        @case("[".ascii()) => self.pair("]".ascii(), .LeftSquare, .DoubleSquare);
        @case("]".ascii()) => self.one(.RightSquare);
        @case("'".ascii()) => self.one(.Tick);
        @case("\"".ascii()) => { self.lex_string(); };
        @case("0".ascii()) => {
            @switch(self.peek_c(1)) {
                @case("x".ascii()) => self.lex_hex();
                @case("b".ascii()) => self.lex_bin();
                @case(".".ascii()) => self.lex_num();
                @inclusive("0".ascii(), "9".ascii()) => self.error(.DenyLeadingZero);
                @default => self.one((Number = 0));
            };
        };
        @inclusive("1".ascii(), "9".ascii()) => self.lex_num();
        @case(0) => self.put_token(.Eof);  // TODO: check that we're actually at the end
        @default fn(c: u8) => { 
            if c >= 128 {
                self.error(.IdentifiersCannotUseUnicodeSorry);
            } else {
                self.error(Unexpected = c.zext());
            };
        };
    };
    self.token&
}

fn skip_to_closing_squigle(self: *Lexer) ?Ty(Str, Span) = {
    start := self.start;
    self.current += 1;
    depth := 1;
    whileb (=> depth.gt(0)) { ($break) |
        if self.eat_white_space_hit_end() {
            return(.None);
        };
        // TODO: skip #! ...... \n but it only matters if you had unnested stuff there which you shouldn't -- Apr 28
        @switch(self.peek_c()) {
            @case("\"".ascii()) => {
                self.skip_string();
            };
            @case("{".ascii()) => {
                depth += 1;
                self.current += 1;
            };
            @case("}".ascii()) => {
                depth -= 1;
                self.current += 1;
            };
            @default => {
                self.current += 1;
            };
        };
    };
    text := self.src.slice(start, self.current);
    span := self.root.subspan(start.trunc(), self.current.trunc());
    self.start = self.current;
    self.peek();
    (Some = (text, span))
}

fn skip_string(self: *Lexer) Ty(Str, bool, bool) = {
    err :: fn() Never => return("FAILED TO LEX STRING YOU SHOULD NEVER SEE THIS ICE", false, false);
    
    is_multiline := self.peek_c(1).eq("\"".ascii()).and(=> self.peek_c(2).eq("\"".ascii()));
    escapes := false;
    text := if is_multiline {
        self.current += 2;
        dowhile {
            self.current += 1;
            @switch(self.peek_c()) {
                @case("\"".ascii()) => {
                    self.peek_c(1).eq("\"".ascii()).and(=> self.peek_c(2).eq("\"".ascii())).not()
                };
                @case(0) => {
                    self.error(.UnterminatedStr);
                    err();
                    false
                };
                @default => true;
            }
        };
        self.current += 3;
        self.src.slice(self.start.add(3), self.current.sub(3))
    } {
        dowhile {
            self.current += 1;
            @switch(self.peek_c()) {
                @case("\"".ascii()) => false;
                @case("\\".ascii()) => {
                    self.current += 1; // extra for "\""
                    escapes = true;
                    true
                };
                @case("\n".ascii()) => {
                    self.error(.UnterminatedStr);
                    err();
                    false
                };
                @case(0) => {
                    self.error(.UnterminatedStr);
                    err();
                    false
                };
                @default => true;
            }
        };
        self.current += 1;
        self.src.slice(self.start.add(1), self.current.sub(1))
    };

    (text, escapes, true)
}

fn lex_string(self: *Lexer) bool = {
    // TODO: destructuring 
    text, escapes, success := self.skip_string();
    if success {
        self.put_token((Quoted = (s = self.pool.insert_owned(text), escapes = escapes)));
    };
    success
}

fn lex_num(self: *Lexer) void = {
    whole := self.lex_int();
    if self.peek_c() == ".".ascii() && self.peek_c(1).is_ascii_digit() {
        // Actually, that's a float.
        self.current += 1;
        start := self.current;
        fraction := self.lex_int();
        end := self.current;
        digits := end.sub(start);
        scale := 10.pow(digits);
        n := whole.float().add(fraction.float().div(scale.float()));
        self.put_token((Float = n));
    } else {
        self.put_token((Number = whole));
    };
}

// TODO: error on overflow
fn lex_int(self: *Lexer) i64 = {
    total := 0;
    dowhile {
        total *= 10;
        total += self.peek_c().dec_digit().unwrap();
        self.current += 1;
        while => self.peek_c() == "_".ascii() {
            self.current += 1;
        };
        self.peek_c().is_ascii_digit()
    };
    total
}

fn lex_hex(self: *Lexer) void #once = {
    self.current += 2;
    total := 0;
    
    if !self.peek_c().is_hex_digit() {
        self.error((Unexpected = self.peek_c().zext()));
        return();
    };
    
    bits := 0;
    dowhile {
        total *= 16;
        bits += 4;
        if bits > 64 {
            self.error(.TooManyBits);
            return();
        };
        total += self.peek_c().hex_digit().unwrap(); // TODO: dumb that i do an extra switch here when i just did one at the end of the loop, but nothing matters. 
        self.current += 1;
        while => self.peek_c() == "_".ascii() {
            self.current += 1;
        };
        self.peek_c().is_hex_digit()
    };
    self.put_token((BinaryNum = (bit_count = bits.trunc(), value = total.bitcast())));
}

fn is_hex_digit(c: u8) bool = {
     @switch(c) {
        @inclusive("0".ascii(), "9".ascii()) => true;
        @inclusive("a".ascii(), "f".ascii()) => true;
        @inclusive("A".ascii(), "F".ascii()) => true;
        @default => false;
    }
}

fn lex_bin(self: *Lexer) void #once = {
    self.current += 2;
    total := 0;
    
    c := self.peek_c();
    if c.ne("0".ascii()).and(c.ne("1".ascii())) {
        self.error((Unexpected = self.peek_c().zext()));
        return();
    };
    
    bits := 0;
    dowhile {
        total *= 2;
        bits += 1;
        if bits.gt(64) {
            self.error(.TooManyBits);
            return();
        };
        more := @switch(self.peek_c()){
            @case("0".ascii()) => {
                self.current += 1;
                true
            };
            @case("1".ascii()) => {
                self.current += 1;
                total += 1;
                true
            };
            @default => false;
        };
        while => self.peek_c() == "_".ascii() {
            self.current += 1;
        };
        more
    };
    bits -= 1;
    total = total.div(2); // TODO: /= doesn't work // TODO: right shift
    self.put_token((BinaryNum = (bit_count = bits.trunc(), value = total.bitcast())));
}

fn lex_ident(self: *Lexer) void = {
    dowhile {
        self.current += 1;
        c := self.peek_c();
        c.is_ascii_alpha() || c.is_ascii_digit() || c == "_".ascii()
    };
    name := self.src.slice(self.start, self.current);
    if name.len == 2 && name[0] == "f".ascii() && name[1] == "n".ascii() {
        self.put_token(.Fn);
    } else {
        ident := self.pool.insert_owned(name);
        self.put_token((Symbol = ident))
    };
}

::if(TokenType);
fn pair(self: *Lexer, maybe: u8, single: TokenType, double: TokenType) void = {
    t := if(self.peek_c(1) == maybe, => {
        self.current += 1;
        double
    }, => single);
    self.one(t);
}

fn one(self: *Lexer, type: TokenType) void = {
    self.current += 1;
    self.put_token(type);
}

fn eat_white_space_hit_end(self: *Lexer) bool = {
    if self.current >= self.src.len {
        self.start = self.current;
        self.put_token(.Eof);
        return(true);
    };
    unterminated := false;
    self.line += import("@/lib/tokenize.fr")'skip_whitespace(fn(n) => self.peek_c(n), => { self.current += 1; }, true, true, unterminated&);
    if unterminated {
        self.error(.UnterminatedComment);
        return(true);
    };
    end := self.current >= self.src.len;
    if end {
        self.start = self.current;
        self.put_token(.Eof);
    };
    end
}

fn error(self: *Lexer, reason: LexErr) void = self.one((Error = reason));
fn put_token(self: *Lexer, type: TokenType) void = {
    //println(self.src.slice(self.start, self.current));
    self.current = self.current.min(self.src.len);
    self.token = (type = type, span = self.root.subspan(self.start.trunc(), self.current.trunc()));
}

fn peek_c(self: *Lexer) u8 = self.peek_c(0);
fn peek_c(self: *Lexer, n: i64) u8 = 
    if(self.current + n < self.src.len, => self.src[self.current.add(n)], => 0);

fn init(pool: *StringPool, root: Span, src: Str) Lexer = {
    self: Lexer = (pool = pool, root = root, src = src, token = Token.zeroed());
    self&.pop(); // get the first token ready. 
    self
}
