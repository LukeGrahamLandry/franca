//! TODO: utf8

// for reference, the rust one was 500 loc.

Token :: @struct(type: TokenType, span: Span);

BinNum :: @struct(bit_count: u8, value: u64);
TokenType :: @tagged(
    Number: i64,
    // TODO: if this is below, it gets shadowed by the varient
    Quoted: @struct(s: Symbol, escapes: bool),
    Symbol: Symbol,
    Qualifier: VarType,
    Op: Operator, 
    Error: LexErr, Eof,
    // Bit count means leading zeros are observable.
    BinaryNum: BinNum,
    LeftSquiggle, RightSquiggle, LeftParen, RightParen, LeftSquare, RightSquare,
    Dot, At, Comma, Colon, Semicolon, DoubleSquare, Hash, FatRightArrow, LeftArrow, DoubleColon, SingleQuote,
    Amp, Question, Pipe, Equals, 
    Fn, Const,
    Float: f64,
);

Operator :: @enum(i64) (Plus, Minus, Star, Slash, Less, Greater, Bang, PlusEq, MinusEq, StarEq, SlashEq, LessEq, GreaterEq, BangEq, EqEq, AmpAmp);
#redirect(Ty(i64, i64), bool) fn eq(a: Operator, b: Operator) bool;

LexErr :: @tagged(
    Unexpected: i64,
    UnterminatedStr,
    /// C has it mean octal which I don't really like but I don't want to accept the same syntax and mean something different.
    DenyLeadingZero,
    TooManyBits,
    UnterminatedComment,
    // TODO: ThatsNotANormalQuoteDidYouCopyPasteFromAPdf,
);

Lexer :: @struct(
    pool: *StringPool,
    root: Span,
    src: Str,
    start := 0,
    current := 0,
    // TODO: can't put `()!uninitialized` here as default value because c backend sees its an enum and thinks it might have a pointer in there and can't deal with it. 
    //       need to be smarter about how constants get emitted. 
    token: Token,
);

// TODO: need be be able to find the ResAddr cause it might not be on top of the stack. (early return from flat_call: big ret/arg value )
fn peek(self: *Lexer) *Token = self.token&;

fn pop(self: *Lexer) *Token = {
    if(self.eat_white_space_hit_end(), => return(self.token&));
    self.start = self.current;
    
    // TODO: fancier switch statements. 
    @switch(self.peek_c()) {
        @inclusive("a".ascii(), "z".ascii()) => self.lex_ident();
        @inclusive("A".ascii(), "Z".ascii()) => self.lex_ident();
        @case("_".ascii()) => self.lex_ident();
        @case(";".ascii()) => self.one(.Semicolon);
        @case(":".ascii()) => self.pair(":".ascii(), .Colon, .DoubleColon);
        @case(".".ascii()) => self.one(.Dot);
        @case("(".ascii()) => self.one(.LeftParen);
        @case(")".ascii()) => self.one(.RightParen);
        @case("{".ascii()) => self.one(.LeftSquiggle);
        @case("}".ascii()) => self.one(.RightSquiggle);
        @case(",".ascii()) => self.one(.Comma);
        @case("+".ascii()) => self.pair("=".ascii(), (Op = .Plus), (Op = .PlusEq));
        @case("-".ascii()) => self.pair("=".ascii(), (Op = .Minus), (Op = .MinusEq));
        @case("*".ascii()) => self.pair("=".ascii(), (Op = .Star), (Op = .StarEq));
        @case("/".ascii()) => self.pair("=".ascii(), (Op = .Slash), (Op = .SlashEq));
        @case("<".ascii()) => self.pair("=".ascii(), (Op = .Less), (Op = .LessEq));
        @case(">".ascii()) => self.pair("=".ascii(), (Op = .Greater), (Op = .GreaterEq));
        @case("!".ascii()) => self.pair("=".ascii(), (Op = .Bang), (Op = .BangEq));
        @case("=".ascii()) => {
            found := @switch(self.peek_c(1)) {
                @case("=".ascii()) => {
                    self.current += 1;
                    @as(TokenType) (Op = .EqEq)
                };
                @case(">".ascii()) => {
                    self.current += 1;
                    TokenType.FatRightArrow
                };
                @default fn(_: u8) => TokenType.Equals;
            };
            self.one(found)
        };
        @case("@".ascii()) => self.one(.At);
        @case("&".ascii()) => self.pair("&".ascii(), .Amp, (Op = .AmpAmp));
        @case("#".ascii()) => self.one(.Hash);
        @case("?".ascii()) => self.one(.Question);
        @case("'".ascii()) => self.one(.SingleQuote);
        @case("|".ascii()) => self.one(.Pipe);
        @case("[".ascii()) => self.pair("]".ascii(), .LeftSquare, .DoubleSquare);
        @case("]".ascii()) => self.one(.RightSquare);
        @case("\"".ascii()) => self.lex_string();
        @case("0".ascii()) => {
            @switch(self.peek_c(1)) {
                @case("x".ascii()) => self.lex_hex();
                @case("b".ascii()) => self.lex_bin();
                @case(".".ascii()) => self.lex_num();
                @inclusive("0".ascii(), "9".ascii()) => self.error(.DenyLeadingZero);
                @default fn(c: u8) => self.one((Number = 0));
            };
        };
        @inclusive("1".ascii(), "9".ascii()) => self.lex_num();
        @case(0) => self.put_token(.Eof);
        @default fn(c: u8) => self.error((Unexpected = c.zext()));
    };
    self.token&
}

fn skip_to_closing_squigle(self: *Lexer) Ty(Str, Span) = {
    start := self.start;
    self.current += 1;
    depth := 1;
    (=> {
        break :: local_return;
        while (=> depth.gt(0)) {|
            if self.eat_white_space_hit_end() {|
                break();
            };
            // TODO: skip #! ...... \n but it only matters if you had unnested stuff there which you shouldn't -- Apr 28
            @switch(self.peek_c()) {
                @case("\"".ascii()) => {
                    self.skip_string();
                };
                @case("{".ascii()) => {
                    depth += 1;
                    self.current += 1;
                };
                @case("}".ascii()) => {
                    depth -= 1;
                    self.current += 1;
                };
                @default fn(_: u8) => {
                    self.current += 1;
                };
            };
        };
    })();
    text := self.src.slice(start, self.current);
    span := self.root.subspan(start.trunc(), self.current.trunc());
    self.start = self.current;
    self.peek();
    (text, span)
}

fn skip_string(self: *Lexer) Ty(Str, bool, bool) = {
    err :: fn() Never => return("FAILED TO LEX STRING YOU SHOULD NEVER SEE THIS ICE", false, false);
    
    is_multiline := self.peek_c(1).eq("\"".ascii()).and(=> self.peek_c(2).eq("\"".ascii()));
    escapes := false;
    text := if is_multiline {|
        self.current += 2;
        dowhile {|
            self.current += 1;
            @switch(self.peek_c()) {
                @case("\"".ascii()) => {
                    self.peek_c(1).eq("\"".ascii()).and(=> self.peek_c(2).eq("\"".ascii())).not()
                };
                @case(0) => {
                    self.error(.UnterminatedStr);
                    err();
                    false
                };
                @default() fn(_: u8) => true;
            }
        };
        self.current += 3;
        self.src.slice(self.start.add(3), self.current.sub(3))
    } {|
        dowhile {|
            self.current += 1;
            @switch(self.peek_c()) {
                @case("\"".ascii()) => false;
                @case("\\".ascii()) => {
                    self.current += 1; // extra for "\""
                    escapes = true;
                    true
                };
                @case(0) => {
                    self.error(.UnterminatedStr);
                    err();
                    false
                };
                @default() fn(_: u8) => true;
            }
        };
        self.current += 1;
        self.src.slice(self.start.add(1), self.current.sub(1))
    };

    (text, escapes, true)
}


fn lex_string(self: *Lexer) void = {
    // TODO: destructuring 
    text_escapes_success := self.skip_string();
    if text_escapes_success._2 {|
        self.put_token((Quoted = (s = self.pool.insert_owned(text_escapes_success._0), escapes = text_escapes_success._1)));
    };
}

fn lex_num(self: *Lexer) void = {
    whole := self.lex_int();
    if self.peek_c().eq(".".ascii()).and(=> self.peek_c(1).is_ascii_digit()) {|
        // Actually, that's a float.
        self.current += 1;
        start := self.current;
        fraction := self.lex_int();
        end := self.current;
        digits := end.sub(start);
        scale := 10.pow(digits);
        n := whole.float().add(fraction.float().div(scale.float()));
        self.put_token((Float = n));
    } {|
        self.put_token((Number = whole));
    
    };
}

fn pow(base: i64, exp: i64) i64 = {
    n := 1;
    range(0, exp) {_|
        n *= base;
    };
    n
}

fn lex_int(self: *Lexer) i64 = {
    total := 0;
    dowhile {|
        total *= 10;
        total += self.peek_c().dec_digit();
        self.current += 1;
        self.peek_c().is_ascii_digit()
    };
    total
}

fn lex_hex(self: *Lexer) void = {
    self.current += 2;
    total := 0;
    
    if not(self.peek_c().is_hex_digit()) {|
        self.error((Unexpected = self.peek_c().zext()));
        return();
    };
    
    bits := 0;
    dowhile {|
        total *= 16;
        bits += 4;
        if bits > 64 {|
            self.error(.TooManyBits);
            return();
        };
        total += self.peek_c().hex_digit(); // TODO: dumb that i do an extra switch here when i just did one at the end of the loop, but nothing matters. 
        self.current += 1;
        self.peek_c().is_hex_digit()
    };
    assert_eq(bits, self.current.sub(self.start).sub(2).mul(4)); // debug
    self.put_token((BinaryNum = (bit_count = bits.trunc(), value = total)));
}

fn is_hex_digit(c: u8) bool = {
     @switch(c) {
        @inclusive("0".ascii(), "9".ascii()) => true;
        @inclusive("a".ascii(), "f".ascii()) => true;
        @inclusive("A".ascii(), "F".ascii()) => true;
        @default fn(_: u8) => false;
    }
}

fn lex_bin(self: *Lexer) void = {
    self.current += 2;
    total := 0;
    
    c := self.peek_c();
    if c.ne("0".ascii()).and(c.ne("1".ascii())) {|
        self.error((Unexpected = self.peek_c().zext()));
        return();
    };
    
    bits := 0;
    dowhile {|
        total *= 2;
        bits += 1;
        if bits.gt(64) {|
            self.error(.TooManyBits);
            return();
        };
        @switch(self.peek_c()){
            @case("0".ascii()) => {
                self.current += 1;
                true
            };
            @case("1".ascii()) => {
                self.current += 1;
                total += 1;
                true
            };
            @default() fn(_: u8) => false;
        }
    };
    bits -= 1;
    total = total.div(2); // TODO: /= doesn't work // TODO: right shift
    assert_eq(bits, self.current - self.start - 2); // debug
    self.put_token((BinaryNum = (bit_count = bits.trunc(), value = total)));
}

fn lex_ident(self: *Lexer) void = {
    dowhile {|
        self.current += 1;
        c := self.peek_c();
        c.is_ascii_alpha().or(=> c.is_ascii_digit()).or(=> c == "_".ascii())
    };
    name := self.src.slice(self.start, self.current);
    // TODO: slow! 
    // TODO: I'm tempted to replace `const name` with `$name`, cause its weird now that I don't use let for normal vars. 
    @switch(name) {
        @case("fn") => self.put_token(.Fn);
        @case("const") => self.put_token(.Const);
        @default fn(s: Str) => {
            ident := self.pool.insert_owned(name);
            self.put_token((Symbol = ident))
        };
    };
}

::if(TokenType);
fn pair(self: *Lexer, maybe: u8, single: TokenType, double: TokenType) void = {
    t := if(self.peek_c(1) == maybe, => {
        self.current += 1;
        double
    }, => single);
    self.one(t);
}

fn one(self: *Lexer, type: TokenType) void = {
    self.current += 1;
    self.put_token(type);
}

fn eat_white_space_hit_end(self: *Lexer) bool = {
    break :: return;
    if self.current >= self.src.len {|
        self.start = self.current;
        self.put_token(.Eof);
        break(true);
    };
    loop {|
        continue :: local_return;
        if self.peek_c().is_whitespace() {|
            self.current += 1;
            continue();
        };
        
        if self.peek_c() == "/".ascii() {|
            @switch(self.peek_c(1)) {
                @case("/".ascii()) => { // single line
                    dowhile {|
                        self.current += 1;
                        self.peek_c().ne("\n".ascii()).and(=> self.peek_c().ne(0))
                    };
                    continue();
                };
                @case("*".ascii()) => { // multiline
                    self.start = self.current; // give right error location if unterminated. 
                    self.current += 2; 
                    depth := 1; 
                    while(=> depth > 0) {|
                        @switch(self.peek_c()){
                            @case("/".ascii()) => {
                                if self.peek_c(1) == "*".ascii() {|
                                    self.current += 1;
                                    depth += 1;
                                };
                            };
                            @case("*".ascii()) => {
                                if self.peek_c(1) == "/".ascii() {|
                                    self.current += 1;
                                    depth -= 1;
                                };
                            };
                            @case(0) => {
                                self.error(.UnterminatedComment);
                                break(true);
                            };
                            @default fn(_: u8) => ();
                        };
                        self.current += 1;
                    };
                    continue();
                };
                // TODO: this should infer the arg type like @match does. -- Jun 5
                @default fn(_: u8) => {}; 
            };
        };
        
        break(false);
    };
    unreachable_hack(bool)
}

fn error(self: *Lexer, reason: LexErr) void = self.one((Error = reason));
fn put_token(self: *Lexer, type: TokenType) void = {
    //println(self.src.slice(self.start, self.current));
    self.current = self.current.min(self.src.len);
    self.token = (type = type, span = self.root.subspan(self.start.trunc(), self.current.trunc()));
}

fn is_whitespace(c: u8) bool = c.eq(" ".ascii()).or(=> c.eq("\n".ascii())).or(=> c.eq("\t".ascii()));

fn peek_c(self: *Lexer) u8 = self.peek_c(0);
fn peek_c(self: *Lexer, n: i64) u8 = 
    if(self.current + n < self.src.len, => self.src[self.current.add(n)], => 0);

fn init(pool: *StringPool, root: Span, src: Str) Lexer = {
    self: Lexer = (pool = pool, root = root, src = src, token = Token.uninitialized());
    self&.pop(); // get the first token ready. 
    self
}

#test fn lexer_doesnt_crash() = {
    pool: StringPool = init(temp());
    codemap: CodeMap = init(temp());
    src := " /*}|*/   println(\"hello world\"); const t = fn hello(); + +=; 123; 0xFF; 0b101010; \"\"\" big string \" ending now\"\"\"";
    span := codemap&.add_file("test", src);
    self: Lexer = init(pool = pool&, root = span, src = src);
    count := 0;
    dowhile {|
        t := self&.peek();
        if VERBOSE_TEST_LOGGING {|
            @println("%, %-%: %", t.type&!tag[], t.span.low, t.span.high, codemap&.source_slice(t.span));
        };
        again := t.type&!tag[].ne(tag_value(TokenType, @symbol Eof));
        self&.pop();
        count += 1;
        again
    };
    if VERBOSE_TEST_LOGGING {|
        @println("Lexed % tokens.", count);
    };
}
