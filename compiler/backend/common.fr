// TODO: traits
// TODO: const fields on structs
// fn inst_call(self: *B, sig: PrimSig, f: FuncId, tail: bool) Slice(B.Val);
// fn inst_trap(self: *B) Unit;
// fn inst_call_ptr(self: *B, sig: PrimSig, ptr: B.Val) Slice(B.Val);
// fn inst_offset(self: *B, ptr: B.Val, bytes: u16) B.Val;
// fn inst_literal(self: *B, value: i64, ty: Prim) B.Val;
// fn inst_load(self: *B, addr: B.Val, ty: Prim) B.Val;
// fn inst_store(self: *B, addr: B.Val, value: B.Val, ty: Prim) B.Val;
// fn inst_copy(self: *B, from: B.Val, to: B.Val, bytes: u16) B.Val;
// fn inst_func_ref(self: *B, fid: FuncId) B.Val;
// fn inst_global(self: *B, id: BakedVarId) B.Val;
// fn inst_jump_if(self: *B, cond: B.Val, true: BbId, false: BbId, args: Slice(B.Val)) Unit;
// fn inst_jump(self: *B, always: BbId, args: Slice(B.Val)) Unit;
// fn inst_return(self: *B, args: Slice(B.Val)) Unit;
// fn move_to_block(self: *B, block: BbId) Unit;
// - declare basic blocks
// - declare stack slots for local variables
// fn setup(self: *B, body: *FnBody, vars_out: *List(B.Val)) Unit;

fn CodeGen(const B: Type) Type = @struct(
    comp: CompCtx,
    backend: B,
    body: *FnBody,
    vars: List(B.Val),
    stack: List(B.Val),
);

GenQbe :: CodeGen(EmitQbe);

fn walk_block(self: *GenQbe, b: BbId) Unit = {
    block := self.body.blocks.items()[b.id.zext()]&;
    break :: @return;
    each(block.insts){ inst |
        @match(inst){
            (fn Nop() => ());
            (fn SaveSsa(slot) => {
                v := self.stack.pop().unwrap();
                self.vars[slot.id.zext()] = v;
            });
            (fn LoadSsa(slot) => {
                v := self.vars[slot.id.zext()];
                self.stack.push(v);
            });
            (fn GetCompCtx() => {
                panic("AOT bytecode should not use GetCompCtx");
            });
            (fn CallDirect(call) => { //  f, tail, sig
                arg_count := call.sig.arg_slots.zext();
                args := self.stack.items().slice_last(arg_count).unwrap();
                ret := self.backend&.inst_call(call.sig, call.f, call.tail);
                self.stack.len -= arg_count;
                self.stack&.push_all(ret);
                if(call.tail.or(sig.no_return)){|
                    self.backend&.inst_trap();
                    break();
                };
            });
            (fn CallFnPtr(call) => {
                arg_count := call.sig.arg_slots.zext();
                ptr := self.stack.items()[self.stack.len.sub(arg_count).sub(1)];
                args := self.stack.items().slice_last(arg_count).unwrap();
                ret := self.backend&.inst_call_ptr(call.sig, ptr);
                self.stack.len -= arg_count;
                self.stack.len -= 1;
                self.stack&.push_all(ret);
            });
            (fn PushConstant(c) => {
                v := self.backend&.inst_literal(c.value, c.ty);
                self.stack&.push(v);
            });
            (fn PushGlobalAddr(id) => {
                v := self.backend&.inst_global(id);
                self.stack&.push(v);
            });
            (fn JumpIf(jump) => { //  { true_ip, false_ip, slots }
                cond := self.stack.pop().unwrap();
                args := self.stack.items().slice_last(jump.slots.zext()).unwrap();
                self.backend&.inst_jump_if(cond, jump.true_ip, jump.false_ip, args);
                self.stack.len -= jump.slots.zext();
                let stack = self.stack.clone();
                self.emit_block(true_ip.0 as usize, builder)?;
                self.stack = stack;
                self.walk_block(jump.false_ip, builder)?;
                break();
            });
            // fn inst_jump_if(self: *B, cond: B.Val, true: BbId, false: BbId, args: Slice(B.Val)) Unit;
            // fn inst_jump(self: *B, always: BbId, args: Slice(B.Val)) Unit;
            (fn Goto(jump) => { // { ip, slots }
                args := self.stack.items().slice_last(jump.slots.zext()).unwrap();
                self.backend&.inst_jump(jump.ip, args);
                self.stack.len -= jump.slots.zext();
                self.emit_block(jump.ip)?;
                break();
            });
            (fn Ret0() => {
                self.backend&.inst_return(empty());
                break();
            });
            (fn Ret1(_) => {
                args := self.stack.items().slice_last(1).unwrap();
                self.backend&.inst_return(args);
                self.stack.len -= 1;
                break();
            });
            (fn Ret2(_, __) => {
                args := self.stack.items().slice_last(2).unwrap();
                self.backend&.inst_return(args);
                self.stack.len -= 2;
                break();
            });
            (fn GetNativeFnPtr(f) => {
                v := self.backend&.inst_func_ref(f);
                self.stack&.push(v);
            });
            (fn Load(ty) => {
                addr := self.stack.pop().unwrap();
                v    := self.backend&.inst_load(addr, ty);
                self.stack.push(v);
            });
            (fn StorePost(ty) => {
                addr := self.stack.pop().unwrap();
                v    := self.stack.pop().unwrap();
                self.backend&.inst_store(addr, v, ty);
                self.stack.len -= 2;
            });
            (fn StorePre(ty) => {
                v    := self.stack.pop().unwrap();
                addr := self.stack.pop().unwrap();
                self.backend&.inst_store(addr, v, ty);
                self.stack.len -= 2;
            });
            (fn AddrVar(slot) => {
                ptr := self.vars[slot.id.zext()];
                self.stack&.push(ptr);
            });
            (fn IncPtrBytes(bytes) => {
                ptr := self.stack.pop().unwrap();
                res := self.backend&.inst_offset(ptr, bytes);
                self.stack.push(res);
            })
            (fn Unreachable() => {
                self.backend&.inst_trap();
                break();
            });
            (fn NoCompile() => {
                panic("ICE: NoCompile");
            });
            (fn LastUse(_) => ());
            (fn PeekDup(skip) => {
                v := self.stack[self.stack.len() - skip as usize - 1];
                self.stack&.push(v);
            });
            (fn Snipe(skip) => {
                index := self.stack.len().sub(skip.zext()).sub(1);
                self.stack&.remove(index);
            });
            (fn CopyBytesToFrom(bytes) => {
                from := self.stack.pop().unwrap();
                to := self.stack.pop().unwrap();
                self.backend&.inst_copy(from, to, bytes);
            });
        };
    };
}
