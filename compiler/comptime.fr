//! There are two contexts for compile-time execution in this language. 
//! - init_driver_vtable: The driver program where you're logically aware of the outside world and might have multiple compiler instances doing different things. 
//! - fill_export_ffi: Within the program like '::' expressions and macros, where you're only aware of the current compiler instance. 
//! In the latter, you don't manually pass the compiler context pointer to every function. 
//! These corrispond to Zig's build.zig vs comptime and Rust's build.rs vs proc-macros/const-fns. 

fn init_driver_vtable() *ImportVTable = {
    the_vtable :: @static(ImportVTable);
    vtable := the_vtable;
    vtable[] = ImportVTable.zeroed();
    
    vtable.driver_abi_version = 1012;
    
    vtable.find_unique_func = fn(c: Compiler, name: Symbol) ?FuncId = { 
        c := c.cast()[][];
        f_ty := c.intern_type(Fn = (arg = void, ret = void, arity = 0)); // :get_or_create_type
        
        value := c.poll_in_place(?Values, => c.find_in_scope(TOP_LEVEL_SCOPE, name, f_ty));
        value := c.unwrap_report_error(?Values, value) || return(.None);
        fid := FuncId.assume_cast(value&)[];
        (Some = fid)
    };
    
    vtable.get_jitted_ptr = fn(c: Compiler, f: FuncId) CRes(rawptr) = {
        self := c.cast()[][];
        vtable := the_vtable;
        self.poll_in_place(rawptr) { () Maybe(rawptr) |
            @match(self.get_fn_callable(f)) {
                fn Some(ptr) => (Ok = ptr);
                fn None() => (Suspend = self.wait_for(Jit = f));
            }
        }
    };
    
    // TODO: remove unused first arg because comptime_jit is in BuildOptions now.
    vtable.init_compiler = fn(options: *BuildOptions) Compiler = {
        vtable := the_vtable;
        mem := init_self_hosted(options);
        mem.legacy_indirection
    };
    
    vtable.compile_func = fn(c: Compiler, f: FuncId, when: ExecStyle) CRes(void) = {
        self := c.cast()[][];
        self.poll_in_place(void, => self.compile_body(f))
    };
    
    vtable.make_and_resolve_and_compile_top_level = fn(cc: Compiler, body: Slice(FatStmt)) CRes(void) = {
        c := cc.cast()[][];
        f := c.make_top_level(body);
        f := f.unwrap();
        @try({the_vtable[].compile_func}(cc, f, .Jit)) return;
        .Ok
    };
    
    vtable.comptime_arch = fn() Ty(Arch, Os) = {
        (query_current_arch(), query_current_os())
    };
   
    // TODO: compiler bug! you used to be able to assign this to the overload set 
    vtable.add_file = add_file;
    vtable.parse_stmts = parse_stmts;
    vtable.intern_string = intern_string;
    vtable.get_string = get_string;
    vtable.get_fns_with_tag = get_fns_with_tag;
    vtable.get_function = fn(c: Compiler, f: FuncId) *Func = {
        c.cast()[][].get_function(f)
    };
    vtable.destroy_compiler = fn(c: Compiler) void = {
        c := c.cast()[][];
        pop_resolver(c.backtrace_node);
        opts := c.get_build_options();
        @if(use_threads) c.comptime_codegen.join_codegen_thread();
        c.comptime_codegen.m.drop(); 
        each c.comptime_codegen.queue { q |
            q.arena&.deinit();
        };
        c.shim_callback_alloc&.deinit();
        arena := c.ast_alloc[];  // copy because the areana is inside itself!
        c[] = SelfHosted.zeroed();  // BEFORE releasing ast_arena;
        arena&.deinit();
    };
    vtable.get_build_options = fn(c: Compiler) *BuildOptions = {
        c := c.cast()[][];
        c.get_build_options()
    };
    vtable.get_default_driver_exports = fn() *ExportVTable = {
        mem := todo_allocator.alloc(ExportVTable, 1);
        mem.ptr[] = default_driver_exports();
        mem.ptr
    };
   
    vtable.get_baked = fn(c: Compiler, id: BakedVarId) *Ty(rawptr, BakedVar) = {
        c.cast()[][].get_baked(id)
    };
    
    vtable._emit_bc = fn() Never = {
        panic("don't call emit_bc through the vtable. get it from examples/old_backend instead.")
    };
    vtable.fmt_error = fn(c: Compiler, err: *CompileError, out: *List(u8)) void = {
        c.cast()[][].fmt_error(err, out);
    };
    
    vtable.add_comptime_library = fn(c: Compiler, lib_name: Symbol, handle: rawptr) void = {
        handle := bit_cast_unchecked(rawptr, Dyn.Handle, handle);
        c.cast()[][].comptime_libraries&.insert(lib_name, handle); // TODO: report conflicts?
    };
    vtable.get_type_meta = fn(c: Compiler, type: Type) *TypeMeta = {
        c.cast()[][].get_info(type)
    };
    vtable.get_type_info = fn(c: Compiler, type: Type) *TypeInfo = {
        c.cast()[][].get_type(type)
    };
    vtable.get_whole_line = fn(c: Compiler, span: Span) FrancaCodeLine = {
        c.cast()[][].codemap.get_whole_line(span)
    };
    vtable.report_aot_progress = fn(c: Compiler, fid: FuncId, is_start: bool, zone_tag: i64) void = {
        @if(ENABLE_TRACY) {
            zone_tag := @as(TraceZone) zone_tag;
            self := c.cast()[][];
            mem :: @static(?HashMap(FuncId, TraceCtx)) (.None);
            if mem.is(.None) {
                mem[] = (Some = init(general_allocator()));
            };
            m := mem[].Some&;
            if is_start {
                if m.get(fid).is_none() {
                    zone := zone_begin(zone_tag);
                    func := self.get_function(fid);
                    real_name := self.pool.get(func.name);
                    ___tracy_emit_zone_name(zone, real_name);
                    m.insert(fid, zone);
                };
            } else {
                if m.get(fid) { zone | 
                    zone_end(zone);
                    m.remove(fid);
                };
            };
        };
    };
    
    vtable.emit_relocatable_constant = fn(c: Compiler, ty: Type, value: []u8) Res(BakedVarId) = {
        c.cast()[][].emit_relocatable_constant(ty, value)
    };
    vtable.log_expr = fn(c: Compiler, e: *FatExpr) Str = {
        log(e, c.cast()[][])
    };
    vtable.log_stmt = fn(c: Compiler, e: *FatStmt) Str = {
        log(e, c.cast()[][])
    };
    vtable.log_type = fn(c: Compiler, e: Type) Str = {
        log_type(c.cast()[][], e)
    };
    vtable.log_func = fn(c: Compiler, e: *Func) Str = {
        log(e, c.cast()[][])
    };
    
    vtable.emit_relocatable_constant_body = fn(c: Compiler, bytes: []u8, ty: Type, force_default_handling: bool) Res(Slice(BakedEntry)) = {
        c.cast()[][].emit_relocatable_constant_body(bytes, ty, force_default_handling)
    };
    
    vtable.check_for_new_aot_bake_overloads = fn(c) = {
        self := c.cast()[][];
        or check_for_new_aot_bake_overloads(self) { err |
            self.report_error(err);
        };
    };
    
    vtable.emit_qbe_included = fn(mm: rawptr, comp: *CompCtx, fns: [] FuncId, entry: ProgramEntry) BucketArray(u8) = {    
        m := QbeModule.ptr_from_raw(mm);
        shared := init(m, comp[].get_alloc(), @as(CodegenWorker) codegen_thread_main);
        main_thread_pump(comp[], shared, fns);
        aaa: BucketArray(u8) = init(0, temp());
        m := shared.m;
        opts := comp[].get_build_options();
        ::if(Ty([]u8, []u8));
        source, files := if opts[].debug_info {
            self := comp.data.cast()[][];
            encode_debug_files(self.codemap.files.items())
        } else {
            ("", "")
        };
        m.seal_debug_info(source, source.len != 0 || opts.retain_function_names, files);
        chunks := {comp.vtable.finish_qbe_module}(QbeModule.raw_from_ptr(m));
        @if(use_threads && show_backend_stats()) {
            frontend := clock_ms(MacosLibc.CLOCK_THREAD_CPUTIME_ID);// :TodoLinux
            @eprintln(">>> [CPU Time] frontend: %ms, codegen: %ms", frontend, shared.codegen_time);  // :WrongClockTime
        };
        for chunks { c |
            aaa&.push_bucket(maybe_uninit = c, len = c.len, gpa = temp());
        };
        aaa
    };
    fill_backend_vtable(vtable);

    vtable.took_address = fn(c, n) = {
        self := c.cast()[][];
        if get_var_type(self.scopes, n[]) { it |
            return(it.took_address);
        };
        
        //@panic("lost % %", self.pool.get(n.name), n.id);
        true // TODO: should be unreachable? :FUCKED
    };
    
    vtable.get_alloc = fn(c) = c.cast()[][].get_alloc();
    vtable.default_handle_message = builtin_driver_callback;
    vtable.compile_ast = fn(c: Compiler, expr: *FatExpr, hint: Type) void = {
        self := c.cast()[][];
        res := self.poll_in_place(void, => self.compile_expr(expr, hint.want()));
        self.unwrap_report_error(void, res);
    };
    
    the_vtable
}

CompilerRs :: ***SelfHosted;  // TODO: really this should be a new type so you can't accidently implement call functions by just adding extra indirection. hopefully the number of pointers makes it clear something's weird. 
fn cast(c: Compiler) CompilerRs #unsafe_noop_cast;

fn add_file(c: Compiler, name: Str, content: Str) AbiHackSpan = {
    c := c.cast();
    loc := c.codemap.add_file(name, content);
    (low = loc.low.zext(), high = loc.high.zext())
}

fn parse_stmts(c: Compiler, f: *Span) Res(Slice(FatStmt)) = {
    c := c.cast();
    @debug_assert_ge(f.high, f.low);
    source := c.codemap.source_slice(f[]);
    @debug_assert(source.len == f[].len(), "source_slice failed");
    id := c.parser.push_parse(source, f[]);
    stmts := @try(c.parser.finish_pending_stmts(id)) return; // TODO: don't return RawList -- Jun 29
    (Ok = stmts.items())
}

fn intern_string(c: Compiler, s: Str) Symbol = {
    c := c.cast();
    c.pool.insert_owned(s)
}

fn get_string(c: Compiler, s: Symbol) Str = {
    c := c.cast();
    c.pool.get(s)
}

// TODO: this is only called in the compiler. because of the annoying two types for compiler data pointer. 
fn get_baked(c: Compiler, id: BakedVarId) BakedVar = {
    val := c.cast()[][].get_baked(id); 
    val._1
}

fn get_fns_with_tag(c: Compiler, tag: Symbol) [] FuncId = {
    c := c.cast();
    found: List(FuncId) = list(temp());
    i := 0;
    each c.functions& { func |
        continue :: local_return;
        each func.annotations { a |
            if a.name == tag {
                found&.push(from_index(i));
                i += 1; 
                continue();
            };
        };
        i += 1; 
    };
    found.items()
}

/////////////////////////////////////////////////////////////////////////////////

fn current_comptime() *SelfHosted = {
    c := context(DefaultContext);
    s := SelfHosted.ptr_from_raw(c.comptime);
    @debug_assert_ne(SelfHosted.int_from_ptr(s), 0, "current_comptime is null");
    // TODO: store the expected index in SelfHosted so you can be on any thread (and have multiple instances on different thread)
    @debug_assert_eq(c.thread_index, 1, "you can only call into comptime compiler functions on the main thread.");
    s
}

fn fill_export_ffi(out: *List(u8)) void = {
    // TODO: fix error message if you forget a semi-colon in the string. 
    @fmt(out, "fn lookup_baked(addr: i64) ?BakedVarId #ct #comptime_addr(%);\n", lookup_baked);
    lookup_baked: rawptr : fn(addr: i64) ?BakedVarId = current_comptime()[].baked.lookup&.get(addr);
    
    @fmt(out, "fn cache_baked(addr: i64, id: BakedVarId) ?BakedVarId #ct #comptime_addr(%);\n", cache_baked);
    cache_baked: rawptr : fn(addr: i64, id: BakedVarId) void = {
        current_comptime()[].baked.lookup&.insert(addr, id); // TODO: error if collide? 
    };
    
    @fmt(out, "fn dyn_bake_relocatable_value(raw_bytes: Slice(u8), ty: Type, force_default_handling: bool) Slice(BakedEntry) #ct #comptime_addr(%);\n", dyn_bake_value);
    dyn_bake_value: rawptr : fn(bytes: Slice(u8), ty: Type, force_default_handling: bool) Slice(BakedEntry) = {
        c := current_comptime();
        r := c.emit_relocatable_constant_body(bytes, ty, force_default_handling); // TODO: sad extra binding forces it to instantiate the type. 
        c.unwrap_report_error(Slice(BakedEntry), r)
    };
    
    @fmt(out, "fn if(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", if_node);
    if_node: rawptr : fn(e: FatExpr) FatExpr = {
        assert(e.expr&.is(.Tuple), "@if expected tuple");
        parts := e.expr.Tuple&;
        (expr = (If = (cond = parts.index(0), if_true = parts.index(1), if_false = parts.index(2))), loc = e.loc, ty = UnknownType, done = false)
    };
    @fmt(out, "fn slice(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", slice_node);
    slice_node: rawptr : fn(e: FatExpr) FatExpr = {
        c := current_comptime();
        e := c.box(e);
        (expr = (Slice = e), loc = e.loc, ty = UnknownType, done = false)
    };
    @fmt(out, "fn uninitialized(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", uninit_node);
    uninit_node: rawptr : fn(e: FatExpr) FatExpr = {
        self := current_comptime();
        ty := UnknownType;
        if !e&.is_raw_unit() {
            res := self.poll_in_place(Type) {
                self.eval(e&, Type)
            };
            ty = self.unwrap_report_error(Type, res);
        };
        (expr = .Uninitialized, loc = e.loc, ty = ty, done = false)
    };
    @fmt(out, "fn loop(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", loop_node);
    loop_node: rawptr : fn(e: FatExpr) FatExpr = {
        self := current_comptime();
        e := self.box(e);
        (expr = (Loop = e), loc = e.loc, ty = Never, done = false)
    };
    
    // TODO it saves ~60/990 ms to have this be a constant instead of an overload set. 
    @fmt(out, "operator_star_prefix :: fn(T: Type) Type #fold #ct #comptime_addr(%);\n", ptr);
    ptr: rawptr : fn(inner: Type) Type = {
        self := current_comptime();
        self.intern_type((Ptr = inner))
    };
    
    // These only exist for debugging the compiler when everything's broken so can't even compile the one defined in the language.
    @fmt(out, "fn debug_log_int(i: i64) void #comptime_addr(%);\n", @as(rawptr) :: (fn(i: i64) void = println(i)));
    @fmt(out, "fn debug_log_str(i: Str) void #comptime_addr(%);\n", @as(rawptr) :: (fn(i: Str) void = println(i)));
    @fmt(out, "fn debug_log_bool(i: bool) void #comptime_addr(%);\n", @as(rawptr) :: (fn(i: bool) void = println(i)));
    
    @fmt(out, "fn str(i: Symbol) Str #ct #fold #comptime_addr(%);\n", str);
    str: rawptr : fn(i: Symbol) Str = {
        current_comptime()[].pool.get(i)
    };
    
    @fmt(out, "fn sym(i: Str) Symbol #ct #fold #comptime_addr(%);\n", sym);
    sym: rawptr : fn(i: Str) Symbol = {
        current_comptime()[].pool.insert_owned(i)
    };
    
    @fmt(out, "fn get_comptime_environment() *ComptimeEnvironment #ct #comptime_addr(%);\n", env);
    env: rawptr : fn() *ComptimeEnvironment = {
        current_comptime()[].env
    };
    
    @fmt(out, "fn by_the_way_you_are_compiling_the_compiler_right_now_just_a_helpful_hint() void #ct #comptime_addr(%);\n", note);
    note: rawptr : fn() void = {
        // This just gives a place to assert we haven't got any weird feature flags turned on while porting stuff over from rust. 
        // It gets a bit scary if the first thing you try to compile is accidentally the compiler so if it miscompiles you're fucked now. 
        // It's philosophically important that we don't actually change behaviour based on this information tho.
    };
    
    @fmt(out, "fn compile_error(msg: Str, loc: Span) Never #ct #comptime_addr(%);\n", report_err);
    report_err: rawptr : fn(msg: Str, loc: Span) Never = {
        // TODO: command line arg to show more context? 
        println("=== ERROR ===");
        println(msg);
        current_comptime()[].codemap.show_error_line(loc);
        panic("Comptime reported error.")
    };
  
    // TODO: version of this that allows caching? but have to think more about when you're allowed to deduplicate.
    @fmt(out, "fn bake_value(v: BakedVar) BakedVarId #ct #comptime_addr(%);\n", bake_var);
    bake_var: rawptr : fn(v: BakedVar) BakedVarId = {
        current_comptime().put_baked(v, .None)
    };
    
    @fmt(out, "fn safety_check_enabled(check: SafetyCheck) bool #ct #comptime_addr(%);\n", safe);
    safe: rawptr : fn(check: SafetyCheck) bool = {
        build_options := current_comptime().get_build_options();
        if(check.raw() >= build_options.safety_checks&.len(), => return(true)); // allow adding new safety checks and then bootstrapping. 
        build_options.safety_checks&.index(check)[]
    };
    
    // TODO: if you name the thing something that collides, the error message is wrong. 
    @fmt(out, "fn get_type_info_ref(T: Type) *TypeInfo #fold #ct #comptime_addr(%);\n", ty_info_r);
    ty_info_r: rawptr : fn(ty: Type) *TypeInfo = {
        info := current_comptime().get_type(ty);
        while => info.is(.Named) {
            info = current_comptime().get_type(info.Named._0);
        };
        info
    };
    
    // TODO: take this out of the compiler
    push_all(out, "fn get_type_info(T: Type) TypeInfo #fold = { get_type_info_ref(T)[] }\n");
    
    @fmt(out, "fn Ty(fst: Type, snd: Type) Type #fold #ct #comptime_addr(%);\n", tuple2);
    tuple2: rawptr : fn(fst: Type, snd: Type) Type = {
        current_comptime().tuple_of(@slice(fst, snd))
    };
    @fmt(out, "fn Ty(types: []Type) Type #fold #ct #comptime_addr(%);\n", tuplen);
    tuplen: rawptr : fn(types: []Type) Type = {
        current_comptime().tuple_of(types)
    };
    // TODO: take this out of the compiler
    push_all(out, "fn Ty(fst: Type, snd: Type, trd: Type) Type #fold = { Ty(@slice(fst, snd, trd)) }\n");
    push_all(out, "fn Ty(fst: Type, snd: Type, trd: Type, frt: Type) Type #fold = { Ty(@slice(fst, snd, trd, frt)) }\n");
   
    @fmt(out, "fn rawptr_from_value(value: *Values) rawptr #comptime_addr(%);\n", rawptr_from_value);
    rawptr_from_value: rawptr : fn(value: *Values) i64 = value.jit_addr();
    
    @fmt(out, "fn Tag(tagged: Type) Type #fold #ct #comptime_addr(%);\n", get_tag);
    get_tag: rawptr : fn(tagged: Type) Type = {
        c := current_comptime();
        raw := c.raw_type(tagged);
        @if_let(c.get_type(raw)) fn Tagged(f) => {
            return(f.tag);
        };
        @panic("Expected @tagged found %", c.log_type(tagged));
        void
    };
    
    @fmt(out, "fn Fn(Arg: Type, Ret: Type) Type #fold #ct #comptime_addr(%);\n", fn_type);
    fn_type: rawptr : fn(arg: Type, ret: Type) Type = {
        c := current_comptime();
        c.intern_type(Fn = (arg = arg, ret = ret, arity = c.arg_types(arg).len().trunc()))
    };
    
    @fmt(out, "fn IntType(bits: i64, signed: bool) Type #fold #ct #comptime_addr(%);\n", make_int_type);
    make_int_type: rawptr : fn(bit_count: i64, signed: bool) Type = {
        current_comptime().intern_type(Int = (bit_count = bit_count, signed = signed))
    };
    
    @fmt(out, "fn builtin(t: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", builtin);
    builtin: rawptr : fn(arg: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.builtin_macro(arg);
        self.unwrap_report_error(FatExpr, res)
    };
    
    @fmt(out, "fn unquote_macro_apply_placeholders(t: Slice(FatExpr)) FatExpr #ct #comptime_addr(%);\n", unquote_placeholders);
    unquote_placeholders: rawptr : fn(args: []FatExpr) FatExpr = {
        self := current_comptime();
        args := args.assume_owned(temp());
        template := args&.pop().expect("ICE: unquote_placeholders always needs template arg");
        // Since we're probably going to call this with different values for the placeholders (like invoking the same macro multiple times),
        // we duplicate to not mess up the constant value of the template. 
        // TODO: i feel like the old version wasn't doing this. why did that work? 
        template := template&.deep_clone(self.get_alloc());
        walk: Unquote = (compiler = self, placeholders = args);
        res := walk&.walk_expr(template&);
        self.unwrap_report_error(void, res);
        unused := 0;
        enumerate walk.placeholders { i, e | 
            if !e.expr&.is(.Poison) {
                unused += 1;
            };
        };
        @assert(unused == 0, "ice: unquote_placeholders didn't use all arguments\n%", template&.log(self));
        self.renumber_expr(template&, .None); // :SLOW
        //walk: MarkNotDone = ();
        //walk&.walk_expr(template&); // TODO: might not need this :SLOW
        template
    };
    
    @fmt(out, "fn Fn(Arg: FatExpr, Ret: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n", fn_type_macro_erase);
    @fmt(out, "fn FnPtr(Arg: FatExpr, Ret: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n", fn_ptr_type_macro_erase);
    @fmt(out, "fn Fn(Ret: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n", fn_type_macro_single);
    @fmt(out, "fn FnPtr(Ret: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n", fn_ptr_type_macro_single);
   
    make_fn_type :: fn(self: *SelfHosted, arg: FatExpr, ret: FatExpr) FnType = {
        inner :: fn() Maybe(FnType) => {
            return :: local_return;
            types: []Type = @match(arg.expr&) {
                fn StructLiteralP(parts) => {
                    // TODO: ugh
                    x := parts.bindings.assume_owned(self.get_alloc());
                    x&.if_empty_add_unit();
                    parts.bindings = x.as_raw();
                    
                    @check(self.infer_type(parts)) return
                }
                fn Tuple(parts) => {
                    types: List(Type) = list(temp());
                    each parts { e | 
                        value := @check(self.immediate_eval_expr(e, self.get_or_create_type(Type))) return;
                        types&.push(Type.assume_cast(value&)[]);
                    };
                    types.items()
                }
                @default => {
                    value := @check(self.immediate_eval_expr(arg&, self.get_or_create_type(Type))) return; 
                    ty := Type.assume_cast(value&)[];
                    lst: List(Type) = list(temp());
                    lst&.push(ty);
                    lst.items()
                };
            };
            arg_ty := self.tuple_of(types);
            value := @check(self.immediate_eval_expr(ret&, self.get_or_create_type(Type))) return; 
            ret_ty := Type.assume_cast(value&)[];
            (Ok = (arg = arg_ty, ret = ret_ty, arity = types.len.trunc()))
        };
        res := self.poll_in_place(FnType, => inner());
        self.unwrap_report_error(FnType, res)
    };
    
    fn_type_macro_erase: rawptr : fn_type_macro;
    fn_type_macro :: fn(arg: FatExpr, ret: FatExpr) FatExpr = {
        c := current_comptime();
        f_ty := make_fn_type(c, arg, ret);
        ty := c.intern_type(Fn = f_ty);
        value := c.to_values(Type, ty); 
        arg&.set(value, c.get_or_create_type(Type));
        arg
    };
    
    fn_ptr_type_macro_erase: rawptr : fn_ptr_type_macro;
    fn_ptr_type_macro :: fn(arg: FatExpr, ret: FatExpr) FatExpr = {
        c := current_comptime();
        f_ty := make_fn_type(c, arg, ret);
        ty := c.intern_type(FnPtr = (ty = f_ty, cc = .CCallReg));
        value := c.to_values(Type, ty); 
        arg&.set(value, c.get_or_create_type(Type));
        arg
    };
    
    fn_ptr_type_macro_single: rawptr : fn(ret: FatExpr) FatExpr = 
        fn_ptr_type_macro(empty_struct_literal(ret.loc), ret);
    
    fn_type_macro_single: rawptr : fn(ret: FatExpr) FatExpr = 
        fn_type_macro(empty_struct_literal(ret.loc), ret);
    
    @fmt(out, "fn literal_ast(ty: Type, ptr: rawptr) FatExpr #ct #comptime_addr(%);\n", literal_ast);
    literal_ast: rawptr : fn(ty: Type, ptr: *u8) FatExpr = {
        c := current_comptime();
        c.finish_layout(ty);
        bytes: i64 = c.get_info(ty)[].stride_bytes.zext();
        value := slice(ptr, bytes);
        value := c.from_bytes(value);
        
        // TODO: zero_padding?
        // TODO: caller should pass in loc?
        synthetic_ty((Value = (bytes = value, coerced = false)), c.last_loc, ty)
    };
    
    @fmt(out, "fn type(e: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n", type_macro);
    type_macro: rawptr : fn(e: FatExpr) FatExpr = {
        self := current_comptime();
        old := self.dispatch.enclosing_function;
        self.dispatch.enclosing_function = .None;
        //e = self.clone(e&); // TODO: do i need to do this? :SLOW
        ty := self.poll_in_place(Type) {()Maybe(Type)|
            @check(self.compile_expr(e&, .None)) local_return;
            (Ok = e.ty)
        };
        self.dispatch.enclosing_function = old;
        ty := self.unwrap_report_error(Type, ty);
        value := self.to_values(Type, ty); 
        e&.set(value, self.get_or_create_type(Type));
        @log_event("we know the type! %", e&.log(self)) self;
        e
    };
    
    @fmt(out, "fn const_eval(expr: FatExpr, ty: Type, result: rawptr) void #ct #comptime_addr(%);\n", const_eval_any);
    
    const_eval_any: rawptr : fn(expr: FatExpr, ty: Type, addr: *u8) void = {
        c := current_comptime();
        size: i64 = c.get_info(ty)[].stride_bytes.zext();
        out := slice(addr, size);
        
        res := c.poll_in_place(void) {()Maybe(void)|
            value := @check(c.immediate_eval_expr(expr&, ty)) local_return;
            b := value&.bytes();
            if b.len == size {
                out.copy_from(b);
                .Ok
            } else {
                @err("ICE: const_eval_any(%) size mismatch for value %", c.log_type(ty), log(value&, c, ty))
            }
        };
        c.unwrap_report_error(void, res);
    };
    
    @fmt(out, "fn struct(arg: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n", struct_macro_wrap);
    struct_macro_wrap: rawptr : fn(expr: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(FatExpr, => self.struct_macro(expr&));
        self.unwrap_report_error(FatExpr, res)
    }; 
    @fmt(out, "fn union(arg: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n", union_macro_wrap);
    union_macro_wrap: rawptr : fn(expr: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(FatExpr, => self.union_macro(expr&));
        self.unwrap_report_error(FatExpr, res)
    }; 
    @fmt(out, "fn tagged(arg: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n", tagged_macro_wrap);
    tagged_macro_wrap: rawptr : fn(expr: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(FatExpr, => self.tagged_macro(expr&));
        self.unwrap_report_error(FatExpr, res)
    };
    @fmt(out, "fn enum(arg: FatExpr, target: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n", enum_macro_wrap);
    enum_macro_wrap: rawptr : fn(arg: FatExpr, target: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(FatExpr, => self.enum_macro(arg&, target&));
        self.unwrap_report_error(FatExpr, res)
    };
    // note: the old verion didn't even use this ast node, it just did the work here like @struct, et al.
    //       maybe thats better, idk, lets see if i still need the name based hack this way. -- Aug 5s
    @fmt(out, "fn as(T: FatExpr, e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", as_node);
    as_node: rawptr : fn(type: FatExpr, value: FatExpr) FatExpr = {
        c := current_comptime();
        value := c.box(value);
        type := c.box(type);
        (expr = (As = (type = type, value = value)), loc = value.loc, ty = UnknownType, done = false)
    };
    
    // TODO: redundant with get_type_info_ref. just impl this in the language.
    @fmt(out, "fn size_of(T: Type) i64 #fold #ct #comptime_addr(%);\n", size_of);
    size_of: rawptr : fn(type: Type) i64 =
        current_comptime().get_info(type)[].stride_bytes.zext();
    
    @fmt(out, "fn debug_log_ast(expr: FatExpr) void #ct #comptime_addr(%);\n", debug_log_ast);
    debug_log_ast: rawptr : fn(e: FatExpr) void = {
        @println("[debug_log_ast] %; %", e.expr&.tag(), e&.log(current_comptime()));
    };
    
    @fmt(out, "fn debug_log_type(type: Type) void #ct #comptime_addr(%);\n", debug_log_type);
    debug_log_type: rawptr : fn(type: Type) void = {
        @println("[debug_log_type %] %", type.as_index(), current_comptime().log_type(type));
    };
    
    @fmt(out, "fn debug_log_func(expr: *Func) void #ct #comptime_addr(%);\n", debug_log_f);
    debug_log_f: rawptr : fn(e: *Func) void = {
        @println("[debug_log_func] %", current_comptime().comp().log(e));
    };
    
    @fmt(out, "fn intern_type_ref(info: *TypeInfo) Type #ct #comptime_addr(%);\n", intern_type_ref);
    intern_type_ref: rawptr : fn(info: *TypeInfo) Type = {
        current_comptime().intern_type(info[]) // TODO: probably more useful if i make a deep copy, why else are you calling this. 
    };
    
    // Infers the type and avoids some redundant work if you duplicate the ast node in a bunch of places after calling this.
    // TODO: should take by reference so its clear that it mutates the deep structure of the node (not a copy)
    @fmt(out, "fn compile_ast(e: FatExpr) FatExpr #ct #comptime_addr(%);\n", compile_ast);
    compile_ast: rawptr : fn(expr: FatExpr) FatExpr = {
        self := current_comptime();
        old := self.dispatch.enclosing_function;
        self.dispatch.enclosing_function = .None;
        //expr = self.clone(expr&); // TODO: do i need to do this? :SLOW
        res := self.poll_in_place(void, => self.compile_expr(expr&, .None));
        self.dispatch.enclosing_function = old;
        self.unwrap_report_error(void, res);
        expr
    };
    
    @fmt(out, "fn symbol(e: FatExpr) FatExpr #outputs(Symbol) #macro #ct #comptime_addr(%);\n", symbol_macro);
    symbol_macro: rawptr : fn(expr: FatExpr) FatExpr = {
        self := current_comptime();
        if expr&.ident() { sym |
            sym := self.to_values(Symbol, sym);
            expr&.set(sym, self.get_or_create_type(Symbol));
            return(expr);    
        };
        x: Res(FatExpr) = @err("@symbol expected an identifier!");
        self.unwrap_report_error(FatExpr, x)
    };
    
    // TODO: is this made redundant by the meta.fr enum helpers or do we need to use this too early? [
    @fmt(out, "fn tag_value(E: Type, case_name: Symbol) i64 #fold #ct #comptime_addr(%);", tag_value_erase);
    tag_value_erase: rawptr : tag_value;
    tag_value :: fn(enum_ty: Type, name: Symbol) i64 = {
        self := current_comptime();
        @match(self.get_type(enum_ty)) {
            fn Enum(it) => {
                // TODO: this is kinda dumb, could be in meta.fr but this us just easier right now. -- Jul 8
                if !self.get_type(it.raw).is(.Int) {
                    @panic("tag_value on @enum (not @tagged) that is not an int!");
                };
                enumerate it.fields { i, it | 
                    if it._0 == name {
                        @debug_assert(it._1&.is(.Small), "called tag_value but value was .Big");
                        return(it._1.Small._0);
                    };
                };
                @panic("bad enum case name % for %", self.pool.get(name), self.log_type(enum_ty))
            }
            fn Tagged(it) => {
                enumerate it.cases { i, it | 
                    if(it._0 == name, => return(i));
                };
                @panic("bad tagged case name % for %", self.pool.get(name), self.log_type(enum_ty))
            }
            fn Named(it) => tag_value(it._0, name);
            @default => @panic("% is not enum. (tried tag_value of %)",
                self.log_type(enum_ty),
                self.pool.get(name)
            );
        }
    };
    
    @fmt(out, "fn c_str(s: Symbol) CStr #fold #ct #comptime_addr(%);\n", symbol_to_cstr);
    symbol_to_cstr: rawptr : fn(s: Symbol) CStr = 
        current_comptime()[].pool.get_c_str(s);
        
    @fmt(out, "fn assert_compile_error(e: FatExpr) FatExpr #fold #ct #macro #outputs(*CompileError) #comptime_addr(%);\n", assert_compile_error);
    assert_compile_error: rawptr : fn(e: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(void, => self.compile_expr(e&, .None));
        if !res&.is(.Err) {
            self.report_error2(ExpectedCompileError = e.loc);
        };
        type := self.env.compile_error_pointer.expect("no @assert_compile_error before bootstrap");
        res := self.to_values(*CompileError, res.Err);
        e&.set(res, type);
        e
    };
    
    @fmt(out, "fn FnPtr(arg: Type, ret: Type) Type #fold #ct #comptime_addr(%);\n", fn_ptr);
    fn_ptr: rawptr : fn(arg: Type, ret: Type) Type = {
        self := current_comptime();
        arity := self.arg_types(arg).len();
        self.intern_type(FnPtr = (ty = (arg = arg, ret = ret, arity = arity.trunc()), cc = .CCallReg))
    };
    
    @fmt(out, "fn get_meta(s: Type) TypeMeta #fold #ct #comptime_addr(%);\n", get_m);
    get_m: rawptr : fn(s: Type) TypeMeta = {
        current_comptime().get_info(s)[]
    };
    
    @fmt(out, "fn ast_alloc() Alloc #ct #comptime_addr(%);\n", get_aa);
    get_aa: rawptr : fn() Alloc = {
        current_comptime().get_alloc()
    };
    
    @fmt(out, "fn current_compiler_context() CompCtx #ct #comptime_addr(%);\n", get_cc);
    get_cc: rawptr : fn() CompCtx = {
        vtable := init_driver_vtable(); // TODO: don't allocate every time :SLOW
        (data = current_comptime()[].legacy_indirection, vtable = vtable)
    };
    
    @fmt(out, "fn resolve_overload(os: OverloadSet, arg: Type, ret: Type, loc: Span) FuncId #fold #ct #comptime_addr(%);\n", resolve_os);
    resolve_os: rawptr : fn(os: OverloadSet, arg: Type, ret: Type, loc: Span) FuncId = {
        self := current_comptime();
        f_ty: FnType = (arg = arg, ret = ret, arity = self.len_arg_types(arg).trunc());
        res := self.poll_in_place(FuncId, => self.resolve_by_type(os, f_ty, loc));
        self.unwrap_report_error(FuncId, res)
    };
    
    @fmt(out, "fn get_function_ast(fid: FuncId, resolve_sign: bool, resolve_body: bool, infer_sign: bool, infer_body: bool) *Func #fold #ct #comptime_addr(%);\n", get_func);
    get_func: rawptr : fn(fid: FuncId, resolve_sign: bool, resolve_body: bool, infer_sign: bool, infer_body: bool) *Func = {
        self := current_comptime();
        res := self.poll_in_place(void) {
            ret :: local_return;
            @if(resolve_sign) @check(self.ensure_resolved_sign(fid)) ret;
            @if(resolve_body) @try(self.ensure_resolved_body(fid)) ret;
            @if(infer_sign) {
                @check(self.infer_arguments(fid)) ret;
                @check(self.infer_return(fid)) ret;
            };
            @if(infer_body) @check(self.compile_body(fid)) ret;
            .Ok
        };
        self.unwrap_report_error(void, res);
        self.get_function(fid)
    };
    @fmt(out, "fn require_layout_ready(type: Type) void #fold #ct #comptime_addr(%);\n", require_layout_ready);
    require_layout_ready: rawptr : fn(type: Type) void = {
        finish_layout(current_comptime(), type);
    };
    
    push_all(out, """__builtin_compiler_has_feature :: fn(s: Str) bool #ct = {
        // import(Str) can load ("@/..." a filepath like #include_std) or ("{ ... };" some code) as a scope value for #use
        if(s == "@franca/import",      => return(true));
        // after calling enable_franca_ir_types, the argument of #ir can be any comptime expression, not just an identifier to find in the enum
        if(s == "@franca/ir_comptime", => return(true)); 
        // new ir operations
        if(s == "@franca/bitops", => return(true)); 
        if(s == "@franca/alloc_slice", => return(true)); 
        false
    };""");
    
    @fmt(out, "fn import(descriptor: Str) ScopeId #ct #comptime_addr(%) #fold;\n", do_import);
    do_import: rawptr : fn(descriptor: Str) ScopeId = {
        self := current_comptime();
        desc := self.pool.insert_owned(descriptor.clone(self.get_alloc()).items());
        res := import_as_scope(self, desc);
        self.unwrap_report_error(ScopeId, res)
    };
    
    @fmt(out, "fn scope_from_value(ty: Type, ptr: rawptr) ?ScopeId #ct #comptime_addr(%);\n", scope_val);
    scope_val: rawptr : fn(type: Type, ptr: *u8) ?ScopeId = {
        self := current_comptime();
        ok := type == ScopeId || type == Type || type == FuncId || self.get_type(type).is(.Fn);
        if !ok {
            return(.None)
        };
        self.finish_layout(type);
        bytes: i64 = self.get_info(type)[].stride_bytes.zext();
        value := slice(ptr, bytes);
        value := self.from_bytes(value);
        res := value_to_scope(self, value, type, .None);
        scope := self.unwrap_report_error(ScopeId, res);
        (Some = scope)
    };
    
    // TODO: a version of this that doesn't require you to know all arguments (just constant ones)
    @fmt(out, "fn invoke_specialized(fid: FuncId, arg: rawptr, ret: rawptr) void #ct #comptime_addr(%);\n", invoke_specialized_impl);
    invoke_specialized_impl: rawptr : fn(fid: FuncId, arg: rawptr, ret: rawptr) void = {
        self := current_comptime();
        res := self.poll_in_place(Type, => self.infer_arguments(fid));
        self.unwrap_report_error(Type, res);
        res := self.poll_in_place(Type, => self.infer_return(fid));
        self.unwrap_report_error(Type, res);
        func := self.get_function(fid);
        f_ty := func.finished_ty().expect("compiled function to have known type");
        loc  := func.loc;  // TODO: would be better if this were the callsite
        
        f := self.to_expr(FuncId, fid, loc);
        arg := self.to_expr(rawptr, arg, loc);
        arg.ty = self.ptr_type(f_ty.arg);
        ret := self.to_expr(rawptr, ret, loc);
        ret.ty = self.ptr_type(f_ty.ret);
        arg: FatExpr = synthetic((Deref = self.box(arg)), loc);
        arg: FatExpr = synthetic((ConstEval = self.box(arg)), loc);
        
        call: FatExpr = synthetic((Call = (f = self.box(f), arg = self.box(arg))), loc);
        dest: FatExpr = synthetic((Deref = self.box(ret)), loc);
        unit: FatExpr = synthetic_ty((Value = (bytes = unit_value, coerced = false)), loc, void);
        body := FatStmt.list(1, temp());
        body&.push(stmt = (Set = (place = dest, value = call)), loc = loc, done = false);
        expr: FatExpr = synthetic(new_block(body.as_raw(), self.box(unit)), loc);
        expr := self.box(expr);
        
        res := self.poll_in_place(Values, => self.immediate_eval_expr(expr, void)); // :get_or_create_type
        self.unwrap_report_error(Values, res);
    };
    
    @fmt(out, "fn get_constants(s: ScopeId) []Symbol #ct #comptime_addr(%) #fold;\n", get_names);
    get_names: rawptr : fn(s: ScopeId) []Symbol = {
        self := current_comptime();
        if(s == NOSCOPE, => return(empty()));
        scope := self.scopes[s].const_lookup&;
        names := Symbol.list(scope.raw.len_including_tombstones, self.get_alloc()); 
        for_keys scope { k | 
            names&.push(k);
        };
        names.items()
    };
    
    @fmt(out, "fn get_constant(s: ScopeId, name: Symbol, type: Type, out: rawptr) bool #ct #comptime_addr(%);\n", get_field_known);
    get_field_known: rawptr : fn(s: ScopeId, name: Symbol, type: Type, out: rawptr) bool = {
        self := current_comptime();
        if(s == NOSCOPE, => return(false));
        res := self.poll_in_place(?Values, => self.find_in_scope(s, name, type));
        value := self.unwrap_report_error(?Values, res) || return(false);
        // TODO: do we have to typecheck type_found?
        dest: []u8 = (ptr = u8.ptr_from_raw(out), len = self.get_info(type)[].stride_bytes.zext());
        dest.copy_from(value&.bytes());
        true
    };
    
    @fmt(out, "fn get_constant(s: ScopeId, name: Symbol) ?Ty(rawptr, Type) #ct #comptime_addr(%);\n", get_field);
    get_field: rawptr : fn(s: ScopeId, name: Symbol) ?Ty(rawptr, Type) = {
        self := current_comptime();
        if(s == NOSCOPE, => return(.None));
        var := self.scopes[s].const_lookup&.get(name) || return(.None);
        res := self.poll_in_place(Ty(Values, Type), => self.find_const(var, .None));
        value, type := self.unwrap_report_error(Ty(Values, Type), res);
        value := @if(value&.is(.Big), value&, {
            v := self.get_alloc().box(Values);
            v[] = value;
            v
        });
        (Some = (value.jit_addr().rawptr_from_int(), type))
    };
}
