//! There are two contexts for compile-time execution in this language. 
//! - init_driver_vtable: The driver program where you're logically aware of the outside world and might have multiple compiler instances doing different things. 
//! - fill_export_ffi: Within the program like '::' expressions and macros, where you're only aware of the current compiler instance. 
//! In the latter, you don't manually pass the compiler context pointer to every function. 
//! These corrispond to Zig's build.zig vs comptime and Rust's build.rs vs proc-macros/const-fns. 

fn init_driver_vtable() *ImportVTable = {
    @static(ImportVTable) {
        storage := ImportVTable.zeroed();
        fill_driver_vtable(storage&);
        storage
    }
}

fn fill_driver_vtable(vtable: *ImportVTable) void = {
    vtable.driver_abi_version = @if(IS_BOOTSTRAPPING, 1119, 1131);
    vtable.magic = DRIVER_VTABLE_MAGIC;
    
    vtable.find_unique_func = fn(c: Compiler, name: Symbol) ?FuncId = { 
        c := c.cast()[][];
        f_ty := c.intern_type(Fn = (arg = void, ret = void, unary = true)); // :get_or_create_type
        
        value := c.poll_in_place(?Values, => c.find_in_scope(TOP_LEVEL_SCOPE, name, f_ty));
        value := c.unwrap_report_error(?Values, value) || return(.None);
        fid := FuncId.assume_cast(value&)[];
        (Some = fid)
    };
    
    vtable.get_jitted_ptr = fn(c: Compiler, f: FuncId) CRes(rawptr) = {
        self := c.cast()[][];
        self.get_function(f).set_flag(.TookPointerValue);
        if self.get_fn_callable(f) { ptr |
            return(Ok = ptr);
        };
        // TODO: why don't i need to call infer(arg/ret) here?
        @try(self.create_jit_shim(f)) return; 
        ptr := self.get_fn_callable(f).unwrap();
        (Ok = ptr)
    };
    
    vtable.init_compiler = fn(options: *BuildOptions) Compiler = {
        mem := init_self_hosted(options);
        mem.legacy_indirection
    };
    
    vtable.compile_func = compile_func;
    
    compile_func :: fn(c: Compiler, f: FuncId, when: ExecStyle) CRes(void) = {
        self := c.cast()[][];
        self.poll_in_place(void, => self.compile_body(f))
    };
    
    vtable.make_and_resolve_and_compile_top_level = fn(cc: Compiler, body: Slice(FatStmt)) CRes(void) = 
        make_top_level(cc.cast()[][], body);
    
    // TODO: compiler bug! you used to be able to assign this to the overload set 
    vtable.add_file = add_file;
    vtable.parse_stmts = parse_stmts;
    vtable.intern_string = intern_string;
    vtable.get_string = get_string;
    vtable.get_fns_with_tag = get_fns_with_tag;
    vtable.get_function = fn(c: Compiler, f: FuncId) *Func = {
        c.cast()[][].get_function(f)
    };
    vtable.destroy_compiler = fn(c: Compiler) void = {
        c := c.cast()[][];
        pop_resolver(c.backtrace_node);
        opts := c.get_build_options();
        m := c.comptime_codegen.m;
        c.comptime_codegen.join_codegen_thread();
        m.drop(); 
        c.shim_callback_alloc&.deinit();
        if show_backend_stats() {
            ::DeriveFmt(@type c.stats);
            @eprintln("%", c.stats&);
        };
        arena := c.ast_alloc[];  // copy because the areana is inside itself!
        c[] = SelfHosted.zeroed();  // BEFORE releasing ast_arena;
        arena&.deinit();
    };
    vtable.get_build_options = fn(c: Compiler) *BuildOptions = {
        c := c.cast()[][];
        c.get_build_options()
    };

   
    vtable.get_baked = fn(c, id) = 
        BakedValue.raw_from_ptr(c.cast()[].baked.values&.nested_index(@as(i64) id.id.zext()));
    
    vtable.fmt_error = fn(c: Compiler, err: *CompileError, out: *List(u8)) void = {
        c.cast()[][].fmt_error(err, out, true /*TODO*/);
    };
    
    vtable.add_comptime_library = fn(c: Compiler, lib_name: Symbol, handle: rawptr) void = {
        handle := bit_cast_unchecked(rawptr, Dyn.Handle, handle);
        c.cast()[][].comptime_libraries&.insert(lib_name, handle); // TODO: report conflicts?
    };
    vtable.get_type_meta = fn(c: Compiler, type: Type) *TypeMeta = {
        c.cast()[][].get_info(type)
    };
    vtable.get_type_info = fn(c: Compiler, type: Type) *TypeInfo = {
        c.cast()[][].get_type(type)
    };
    vtable.get_whole_line = fn(c: Compiler, span: Span) FrancaCodeLine = {
        c.cast()[][].codemap.get_whole_line(span)
    };
    vtable.report_aot_progress = fn(c: Compiler, fid: FuncId, is_start: bool, zone_tag: i64) void = {
        @if(ENABLE_TRACY) {
            zone_tag := @as(TraceZone) zone_tag;
            self := c.cast()[][];
            mem :: @static(?HashMap(Ty(FuncId, i64), TraceCtx)) (.None);
            if mem.is(.None) {
                mem[] = (Some = init(general_allocator()));
            };
            m := mem[].Some&;
            // :ThisIsNotOkBecauseMemoryWillBeReused
            key := (fid, bit_cast_unchecked(Compiler, i64, c));
            ::AutoHash(@type key, TrivialHasher); ::AutoEq(@type key);
            if is_start {
                if m.get(key).is_none() {
                    zone := zone_begin(zone_tag);
                    func := self.get_function(fid);
                    real_name := self.pool.get(func.name);
                    ___tracy_emit_zone_name(zone, real_name);
                    m.insert(key, zone);
                };
            } else {
                if m.get(key) { zone | 
                    zone_end(zone);
                    m.remove(key);
                };
            };
        };
    };
    
    vtable.emit_relocatable_constant = fn(c: Compiler, ty: Type, value: []u8, loc: Span) Res(BakedVarId) = {
        id, off := @try(c.cast()[][].bake_relocatable_constant(value, ty, loc, .None)) return;
        @assert_eq(off, 0, "TODO: internal pointers in vtable.emit_relocatable_constant");
        (Ok = id)
    };
    vtable.log_expr = fn(c: Compiler, e: *FatExpr) Str = {
        log(e, c.cast()[][])
    };
    vtable.log_stmt = fn(c: Compiler, e: *FatStmt) Str = {
        log(e, c.cast()[][])
    };
    vtable.log_type = fn(c: Compiler, e: Type) Str = {
        log_type(c.cast()[][], e)
    };
    vtable.log_func = fn(c: Compiler, e: *Func) Str = {
        log(e, c.cast()[][])
    };
    
    vtable.emit_relocatable_constant_body = fn(c: Compiler, bytes: []u8, ty: Type, force_default_handling: bool) Res(Slice(BakedEntry)) = {
        c.cast()[][].emit_relocatable_constant_body(bytes, ty, force_default_handling)
    };
    
    vtable.check_for_new_aot_bake_overloads = fn(c) = {
        self := c.cast()[][];
        or check_for_new_aot_bake_overloads(self) { err |
            self.report_error(err, true /*TODO*/);
        };
    };
    
    // :UpdateBoot get rid of this
    vtable.emit_qbe_included_old = ::@as(rawptr) fn(mm: rawptr, comp: *CompCtx, fns: [] FuncId, entry: ProgramEntry) BucketArray(u8) = {
        chunks := emit_qbe_included(mm, comp, fns, entry);
        aaa: BucketArray(u8) = init(0, temp());
        for chunks { c |
            aaa&.push_bucket(assume_owned(c, temp()));
        };
        aaa
    };
    
    vtable.emit_qbe_included = emit_qbe_included;
    
    emit_qbe_included :: fn(mm: rawptr, comp: *CompCtx, fns: [] FuncId, entry: ProgramEntry) [][]u8 = {    
        m := QbeModule.ptr_from_raw(mm);
        threaded := entry != .GiveMeTheCodeAndGiveItToMeRawAlsoSingleThreadCodegen;
        shared := backend'worker_start(m, comp[].get_alloc(), @as(CodegenWorker) codegen_thread_main, threaded);
        main_thread_pump(comp[], shared, fns, entry == .WrapMain);
        opts := comp[].get_build_options();
        ::if(Ty([]u8, []u8));
        source, files := if opts[].debug_info {
            self := comp.data.cast()[][];
            encode_debug_files(self.codemap.files.items())
        } else {
            ("", "")
        };
        m.seal_debug_info(source, source.len != 0 || opts.retain_function_names, files);
        chunks := {comp.vtable.finish_qbe_module}(QbeModule.raw_from_ptr(m));
        @if(use_threads && show_backend_stats()) {
            frontend := clock_ms(MacosLibc.CLOCK_THREAD_CPUTIME_ID);// :TodoLinux
            // shared was deallocated when joined but it's in an arena so it's fine. meh
            @eprintln(">>> [CPU Time] frontend: %ms, codegen: %ms", frontend, shared.codegen_time);  // :WrongClockTime
        };
        chunks
    };
    fill_backend_vtable(vtable);

    vtable.took_address = fn(c, n) = {
        self := c.cast()[][];
        it := self.scopes.get_var_data(n[]);
        it.took_address
    };
    
    vtable.get_alloc = fn(c) = c.cast()[][].get_alloc();
    vtable.compile_ast = fn(c: Compiler, expr: *FatExpr, hint: Type) void = {
        self := c.cast()[][];
        res := self.poll_in_place(void, => self.compile_expr(expr, hint.want()));
        self.unwrap_report_error(void, res);
    };
    
    vtable.intern_type = fn(c, info) = 
        c.cast()[][].intern_type(info[]);
        
    vtable.intern_func = fn(c, info) = 
        c.cast()[][].add_function(info[]);

    vtable.add_to_scope = fn(c, s, name, type, value) = {
        loc   := zeroed Span;
        c     := c.cast()[][];
        value := u8.ptr_from_raw(value).slice(c.get_info(type)[].stride_bytes.zext());
        e: FatExpr = (expr = (Value = (bytes = to_value(value, c.get_alloc()), coerced = false)), ty = type, loc = loc, done = true);
        add_to_scope(c, s, name, (Finished = type), e);
    };
    
    // TODO: replace ^ with this one V in user space
    vtable.add_expr_to_scope = fn(c, s, name, expr) = {
        c     := c.cast()[][];
        scope := c.scopes.index(s);
        add_to_scope(c, s, name, .Infer, expr);
    };
    // TODO: return addend like lookup_baked so you don't have to call both?
    vtable.reserve_baked = fn(c, jit_addr) = {
        _, id := c.cast()[][].reserve_baked(jit_addr);
        id
    };
 
    vtable.import_frc = fn(c: Compiler, bytes: []u8) CRes(ScopeId) = {
        self := c.cast()[][];
        @if(DISABLE_IMPORT_FRC) return(@err("TODO: DISABLE_IMPORT_FRC because scoping when you import the compiler is messed up"));
        self.import_frc(bytes)
    };
    
    vtable.cached_compile_module = fn(path: Str, opts: *BuildOptions, out_alloc: Alloc) CRes([]u8) = {
        @if(DISABLE_IMPORT_FRC) return(@err("TODO: DISABLE_IMPORT_FRC because scoping when you import the compiler is messed up"));
        Incr'cached_compile_module(path, opts, out_alloc)
    };
    
    if enable_incremental() && !DISABLE_IMPORT_FRC {
        vtable.frc_module_magic_v = Incremental.MAGIC;
    };
    
    vtable.mangle_name = fn(c, fid) = {
        self := c.cast()[][];
        self.comp().fmt_fn_name(fid)
    };
    
    vtable.put_baked_var = fn(c, id, v) = {
        self := c.cast()[][];
        dest := self.baked.values&.nested_index(id.id.zext());
        n := dest.name;
        dest[] = self.from_legacy(v);
        dest.name = n;
    };
}

CompilerRs :: ***SelfHosted;  // TODO: really this should be a new type so you can't accidently implement call functions by just adding extra indirection. hopefully the number of pointers makes it clear something's weird. 
fn cast(c: Compiler) CompilerRs #ir(.copy, .Kl);

fn add_file(c: Compiler, name: Str, content: Str) AbiHackSpan = {
    c := c.cast();
    loc := c.codemap.add_file(name, content);
    (low = loc.low.zext(), high = loc.high.zext())
}

fn parse_stmts(c: Compiler, f: *Span) Res(Slice(FatStmt)) = {
    c := c.cast();
    @debug_assert_ge(f.high, f.low);
    source := c.codemap.source_slice(f[]);
    @debug_assert(source.len == f[].len(), "source_slice failed");
    id := c.parser.push_parse(source, f[]);
    stmts := @try(c.parser.finish_pending_stmts(id)) return; // TODO: don't return RawList -- Jun 29
    (Ok = stmts.items())
}

fn intern_string(c: Compiler, s: Str) Symbol = {
    c := c.cast();
    c.pool.insert_borrowed(s, c[][].get_alloc())
}

fn get_string(c: Compiler, s: Symbol) Str = {
    c := c.cast();
    c.pool.get(s)
}

fn get_fns_with_tag(c: Compiler, tag: Symbol) [] FuncId = {
    c := c.cast();
    found: List(FuncId) = list(temp());
    i := 0;
    each c.functions& { func |
        continue :: local_return;
        each func.annotations { a |
            if a.name == tag {
                found&.push(from_index(i));
                i += 1; 
                continue();
            };
        };
        i += 1; 
    };
    found.items()
}

/////////////////////////////////////////////////////////////////////////////////

fn current_comptime() *SelfHosted = {
    c := context(DefaultContext);
    s := SelfHosted.ptr_from_raw(c.comptime);
    @debug_assert_ne(SelfHosted.int_from_ptr(s), 0, "current_comptime is null");
    @if(use_threads && !SLOW_USERSPACE_THREADS/*TODO*/) @debug_assert_eq(c.thread_index, s.main_thread_index, "you can only call into comptime compiler functions on the main thread.");
    s
}

fn fill_export_ffi(out: *List(u8)) void = {
    @fmt(out, """
        __builtin_compiler_abi :: 1263;
        
        // TODO: take this out of the compiler
        fn size_of(T: Type) i64 #fold = { t := get_meta(T); t.stride_bytes.zext() }
    """);
    
    data :: {
        s := Type.scope_of(compiler_exports);
        names := get_constants(s);
        src := u8.list(names.len * 70, ast_alloc());
        fns := rawptr.list(names.len, ast_alloc());
        fns2 := FatExpr.list(names.len, ast_alloc());
        fr := current_compiler_context();
        for names { name |
            fid := get_constant(FuncId, s, name) 
                || @panic("fill_export_ffi '%' is not a function", name.str());
            func := get_function_ast(fid, true, false, false, false);
            sign := "";
            each func.annotations { it |
                if it.name == (@symbol export) {
                    sign = const_eval(Str)(it.args);
                };
            };
            if sign != "" {
                p := @if(IS_BOOTSTRAPPING,
                    const_eval(rawptr)(@{ x :: @as(rawptr) @[@literal fid]; x }), 
                    fr.get_jitted(fid),
                );
                fns&.push(p);
                src&.push_all(sign);
            };
        };
        (src.items(), fns.items())
    };
    
    src, fns := data;
    out.reserve(src.len + fns.len*10);
    i := 0;
    for src { b |
        if b == "%".ascii() {
            @fmt(out, "%", fns&[i]);
            i += 1;
        } else {
            out.push(b);
        };
    };
    @assert_eq(i, fns.len);
    //@fmt(out, src, ..fns);  this would be kinda cool
}

compiler_exports :: @struct {
    // TODO: fix error message if you forget a semi-colon in the string. 
    
    // TODO: do something if the bytes are too big for the allocation. 
    #export("fn lookup_baked_vbytes(vbytes: []u8) ?Ty(BakedVarId, i32) #ct #comptime_addr(%);\n")
    lookup_baked_vbytes :: fn(vbytes: []u8) ?Ty(BakedVarId, i32) = {
        addr := u8.raw_from_ptr(vbytes.ptr);
        if current_comptime()[].baked.vmem&.get(addr) { it, addend |
            @if_let(it) fn BakedVarId(it) => return(Some = (it, addend.intcast()));
        };
        .None
    };
    
    // TODO: these need to return a different BakedVarId if you had to deduplicate. 
    //       (instead of error if collide... tho rn it's just nothing)
    #export("fn cache_baked_vbytes(addr: []u8, id: BakedVarId) void #ct #comptime_addr(%);\n")
    cache_baked_vbytes :: fn(addr: []u8, id: BakedVarId) void = {
        current_comptime()[].baked.vmem&.insert(addr, (BakedVarId = id)); // TODO: error if collide? 
    };
    
    #export("fn dyn_bake_relocatable_value(raw_bytes: Slice(u8), ty: Type, force_default_handling: bool) Slice(BakedEntry) #ct #comptime_addr(%);\n")
    dyn_bake_value :: fn(bytes: Slice(u8), ty: Type, force_default_handling: bool) Slice(BakedEntry) = {
        c := current_comptime();
        r := c.emit_relocatable_constant_body(bytes, ty, force_default_handling); // TODO: sad extra binding forces it to instantiate the type. 
        c.unwrap_report_error(Slice(BakedEntry), r)
    };
    
    #export("fn if(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n")
    if_node :: fn(e: FatExpr) FatExpr = {
        assert(e.expr&.is(.Tuple), "@if expected tuple");
        parts := e.expr.Tuple&;
        if parts.len != 3 {
            e: CRes(void) = @err("expected @if(cond, if_true, if_false)");
            current_comptime().comp().report_error(e.Err);
        };
        (expr = (If = (cond = parts.index(0), if_true = parts.index(1), if_false = parts.index(2))), loc = e.loc, ty = UnknownType, done = false)
    };
    #export("fn slice(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n")
    slice_node :: fn(e: FatExpr) FatExpr = {
        c := current_comptime();
        e := c.box(e);
        (expr = (Slice = e), loc = e.loc, ty = UnknownType, done = false)
    };
    #export("fn uninitialized(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n")
    uninit_node :: fn(e: FatExpr) FatExpr = {
        self := current_comptime();
        ty := UnknownType;
        if !e&.is_raw_unit() {
            res := self.poll_in_place(Type) {
                self.eval(e&, Type)
            };
            ty = self.unwrap_report_error(Type, res);
        };
        (expr = .Uninitialized, loc = e.loc, ty = ty, done = false)
    };
    #export("fn loop(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n")
    loop_node :: fn(e: FatExpr) FatExpr = {
        self := current_comptime();
        e := self.box(e);
        (expr = (Loop = e), loc = e.loc, ty = Never, done = false)
    };
    
    #export("fn operator_star_prefix(T: Type) Type #fold #ct #comptime_addr(%);\n")
    ptr :: fn(inner: Type) Type = {
        self := current_comptime();
        self.intern_type((Ptr = inner))
    };
    
    // These only exist for debugging the compiler when everything's broken so can't even compile the one defined in the language.
    #export("fn debug_log_int(i: i64) void #comptime_addr(%);\n")
    debug_log_int :: fn(i: i64) void = println(i);
    
    #export("fn debug_log_str(i: Str) void #comptime_addr(%);\n")
    debug_log_str :: fn(i: Str) void = println(i);
    
    #export("fn debug_log_bool(i: bool) void #comptime_addr(%);\n")
    debug_log_bool :: fn(i: bool) void = println(i);
        
    #export("fn str(i: Symbol) Str #ct #fold #comptime_addr(%);\n")
    str :: fn(i: Symbol) Str = {
        current_comptime()[].pool.get(i)
    };
    
    #export("fn sym(i: Str) Symbol #ct #fold #comptime_addr(%);\n")
    sym :: fn(i: Str) Symbol = {
        self := current_comptime();
        self.pool.insert_borrowed(i, self.get_alloc())
    };
    
    #export("fn get_comptime_environment() *ComptimeEnvironment #ct #comptime_addr(%);\n")
    env :: fn() *ComptimeEnvironment = {
        current_comptime()[].env
    };
    
    #export("fn compile_error(msg: Str, loc: Span) Never #ct #comptime_addr(%);\n")
    report_err :: fn(msg: Str, loc: Span) Never = {
        // TODO: command line arg to show more context? 
        println("=== ERROR ===");
        println(msg);
        current_comptime()[].codemap.show_error_line(loc, true /*TODO*/);
        panic("Comptime reported error.")
    };
  
    #export("fn safety_check_enabled(check: SafetyCheck) bool #ct #comptime_addr(%);\n")
    safe :: fn(check: SafetyCheck) bool = {
        build_options := current_comptime().get_build_options();
        if(check.raw() >= build_options.safety_checks&.len(), => return(true)); // allow adding new safety checks and then bootstrapping. 
        build_options.safety_checks&.index(check)[]
    };
    
    // TODO: if you name the thing something that collides, the error message is wrong. 
    #export("fn get_type_info_ref(T: Type) *TypeInfo #fold #ct #comptime_addr(%);\n")
    ty_info_r :: fn(ty: Type) *TypeInfo = {
        info := current_comptime().get_type(ty);
        while => info.is(.Named) {
            info = current_comptime().get_type(info.Named._0);
        };
        info
    };
    
    #export("fn Ty(fst: Type, snd: Type) Type #fold #ct #comptime_addr(%);\n")
    tuple2 :: fn(fst: Type, snd: Type) Type = {
        current_comptime().tuple_of(@slice(fst, snd))
    };
    #export("fn Ty(types: []Type) Type #fold #ct #comptime_addr(%);\n")
    tuplen :: fn(types: []Type) Type = {
        current_comptime().tuple_of(types)
    };
   
    #export("fn rawptr_from_value(value: *Values) rawptr #comptime_addr(%);\n")
    rawptr_from_value :: fn(value: *Values) i64 = value.jit_addr();
    
    #export("fn Tag(tagged: Type) Type #fold #ct #comptime_addr(%);\n")
    get_tag :: fn(tagged: Type) Type = {
        c := current_comptime();
        raw := c.raw_type(tagged);
        @if_let(c.get_type(raw)) fn Tagged(f) => {
            return(f.tag);
        };
        @panic("Expected @tagged found %", c.log_type(tagged));
        void
    };
    
    #export("fn Fn(Arg: Type, Ret: Type) Type #fold #ct #comptime_addr(%);\n")
    fn_type :: fn(arg: Type, ret: Type) Type = {
        c := current_comptime();
        c.intern_type(Fn = (arg = arg, ret = ret, unary = c.comp().is_unary(arg)))
    };
    
    #export("fn IntType(bits: i64, signed: bool) Type #fold #ct #comptime_addr(%);\n")
    make_int_type :: fn(bit_count: i64, signed: bool) Type = {
        current_comptime().intern_type(Int = (bit_count = bit_count, signed = signed))
    };
    
    #export("fn builtin(t: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n")
    builtin :: fn(arg: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.builtin_macro(arg);
        self.unwrap_report_error(FatExpr, res)
    };
    
    #export("fn unquote_macro_apply_placeholders(t: Slice(FatExpr)) FatExpr #ct #comptime_addr(%);\n")
    unquote_placeholders :: fn(args: []FatExpr) FatExpr = {
        self := current_comptime();
        args := args.assume_owned(temp());
        template := args&.pop().expect("ICE: unquote_placeholders always needs template arg");
        // Since we're probably going to call this with different values for the placeholders (like invoking the same macro multiple times),
        // we duplicate to not mess up the constant value of the template. 
        // TODO: i feel like the old version wasn't doing this. why did that work? 
        template := self.clone(template&);
        walk: Unquote = (compiler = self, placeholders = args);
        res := walk&.walk_expr(template&);
        self.unwrap_report_error(void, res);
        each(walk.placeholders, fn(e) => @assert(e.expr&.is(.Poison), "ice: unquote_placeholders didn't use all arguments\n%", template&.log(self)));
        self.renumber_expr(template&, .None); // :SLOW
        template
    };
    
    make_fn_type :: fn(self: *SelfHosted, arg: FatExpr, ret: FatExpr) FnType = {
        inner :: fn() Maybe(FnType) => {
            return :: local_return;
            types: []Type = @match(arg.expr&) {
                fn StructLiteralP(parts) => {
                    // TODO: ugh
                    x := parts.bindings.assume_owned(self.get_alloc());
                    x&.if_empty_add_unit();
                    parts.bindings = x.as_raw();
                    
                    @check(self.infer_type(parts)) return
                }
                fn Tuple(parts) => {
                    types: List(Type) = list(temp());
                    each parts { e | 
                        value := @check(self.immediate_eval_expr(e, self.get_or_create_type(Type))) return;
                        types&.push(Type.assume_cast(value&)[]);
                    };
                    types.items()
                }
                @default => {
                    value := @check(self.immediate_eval_expr(arg&, self.get_or_create_type(Type))) return; 
                    ty := Type.assume_cast(value&)[];
                    lst: List(Type) = list(temp());
                    lst&.push(ty);
                    lst.items()
                };
            };
            arg_ty := self.tuple_of(types);
            value := @check(self.immediate_eval_expr(ret&, self.get_or_create_type(Type))) return; 
            ret_ty := Type.assume_cast(value&)[];
            (Ok = (arg = arg_ty, ret = ret_ty, unary = types.len <= 1))
        };
        res := self.poll_in_place(FnType, => inner());
        self.unwrap_report_error(FnType, res)
    };
    
    #export("fn Fn(Arg: FatExpr, Ret: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n")
    fn_type_macro :: fn(arg: FatExpr, ret: FatExpr) FatExpr = {
        c := current_comptime();
        f_ty := make_fn_type(c, arg, ret);
        ty := c.intern_type(Fn = f_ty);
        value := c.to_values(Type, ty); 
        arg&.set(value, c.get_or_create_type(Type));
        arg
    };
    
    #export("fn FnPtr(Arg: FatExpr, Ret: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n")
    fn_ptr_type_macro :: fn(arg: FatExpr, ret: FatExpr) FatExpr = {
        c := current_comptime();
        f_ty := make_fn_type(c, arg, ret);
        ty := c.intern_type(FnPtr = (ty = f_ty));
        value := c.to_values(Type, ty); 
        arg&.set(value, c.get_or_create_type(Type));
        arg
    };
    
    #export("fn FnPtr(Ret: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n")
    fn_ptr_type_macro_single :: fn(ret: FatExpr) FatExpr = 
        fn_ptr_type_macro(empty_struct_literal(ret.loc), ret);
    
    #export("fn Fn(Ret: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n")
    fn_type_macro_single :: fn(ret: FatExpr) FatExpr = 
        fn_type_macro(empty_struct_literal(ret.loc), ret);
    
    #export("fn literal_ast(ty: Type, ptr: rawptr) FatExpr #ct #comptime_addr(%);\n")
    literal_ast :: fn(ty: Type, ptr: *u8) FatExpr = {
        c := current_comptime();
        c.finish_layout(ty);
        bytes: i64 = c.get_info(ty)[].stride_bytes.zext();
        value := slice(ptr, bytes);
        value := c.from_bytes(value);
        
        // TODO: zero_padding?
        // TODO: caller should pass in loc?
        synthetic_ty((Value = (bytes = value, coerced = false)), c.last_loc, ty)
    };
    
    #export("fn type(e: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n")
    type_macro :: fn(e: FatExpr) FatExpr = {
        self := current_comptime();
        old := self.dispatch.enclosing_function;
        self.dispatch.enclosing_function = .None;
        ty := self.poll_in_place(Type) {()Maybe(Type)|
            @check(self.compile_expr(e&, .None)) local_return;
            (Ok = e.ty)
        };
        self.dispatch.enclosing_function = old;
        ty := self.unwrap_report_error(Type, ty);
        value := self.to_values(Type, ty); 
        e&.set(value, self.get_or_create_type(Type));
        e
    };
    
    #export("fn const_eval(expr: FatExpr, ty: Type, result: rawptr) void #ct #comptime_addr(%);\n")
    const_eval_any :: fn(expr: FatExpr, ty: Type, addr: *u8) void = {
        c := current_comptime();
        size: i64 = c.get_info(ty)[].stride_bytes.zext();
        out := slice(addr, size);
        
        res := c.poll_in_place(void) {()Maybe(void)|
            value := @check(c.immediate_eval_expr(expr&, ty)) local_return;
            b := value&.bytes();
            if b.len == size {
                out.copy_from(b);
                .Ok
            } else {
                @err("ICE: const_eval_any(%) size mismatch for value %", c.log_type(ty), log(value&, c, ty))
            }
        };
        c.unwrap_report_error(void, res);
    };
    
    #export("fn struct(arg: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n")
    struct_macro_wrap :: fn(expr: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(FatExpr, => self.struct_macro(expr&));
        self.unwrap_report_error(FatExpr, res)
    }; 
    #export("fn union(arg: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n")
    union_macro_wrap :: fn(expr: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(FatExpr, => self.union_macro(expr&));
        self.unwrap_report_error(FatExpr, res)
    }; 
    #export("fn tagged(arg: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n")
    tagged_macro_wrap :: fn(expr: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(FatExpr, => self.tagged_macro(expr&));
        self.unwrap_report_error(FatExpr, res)
    };
    #export("fn enum(arg: FatExpr, target: FatExpr) FatExpr #outputs(Type) #macro #ct #comptime_addr(%);\n")
    enum_macro_wrap :: fn(arg: FatExpr, target: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(FatExpr, => self.enum_macro(arg&, target&));
        self.unwrap_report_error(FatExpr, res)
    };
    // note: the old verion didn't even use this ast node, it just did the work here like @struct, et al.
    //       maybe thats better, idk, lets see if i still need the name based hack this way. -- Aug 5s
    #export("fn as(T: FatExpr, e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n")
    as_node :: fn(type: FatExpr, value: FatExpr) FatExpr = {
        c := current_comptime();
        value := c.box(value);
        type := c.box(type);
        (expr = (As = (type = type, value = value)), loc = value.loc, ty = UnknownType, done = false)
    };
    
    #export("fn debug_log_ast(expr: FatExpr) void #ct #comptime_addr(%);\n")
    debug_log_ast :: fn(e: FatExpr) void = {
        @println("[debug_log_ast] %; %", e.expr&.tag(), e&.log(current_comptime()));
    };
    
    #export("fn debug_log_type(type: Type) void #ct #comptime_addr(%);\n")
    debug_log_type :: fn(type: Type) void = {
        @println("[debug_log_type %] %", type.as_index(), current_comptime().log_type(type));
    };
    
    #export("fn debug_log_func(expr: *Func) void #ct #comptime_addr(%);\n")
    debug_log_f :: fn(e: *Func) void = {
        self := current_comptime();
        self.codemap.show_error_line(e.loc, true /*TODO*/);
        @println("[debug_log_func] %", self.comp().log(e));
    };
    
    #export("fn intern_type_ref(info: *TypeInfo) Type #ct #comptime_addr(%);\n")
    intern_type_ref :: fn(info: *TypeInfo) Type = {
        current_comptime().intern_type(info[]) // TODO: probably more useful if i make a deep copy, why else are you calling this. 
    };
    
    // Infers the type and avoids some redundant work if you duplicate the ast node in a bunch of places after calling this.
    // TODO: should take by reference so its clear that it mutates the deep structure of the node (not a copy)
    #export("fn compile_ast(e: FatExpr) FatExpr #ct #comptime_addr(%);\n")
    compile_ast :: fn(expr: FatExpr) FatExpr = {
        self := current_comptime();
        old := self.dispatch.enclosing_function;
        self.dispatch.enclosing_function = .None;
        res := self.poll_in_place(void, => self.compile_expr(expr&, .None));
        self.dispatch.enclosing_function = old;
        self.unwrap_report_error(void, res);
        expr
    };
    
    // TODO: is this made redundant by the meta.fr enum helpers or do we need to use this too early? [
    #export("fn tag_value(E: Type, case_name: Symbol) i64 #fold #ct #comptime_addr(%);")
    tag_value :: fn(enum_ty: Type, name: Symbol) i64 = {
        self := current_comptime();
        @match(self.get_type(enum_ty)) {
            fn Enum(it) => {
                // TODO: this is kinda dumb, could be in meta.fr but this us just easier right now. -- Jul 8
                if !self.get_type(it.raw).is(.Int) {
                    @panic("tag_value on @enum (not @tagged) that is not an int!");
                };
                enumerate it.fields { i, it | 
                    if it._0 == name {
                        @debug_assert(it._1&.is(.Small), "called tag_value but value was .Big");
                        return(it._1.Small._0);
                    };
                };
                @panic("bad enum case name % for %", self.pool.get(name), self.log_type(enum_ty))
            }
            fn Tagged(it) => {
                enumerate it.cases { i, it | 
                    if(it._0 == name, => return(i));
                };
                @panic("bad tagged case name % for %", self.pool.get(name), self.log_type(enum_ty))
            }
            fn Named(it) => tag_value(it._0, name);
            @default => @panic("% is not enum. (tried tag_value of %)",
                self.log_type(enum_ty),
                self.pool.get(name)
            );
        }
    };
    
    #export("fn c_str(s: Symbol) CStr #fold #ct #comptime_addr(%);\n")
    symbol_to_cstr :: fn(s: Symbol) CStr = 
        current_comptime()[].pool.get_c_str(s);
        
    #export("fn assert_compile_error(e: FatExpr) FatExpr #fold #ct #macro #outputs(*CompileError) #comptime_addr(%);\n")
    assert_compile_error :: fn(e: FatExpr) FatExpr = {
        self := current_comptime();
        res := self.poll_in_place(void, => self.compile_expr(e&, .None));
        if !res&.is(.Err) {
            self.report_error2((ExpectedCompileError = e.loc), true /*TODO*/);
        };
        type := self.env.compile_error_pointer.expect("no @assert_compile_error before bootstrap");
        res := self.to_values(*CompileError, res.Err);
        e&.set(res, type);
        e
    };
    
    #export("fn FnPtr(arg: Type, ret: Type) Type #fold #ct #comptime_addr(%);\n")
    fn_ptr :: fn(arg: Type, ret: Type) Type = {
        self := current_comptime();
        f_ty: FnType = (arg = arg, ret = ret, unary = self.comp().is_unary(arg));
        self.intern_type(FnPtr = (ty = f_ty))
    };
    
    #export("fn get_meta(s: Type) TypeMeta #fold #ct #comptime_addr(%);\n")
    get_m :: fn(s: Type) TypeMeta = 
        current_comptime().get_info(s)[];
    
    #export("fn ast_alloc() Alloc #ct #comptime_addr(%);\n")
    get_aa :: fn() Alloc = 
        current_comptime().get_alloc();
    
    #export("fn current_compiler_context() CompCtx #ct #comptime_addr(%);\n")
    get_cc :: fn() CompCtx = {
        vtable := init_driver_vtable(); // TODO: don't allocate every time :SLOW
        (data = current_comptime()[].legacy_indirection, vtable = vtable)
    };
    
    #export("fn resolve_overload(os: OverloadSet, arg: Type, ret: Type, loc: Span) FuncId #fold #ct #comptime_addr(%);\n")
    resolve_os :: fn(os: OverloadSet, arg: Type, ret: Type, loc: Span) FuncId = {
        self := current_comptime();
        f_ty: FnType = (arg = arg, ret = ret, unary = self.comp().is_unary(arg));
        res := self.poll_in_place(FuncId, => self.resolve_by_type(os, f_ty, loc));
        self.unwrap_report_error(FuncId, res)
    };
    
    #export("fn get_function_ast(fid: FuncId, resolve_sign: bool, resolve_body: bool, infer_sign: bool, infer_body: bool) *Func #fold #ct #comptime_addr(%);\n")
    get_func :: fn(fid: FuncId, resolve_sign: bool, resolve_body: bool, infer_sign: bool, infer_body: bool) *Func = {
        self := current_comptime();
        res := self.poll_in_place(void) {
            ret :: local_return;
            @if(resolve_sign) @check(self.ensure_resolved_sign(fid)) ret;
            @if(resolve_body) @try(self.ensure_resolved_body(fid)) ret;
            @if(infer_sign) {
                @check(self.infer_arguments(fid)) ret;
                @check(self.infer_return(fid)) ret;
            };
            @if(infer_body) @check(self.compile_body(fid)) ret;
            .Ok
        };
        self.unwrap_report_error(void, res);
        self.get_function(fid)
    };
    #export("fn require_layout_ready(type: Type) void #fold #ct #comptime_addr(%);\n")
    require_layout_ready :: fn(type: Type) void = {
        finish_layout(current_comptime(), type);
    };
    
    #export("__builtin_compiler_has_feature :: fn(s: Str) bool #fold #ct #comptime_addr(%);\n")
    has_feature_s :: fn(s: Str) bool = {
        if(s == "@franca/alloc_slice", => return(true)); 
        if(s == "@franca/fewer_builtins", => return(true)); 
        if(s == "@franca/no_merged_funcimpl", => return(true)); 
        if(s == "@franca/internal_pointers", => return(true)); 
        false
    };
    
    #export("fn import(descriptor: Str) ScopeId #ct #comptime_addr(%) #fold;\n")
    do_import :: fn(descriptor: Str) ScopeId = {
        self := current_comptime();
        desc := self.pool.insert_owned(descriptor.clone(self.get_alloc()).items());
        res := import_as_scope(self, desc, self.last_loc /*TODO*/, .None);
        self.unwrap_report_error(ScopeId, res)
    };
    
    #export("fn scope_from_value(ty: Type, ptr: rawptr) ?ScopeId #ct #comptime_addr(%);\n")
    scope_val :: fn(type: Type, ptr: *u8) ?ScopeId = {
        self := current_comptime();
        ok := type == ScopeId || type == Type || type == FuncId || self.get_type(type).is(.Fn);
        if !ok {
            return(.None)
        };
        self.finish_layout(type);
        bytes: i64 = self.get_info(type)[].stride_bytes.zext();
        value := slice(ptr, bytes);
        value := self.from_bytes(value);
        res := value_to_scope(self, value, type, .None);
        scope := self.unwrap_report_error(ScopeId, res);
        (Some = scope)
    };
    
    #export("fn get_constants(s: ScopeId) []Symbol #ct #comptime_addr(%) #fold;\n")
    get_names :: fn(s: ScopeId) []Symbol = {
        self := current_comptime();
        if(s == NOSCOPE, => return(empty()));
        self.unwrap_report_error(void, self.fill_directory_scope(s));
        scope := self.scopes[s].vars&;
        names := Symbol.list(scope.len, self.get_alloc()); 
        // TODO: it's actually more useful for the callee if i return a []Var here and then 
        //       this could just be a slice without reallocating. that locks the Var abi
        //       which is bad but it's already locked elsewhere anyway so that's a bit of a lost cause at this point. 
        if true {
            break :: local_return;
            // scope.vars is in insertion order and constants are hoisted so they're always first. 
            each scope { v |
                v.kind == .Const || break();
                names&.push(v.name);
            };
        };
        names.items()
    };
    
    #export("fn get_constant(s: ScopeId, name: Symbol, type: Type, out: rawptr) bool #ct #comptime_addr(%);\n")
    get_field_known :: fn(s: ScopeId, name: Symbol, type: Type, out: rawptr) bool = {
        self := current_comptime();
        if(s == NOSCOPE, => return(false));
        res := self.poll_in_place(?Values, => self.find_in_scope(s, name, type));
        value := self.unwrap_report_error(?Values, res) || return(false);
        // TODO: do we have to typecheck type_found?
        //       answer: YES
        size: i64 = self.get_info(type)[].stride_bytes.zext();
        // TODO: this needs to be based on a real coerce + type check not just size. 
        //       it's totally crippling if you get back a Type when you asked for a FuncId :FUCKED
        if size != value&.len() {
            return(false); // TODO: this really should be an error we catch from find_in_scope
        };
        //@debug_assert_eq(size, value&.len(), "get_constant() size mismatch");
        dest: []u8 = (ptr = u8.ptr_from_raw(out), len = size);
        dest.copy_from(value&.bytes());
        true
    };
    
    #export("fn get_constant(s: ScopeId, name: Symbol) ?Ty(rawptr, Type) #ct #comptime_addr(%);\n")
    get_field :: fn(s: ScopeId, name: Symbol) ?Ty(rawptr, Type) = {
        self := current_comptime();
        if(s == NOSCOPE, => return(.None));
        var := self.scopes[s].lookup&.get(name) || return(.None);
        if(var.kind != .Const, => return(.None));
        res := self.poll_in_place(Ty(Values, Type), => self.find_const(var, .None));
        value, type := self.unwrap_report_error(Ty(Values, Type), res);
        value := @if(value&.is(.Big), value&, {
            v := self.get_alloc().box(Values);
            v[] = value;
            v
        });
        (Some = (value.jit_addr().rawptr_from_int(), type))
    };
    
    // get a string representation of the type. 
    // we try to infer this as something reasonable based on constant declarations that had the type on the right.
    #export("fn typename(type: Type) Symbol #fold #ct #comptime_addr(%);\n")
    typename :: fn(type: Type) Symbol = {
        self := current_comptime();
        self.pool.insert_borrowed(self.log_type(type), self.get_alloc())
    };
    
    #export("fn get_or_create_overloads(name: Symbol, scope: ScopeId, loc: Span) OverloadSet #fold #ct #comptime_addr(%);\n")
    gco :: fn(name: Symbol, scope: ScopeId, loc: Span) OverloadSet = {
        self := current_comptime();
        res := self.poll_in_place(OverloadSet, => self.get_or_create_overloads(name, scope, loc));
        self.unwrap_report_error(OverloadSet, res)
    };
    
    #export("fn add_to_overload_set(os: OverloadSet, fid: FuncId) void #fold #ct #comptime_addr(%);\n")
    ato :: fn(os: OverloadSet, fid: FuncId) void = {
        current_comptime().add_to_overload_set(os, fid);
    };
};
