//! There are two contexts for compile-time execution in this language. 
//! - fill_driver_vtable: The driver program where you're logically aware of the outside world and might have multiple compiler instances doing different things. 
//! - fill_export_ffi: Within the program like '::' expressions and macros, where you're only aware of the current compiler instance. 
//! In the latter, you don't manually pass the compiler context pointer to every function. 
//! These corrispond to Zig's build.zig vs comptime and Rust's build.rs vs proc-macros/const-fns. 

fn fill_driver_vtable(vtable: *ImportVTable) void = {
    vtable.add_file = add_file;
    vtable.parse_stmts = parse_stmts;
    vtable.intern_string = intern_string;
    vtable.get_string = get_string;
    vtable.emit_llvm = emit_llvm; // TODO: have a compile option to not include the things you don't need for bootstrapping. so i can commit a smaller blob. 
    vtable.get_fns_with_tag = get_fns_with_tag;
    vtable.get_function = fn(c: Compiler, f: FuncId) *Func = {
        c.cast()[][].get_function(f)
    };
    vtable.make_jitted_exec = fn(c: Compiler) void = {
        c := c.cast()[][]; // TODO: can't inline cause it confuses deduplicator. -- Jul 29
        c.aarch64&.bump_dirty();
    };
    vtable.give_vtable = fn(c: Compiler, vptr: *ExportVTable, userdata: rawptr) void = {
        c := c.cast()[][];
        c.env.driver_vtable_ptr = ExportVTable.raw_from_ptr(vptr);
        c.env.driver_vtable_user_data = userdata;
    };
    @if(ENABLE_QBE_BACKEND) {
        vtable.emit_qbe = emit_qbe; // TODO: have a compile option to not include the things you don't need for bootstrapping. so i can commit a smaller blob. 
    };
}

CompilerRs :: ***SelfHosted;  // TODO: really this should be a new type so you can't accidently implement call functions by just adding extra indirection. hopefully the number of pointers makes it clear something's weird. 
fn cast(c: Compiler) CompilerRs #unsafe_noop_cast;
fn cast(c: CompilerRs) Compiler #unsafe_noop_cast;

fn add_file(c: Compiler, name: Str, content: Str) Span = {
    c := c.cast();
    c.codemap.add_file(name, content)
}

fn parse_stmts(c: Compiler, f: *Span) Result(Slice(FatStmt), ParseErr) = {
    c := c.cast();
    source := c.codemap.source_slice(f[]);
    id := c.parser.push_parse(source, f[]);
    stmts := @try_deref_err(c.parser.finish_pending_stmts(id)) return; // TODO: don't return RsVec -- Jun 29
    (Ok = stmts.items())
}

fn intern_string(c: Compiler, s: Str) Symbol = {
    c := c.cast();
    c.pool.insert_owned(s)
}

fn get_string(c: Compiler, s: Symbol) Str = {
    c := c.cast();
    c.pool.get(s)
}

// TODO: this is only called in the compiler. because of the annoying two types for compiler data pointer. 
fn get_baked(c: Compiler, id: BakedVarId) BakedVar = {
    val := c.cast()[][].get_baked(id); 
    val._1
}

fn get_fns_with_tag(c: Compiler, tag: Symbol) [] FuncId = {
    c := c.cast();
    found: List(FuncId) = list(temp());
    i: u32 = 0;
    each c.functions& { func |
        continue :: local_return;
        // TODO: defer { i += 1; };
        if(!func.get_flag(.NotEvilUninit), => { i += 1; continue() });
        each func.annotations { a |
            if a.name == tag {|
                found&.push(funcid_from_index(i));
                i += 1; 
                continue();
            };
        };
        i += 1; 
    };
    found.items()
}

/////////////////////////////////////////////////////////////////////////////////

fn fill_export_ffi(out: *List(u8)) void = {
    // TODO: fix error message if you forget a semi-colon in the string. 
    @fmt(out, "fn lookup_baked(addr: i64) ?BakedVarId #ct #comptime_addr(%);\n", lookup_baked);
    lookup_baked: rawptr : fn(c: CompilerRs, addr: i64) ?BakedVarId = c.baked.lookup&.get(addr);
    
    @fmt(out, "fn cache_baked(addr: i64, id: BakedVarId) ?BakedVarId #ct #comptime_addr(%);\n", cache_baked);
    cache_baked: rawptr : fn(c: CompilerRs, addr: i64, id: BakedVarId) void = {
        c.baked.lookup&.insert(addr, id); // TODO: error if collide? 
    };
    
    @fmt(out, "fn dyn_bake_relocatable_value(raw_bytes: Slice(u8), ty: Type, force_default_handling: bool) Slice(BakedEntry) #ct #comptime_addr(%);\n", dyn_bake_value);
    dyn_bake_value: rawptr : fn(c: CompilerRs, bytes: Slice(u8), ty: Type, force_default_handling: bool) Slice(BakedEntry) = {
        r := c[][].emit_relocatable_constant_body(bytes, ty, force_default_handling); // TODO: sad extra binding forces it to instantiate the type. 
        r.unwrap()
    };
    
    @fmt(out, "fn if(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", if_node);
    if_node: rawptr : fn(c: CompilerRs, e: FatExpr) FatExpr = {
        assert(e.expr&.is(.Tuple), "@if expected tuple");
        parts := e.expr.Tuple&;
        (expr = (If = (cond = parts.index(0), if_true = parts.index(1), if_false = parts.index(2))), loc = e.loc, ty = UnknownType, done = false)
    };
    @fmt(out, "fn slice(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", slice_node);
    slice_node: rawptr : fn(c: CompilerRs, e: FatExpr) FatExpr = {
        e := c[][].box(e);
        (expr = (Slice = e), loc = e.loc, ty = UnknownType, done = false)
    };
    @fmt(out, "fn _uninitialized(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", uninit_node);
    uninit_node: rawptr : fn(c: CompilerRs, e: FatExpr) FatExpr = {
        (expr = .Uninitialized, loc = e.loc, ty = UnknownType, done = false)
    };
    @fmt(out, "fn loop(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", loop_node);
    loop_node: rawptr : fn(c: CompilerRs, e: FatExpr) FatExpr = {
        e := c[][].box(e);
        (expr = (Loop = e), loc = e.loc, ty = UnknownType, done = false)
    };
    
    @fmt(out, "fn operator_star_prefix(T: Type) Type #fold #ct #comptime_addr(%);\n", ptr);
    ptr: rawptr : fn(c: Compiler, inner: Type) Type = {
        c.cast()[][].intern_type((Ptr = inner))
    };
    @fmt(out, "fn Label(Ret: Type) Type #fold #ct #comptime_addr(%);\n", label);
    label: rawptr : fn(c: Compiler, inner: Type) Type = {
        c.cast()[][].intern_type(Label = inner)
    };
    
    // These only exist for debugging the compiler when everything's broken so can't even compile the one defined in the language.
    @fmt(out, "fn debug_log_int(i: i64) void #comptime_addr(%);\n", @as(rawptr) :: (fn(i: i64) void = println(i)));
    @fmt(out, "fn debug_log_str(i: Str) void #comptime_addr(%);\n", @as(rawptr) :: (fn(i: Str) void = println(i)));
    
    @fmt(out, "fn str(i: Symbol) Str #ct #fold #comptime_addr(%);\n", str);
    str: rawptr : fn(c: CompilerRs, i: Symbol) Str = {
        c.pool.get(i)
    };
    
    @fmt(out, "fn sym(i: Str) Symbol #ct #fold #comptime_addr(%);\n", sym);
    sym: rawptr : fn(c: CompilerRs, i: Str) Symbol = {
        c.pool.insert_owned(i)
    };
    
    @fmt(out, "fn get_comptime_environment() *ComptimeEnvironment #ct #comptime_addr(%);\n", env);
    env: rawptr : fn(c: CompilerRs) *ComptimeEnvironment = {
        c[][].env
    };
    
    @fmt(out, "fn by_the_way_you_are_compiling_the_compiler_right_now_just_a_helpful_hint() void #ct #comptime_addr(%);\n", note);
    note: rawptr : fn(c: CompilerRs) void = {
        // This just gives a place to assert we haven't got any weird feature flags turned on while porting stuff over from rust. 
        // It gets a bit scary if the first thing you try to compile is accidentally the compiler so if it miscompiles you're fucked now. 
        // It's philosophically important that we don't actually change behaviour based on this information tho.
    };
    
    @fmt(out, "fn compile_error(msg: Str, loc: Span) Never #ct #comptime_addr(%);\n", report_err);
    report_err: rawptr : fn(c: CompilerRs, msg: Str, loc: Span) Never = {
        // TODO: command line arg to show more context? 
        println("=== ERROR ===");
        println(msg);
        c[][].codemap.show_error_line(loc);
        panic("Comptime reported error.")
    };
    
    // TODO: this should work but "unsafe precondition violated". -- Jul 6
    //@fmt(out, "fn ast_alloc() Alloc #ct #comptime_addr(%);\n", the_allloc);
    //the_allloc: rawptr : fn(c: CompilerRs) Alloc = {
    //    c[][].get_alloc()
    //};
    
    // TODO: version of this that allows caching? but have to think more about when you're allowed to deduplicate.
    @fmt(out, "fn bake_value(v: BakedVar) BakedVarId #ct #comptime_addr(%);\n", bake_var);
    bake_var: rawptr : fn(c: CompilerRs, v: BakedVar) BakedVarId = {
        c[][].put_baked(v, .None)
    };
    
    // Generated for @BITS to bootstrap encoding for inline asm.
    // TODO: remove this. @BITS is unused because of intrinsics. 
    @fmt(out, "fn __shift_or_slice(ints: Slice(i64)) u32 #no_tail #fold #comptime_addr(%);\n", shift_or_slice);
    shift_or_slice: rawptr : fn(ints: []i64) u32 = {
        //::display_slice(i64);
        //@println("%", ints);
        @assert(ints.len < 32, "% is too many args for fold_shift_or", ints.len);
        acc := 0;
        range(0, ints.len / 3) { i |
            //@print("% ", acc); // :debug
            x := ints[i * 3];
            sh := ints[i * 3 + 1];
            size_info := ints[i * 3 + 2]; // HACK. masking fixed maual_mmap. u16 has garabge memory where read as u64.
            bit_count := size_info.abs();
            is_signed := size_info < 0;
            if is_signed {|
                x = signed_truncate(x, bit_count).zext();
            };
            @assert(sh < 32, "% too much shift", sh);
            //@assert(x.shift_left(sh) <= 1.shift_left(32), "% << %", x, sh);
            mask := 1.shift_left(bit_count) - 1;
            acc = acc.bit_or(x.bit_and(mask).shift_left(sh));
        };
        //@println("%", acc); // :debug
        @assert(acc > 0 && acc <= MAX_u32.zext(), "% is not a valid u32", acc);
        acc.trunc()
    };
 
    @fmt(out, "fn number_of_functions() i64 #ct #comptime_addr(%);\n", num_f);
    num_f: rawptr : fn(c: CompilerRs) i64 = {
        c.functions.len
    };
    
    @fmt(out, "fn safety_check_enabled(check: SafetyCheck) bool #ct #comptime_addr(%);\n", safe);
    safe: rawptr : fn(c: CompilerRs, check: SafetyCheck) bool = {
        build_options := c[][].get_build_options();
        if(check.raw() >= build_options.safety_checks&.len(), => return(true)); // allow adding new safety checks and then bootstrapping. 
        build_options.safety_checks&.index(check)[]
    }
     
    @fmt(out, "fn get_type_info_ref(T: Type) *TypeInfo #fold #ct #comptime_addr(%);\n", ty_info);
    ty_info: rawptr : fn(c: CompilerRs, ty: Type) *TypeInfo = {
        info := c[][].get_type(ty);
        while => info.is(.Named) {|
            info = c[][].get_type(info.Named._0);
        };
        info
    };
    
    @fmt(out, "fn Ty(fst: Type, snd: Type) Type #fold #ct #comptime_addr(%);\n", tuple2);
    tuple2: rawptr : fn(c: CompilerRs, fst: Type, snd: Type) Type = {
        c[][].tuple_of(@slice(fst, snd))
    };
    @fmt(out, "fn Ty(fst: Type, snd: Type, trd: Type) Type #fold #ct #comptime_addr(%);\n", tuple3);
    tuple3: rawptr : fn(c: CompilerRs, fst: Type, snd: Type, trd: Type) Type = {
        c[][].tuple_of(@slice(fst, snd, trd))
    };
    @fmt(out, "fn Ty(fst: Type, snd: Type, trd: Type, frt: Type) Type #fold #ct #comptime_addr(%);\n", tuple4);
    tuple4: rawptr : fn(c: CompilerRs, fst: Type, snd: Type, trd: Type, frt: Type) Type = {
        c[][].tuple_of(@slice(fst, snd, trd, frt))
    };
}

fn get_build_options(c: *SelfHosted) *BuildOptions = {
    BuildOptions.ptr_from_raw(c.env.build_options)
}

fn new_sema_fill_export_ffi(out: *List(u8)) void = {
    @fmt(out, "fn Tag(tagged: Type) Type #fold #ct #comptime_addr(%);\n", get_tag);
    get_tag: rawptr : fn(c: CompilerRs, tagged: Type) Type = {
        raw := c[][].raw_type(tagged);
        @if_let(c[][].get_type(raw)) fn Tagged(f) => {
            return(f.tag);
        };
        @panic("Expected @tagged found %", c[][].log_type(tagged));
        void
    };
    
    @fmt(out, "fn Fn(Arg: Type, Ret: Type) Type #fold #ct #comptime_addr(%);\n", fn_type);
    fn_type: rawptr : fn(c: CompilerRs, arg: Type, ret: Type) Type = {
        arity := 1;
        types := c[][].tuple_types(arg);
        if types { types |
            arity = types.len;
        };
        c[][].intern_type(Fn = (arg = arg, ret = ret, arity = arity.trunc()))
    };
    
    @fmt(out, "fn IntType(bits: i64, signed: bool) Type #fold #ct #comptime_addr(%);\n", make_int_type);
    make_int_type: rawptr : fn(c: CompilerRs, bit_count: i64, signed: bool) Type = {
        c[][].intern_type(Int = (bit_count = bit_count, signed = signed))
    };
    
    @fmt(out, "fn builtin(t: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", builtin);
    builtin: rawptr : fn(c: CompilerRs, arg: FatExpr) FatExpr = {
        self := c[][];
        res := self.builtin_macro(arg);
        self.unwrap_report_error(FatExpr, res)
    };
    
    @fmt(out, "fn unquote_macro_apply_placeholders(t: Slice(FatExpr)) FatExpr #ct #comptime_addr(%);\n", unquote_placeholders);
    unquote_placeholders: rawptr : fn(c: CompilerRs, args: []FatExpr) FatExpr = {
        self := c[][];
        args := args.assume_owned(temp());
        template := args&.pop().expect("ICE: unquote_placeholders always needs template arg");
        // Since we're probably going to call this with different values for the placeholders (like invoking the same macro multiple times),
        // we duplicate to not mess up the constant value of the template. 
        // TODO: i feel like the old version wasn't doing this. why did that work? 
        template := template&.deep_clone(self.get_alloc());
        walk: Unquote = (compiler = self, placeholders = args);
        res := walk&.walk_expr(template&);
        self.unwrap_report_error(void, res);
        unused := 0;
        enumerate walk.placeholders { i, e | 
            if !e.expr&.is(.Poison) {|
                unused += 1;
                @println("- [%] %", i, e.log(self.pool));
            };
        };
        @assert(unused == 0, "ice: unquote_placeholders didn't use all arguments\n%", template&.log(self.pool));
        self.renumber_expr(template&, .None);
        template
    };
    
    @fmt(out, "fn Fn(Arg: FatExpr, Ret: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", fn_type_macro_erase);
    @fmt(out, "fn FnPtr(Arg: FatExpr, Ret: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", fn_ptr_type_macro_erase);
    @fmt(out, "fn Fn(Ret: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", fn_type_macro_single);
    @fmt(out, "fn FnPtr(Ret: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", fn_ptr_type_macro_single);
   
    make_fn_type :: fn(c: CompilerRs, arg: FatExpr, ret: FatExpr) FnType = {
        self := c[][];
        inner :: fn() Maybe(FnType) => {
            return :: local_return;
            types: []Type = @match(arg.expr&) {
                fn StructLiteralP(parts) => {
                    // TODO: ugh
                    x := parts.bindings.assume_owned(self.get_alloc());
                    x&.if_empty_add_unit();
                    parts.bindings = x.rs();
                    
                    @check(self.infer_type(parts)) return
                }
                fn Tuple(parts) => {
                    types: List(Type) = list(temp());
                    each parts { e | 
                        value := @check(self.immediate_eval_expr(e, Type)) return; // :get_or_create_type
                        types&.push(Type.assume_cast(value&)[]);
                    };
                    types.items()
                }
                @default => {
                    value := @check(self.immediate_eval_expr(arg&, Type)) return; // :get_or_create_type
                    ty := Type.assume_cast(value&)[];
                    lst: List(Type) = list(temp());
                    lst&.push(ty);
                    lst.items()
                };
            };
            arg_ty := self.tuple_of(types);
            value := @check(self.immediate_eval_expr(ret&, Type)) return; // :get_or_create_type
            ret_ty := Type.assume_cast(value&)[];
            (Ok = (arg = arg_ty, ret = ret_ty, arity = types.len.trunc()))
            
        };
        res := self.poll_in_place(FnType, => inner());
        return(self.unwrap_report_error(FnType, res));
        FnType.unreachable_hack()
    };
    
    fn_type_macro_erase: rawptr : fn_type_macro;
    fn_type_macro :: fn(c: CompilerRs, arg: FatExpr, ret: FatExpr) FatExpr = {
        f_ty := make_fn_type(c, arg, ret);
        ty := c[][].intern_type(Fn = f_ty);
        value := c[][].to_values(Type, ty); 
        arg&.set(value, Type); // :get_or_create_type
        arg
    };
    
    fn_ptr_type_macro_erase: rawptr : fn_ptr_type_macro;
    fn_ptr_type_macro :: fn(c: CompilerRs, arg: FatExpr, ret: FatExpr) FatExpr = {
        f_ty := make_fn_type(c, arg, ret);
        ty := c[][].intern_type(FnPtr = (ty = f_ty, cc = .CCallReg));
        value := c[][].to_values(Type, ty); 
        arg&.set(value, Type); // :get_or_create_type
        arg
    };
    
    fn_ptr_type_macro_single: rawptr : fn(c: CompilerRs, ret: FatExpr) FatExpr = 
        c.fn_ptr_type_macro(empty_struct_literal(ret.loc), ret);
    
    fn_type_macro_single: rawptr : fn(c: CompilerRs, ret: FatExpr) FatExpr = 
        c.fn_type_macro(empty_struct_literal(ret.loc), ret);
    
    empty_struct_literal :: fn(loc: Span) FatExpr = {
        (expr = (StructLiteralP = (bindings = empty(), loc = loc)), loc = loc, ty = UnknownType, done = false)
    };
    @fmt(out, "fn literal_ast(ty: Type, ptr: rawptr) FatExpr #ct #comptime_addr(%);\n", literal_ast);
    literal_ast: rawptr : fn(c: CompilerRs, ty: Type, ptr: *u8) FatExpr = {
        bytes: i64 = c[][].get_info(ty)[].stride_bytes.zext();
        value := slice(ptr, bytes);
        value := c[][].from_bytes(value);
        // TODO: zero_padding?
        // TODO: caller should pass in loc?
        synthetic_ty((Value = (bytes = value, coerced = false)), c.last_loc, ty)
    };
    
    @fmt(out, "fn type(e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", type_macro);
    type_macro: rawptr : fn(c: CompilerRs, e: FatExpr) FatExpr = {
        ty := c[][].poll_in_place(Type) {()Maybe(Type)|
            @check(c[][].compile_expr(e&, .None)) local_return;
            (Ok = e.ty)
        };
        ty := c[][].unwrap_report_error(Type, ty)
        value := c[][].to_values(Type, ty); 
        e&.set(value, Type); // :get_or_create_type
        @println("we know the type! %", e&.log(c[][].pool));
        return(e);
        FatExpr.unreachable_hack() // :FUCKED
    };
    
    @fmt(out, "fn const_eval(expr: FatExpr, ty: Type, result: rawptr) void #ct #comptime_addr(%);\n", const_eval_any);
    
    const_eval_any: rawptr : fn(c: CompilerRs, expr: FatExpr, ty: Type, addr: *u8) void = {
        len: i64 = c[][].get_info(ty)[].stride_bytes.zext();
        out := slice(addr, len);
        
        res := c[][].poll_in_place(void) {()Maybe(void)|
            value := @check(c[][].immediate_eval_expr(expr&, ty)) local_return;
            out.copy_from(value&.bytes());
            .Ok
        };
        c[][].unwrap_report_error(void, res);
    };
    
    @fmt(out, "fn struct(arg: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", struct_macro_wrap);
    struct_macro_wrap: rawptr : fn(c: CompilerRs, expr: FatExpr) FatExpr = {
        self := c[][];
        res := self.poll_in_place(FatExpr, => self.struct_macro(expr&));
        res := self.unwrap_report_error(FatExpr, res);
        return(res); // :FUCKED. miscompilation if you just have the expr at the end normally. losing the ret ptr???? -- Aug 5
        FatExpr.unreachable_hack()
    };  
    @fmt(out, "fn tagged(arg: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", tagged_macro_wrap);
    tagged_macro_wrap: rawptr : fn(c: CompilerRs, expr: FatExpr) FatExpr = {
        @println("start tagged_macro_wrap");
        self := c[][];
        res := self.poll_in_place(FatExpr, => self.tagged_macro(expr&));
        res := self.unwrap_report_error(FatExpr, res);
        return(res); // :FUCKED. miscompilation if you just have the expr at the end normally. losing the ret ptr???? -- Aug 5
        FatExpr.unreachable_hack()
    };
    
    // note: the old verion didn't even use this ast node, it just did the work here like @struct, et al.
    //       maybe thats better, idk, lets see if i still need the name based hack this way. -- Aug 5s
    @fmt(out, "fn as(T: FatExpr, e: FatExpr) FatExpr #macro #ct #comptime_addr(%);\n", as_node);
    as_node: rawptr : fn(c: CompilerRs, type: FatExpr, value: FatExpr) FatExpr = {
        value := c[][].box(value);
        type := c[][].box(type);
        (expr = (As = (type = type, value = value)), loc = value.loc, ty = UnknownType, done = false)
    };
    
    // TODO: redundant with get_type_info_ref. just impl this in the language.
    @fmt(out, "fn size_of(T: Type) i64 #fold #ct #comptime_addr(%);\n", size_of);
    size_of: rawptr : fn(c: CompilerRs, type: Type) i64 =
        c[][].get_info(type)[].stride_bytes.zext();
    
    // TODO: redundant with get_type_info_ref. just impl this in the language.
    @fmt(out, "fn get_type_info(T: Type) TypeInfo #fold #ct #comptime_addr(%);\n", ty_info);
    ty_info: rawptr : fn(c: CompilerRs, ty: Type) TypeInfo = {
        info := c[][].get_type(ty);
        while => info.is(.Named) {|
            info = c[][].get_type(info.Named._0);
        };
        info[]
    };
    @fmt(out, "fn debug_log_ast(expr: FatExpr) void #ct #comptime_addr(%);\n", debug_log_ast);
    debug_log_ast: rawptr : fn(c: CompilerRs, e: FatExpr) void = {
        @println("[debug_log_ast] %", e&.log(c[][].pool));
    };
    
}

unwrap_report_error :: fn(self: *SelfHosted, $T: Type, value: Res(T)) T #generic = {
    @match(value) {
        fn Ok(it) => it;
        fn Err(it) => {
            self.codemap.show_error_line(it.span);
            @panic("Compile Error: %", it.msg);
            T.unreachable_hack()
        }
    }
};

//////////////////////////////////////////////////////////////////////////////
// these are just stupid helpers to deal with the awquard multiple compiler types for calling into the rust code. 

fn check_for_new_aot_bake_overloads(comp: CompilerRs) CRes(void) = {
    {comp[][].vtable.check_for_new_aot_bake_overloads}(comp.cast())
}

fn index(comp: CompilerRs, f: FuncId) *Func = {
    comp[][].get_function(f)
}
