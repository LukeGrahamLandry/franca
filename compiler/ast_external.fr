fn decode_sig(self: *FnBody, i: u32) *PrimSig = { // Note: not stable if you push again!!
    self.sig_payloads&.index(i.zext())
} 

// This includes the indirect ret pointer!!
fn arg_slots(self: *PrimSig) i64 = {
    if(self.first_arg_is_indirect_return, => self.args.len + 1, => self.args.len)
}

fn decode_switch(cases: *RsVec(SwitchPayload)) Ty([]SwitchPayload, ?BbId) = {
    has_default := cases.last().unwrap()[].value == -1;
    ::if(Ty([]SwitchPayload, ?BbId));
    if(has_default) {
        (cases.items().slice(0, cases.len - 1), (Some = cases.last().unwrap()[].block))
    } else {
        (cases.items(), .None)
    }
}

fn get_info(c: CompCtx, type: Type) *TypeMeta = {
    {c.vtable.get_type_meta}(c.data, type)
}

fn get_type(c: CompCtx, type: Type) *TypeInfo = {
    {c.vtable.get_type_info}(c.data, type)
}

fn get_baked(c: CompCtx, id: BakedVarId) *Ty(rawptr, BakedVar) = {
    {c.vtable.get_baked}(c.data, id)
}

fn get_build_options(c: CompCtx) *BuildOptions = {
    {c.vtable.get_build_options}(c.data)
}

fn emit_relocatable_constant(c: CompCtx, ty: Type, value: []u8) CRes(BakedVarId) = {
    {c.vtable.emit_relocatable_constant}(c.data, ty, value)
}

fn log(c: CompCtx, e: *FatExpr) Str #inline = {
    {c.vtable.log_expr}(c.data, e)
}

fn log(c: CompCtx, e: *FatStmt) Str #inline = {
    {c.vtable.log_stmt}(c.data, e)
}

fn log(c: CompCtx, e: Type) Str #inline = {
    {c.vtable.log_type}(c.data, e)
}

fn log(c: CompCtx, e: *Func) Str #inline = {
    {c.vtable.log_func}(c.data, e)
}

fn follow_redirects(program: CompCtx, f_id: FuncId) FuncId = {
    dowhile() {
        @match(program.get_function(f_id)[].body&) {
            fn Redirect(target) => {
                f_id = target[];
                true
            }
            @default => false;
        }
    };
    f_id
}

// TODO: prepending all this shit to every program is getting a bit dumb. 

fn display(self: *FuncId, out: *List(u8)) void = {
    @fmt(out, "F%", self[].as_index());
}
fn display(self: FuncId, out: *List(u8)) void = {
    @fmt(out, "F%", self.as_index());
}

fn finished_ty(self: *Func) ?FnType = {
    if self.finished_arg { arg |
        if self.finished_ret { ret |
            return(Some = (arg = arg, ret = ret, arity = @as(u16) self.arg.bindings.len().max(1).trunc()));
        };
    };
    .None
}

fn arity(expr: *FatExpr) i64 = {
    @match(expr.expr&) {
        fn Tuple(parts) => parts.len;
        @default => 1;
    }
} 

fn unptr_ty(c: CompCtx, ty: Type) ?Type = {
    @match(c.get_type(ty)) {
        fn Ptr(inner) => (Some = inner[]);
        @default => .None; // TODO: do i need to raw_type? 
    }
}

/////////////////////////////////////
/// Primitive Type Representation ///
// 
// The distinction between backend types and front end types is important. 
// There are different registers for storing integers/pointers vs floats so the backend really does need to know which everything is. 
// It was much more confusing before when I was keeping a mask of which parts were floats and only had one type of float/int. 
// But the current implementation is more complicated than it needs to be because I wasn't sure what was important at the time. 
// 

// This (prim_sig implementation) is painful. 
// At least the interface is fairly thin. ~almost~ only emit_bc needs to deal with creating prim_sigs.
// but every backend needs to remember to handle indirect returns specially every time they touch one. 
//
// I treat the indirect seperately because the backend wants to put it in a special register. 
// But then for the block args, you do want the indirect ptr because the bc expects it. 
// And then compctx is weird because the front end doesn't want to insert it into the arguments, 
// so its not as part of the function type, its in the calling convention. -- Jul 5
//
// :ConfusingPrims These slices always have (P64) before them so you can offset backwards for indirect returns. 
//
fn prim_sig(program: CompCtx, f_ty: FnType) Res(PrimSig) = {
    @err_assert(!f_ty.arg.is_unknown() && !f_ty.ret.is_unknown(), "unknown fn types") return;
    ret := program.get_info(f_ty.ret);

    sig: PrimSig = (
        ret1 = .None,
        ret2 = .None,
        return_value_bytes = ret.stride_bytes,
        first_arg_is_indirect_return = ret.size_slots > @as(u16) 2.trunc(),
        no_return = f_ty.ret.is_never(),
    ); // TODO: if you typeo make this a '}' need to have a good error message. -- Jul 6

    @switch(ret.size_slots) {
        @case(0) => ();
        @case(1) => {
            sig.ret1 = program.prim(f_ty.ret);
        };
        @case(2) => {
            a, b := @try(program.prim_pair(f_ty.ret)) return;
            sig.ret1 = (Some = a);
            sig.ret2 = (Some = b);
        };
        @default => {
            // Note: not adding indirect pointer to sig because its handled sperately. TODO: that's kinda confusing.
        };
    };

    args: List(Prim) = list(program.get_alloc());
    // :ConfusingPrims
    args&.push(.P64); // for ret

    found_arity := 0;
    // TODO: compiler bug? what push_arg am i possibly shadowing?????? -- Jul 6
    push_arg__wtf :: fn(ty: Type) void => {
        found_arity += 1;
        info := program.get_info(ty);
        if info.pass_by_ref {
            args&.push(.P64);
        } else {
            for program.flat_tuple_types(ty) { t | 
                args&.push(program.prim(t).expect("arg prim"));
            };
        };
    };

    done := false;
    // TODO: if i always collapsed tuples of the same to array this would need different handling.
    @if_let(program.get_type(f_ty.arg)) 
        (fn Struct(f) => {
            if f.is_tuple {
                done = true;
                // TODO: :const_field_fix (not done on rust side either so add test for this!)
                each f.fields { f |
                    push_arg__wtf(f.ty);
                };
            };
        });
    if !done {
        push_arg__wtf(f_ty.arg);
    };

    // TODO: decide what i want a tuple to be. is it a real type you can have in memory or is it the thing that multiple arguments are?
    //       those ideas should extend to return values instead of them being special.
    //       should have a spread operator for calling a function on a tuple of arguments? like 'a := (1, 2); f(..a)'
    // @assert_eq(found_arity, f_ty.arity, "TODO: fn(a: Ty(i64, i64))");

    
    // :ConfusingPrims
    prims := args.items();
    prims.ptr = prims.ptr.offset(1);
    prims.len -= 1;
    
    sig.args = prims;
    
    sig.arg_int_count = 0;
    for sig.args { p |
        if !p.is_float() {
            sig.arg_int_count += 1;
        };
    };
    
    (Ok = sig)
}

fn prim_pair(self: CompCtx, ty: Type) Res(Ty(Prim, Prim)) = {
    types := self.flat_tuple_types(ty); // TODO: don't allocate
    @debug_assert_eq(types.len(), 2);
    a : Prim = @unwrap(self.prim(types[0]), "non-prim") return;
    b := @unwrap(self.prim(types[1]), "non-prim") return;
    (Ok = @as(Ty(Prim, Prim)) (a, b))
}

// note: this just gives empty for unit so you can't offset it like :ConfusingPrims
fn get_primatives(self: CompCtx, ty: Type) [] Prim = {
    if(ty.is_unit() || ty.is_never(), => return(empty()));
    slots := self.get_info(ty).size_slots();
    flat_types := self.flat_tuple_types(ty);
    types: List(Prim) = list(self.get_alloc());
    // :ConfusingPrims
    types&.push(.P64);  // for ret
    types&.push(.P64);  // for #ct
    
    for flat_types { t |
        if !t.is_unit().or(t.is_never()) {
            types&.push(self.prim(t).expect("tuple part to be prim"));
        };
    };
    // :ConfusingPrims
    prims := types.items();
    prims.ptr = prims.ptr.offset(2);
    prims.len -= 2;
    prims
}

fn prim(self: CompCtx, ty: Type) ?Prim = {
    p: Prim = @match(self.get_type(ty)) {
        fn F64()     => .F64;
        fn F32()     => .F32;
        fn Bool()    => .I8 ;
        fn VoidPtr() => .P64;
        fn FnPtr(_)  => .P64;
        fn Ptr(_)    => .P64;
        fn Fn(_)     => .I32;
        fn Label(_)  => .I32;
        fn Int(int) => 
            @switch(int.bit_count) { 
                @case(8)  => .I8 ;
                @case(16) => .I16;
                @case(32) => .I32;
                @default  => .I64;  // TODO: :fake_ints_too_big
            };
        fn Struct(f) => {
            if f.fields.len - f.const_field_count.zext() == 1 {
                fst := f.fields[0]&;
                assert(fst.kind != .Const, "TODO: first field const");
                if self.slot_count(fst.ty) == 1 {
                    return(self.prim(fst.ty));
                };
            };
            return(.None)
        }
        fn Tagged(f) => {
            each f.cases { c |
                if !c._1.is_unit() {
                    return(.None);
                };
            };
            .I64 // TODO: :tag_is_always_i64
        }
        fn Named(f) => return(self.prim(f._0));
        fn Enum(f) => return(self.prim(f.raw));
        fn Swizzler(f) => return(self.prim(f.raw));
        fn Array(f) => {
            if f.len == 1 {
                return(self.prim(f.inner));
            };
            return(.None)
        }
        @default => return(.None);
    };
    (Some = p)
}

fn flat_tuple_types(self: CompCtx, ty: Type) List(Type) = {
    @match(self.get_type(ty)) {
        fn Struct(f) => {
            out: List(Type) = list(temp());
            each f.fields { f | 
                if !f.kind.eq(.Const) {| 
                    out&.push_all(self.flat_tuple_types(f.ty).items());
                };
            };
            out
        }
        fn Enum(f) => self.flat_tuple_types(f.raw);
        fn Swizzler(f) => self.flat_tuple_types(f.raw);
        fn Named(f) => self.flat_tuple_types(f._0);
        // TODO: this is sketchy
        fn Tagged(f) => {
            slots: i64 = self.slot_count(ty).zext();
            varients: List(List(Type)) = list(f.cases.len, temp());
            for f.cases { f |
                var := self.flat_tuple_types(f._1);
                if var.len > 0 {
                    varients&.push(var);
                };
            };
            if varients.len() == 1 {
                varients[0]&.insert(0, i64);
                @debug_assert_eq(slots, varients[0].len());
                return(varients[0]);
            };
            // TODO: hack
            i64.repeated(slots, temp())
        }
        fn Array(f) => {
            out := self.flat_tuple_types(f.inner);
            single := out.len;
            // TODO: fix underflow. better ban 0 len array -- Jul 9
            range(0, f.len.zext() - 1) { i|
                // reslice everytime because we might reallocate. TODO: just reserve at the beginning.  -- Jul 6
                out&.push_all(out.items().slice(0, single));
            };
            out
        }
        fn void() => list(temp());
        @default => ty.repeated(1, temp());
    }
}

fn get_comptime_env(comp: CompCtx) *ComptimeEnvironment = 
    ComptimeEnvironment.ptr_from_raw(comp.get_build_options()[].env);

fn fmt_fn_name(program: CompCtx, f: FuncId) Str = {
    opts := program.get_build_options();
    func := program.get_function(f);
    //if func.get_flag(.NoMangle) { 
    //    return(program.get_string(func.name));
    //};
    if opts.retain_function_names {
        real_name := program.get_string(func.name);
        @tfmt("%__%", real_name, f.to_index())
    } else {
        @tfmt("F%", f.to_index())
    }
}

fn tuple_types(self: CompCtx, ty: Type) ?[]Type = {
    @match(self.get_type(ty)) {
        fn Struct(f) => {
            out: List(Type) = list(f.fields.len, temp());
            // :const_args_are_not_const_in_tuple
            @debug_assert(f.is_tuple, "called tuple_types on a struct, which might be fine but i don't think happens");
            @debug_assert(f.const_field_count == 0, "tuples don't have constant fields");
            each f.fields { f |
                @debug_assert(f.kind != .Const); // we don't know what the caller's expecting
                out&.push(f.ty);
            };
            (Some = out.items())
        }
        fn Named(f) => self.tuple_types(f._0);
        fn Array(f) => (Some = f.inner.repeated(f.len.zext(), temp()).items());
        @default => .None;
    }
}

max_homogeneous_tuple :: 50;

fn arg_types(self: CompCtx, ty: Type) []Type = {
    @match(self.get_type(ty)) {
        fn Struct(f) => {
            if f.is_tuple {
                types := self.tuple_types(ty);
                return(types.unwrap());
            };
            (@list(ty) temp()).items()
        };
        // :hacky_type_compression
        // this is a :HACK to fix @slice(>50 elements)
        // TODO: but does this miscompile `fn foo(a: Array(Bar, 51)) void;`? 
        //       or do we makes sure it's wrapped in an extra tuple? if so then we don't need the second case maybe? -- Nov 18
        fn Array(it) => {
            if it.len.zext() > max_homogeneous_tuple {
                return(it.inner.repeated(it.len.zext(), temp()).items()); // TODO: aaa :SLOW
            } else {
                return((@list(ty) temp()).items());
            };
            unreachable()
        }
        @default => {
            xx := @list(ty) temp();
            xx.items()  
        };
    }
}

///////////////////////////
// TODO: should try to clean these up.

// @err_assert(cond, "msg %", 123) return;
fn err_assert(arg: FatExpr, ret: FatExpr) FatExpr #macro = {
    loc := arg.loc;
    arg := compile_ast(arg);
    arg_err :: "@err_assert expected '(cond, fmt_string, args)'";
    if arg.ty == bool {
        arg = compile_ast(@{ (@[arg], "Assertion Failed") });
    };
    @ct_assert(arg.expr&.is(.Tuple), loc, arg_err);
    parts := arg.expr.Tuple.items();
    @ct_assert(parts.len >= 2, loc, arg_err);
    @ct_assert(parts[1].ty == Str, loc, arg_err);
    
    if parts.len == 2 {
        @{ 
            if !@[parts[0]] {
                @[ret](@err(@[parts[1]]));
            };
        }
    } else {
        @{
            if !@[parts[0]] {
                out: List(u8) = list(temp());
                @[format_into(@{ out& }, parts.rest(1), arg.loc)];
                @[ret](@err(out.items()));
            };
        }
    }
}

fn unwrap(arg: FatExpr, ret: FatExpr) FatExpr #macro = {
    loc := arg.loc;
    arg := compile_ast(arg);
    if arg.ty == bool {
        arg = compile_ast(@{ (@[arg], "Assertion Failed") });
    };
    arg_err :: "@assert expected '(nullable, fmt_string, args)'";
    @ct_assert(arg.expr&.is(.Tuple), loc, arg_err);
    parts := arg.expr.Tuple.items();
    @ct_assert(parts.len >= 2, loc, arg_err);
    @ct_assert(parts[1].ty == Str, loc, arg_err);
    @{
        cond := @[parts[0]];
        if cond&.is_none() {
            out: List(u8) = list(temp());
            out&.push_all("Missing Value: ");
            @[format_into(@{ out& }, parts.rest(1), arg.loc)];
            @[ret](@err(out.items()));
        };
        cond.unwrap()
    }
}

fn err(arg: FatExpr) FatExpr #macro = {
    @if(BOOTSTRAP_ONLY_MODE) {
        arg = @{"---"};
    };
    if !arg.expr&.is(.Tuple) {
        return(@{ (Err = make_error(@[arg])) });
    };
    @{
        out: List(u8) = list(libc_allocator);
        @[ format_into(@{ out& }, arg.expr.Tuple.items(), arg.loc) ];
        (Err = make_error(out.items()))
    }
}

// TODO: dont call malloc here!
fn make_error(msg: Str) *CompileError = {
    mem := libc_allocator.alloc(CompileError, 1);
    mem.ptr[] = (Msg = (span = Span.zeroed(), msg = msg));
    mem.ptr
}

fn update_main_span(err: *CompileError, new_loc: Span) void = {
    @match(err) {
        fn Msg(it) => {
            if it.span.low == 0 && it.span.high == 0 {
                it.span = new_loc;
            };
        }
        fn TypeMismatch(it) => {
            if it.span.low == 0 && it.span.high == 0 {
                it.span = new_loc;
            };
        }
        fn CoerceConst(it) => {
            if it.span.low == 0 && it.span.high == 0 {
                it.span = new_loc;
            };
        }
        fn InvalidField(it) => {
            if it.span.low == 0 && it.span.high == 0 {
                it.span = new_loc;
            };
        }
        @default => (); // TODO
    };
}

fn choose_impl(self: *FuncImpl, prio: []FuncImpl.Tag()) ?*FuncImpl = {
    @if_let(self) fn Merged(parts) => {
        // :SLOW make prio $ and have a lookup table for value and just find max in one pass, but N is like 3 so meh.
        for prio { p | 
            each parts { check |
                @debug_assert(!check.is(.Merged), "nested FuncImpl.Merged");
                if check.tag() == p {
                    return(Some = check);
                };
            };
        };
        return(.None);
    };
    
    for prio { p |
        if self.tag() == p {
            return(Some = self);
        };
    };
    .None
} 

// :get_or_create_type
fn is_unit(t: Type) bool = t == void;
fn is_unknown(t: Type) bool = t == UnknownType;
fn is_never(t: Type) bool = t == Never;

fn raw_type(c: CompCtx, ty: Type) Type = {
    loop {
        @match(c.get_type(ty)) {
            fn Named(f) => {
                ty = f._0;
            }
            fn Enum(f) => {
                ty = f.raw;
            }
            @default => {
                return(ty);
            };
        };
    };
    ty
}

// Mote: this is weak! often you'd rather use immediate_eval_expr.
fn as_const(self: *FatExpr) ?Values = {
    @if_let(self.expr&)
        fn Value(f) => { return(Some = f.bytes); };  // TODO: this should work when the branch returns never (no extra { ..; }) -- Jul 8
    
    .None
}

// fn from_values
fn assume_cast($T: Type, self: *Values) *T #generic = {
    b := self.bytes();
    assert_eq(b.len, T.size_of());  // TODO: check alignment
    ptr_cast_unchecked(u8, T, b.ptr)
}

::enum(CallConv);

fn find_impl(self: *FuncImpl, $p: FuncImpl.Tag()) ?*get_variant_type(FuncImpl, p) #generic = {
    if self.tag() == p {
        return(Some = get_variant_ptr(FuncImpl, self, p));
    };
    @if_let(self) fn Merged(parts) => {
        each parts { check | 
            @debug_assert(!check.is(.Merged), "nested FuncImpl.Merged");
            if check.tag() == p {
                return(Some =  get_variant_ptr(FuncImpl, check, p));
            };
        };
    };
    .None
} 

:: {
    H :: TrivialHasher;
    
    fn DerefHash($T: Type) void = {
        fn hash(hasher: *H, a: *T) void #inline = hasher.hash(a[]);
    }
    
    #redirect(Ty(*H, *u32), void) fn hash(h: *H, s: *LabelId) void;    AutoHash(TypeInfo, H); AutoEq(TypeInfo);
    DerefHash(*TypeInfo); DerefEq(*TypeInfo);
    enum(CallConv); DerefEq(CallConv);
    enum(VarType); DerefEq(VarType);
    
    fn hash(h: *H, s: *CallConv) void #redirect(Ty(*H, *i64), void);
    fn hash(h: *H, s: *VarType) void #redirect(Ty(*H, *i64), void);
    
    fn hash(h: *H, s: *Var) void = {
        h.hash(s.id&);
    }
    
    fn hash(h: *H, s: *Values) void = {
        b := s.bytes();
        h.hash(b&);
    }
};

fn bytes(self: *Values) Slice(u8) = {
    @match(self) {
        (fn Small(v) Slice(u8) => (ptr = ptr_cast_unchecked(i64, u8, v._0&), len = v._1.zext()));
        (fn Big(v) Slice(u8) => v.items());
    }
}

fn len(self: *Values) i64 = {
    @match(self) {
        (fn Small(v) i64 => { v._1.zext() });
        (fn Big(v) i64 => { v.len });
    }
}

fn var(self: *Binding) ?Var = {
    @match(self.name) {
        fn Var(v) => (Some = v);
        @default => .None;
    }
}

fn ne(a: Symbol, b: Symbol) bool #redirect(Ty(u32, u32), bool);

fn hash(i: *Var) i64 = {
    i := (@as(i64) i.id.zext());
    i&.hash()
}
fn eq(a: Var, b: Var) bool = a.id == b.id;
fn eq(a: *Var, b: *Var) bool = a[] == b[]; // TODO: this should be automatic, or == should always look for the ref version? or i should commit to rls like zig so it doesn't matter. 
fn hash(i: *Symbol) i64 = {
    i := (@as(i64) i[].id().zext());
    i&.hash()
}

fn contains_pointers(s: *TypeMeta) bool = s.contains_pointers;

fn jit_addr(v: *Values) i64 = {
    s := v.bytes();
    u8.int_from_ptr(s.ptr)
}

fn unwrap(self: Name) Symbol = {
    @match(self) {
        fn Var(v) => v.name;
        fn Ident(v) => v;
        @default => panic("Expected name!");
    }
}

// It makes me feel better to guess that they provided the fields in order before scanning. 
// The arrays are so short its not a measurable difference tho -- Sep 18
fn find_struct_field(f: *get_variant_type(TypeInfo, .Struct), name: Symbol, index_guess: i64) ?*Field = {
    field := index_guess;
    if field >= f.fields.len || f.fields[field].name != name { 
        miscompilation_if_you_inline_this := f.fields&.position(fn(f) => f.name == name); // :fucked // TODO: check if thats still true
        field = or miscompilation_if_you_inline_this {
            return(.None)
        };
    };
    (Some = f.fields.index(field))
}

fn log(v: *Var, pool: CompCtx) Str = 
    items(@format("%%%", pool.get_string(v.name), "%", v.id) temp());

fn unwrap_ty(self: *Binding) Type = {
    assert(self.ty&.is(.Finished), "type not ready!");
    self.ty.Finished
}

// :link_rename
fn check_link_rename(comp: CompCtx, base_import_name: Symbol, func: *Func, target: TargetEnv) Str = {
    if func.nullable_link_rename_func != 0 {
        out: List(u8) = list(temp());
        arg: LinkRenameArg = (
            target = target,
            out = out&,
            old_name = comp.get_string(base_import_name),
        );
        addr := rawptr_from_int(func.nullable_link_rename_func);
        addr := assume_types_fn(*LinkRenameArg, void, addr);
        addr(arg&);
        out.items()
    } else {
        comp.get_string(base_import_name)
    }
}

fn get_default(b: *Binding) ?*FatExpr = {
    e := b.default.expr&;
    ::enum(@type e.Poison);
    if e.is(.Poison) && e.Poison == .EmptyBindingValue {
        return(.None);
    };
    (Some = b.default&)
}

fn binding_missing_default()  FatExpr = (expr = (Poison = .EmptyBindingValue), ty = UnknownType, done = false, loc = Span.zeroed());

fn get_default(b: *Field) ?Var = {
    if(b.default.id == 0, => return(.None));
    (Some = b.default)
}

