// TODO: have first.fr pass vtable to #test if non-void argument. 

ResultType :: @tagged(
    Specific: Type,
    Returning: Type,
    None
);

OverloadSetData :: @struct(
    ready: RsVec(OverloadOption),
    name: Symbol,
    pending: RsVec(FuncId),
);

OverloadOption :: @struct(
    func: FuncId,
    arg: Type,
    ret: ?Type, // For #generic, we might not know without the args
    arity: u16,
);

fn compile_stmt(self: *SelfHosted, stmt: *FatStmt) Maybe(void) = {
    self.last_loc = stmt.loc;
    @match(stmt.stmt&) {
        fn Noop() => return(.Ok);
        fn Eval(expr) => return(self.compile_expr(expr, .None));
        fn DeclVar(f) => {
            assert(f.name.kind != .Const, "hit unhoisted constant");
            return(self.decl_var(f.name, f.ty&, f.value&))
        }
        fn Set(f) => {
            // TODO: or patterns in @match would be nice here. :lang
            tag := f.place.expr&.tag();
            // TODO: PrefixMacro is sketchy but makes []->.index work.
            if tag.eq(.PrefixMacro).or(tag == .GetVar).or(tag == .FieldAccess).or(tag == .Deref) {|
                @check(self.compile_place_expr(f.place&, .None, true)) return;
                @check(self.compile_expr(f.value&, f.place.ty.want())) return;
                if f.place.ty != f.value.ty {|
                    return(@err("tried to set % to %", self.log_type(f.place.ty), self.log_type(f.value.ty)));
                };
                // TODO: self.type_check_arg(f.place.ty, f.value.ty, "reassign var")?; /:type_check
                return(.Ok);
            };
            return(@err("Illegal place expression: %", tag))
        }
        @default => @panic("TODO: unhandled compile_stmt type %", stmt.stmt&.tag());
    };
    unreachable_hack(Maybe(void))
}

::opt_map(Type, Type);
fn compile_place_expr(self: *SelfHosted, place: *FatExpr, requested: ResultType, want_deref: bool) Maybe(void) = {
    loc := place.loc;
    @match(place.expr&) {
        fn GetVar(var) => {
            val_ty := self.scopes.get_var_type(var[]);
            val_ty := or val_ty {| 
                return(@err("var must be declared: %", var.log(self.pool)))
            };
            ptr_ty := self.ptr_type(val_ty);

            place[] = synthetic_ty((Addr = self.box(place[])), loc, ptr_ty);
            place.done = true;
            if want_deref {|
                @check(self.deref_one(place)) return;
                place.done = true;
            };
        }
        fn FieldAccess(f) => {
            // TODO: could lookup field and pass down requested
            // Note: compile_expr may have already walked the container because it has to check if its an enum/scope.
            @check(self.compile_place_expr(f.container, .None, false)) return;

            // :AutoDeref
            {
                raw   := self.raw_type(f.container.ty);
                inner := or self.unptr_ty(raw) {|
                    return(@err("PlaceExpr of FieldAccess should be ptr"))
                };
                inner = self.raw_type(inner);
                // Pointers never have fields, so the thing behind the pointer, shouldn't be a pointer.
                // This lets you write `self: *Self; self.name` instead of  `self: *Self; self[].name`.
                while => self.unptr_ty(inner) { next_inner | 
                    @check(self.deref_one(f.container)) return;
                    inner = self.raw_type(next_inner);
                };
            };
            (bytes, field_val_ty) := @check(self.field_access_expr(f.container, f.name)) return;
            field_ptr_ty := self.ptr_type(field_val_ty);
            @debug_assert(!f.container.expr&.is(.GetVar), "ICE: place expr can't be direct var access");
            e := self.box(f.container[]);
            if bytes == 0 {|
                place.expr = (Cast = e);
            } else {|
                place.expr = (PtrOffset = (
                    ptr = e,
                    bytes = bytes,
                    name = f.name,
                ));
            };
            place.done = true;
            if want_deref {|
                place.ty = field_ptr_ty;
                // Now we have the offset-ed ptr, add back the deref
                @check(self.deref_one(place)) return;

                // Don't set done again because you want to go around the main compile_expr another time so special load/store overloads get processed.
                // TODO: that shouldn't be true anymore
            } else {|
                // place.done = true;
                place.ty = field_ptr_ty;
            };
        }
        fn Deref(_) => {
            return(self.compile_deref_place(place, requested, want_deref));
        }
        fn GetNamed(n) => return(@err("Undeclared Identifier: %", self.pool.get(n[])));
        fn PrefixMacro(_) => {
            // TODO: this is sketchy but makes []->.index work.
            //       need to think about how requested/want_deref are handled
            @check(self.compile_expr(place, requested)) return;
            return(self.compile_place_expr(place, requested, want_deref));
        }
        @default => {
            if !place.ty.is_unknown() {|
                // TODO: pass in if we're currently trying to access a field so we can give a better error message if its on an int or something?
                return(@err("Place expression of type % expected pointer dereference.\n%", self.log_type(place.ty), place.log(self.pool)));
            };
            return(@err("TODO: other `place=e;` % %", place.log(self.pool), self.log_type(place.ty)));
        };
    };
    .Ok
}

fn compile_deref_place(self: *SelfHosted, place: *FatExpr, requested: ResultType, want_deref: bool) Maybe(void) = {
    @debug_assert(place.expr&.is(.Deref));
    arg := place.expr.Deref;
    // When you see a !deref, treat the expression as a pointer value.
    req := requested.specific().map(fn(r) => self.ptr_type(r));
    @check(self.compile_expr(arg, req.want())) return;
    if want_deref {|
        place.ty = or self.unptr_ty(arg.ty) {|
            return(@err("tried to deref non-pointer"))
        };
        place.done = arg.done;
    } else {|
        place[] = arg[];
    };
    .Ok
}

// :PlaceExpr
fn field_access_expr(self: *SelfHosted, container_ptr: *FatExpr, name: Symbol) Maybe(Ty(i64, Type)) #once = {
    container_ptr_ty := self.raw_type(container_ptr.ty);
    depth := self.ptr_depth(container_ptr_ty);
    if depth != 1 {|
        return(@err("index expr ptr must be one level of indirection. %", self.log_type(container_ptr_ty)));
    };
    container_ty := self.unptr_ty(container_ptr_ty).expect("ICE: we just checked its a pointer");

    raw_container_ty := self.raw_type(container_ty);
    or self.finish_layout(raw_container_ty) { (e: ParseErr) |
        return(Err = self.box(e))
    };
    @match(self.get_type(raw_container_ty)) {
        fn Struct(f) => {
            @debug_assert(f.layout_done);
            each f.fields { f | 
                if f.name == name {|
                    container_ptr.done = true;
                    return(Ok = (f.byte_offset, f.ty));
                };
            };
            return(@err("unknown name % on %", self.pool.get(name), self.log_type(container_ty)))
        }
        fn Tagged(f) => {
            each f.cases { f |
                if f._0 == name {|
                    return(Ok = (8, f._1));
                };
            };
            return(@err("unknown name % on %", self.pool.get(name), self.log_type(container_ty)))
        }
        @default => {
            return(@err("only structs/enums support field access (name: %) but found %", self.pool.get(name), self.log_type(container_ty)))
        };
    }
}

// TODO: have a different version of @check for something that can error but not yield? 
fn deref_one(self: *SelfHosted, ptr: *FatExpr) Maybe(void) = {
    raw   := self.raw_type(ptr.ty);  // TODO: why are we going through enums...? -- Jul 30
    inner := or self.unptr_ty(raw) {|
        return(@err("expected ptr for deref_one"))
    };
    
    @match(ptr.expr&) {
        fn Addr(arg) => {
            // this allows auto deref to work on let ptr vars.
            if arg.expr&.is(.GetVar) {|
                // raw var expr is not allowed, we always refer to variables through thier address.
                ptr[] = synthetic_ty((Deref = self.box(ptr[])), ptr.loc, inner);
            } else {|
                // Avoid reduntant (whatever)&[].
                ptr[] = arg[][];
                if ptr.ty.is_unknown() {|
                    ptr.ty = inner; // TODO: this shouldn't happen
                };
            };
        }
        @default => {
            ptr[] = synthetic_ty((Deref = self.box(ptr[])), ptr.loc, inner);
        };
    };
    .Ok
}

fn decl_var(self: *SelfHosted, name: Var, ty: *LazyType, value: *FatExpr) Maybe(void) #once = {
    @println("decl_var %", name&.log(self.pool)); // :debug
    @debug_assert(self.dispatch.enclosing_function.is_some(), "ICE: runtime vars must have an enclosing function");
    no_type := ty.is(.Infer);
    assert(no_type.or(ty.is(.Finished)), "TODO: self.infer_types_progress(ty)?;");
    self.last_loc = value.loc;
    @check(self.compile_expr(value, ty.want())) return;
    final_ty := value.ty;
    @debug_assert(!final_ty.is_unknown(), "if we didn't yield, we should know the type");
    if no_type {|
        // Since there was no type annotation, we don't need a type check. Whatever we got is the type of this variable now. 
        ty[] = (Finished = final_ty);
        self.finish_layout_deep(final_ty).unwrap();
    } else {|
        expected_ty := ty.unwrap();
        // TODO: :delay_layout
        //       Instead of doing this now, add it as an Action in the dispatch loop.
        //       We don't actually care about the field offsets yet, we just need them later for emitting bytecode. 
        //       This was one of the changes that inspired the sema rewrite.  -- Jul 25
        self.finish_layout_deep(expected_ty).unwrap();
        self.finish_layout_deep(final_ty).unwrap();
        // TODO: panic("TODO: self.type_check_arg(value, ty, \"var decl\")?;");
    };

    prev := self.scopes.get_var_type(name); 
    self.scopes.put_var_type(name, final_ty); // TODO: this returns is_new, i want to just assert that. we shouldn't be compiling more than once -- Jul 25
    // TODO: prev should always be none?? but its not a constant and seems to always be the same so its probablby not a super huge deal? -- Apr 23
    //       maybe its just cause im not zeroing the stmt and end up compiling multiple times. -- Apr 25
    @assert(prev.is_none().or(=> prev.unwrap() == final_ty));
    
    // TODO: :mark_stmt_done
    //       this function is called multiple times (if the containing block needs to yield). need to have a done flag on the fatstmt
    //       but thats easier to change once all the stuff is written in one language -- Jul 25
    .Ok
}

fn ensure_resolved_sign(self: *SelfHosted, fid: FuncId) Maybe(void) = {
    func := self.get_function(fid);
    if(func.get_flag(.ResolvedSign), => return(.Ok));
    res := self.resolve_sign(func);
    if res&.is_err() {|
        return(Err = self.box(res.Err));
    };
    func.set_flag(.ResolvedSign);
    .Ok
}

fn ensure_resolved_body(self: *SelfHosted, fid: FuncId) Maybe(void) = {
    @check(self.ensure_resolved_sign(fid)) return;
    func := self.get_function(fid);
    if(func.get_flag(.ResolvedBody), => return(.Ok));
    res := self.resolve_body(func);
    if res&.is_err() {|
        return(Err = self.box(res.Err));
    };
    func.set_flag(.ResolvedBody);
    .Ok
}

fn handle_compile_func_body(self: *SelfHosted, fid: FuncId) Maybe(void) #once = {
    @debug_assert(self.dispatch.function_in_progress&.get(fid.as_index()), "expected to do work on in progress function");
    self.ensure_resolved_body(fid);
    func := self.get_function(fid);
    if(func.get_flag(.EnsuredCompiled), => return(.Ok));
    assert(!func.get_flag(.MayHaveAquiredCaptures), "closures need to be specialized");
    assert(!func.get_flag(.AnyConstArgs), "const args need to be specialized");
    
    // Before we can do the body, we really need to know the argument types, 
    // and it would be nice to know the return type too but that's less important. 
    @check(self.infer_arguments(fid)) return;
    
    // you need to only do this once so args are unique but we might yield below. 
    // you can't yield in this block! MadeVarsForRuntimeArgs needs to be atomic!
    // TODO: alternativly, if i trusted myself, you could just say its fine when the arg is already there, 
    //       because surely we put it there ourselves last time around. 
    //       but for now i think this is a valuable sanity check that renumbering went well.  -- Jul 30
    if !func.get_flag(.MadeVarsForRuntimeArgs) {|
        each func.arg.bindings { b | 
            // TODO: probably want to change this so you can do as much compiling as possible before expanding templates.
            @debug_assert(b.kind != .Const, "ICE: Tried to emit before binding const args.");
            @if_let(b.name) fn Var(name) => {
                @debug_assert(b.kind == name.kind);
                is_new := self.scopes.put_var_type(name, b.ty&.unwrap());
                @println("bind %", name&.log(self.pool));
                if(!is_new, => return(@err("overwrite arg? %", name&.log(self.pool))));
            };
        };
        func.set_flag(.MadeVarsForRuntimeArgs) ;
    };
    
    @match(func.body&) {
        fn Normal(expr) => {
            old_func := self.dispatch.enclosing_function;
            self.dispatch.enclosing_function = (Some = fid);
            
            if func.return_var { return_var |
                // TODO: this means you cant early return from non-block functions but the error message will be useless -- Jul 9 
                @if_let(expr.expr&) fn Block(f) => {
                    if f.ret_label.is_none() {|  // we might have already tried to compile this function. 
                        ret: LabelId = from_index(self.dispatch.next_label);
                        self.dispatch.next_label += 1;
                        label_ty := LabelId; // :get_or_create_type
                        if func.finished_ret { ret_ty | 
                            label_ty = self.intern_type(Label = ret_ty);
                        };
                        val := self.to_values(LabelId, ret);
                        @check(self.save_const_values(return_var, val, label_ty, func.loc)) return;
                        f.ret_label = (Some = ret);
                    };
                };
            };

            @check(self.compile_expr(expr, func.finished_ret.want())) return;
            self.dispatch.enclosing_function = old_func;
            if func.ret&.is(.Infer) {|
                func.finished_ret = (Some = expr.ty);
            };
        }
        fn Intrinsic(op) => ();
        fn ComptimeAddr(ptr) => {
            panic("TODO: ComptimeAddr");
        }
        @default => panic("TODO: unhandled function body type");
    };
    @println("body compiled: %", fid.as_index());
    func.set_flag(.EnsuredCompiled);
    .Ok
}

::tagged(ResultType);
fn compile_expr(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) = {
    self.last_loc = expr.loc;
    if expr.done {|
        assert(expr.ty != UnknownType, "done but unknown type");
        return(.Ok);
    };
    self.dispatch.active_stack.push(expr = expr, requested = requested);
    
    @match(expr.expr&) {
        fn Poison() => {
            return(@err("Poison expression"));
        }
        fn Value(f) => {
            if(expr.ty == UnknownType, => return(@err("ICE: Value expression must have known type")));
            if !f.coerced {|
                @if_let(requested) fn Specific(ty) => {
                    if expr.ty != ty {|
                        panic("TODO: coerce const");
                    };
                };
            };
            expr.done = true;
        }
        fn Call() => {
            @check(self.compile_call(expr, requested)) return;
        }
        fn Block(f) => {
            if !f.hoisted_constants {|
                @check(self.hoist_constants(f.body.items())) return;
                f.hoisted_constants = true;
            };
            each f.body { stmt | 
                @check(self.compile_stmt(stmt)) return;
            };
            @check(self.compile_expr(f.result, requested)) return;
            expr.ty = f.result.ty;
        }
        fn Tuple(parts) => {
            types: List(Type) = list(parts.len, temp()); 
            each parts { expr | 
                if !expr.done {|
                    // TODO: req_part := panic("TODO: pass through tuple_types if known requested");
                    req_part := ResultType.None;
                    @check(self.compile_expr(expr, req_part)) return;
                };
                types&.push(expr.ty);
            };
            if expr.ty.is_unknown() {|
                expr.ty = self.tuple_of(types.items());
                self.finish_layout_deep(expr.ty);
            };  // TODO: else :type_check
        }
        fn PrefixMacro() => {
            @check(self.compile_prefix_macro(expr)) return;
        }
        fn GetVar(var) => return(self.compile_get_var(expr, requested));
        fn GetNamed(n) => return(@err("Undeclared Identifier: %", self.pool.get(n[])));
        fn String() => {
            // This is only different from a Value node because the 'Str' is not a builtin so the parser is unable to create it.
            byte := self.get_or_create_type(u8);
            expr.ty = @check(self.create_slice_type(byte)) return;
            panic("TODO: self.set_literal(expr, self.pool.get(i)");
            expr.done = true;
        }
        fn ConstEval(inner) => {
            // :PushConstFnCtx // TODO
            // We need to track that any callees of this expression are not runtime callees!
            // self.wip_stack.push((None, ExecStyle::Jit)); // this is what the old version did
            // but maybe we're trying to track that in the dispatch thing now. 
            // i guess expression tasks need to have a containing function context? 
            @check(self.compile_expr(inner[], requested)) return; // TODO: this is probably wrong! ^ -- Jul 30
            // TODO: its a bit silly that i have to specifiy the type since the first thing it does is compile it
            value := @check(self.immediate_eval_expr(inner[], inner.ty)) return;
            expr.set(value, inner.ty);
        }
        fn Deref(inner) => @check(self.compile_deref_place(expr, requested, true)) return;
        fn Addr(inner) => {
            // Note: the old version had special handling for GetVar here to avoid loops but this seems fine... - Jul 30
            @check(self.compile_place_expr(inner[], requested, false)) return;
            expr[] = inner[][];
        }
        fn PtrOffset(_) => return(@err("ICE: PtrOffset should be done=true"));
        fn GetParsed() => return(@err("ICE: GetParsed is handled by scope.fr"));
        fn Closure(func) => {
            fid := self.add_function(func[][]);
            fid_value := self.to_values(FuncId, fid);
            expr.set(fid_value, FuncId); // :get_or_create_type
            func := self.get_function(fid);
            self.update_function_metadata(func);
            if !requested&.is(.None) {|
                @check(self.coerce_const_expr(expr, requested)) return;
            };
        }
        @default => @panic("TODO: unhandled node type %: %", expr.expr&.tag(), expr.log(self.pool));
    };
    self.dispatch.active_stack.pop();
    @debug_assert(!expr.ty.is_unknown(), "Unknown type for %", expr.log(self.pool));
    .Ok
}

fn compile_call(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) #once = {
    @debug_assert(expr.expr&.is(.Call));
    f := expr.expr.Call.f;
    arg := expr.expr.Call.arg;
    req_fn: ResultType = @match(requested) {
        fn Specific(t) => (Returning = t);
        @default => .None;
    };
    
    @check(self.compile_expr(f, req_fn)) return;
    
    ::if(ResultType);
    req_arg: ResultType = if(arg.ty == UnknownType, => .None, => (Specific = arg.ty));
    @check(self.compile_expr(arg, req_arg)) return;
    
    if f.ty == OverloadSet {|  // :get_or_create_type
        panic("TODO: OverloadSet");
    };
    
    if f.ty == FuncId {|  // :get_or_create_type
        return(self.call_direct(expr));
    };
    
    if f.ty == LabelId {|  // :get_or_create_type
        panic("TODO: early return before ret type infered (could try more aggressivly in handle_compile_body)");
    };
    
    @match(self.get_type(f.ty)) {
        fn FnPtr(it) => {
            expr.ty = it.ty.ret;
        }
        fn Fn(it) => return(self.call_direct(expr));
        fn Label(it) => {
            if arg.ty != it[] {|
                return(@err("early return type mismatch. TODO: better type checking"));
            };
            expr.ty = Never; // :get_or_create_type
            expr.done = arg.done; 
        }
        @default => return(@err("not callable %", f.log(self.pool)));
    };
    
    .Ok
}

// TODO: check function ret type against requested
fn call_direct(self: *SelfHosted, expr: *FatExpr) Maybe(void) = {
    f_expr := expr.expr.Call.f;
    arg_expr := expr.expr.Call.arg;
    fid := @check(self.immediate_eval_expr(f_expr, f_expr.ty)) return;
    fid := FuncId.assume_cast(fid&)[];
    func := self.get_function(fid);
    
    assert(func.cc.expect("known cc") != .Inline 
        && !func.get_flag(.Generic) && !func.get_flag(.AnyConstArgs) 
        && !func.get_flag(.MayHaveAquiredCaptures) && !func.get_flag(.UnsafeNoopCast)
        && !func.get_flag(.TryConstantFold)
    , "Not Yet Implemented: unhandled complex call");
    
    arg_ty := @check(self.infer_arguments(fid)) return;
    ret_ty := @check(self.infer_return(fid))    return;
    
    // TODO: better type checking
    if arg_ty != arg_expr.ty {|
        return(@err("arg type mismatch"));
    };
    
    if self.dispatch.enclosing_function { current |
        current := self.get_function(current);
        current.callees&.add_unique(fid, self.get_alloc());
        self.aarch64&.extend_blanks(fid);
        println("added callee");
    };
    
    expr.done = f_expr.done && arg_expr.done;
    expr.ty = ret_ty;
    
    if f_expr.ty == FuncId {|  // :get_or_create_type
        f_expr.ty = self.intern_type(Fn = (arg = arg_ty, ret = ret_ty, arity = func.arg.bindings.len.trunc()));
    };
    
    if func.get_flag(.Once) {|
        // TODO: better error message. should show the previous usage. 
        if(func.get_flag(.OnceConsumed), => return(@err("tried to call once function again")));
        func.set_flag(.OnceConsumed);
        assert(expr.done, "ICE: if we applied #once, the expression really needs to be .done");
    };
    
    .Ok
}

fn infer_type(self: *SelfHosted, b: *LazyType) Maybe(?Type) = {
    @match(b) {
        fn PendingEval(e) => {
            ty := @check(self.immediate_eval_expr(e, Type)) return; // :get_or_create_type
            ty := Type.assume_cast(ty&)[]; 
            b[] = (Finished = ty);
            return(Ok = (Some = ty))
        }
        fn Finished(ty) => return(Ok = (Some = ty[])); // cool, we're done. 
        fn EvilUninit() => panic("ICE: nothing creates this: eviluninit binding"); 
        fn Returning(_) => return(@err("ICE: tried to infer on LazyType.Returning... figure out what to do about that..."));
        fn Infer() => return(Ok = .None);
    }
}

fn infer_arguments(self: *SelfHosted, fid: FuncId) Maybe(Type) = {
    func := self.get_function(fid);
    if(func.finished_arg, fn(ty) => return(Ok = ty));
    @check(self.ensure_resolved_sign(fid)) return;
    
    types: List(Type) = list(func.arg.bindings.len, temp());
    each func.arg.bindings { b |
        ty := or @check(self.infer_type(b.ty&)) return {|
            // TODO: really thats not what you want for closures tho... 
            return(@err("function arguments must have type annotation (cannot be inferred)"))
        };
        types&.push(ty);
    };
    ty := self.tuple_of(types.items());
    func.finished_arg = (Some = ty);
    (Ok = ty)
}

fn infer_return(self: *SelfHosted, fid: FuncId) Maybe(Type) = {
    func := self.get_function(fid);
    if(func.finished_ret, fn(ty) => return(Ok = ty));
    @check(self.ensure_resolved_sign(fid)) return;
    
    ty := or @check(self.infer_type(func.ret&)) return {|
        // Infer is a valid return type. To deal with that, we just compile the body, and that will set the finished_ret for us. 
        self.dispatch.function_in_progress&.set(fid.as_index());
        return(Suspend = self.wait_for(CompileBody = fid))
    };
    func.finished_ret = (Some = ty);
    (Ok = ty)
}

fn compile_prefix_macro(self: *SelfHosted, expr: *FatExpr) Maybe(void) #once = {
    // TODO: Bring back tag checks so i don't have to be paranoid!!
    //       this annoys be enough that im tempted to go back to inlining all of these. 
    //       tho maybe #once is reassuring enough. think about it. -- Jul 22
    @debug_assert(expr.expr&.is(.PrefixMacro)); 
    invocation := expr.expr.PrefixMacro&;
    fat_expr_type := or self.env.fat_expr_type {|
        return(self.early_builtin_prefix_macro(expr))
    };
    
    panic("TODO: call user macros");
    .Ok
}

// If we're early in bootstrapping and haven't compiled the FatExpr type yet, so some special handling.
fn early_builtin_prefix_macro(self: *SelfHosted, expr: *FatExpr) Maybe(void) #once = {
    invocation := expr.expr.PrefixMacro&;
    if !invocation.handler.expr&.is(.GetVar) {|
        return(@err("macro calls must be GetVar while bootstrapping. tried to run something too compilicated too soon: %", invocation.handler.log(self.pool)));
    };
    
    name := invocation.handler.expr.GetVar.name;
    @switch(name) {
        @case(Flag.builtin.ident()) => {
            if !invocation.arg.expr&.is(.String) {|
                return(@err("@builtin arg must be String literal"));
            };
            builtin_name := invocation.arg.expr.String;
            @println("called builtin %", self.pool.get(builtin_name));
            builtin_type :: fn(T: Type) void => {
                ptr := T;  // :get_or_create_type
                val := ptr_cast_unchecked(Type, u32, ptr&)[];
                expr.set((Small = (val.zext(), 4)), Type);  // :get_or_create_type
            };
            // These could call :get_or_create_type but it doesn't matter for now because these are hardcoded
            @switch(builtin_name) {
                @case(Flag.i64.ident())         => builtin_type(i64);
                @case(Flag.bool.ident())        => builtin_type(bool);
                @case(Flag.OverloadSet.ident()) => builtin_type(OverloadSet);
                @case(Flag.Scope.ident())       => builtin_type(Scope);
                @case(Flag.FuncId.ident())      => builtin_type(FuncId);
                @case(Flag.LabelId.ident())     => builtin_type(LabelId);
                @case(Flag.Symbol.ident())      => builtin_type(Symbol);
                @case(Flag.void.ident())        => builtin_type(void);
                @case(Flag.true.ident())        => expr.set((Small = (1, 1)), bool);
                @case(Flag.false.ident())       => expr.set((Small = (0, 1)), bool);
                @case(Flag.compiler_debug_assert_eq_i64.ident()) => {
                    my_assert_eq: rawptr : fn(a: i64, b: i64) i64 = {
                        @println("[my_assert_eq] % vs %", a, b);
                        assert_eq(a, b);
                        a
                    };
                    ty := self.tuple_of(@slice(i64, i64));
                    ty := self.intern_type(FnPtr = (ty = (arg = ty, ret = i64, arity = 2), cc = .CCallReg));
                    expr.set((Small = (my_assert_eq.int_from_rawptr(), 8)), ty);
                };
                @default => {
                    return(@err("unknown @builtin '%'.", self.pool.get(builtin_name)));
                };
            };
        };
        @default => {
            return(@err("tried to call non-builtin macro '%' calls while bootstrapping.", self.pool.get(name)));
        };
    };
    
    .Ok
}

// - you want macros to be able to create new constant declarations in macro expansions and const arg functions.
// - for now constants are always stored globally and restricted visibility is just handled by scope resolution.
// So we delay taking constants until you try to compile the expression that contains them.
// Also, to be order independent, we don't actually evaluate or type-check them yet, that's done lazily the first time they're referenced. 
// TODO: the old compiler did #when here, but I think its better to delay until we know we care and can hope more stuff is ready. 
fn hoist_constants(self: *SelfHosted, body: []FatStmt) Maybe(void) #once = {
    each body { stmt |
        @match(stmt.stmt&) {
            fn DeclFunc(func) => {
                @debug_assert(func[].get_flag(.NotEvilUninit));
                fid := self.add_function(func[][]);
                stmt.stmt = .Noop;
                func := self.get_function(fid);
                overload_out: ?OverloadSet = .None;
        
                // I thought i dont have to add to constants here because we'll find it on the first call when resolving overloads.
                // But it does need to have an empty entry in the overload pool because that allows it to be closed over so later stuff can find it and share if they compile it.
                if func.var_name& { var |
                    // TODO: allow function name to be any expression that resolves to an OverloadSet so you can overload something in a module with dot syntax.
                    // TODO: distinguish between overload sets that you add to and those that you re-export
                    @debug_assert(!func.get_flag(.ResolvedSign));
                    @debug_assert(!func.get_flag(.ResolvedBody));
                    if self.is_empty_constant(var[]) {|
                        // We're the first to reference this overload set so create it. 
                        i: OverloadSet = from_index(self.dispatch.overloads.len);
                        self.dispatch.overloads&.push(
                            ready = empty(),
                            name = var.name,
                            pending = fid.single(self.get_alloc()).rs(),
                        );
                        os_value := self.to_values(OverloadSet, i);
                        @check(self.save_const_values(var[], os_value, OverloadSet, func.loc)) return;  // :get_or_create_type
                        overload_out = (Some = i);
                    } else {|
                        overloads := @check(self.find_const(var[], OverloadSet.want())) return;  // :get_or_create_type
                        i := OverloadSet.assume_cast(overloads._0&)[];
                        os := self.dispatch.overloads&.nested_index(i.as_index());
                        os.pending&.push(fid, self.get_alloc());
                        overload_out = (Some = i);
                    };
                };
                
                self.update_function_metadata(func);
            }
            fn DeclVar(f) => if f.name.kind == .Const {|
                self.scopes.put_constant(f.name, f.value, f.ty);
                stmt.stmt = .Noop;
            };
            @default => ();
        }
    };
    .Ok
}

fn update_function_metadata(self: *SelfHosted, func: *Func) void = {
    any_const_args :: fn(self: *Func) bool = {
        each self.arg.bindings { b |
            if(b.kind == .Const, => return(true));
        };
        false
    };
    if func.any_const_args() {|
        func.set_flag(.AnyConstArgs);
    };

    each func.annotations { tag | 
        @switch(tag.name) {
            @case(Flag.fold.ident())     => func.set_flag(.TryConstantFold);
            @case(Flag.noinline.ident()) => func.set_flag(.NoInline);
            // TODO: generic+unsafe_noop_cast are done in scope for old sema but i want to move them here. -- Jul 30
            @case(Flag.generic.ident())  => func.set_flag(.Generic);
            @case(Flag.unsafe_noop_cast.ident()) => func.set_flag(.UnsafeNoopCast);
            @case(Flag.redirect.ident()) => {
                // TODO: pass in ?overloadsetid and do this stuff -- Jul 30
                // // dman it bnoarow chekcser
                //let os = self.as_literal(out.1.unwrap(), loc)?;
                //if let Some(types) = self.program[id].get_tag_mut(Flag::Redirect) {
                //    let Expr::Tuple(parts) = &mut types.args.as_mut().unwrap().expr else {
                //        err!("bad",)
                //    };
                //    parts.push(os);
                //}
            };
            // TODO: actually im not sure if its better to do this later...
            //       it would be nice to do only one pass over the annotations 
            //       but it would also be nice to do absolutely no work if you never try to call the function. 
            @case(Flag.comptime_addr.ident()) => {
                panic("TODO: hoist comptime addr into body right now?");
            };
            @case(Flag.intrinsic.ident()) => {
                panic("TODO: hoist intrinsic into body right now?");
            };
            @case(Flag.inline.ident()) => {
                // TODO: error on conflicting annotations. 
                func.cc = (Some = .Inline);
            };
            @case(Flag.ct.ident()) => {
                // TODO: error on conflicting annotations. 
                func.cc = (Some = .CCallRegCt);
            };
            @default => ();
        };
    };
    
    if func.cc.is_none() {|
        func.cc = (Some = .CCallReg);
    };
}

::if(Maybe(void));
::if_opt(Type, Maybe(void));
fn compile_get_var(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) #once = {
    @debug_assert(expr.expr&.is(.GetVar));
    var := expr.expr.GetVar;
    if var.kind == .Const {|
        (value, ty) := @check(self.find_const(var, requested)) return;
        expr.set(value, ty);
        @check(self.coerce_const_expr(expr, requested)) return;
        .Ok
    } else {|
        if self.scopes.get_var_type(var) { ty | 
            expr.ty = ty;
            expr.done = true;
            // Reading a variable. Convert it to `var&[]` so compiling it checks for smaller loads (u8, etc).
            ptr_ty := self.ptr_type(ty);
            expr[] = synthetic_ty((Addr = self.box(expr[])), expr.loc, ptr_ty);
            expr.done = true;
            // Note: not using deref_one, because don't want to just remove the ref, we want raw variable expressions to not exist. kinda HACK
            expr[] = synthetic_ty((Deref = self.box(expr[])), expr.loc, ty);
            expr.done = true;
            .Ok
        } else {|
            // For now runtime vars are always declared in order so we always know thier type.
            // This might change to allow peeking into return-ed expressions when infering closure return type? -- Jul 15
            @err("Unknown type for runtime var %", self.pool.get(var.name))
        }
    }
}

// TODO: this is kinda weird. `fn` statements create an overload set or add to an existing one. 
fn is_empty_constant(self: *SelfHosted, name: Var) bool #once = {
    var := self.scopes.get_constant(name);
    var := var.expect("constant should always be known (even if its Poison)");
    var._0.expr&.is(.Poison)
}

// Passing in the requested type here feels a bit weird, but I think it will make anon-functions less painful. 
fn find_const(self: *SelfHosted, name: Var, requested: ResultType) Maybe(Ty(Values, Type)) = {
    // If someone else is already trying to compile this, we don't want to fight over it. 
    if self.dispatch.const_var_in_progress&.get(name.id.zext()) {|
        return(Suspend = self.wait_for(EvalConstant = (name = name, requested = requested)));
    };
    
    var := self.scopes.get_constant(name);
    var := var.expect("constant should always be known (even if its Poison)");
    
    // If we've compiled this before, great.
    //     We can't coerce_constant here because we don't have a unique expression node to stick changes into if needed. 
    //     (need to change the expression to create function pointers because they might not be compiled yet)
    @if_let(var._0.expr&) fn Value(f) => {
        return(Ok = (f.bytes&.clone(self.get_alloc()), var._0.ty));
    };
    
    self.dispatch.const_var_in_progress&.set(name.id.zext());
    
    // TODO: -- Jul 21
    // its sad to always yield here because _most_ of the time you could just do it now and it would be fine.
    // so an easy optimisation might be just trying now, if it wasn't already const_var_in_progress so we know nobody else is working on it. 
    // but since any _could_ yield, its a bug if we can't compile with _everything_ yielding,
    // so at least keep a flag to toggle this behaviour? 
    
    (Suspend = self.wait_for(EvalConstant = (name = name, requested = requested)))
}

fn handle_declare_constant(self: *SelfHosted, name: Var, ty: *LazyType, value: *FatExpr) Maybe(void) #once = {
    @debug_assert(self.dispatch.enclosing_function.is_none(), "ICE: handle_declare_constant should have no enclosing function");
    
    // TODO: do the @rec and type checking stuff from the rust version. 
    @check(self.compile_expr(value, .None)) return;
    if value.ty == UnknownType {|
        return(@err("TODO: needed type hint for %", self.pool.get(name.name)));
    };
    if !value.expr&.is(.Value) {|
        val := @check(self.immediate_eval_expr(value, value.ty)) return;
        value.set(val, value.ty);
    };
    .Ok
}

fn save_const_values(self: *SelfHosted, name: Var, value: Values, final_ty: Type, loc: Span) Maybe(void) = {
    self.save_const(name, (Value = (bytes = value, coerced = false)), final_ty, loc)
}

fn save_const(self: *SelfHosted, name: Var, val_expr: Expr, final_ty: Type, loc: Span) Maybe(void) #once = {
    // TODO: do i have to check if someone is already working on this constant? -- Jul 30
    val := self.scopes.get_constant(name);
    // TODO: the old one had a case if its none for renumbering during specialization, 
    //       but i think i want to add those sooner? -- Jul 30
    val := val.expect("constant should always be known (even if its Poison) (?)");
    
    if val._1&.is(.Finished) {|
        return(@err("tried to re-save constant %", name&.log(self.pool)));
    };
    if !val._0.expr&.is(.Poison) {|
        return(@err("tried to stomp constant %", name&.log(self.pool)));
    };
    
    val._0.expr = val_expr;
    val._0.ty = final_ty;
    val._1 = (Finished = final_ty);
    .Ok
}

fn coerce_const_expr(self: *SelfHosted, expr: *FatExpr, req: ResultType) Maybe(void) = {
    @debug_assert(expr.expr&.is(.Value), "tried to coerce non-value expr");
    
    if req.specific() { req | 
        if expr.ty != req {|
            @assert(!expr.expr.Value.coerced, "const mismatch. % vs % but already coerced", self.log_type(expr.ty), self.log_type(req));
            
            expr.expr.Value.coerced = true;
            expr.ty = req;
            panic("TODO: coerce constant (might be an actual type error)");
        };
    };
    .Ok
}

fn immediate_eval_expr(self: *SelfHosted, expr: *FatExpr, ret_ty: Type) Maybe(Values) = {
    old_func := self.dispatch.enclosing_function;
    self.dispatch.enclosing_function = .None;
    ::?Values;
    if self.check_quick_eval(expr, ret_ty) { val |
        self.dispatch.enclosing_function = old_func;
        return(Ok = val);
    };
    
    // TODO: you need to be on a new stack for this.
    req: ResultType = (Specific = ret_ty);
    @check(self.compile_expr(expr, req)) return;
    if self.check_quick_eval(expr, ret_ty) { val |
        self.dispatch.enclosing_function = old_func;
        return(Ok = val);
    };
    
    self.codemap.show_error_line(expr.loc);
    @panic("TODO: immediate_eval_expr %", expr.log(self.pool))
}

fn check_quick_eval(self: *SelfHosted, expr: *FatExpr, ret_ty: Type) ?Values = {
    @match(expr.expr&) {
        fn Value(f) => (Some = f.bytes&.clone(self.get_alloc()));
        fn Block(it) => {
            if it.body.is_empty() {|
                return(self.check_quick_eval(it.result, ret_ty));
            };
            .None
        }
        fn Tuple(parts) => {
            all: List(u8) = list(self.get_alloc());
            each parts { part |
                // TODO: tuple_types
                val := or self.check_quick_eval(part, part.ty) {|
                    return(.None)
                };
                all&.push_all(val&.bytes());
            };
            (Some = (Big = all.rs()))
        }
        fn Call(it) => {
            if it.f.expr&.is(.Value) {|
                @if_let(self.get_type(it.f.ty)) fn FnPtr(f) => {
                    if self.check_quick_eval(it.arg, f.ty.arg) { arg_value |
                        f_ptr := i64.assume_cast(it.f.expr.Value.bytes&)[];
                        // SAFETY: we're passing comp_ctx=false so it won't try to use the pointer as a real CompilerRs.
                        evil_hack := self;
                        evil_hack := self&;
                        self.finish_layout_deep(it.f.ty);
                        res := evil_hack&.call_dynamic_values(f_ptr, f.ty&, arg_value&.bytes(), false);
                        @match(res) {
                            fn Ok(res) => {
                                expr.set(res&.clone(self.get_alloc()), f.ty.ret);
                                return(Some = res);
                            }
                            fn Err(e) => (); // TODO: don't just swollow errors
                        }
                    };
                };
            };
            .None
        }
        @default => .None;
    }
}

fn create_slice_type(self: *SelfHosted, inner: Type) Maybe(Type) = {
    panic("TODO: create_slice_type")
}
