// the compiler of theseus 

// TODO: resolve lazily because some things don't care, 
//       like @enum(a, b, c) just treats the expressions as identifiers. 
//       we have to keep the scope info around forever anyway, if it was done here, 
//       we wouldn't traverse the tree twice. but then even more redundant work when cloning for generics? 

ResultType :: @rec @tagged(
    Specific: Type,
    Returning: Type,
    Tuple: []ResultType,  // temporary storage! don't hold across yield points. 
    None
);

OverloadSetData :: @struct(
    ready: RsVec(OverloadOption),
    name: Symbol,
    pending: RsVec(FuncId),
);

OverloadOption :: @struct(
    func: FuncId,
    args: []ResultType,
    ret: ?Type, // For #generic, we might not know without the args
);

fn log_event(fmt_args: FatExpr, compiler: FatExpr) FatExpr #macro = {
    if DEBUG_SPAM_LOG {
        return(println(fmt_args));
    };
    @if(ENABLE_LOGGING_CALLBACKS, @{
        c := @[compiler];
        has_driver_handler := !c.env.driver_vtable_ptr.is_null(); // TODO: garbage
        if has_driver_handler {
            vtable := ExportVTable.ptr_from_raw(c.env.driver_vtable_ptr);
            if vtable.log_event { callback | 
                legacy := c.stable_compiler_context();
                msg := (@format(@[fmt_args]) temp()).items();
                event: CompilerLogEvent = (Msg = msg);
                callback(c.env.driver_vtable_user_data, legacy, event&);
            };
        };
    }, @{ 1 + 1; })
}

fn compile_stmt(self: *SelfHosted, stmt: *FatStmt) Maybe(bool) = {
    self.last_loc = stmt.loc;
    @match(stmt.stmt&) {
        fn Noop() => (Ok = true);
        fn Eval(expr) => {
            @check(self.compile_expr(expr, .None)) return;
            (Ok = expr.done)
        }
        fn DeclVar(f) => {
            assert(f.name.kind != .Const, "hit unhoisted constant");
            @check(self.decl_var(f.name, f.ty&, f.value&)) return;
            (Ok = f.value.done)
        }
        fn Set(f) => {
            // TODO: or patterns in @match would be nice here. :lang
            tag := f.place.expr&.tag();
            // TODO: PrefixMacro is sketchy but makes []->.index work.
            if tag.eq(.PrefixMacro).or(tag == .GetVar).or(tag == .FieldAccess).or(tag == .Deref).or(tag == .Block) {
                @check(self.compile_place_expr(f.place&, .None, true)) return;
                @check(self.compile_expr(f.value&, f.place.ty.want())) return;
                if f.place.ty != f.value.ty {
                    return(@err("tried to set % <- % (%)", self.log_type(f.place.ty), self.log_type(f.value.ty), f.value&.log(self.pool)));
                };
                // TODO: self.type_check_arg(f.place.ty, f.value.ty, "reassign var")?; /:type_check
                return(Ok = f.value.done && f.place.done);
            };
            @err("Illegal place expression: %", tag)
        }
        fn DeclVarPattern(f) => self.decl_var_pattern(stmt);
        @default => @panic("TODO: unhandled compile_stmt type %", stmt.log(self.pool));
    }
}

fn decl_var_pattern(self: *SelfHosted, stmt: *FatStmt) Maybe(bool) #once = {
    @debug_assert(stmt.stmt&.is(.DeclVarPattern));
    bindings, value := (stmt.stmt.DeclVarPattern.binding.bindings&, stmt.stmt.DeclVarPattern.value&);
    if value.is_raw_unit() {
        // TODO: typecheck the pattern! this was fine a long time ago when this node was only made by closures. 
        stmt.stmt = .Noop;
        return(Ok = true);
    };
    
    if bindings.len == 1 {
        b := bindings[0]&;
        if(b.kind == .Const, => return(@err("unreachable? destructure single arg must be closure but const args should already be handled")));
        if b.var() { name |
            // TODO: could reduce the ast node but it doesn't matter. 
            @check(self.decl_var(name, b.ty&, value)) return;
            return(Ok = value.done);
        };
        // match branch that doesn't specify an argument gets here. (because parser puts in fake Binding with name=None).
        // just to be safe, still keep the expression in case it somehow happens in a different situation and has side effects.
        stmt.stmt = (Eval = value[]);
        @check(self.compile_expr(stmt.stmt.Eval&, .None)) return;
        return(Ok = stmt.stmt.Eval.done);
    };
    
    // So its not a tuple, we don't know how to destructure it (emit_bc does), but we can still type check it. 
    // Even if it was a tuple, all we'd do differently is pass in the ResultTypes seperatly, but now we can just do that for any expression. 
    // If i was inspired this could grow a speical case for tuples like the old one had to avoid allocating the lists,
    // but temp() is cheap so its probably fine.  -- Aug 1
    
    result_types: List(ResultType) = list(bindings.len, temp());
    each bindings { b | 
        if(b.kind == .Const, => return(@err("TODO: destructure with constants")));
        request := ResultType.None; 
        if @check(self.infer_type(b.ty&)) return { known |
            request = (Specific = known);
        };
        result_types&.push(request);
    };
    
    @check(self.compile_expr(value, (Tuple = result_types.items()))) return; 
    types := or self.tuple_types(value.ty) {
        return(@err("destructure expected tuple type"))
    };
    if(types.len != bindings.len, => return(@err("destructuring arity mismatch expected % but found %", bindings.len, types.len)));
    
    enumerate bindings { i, b |
        if b.var() { name | 
            prev := self.scopes.get_var_type(name); 
            self.scopes.put_var_type(name, types[i]);
            @assert(prev.is_none().or(=> prev.unwrap() == types[i]));
        };
        // An inlined closure might have had a polymorphic parameter, but emit_bc expects known types.
        if b.ty&.is(.Infer) {
            b.ty = (Finished = types[i]);
        };
    };
    
    // TODO: :mark_stmt_done 

    (Ok = value.done)
}

::opt_map(Type, Type);
fn compile_place_expr(self: *SelfHosted, place: *FatExpr, requested: ResultType, want_deref: bool) Maybe(void) = {
    loc := place.loc;
    self.last_loc = place.loc;
    @match(place.expr&) {
        fn Block(f) => {
            // TODO: the old version didn't have to do this... 
            if f.body.is_empty() && f.ret_label.is_none() {
                place[] = f.result[]; // Not required but makes debugging easier cause there's less stuff.
                return(self.compile_place_expr(place, requested, want_deref));
            };
            return(@err("a block cannot be a place expression (for spite reasons, not technical ones)"));
        }
        fn Cast(arg) => {
            return(self.compile_place_expr(arg[], requested, want_deref));
        }
        fn GetVar(var) => {
            val_ty := self.scopes.get_var_type(var[]);
            val_ty := or val_ty {| 
                return(@err("var must be declared: %", var.log(self.pool)))
            };
            ptr_ty := self.ptr_type(val_ty);

            place[] = synthetic_ty((Addr = self.box(place[])), loc, ptr_ty);
            place.done = true;
            if want_deref {
                @check(self.deref_one(place)) return;
                place.done = true;
            };
        }
        fn FieldAccess(f) => {
            // TODO: could lookup field and pass down requested
            // Note: compile_expr may have already walked the container because it has to check if its an enum/scope.
            @check(self.compile_place_expr(f.container, .None, false)) return;
            done := f.container.done;

            // :AutoDeref
            {
                raw   := self.raw_type(f.container.ty);
                inner := or self.unptr_ty(raw) {
                    return(@err("PlaceExpr of FieldAccess should be ptr"))
                };
                inner = self.raw_type(inner);
                // Pointers never have fields, so the thing behind the pointer, shouldn't be a pointer.
                // This lets you write `self: *Self; self.name` instead of  `self: *Self; self[].name`.
                while => self.unptr_ty(inner) { next_inner | 
                    @check(self.deref_one(f.container)) return;
                    inner = self.raw_type(next_inner);
                };
            };
            bytes, field_val_ty := @check(self.field_access_expr(f.container, f.name)) return;
            field_ptr_ty := self.ptr_type(field_val_ty);
            @debug_assert(!f.container.expr&.is(.GetVar), "ICE: place expr can't be direct var access");
            e := self.box(f.container[]);
            if bytes == 0 {
                place.expr = (Cast = e);
            } else {
                place.expr = (PtrOffset = (
                    ptr = e,
                    bytes = bytes,
                    name = f.name,
                ));
            };
            place.done = done;
            if want_deref {
                place.ty = field_ptr_ty;
                // Now we have the offset-ed ptr, add back the deref
                @check(self.deref_one(place)) return;
                place.done = done;
            } else {
                place.ty = field_ptr_ty;
            };
        }
        fn Deref(_) => {
            return(self.compile_deref_place(place, requested, want_deref));
        }
        fn GetNamed(n) => return(@err("Undeclared Identifier: %", self.pool.get(n[])));
        fn PrefixMacro(_) => {
            // TODO: this is sketchy but makes []->.index work.
            //       need to think about how requested/want_deref are handled
            @check(self.compile_expr(place, requested)) return;
            return(self.compile_place_expr(place, requested, want_deref));
        }
        @default => {
            if !place.ty.is_unknown() {
                // TODO: pass in if we're currently trying to access a field so we can give a better error message if its on an int or something?
                return(@err("Place expression of type % expected pointer dereference.\n%", self.log_type(place.ty), place.log(self.pool)));
            };
            return(@err("TODO: other `place=e;` % %", place.log(self.pool), self.log_type(place.ty)));
        };
    };
    .Ok
}

fn compile_deref_place(self: *SelfHosted, place: *FatExpr, requested: ResultType, want_deref: bool) Maybe(void) = {
    @debug_assert(place.expr&.is(.Deref));
    arg := place.expr.Deref;
    // When you see a !deref, treat the expression as a pointer value.
    req := requested.specific().map(fn(r) => self.ptr_type(r));
    @check(self.compile_expr(arg, req.want())) return;
    if want_deref {
        place.ty = or self.unptr_ty(arg.ty) {
            return(@err("tried to deref non-pointer"))
        };
        place.done = arg.done;
    } else {
        place[] = arg[];
    };
    .Ok
}

// :PlaceExpr
fn field_access_expr(self: *SelfHosted, container_ptr: *FatExpr, name: Symbol) Maybe(Ty(i64, Type)) #once = {
    container_ptr_ty := self.raw_type(container_ptr.ty);
    depth := self.ptr_depth(container_ptr_ty);
    if depth != 1 {
        return(@err("index expr ptr must be one level of indirection. %", self.log_type(container_ptr_ty)));
    };
    container_ty := self.unptr_ty(container_ptr_ty).expect("ICE: we just checked its a pointer");

    raw_container_ty := self.raw_type(container_ty);
    x := self.finish_layout(raw_container_ty);
    or x { (e: ParseErr) |
        return(Err = self.box(e))
    };
    @match(self.get_type(raw_container_ty)) {
        fn Struct(f) => {
            @debug_assert(f.layout_done);
            each f.fields { f | 
                if f.name == name {
                    return(Ok = (f.byte_offset, f.ty));
                };
            };
            return(@err("unknown name % on %!", self.pool.get(name), self.log_type(container_ty)))
        }
        fn Tagged(f) => {
            each f.cases { f |
                if f._0 == name {
                    return(Ok = (8, f._1));
                };
            };
            return(@err("unknown name % on %", self.pool.get(name), self.log_type(container_ty)))
        }
        @default => {
            return(@err("only structs/enums support field access (name: %) but found %", self.pool.get(name), self.log_type(container_ty)))
        };
    }
}

// TODO: have a different version of @check for something that can error but not yield? 
fn deref_one(self: *SelfHosted, ptr: *FatExpr) Maybe(void) = {
    raw   := self.raw_type(ptr.ty);  // TODO: why are we going through enums...? -- Jul 30
    inner := or self.unptr_ty(raw) {
        return(@err("expected ptr for deref_one"))
    };
    
    @match(ptr.expr&) {
        fn Addr(arg) => {
            // this allows auto deref to work on let ptr vars.
            if arg.expr&.is(.GetVar) {
                // raw var expr is not allowed, we always refer to variables through thier address.
                ptr[] = synthetic_ty((Deref = self.box(ptr[])), ptr.loc, inner);
            } else {
                // Avoid reduntant (whatever)&[].
                ptr[] = arg[][];
                if ptr.ty.is_unknown() {
                    ptr.ty = inner; // TODO: this shouldn't happen
                };
            };
        }
        @default => {
            ptr[] = synthetic_ty((Deref = self.box(ptr[])), ptr.loc, inner);
        };
    };
    .Ok
}

fn decl_var(self: *SelfHosted, name: Var, ty: *LazyType, value: *FatExpr) Maybe(void) = {
    @log_event("decl_var %", name&.log(self.pool)) self; // :debug
    // TODO: this would make sense but i don't actually need it i guess since i store variable types globally.
    //@debug_assert(self.dispatch.enclosing_function.is_some(), "ICE: runtime vars must have an enclosing function");
    no_type := ty.is(.Infer);
    self.last_loc = value.loc;
    want := ResultType.None;
    if @check(self.infer_type(ty)) return { known |
        want = (Specific = known);
    };
    @check(self.compile_expr(value, want)) return;
    final_ty := value.ty;
    @debug_assert(!final_ty.is_unknown(), "if we didn't yield, we should know the type");
    if no_type {
        // Since there was no type annotation, we don't need a type check. Whatever we got is the type of this variable now. 
        ty[] = (Finished = final_ty);
        self.finish_layout_deep(final_ty).unwrap();
    } else {
        expected_ty := ty.unwrap();
        // TODO: :delay_layout
        //       Instead of doing this now, add it as an Action in the dispatch loop.
        //       We don't actually care about the field offsets yet, we just need them later for emitting bytecode. 
        //       This was one of the changes that inspired the sema rewrite.  -- Jul 25
        self.finish_layout_deep(expected_ty).unwrap();
        self.finish_layout_deep(final_ty).unwrap();
        @check(self.can_assign(expected_ty, final_ty)) return;
        // TODO: panic("TODO: self.type_check_arg(value, ty, \"var decl\")?;");
    };

    prev := self.scopes.get_var_type(name); 
    self.scopes.put_var_type(name, final_ty); // TODO: this returns is_new, i want to just assert that. we shouldn't be compiling more than once -- Jul 25
    // TODO: prev should always be none?? but its not a constant and seems to always be the same so its probablby not a super huge deal? -- Apr 23
    //       maybe its just cause im not zeroing the stmt and end up compiling multiple times. -- Apr 25
    @assert(prev.is_none().or(=> prev.unwrap() == final_ty));
    
    // TODO: :mark_stmt_done
    //       this function is called multiple times (if the containing block needs to yield). need to have a done flag on the fatstmt
    //       but thats easier to change once all the stuff is written in one language -- Jul 25
    .Ok
}

fn ensure_resolved_sign(self: *SelfHosted, fid: FuncId) Maybe(void) = {
    func := self.get_function(fid);
    if(func.get_flag(.ResolvedSign), => return(.Ok));
    res := self.resolve_sign(func);
    if res&.is_err() {
        return(Err = self.box(res.Err));
    };
    func.set_flag(.ResolvedSign);
    .Ok
}

fn ensure_resolved_body(self: *SelfHosted, fid: FuncId) Maybe(void) = {
    @check(self.ensure_resolved_sign(fid)) return;
    func := self.get_function(fid);
    if(func.get_flag(.ResolvedBody), => return(.Ok));
    res := self.resolve_body(func);
    if res&.is_err() {
        return(Err = self.box(res.Err));
    };
    func.set_flag(.ResolvedBody);
    .Ok
}

fn handle_compile_func_body(self: *SelfHosted, fid: FuncId) Maybe(void) #once = {
    @debug_assert(self.dispatch.function_in_progress&.get(fid.as_index()), "expected to do work on in progress function");
    self.ensure_resolved_body(fid);
    func := self.get_function(fid);
    if(func.get_flag(.EnsuredCompiled), => return(.Ok));
    assert(!func.get_flag(.MayHaveAquiredCaptures), "closures need to be specialized");
    assert(!func.get_flag(.AnyConstArgs), "const args need to be specialized");
    
    // Before we can do the body, we really need to know the argument types, 
    // and it would be nice to know the return type too but that's less important. 
    @check(self.infer_arguments(fid)) return;
    
    // you need to only do this once so args are unique but we might yield below. 
    // you can't yield in this block! MadeVarsForRuntimeArgs needs to be atomic!
    // TODO: alternativly, if i trusted myself, you could just say its fine when the arg is already there, 
    //       because surely we put it there ourselves last time around. 
    //       but for now i think this is a valuable sanity check that renumbering went well.  -- Jul 30
    if !func.get_flag(.MadeVarsForRuntimeArgs) {
        each func.arg.bindings { b | 
            // TODO: probably want to change this so you can do as much compiling as possible before expanding templates.
            @debug_assert(b.kind != .Const, "ICE: Tried to emit before binding const args.");
            @if_let(b.name) fn Var(name) => {
                @debug_assert(b.kind == name.kind);
                is_new := self.scopes.put_var_type(name, b.ty&.unwrap());
                @log_event("bind param %", name&.log(self.pool)) self;
                if(!is_new, => return(@err("overwrite arg? %", name&.log(self.pool))));
            };
        };
        func.set_flag(.MadeVarsForRuntimeArgs);
    };
    
    if func.get_flag(.BodyIsSpecial) {
        @check(self.emit_special_body(fid)) return;
    } else {
        @match(func.body&) {
            fn Normal(expr) => {
                old_func := self.dispatch.enclosing_function;
                self.dispatch.enclosing_function = (Some = fid);
                
                if !func.get_flag(.Generic) && !func.ret&.is(.Infer) {
                    @check(self.infer_return(fid)) return;
                };
    
                if func.return_var { return_var |
                    // TODO: this means you cant early return from non-block functions but the error message will be useless -- Jul 9 
                    @if_let(expr.expr&) fn Block(f) => {
                        if f.ret_label.is_none() {|  // we might have already tried to compile this function. 
                            ret: LabelId = from_index(self.dispatch.return_labels.len);
                            self.dispatch.return_labels&.push(fid);
                            label_ty := LabelId; // :get_or_create_type
                            if func.finished_ret { ret_ty | 
                                label_ty = self.intern_type(Label = ret_ty);
                            };
                            val := self.to_values(LabelId, ret);
                            @check(self.save_const_values(return_var, val, label_ty, func.loc)) return;
                            f.ret_label = (Some = ret);
                        };
                    };
                };
                
                @check(self.compile_expr(expr, func.finished_ret.want())) return;
                //@debug_assert(self.dispatch.enclosing_function.is_some() && self.dispatch.enclosing_function.unwrap() == fid, "lost enclosing");
                
                if func.ret&.is(.Infer) {
                    func.finished_ret = (Some = expr.ty);
                } else {
                    wanted := @check(self.infer_return(fid)) return;
                    if expr.is_const() {
                        @check(self.coerce_const_expr(expr, (Specific = wanted))) return;
                    };
                    @check(self.can_assign(wanted, expr.ty)) return;
                };
                self.dispatch.enclosing_function = old_func;
            }
            @default => return(@err("non special function must have body. (or ICE: double compiled function?)"));
        };
    };
    
    @log_event("body compiled: %", fid.as_index()) self;
    func.set_flag(.EnsuredCompiled);
    .Ok
}

fn emit_special_body(self: *SelfHosted, fid: FuncId) Maybe(void) = {
    @check(self.infer_return(fid)) return;
    func := self.get_function(fid);
    good := false;
    fn eval_str(self: *SelfHosted, e: *FatExpr) Maybe(Symbol) = {
        str := @check(self.create_slice_type(u8, e.loc)) return;
        ir := @check(self.immediate_eval_expr(e, str)) return;
        ir := Str.assume_cast(ir&)[];
        (Ok = self.pool.insert_owned(ir)) 
    }
    each func.annotations { tag | 
        @switch(tag.name) {
            @case(Flag.libc.ident()) => {
                good = true;
                // :io_driver TODO: all this fs stuff should be passed in (or better messaged out) by the driver
                // TODO: figure out the right path for different oses.
                // TODO: don't re-dlopen every time. tho i think its cached.
                s := @run c_str(@symbol "/usr/lib/libc.dylib");
    
                libc := dlopen(s, .Lazy);
                addr := libc.dlsym(self.pool.get_c_str(func.name));
                if addr.is_null() {
                    // TODO: warn? have different #import that means we expect not at comptime?
                    func.body = (DynamicImport = func.name);
                } else {
                    self.aarch64&.extend_blanks(fid);
                    self.aarch64.dispatch[fid.as_index()] = addr;
                    impls: List(FuncImpl) = list(2, self.get_alloc());
                    impls&.push(ComptimeAddr = addr.int_from_rawptr());
                    impls&.push(DynamicImport = func.name);
                    func.body = (Merged = impls.rs());
                };
            };
            @case(Flag.import.ident()) => {
                // :io_driver
                lib_name := @match(tag.args&.as_ref()) {
                    fn Some(lib_name) => @check(self.eval_str(lib_name)) return;
                    fn None() => self.pool.insert_owned("");
                };
    
                has_driver_handler := !self.env.driver_vtable_ptr.is_null(); // TODO: garbage
                if has_driver_handler {
                    vtable := ExportVTable.ptr_from_raw(self.env.driver_vtable_ptr);
                    if vtable.resolve_comptime_import { callback | 
                        legacy := self.stable_compiler_context();
                        @match(callback(self.env.driver_vtable_user_data, legacy, fid, lib_name, func.name)) {
                            fn Some(addr) => {
                                impls := self.get_alloc().alloc(FuncImpl, 2);
                                impls[0] = (ComptimeAddr = addr.int_from_rawptr());
                                impls[1] = (DynamicImport = func.name);
                                func.body = (Merged = impls.rs());
                                self.aarch64&.extend_blanks(fid);
                                self.aarch64.dispatch[fid.as_index()] = addr;
                                good = true;
                            }
                            fn None() => {
                                // TODO: warn? have different #import that means we expect not at comptime?
                                func.body = (DynamicImport = func.name);
                                good = true;
                            }
                        };
                    };
                };
            };
            @case(Flag.unsafe_noop_cast.ident()) => {
                good = true;
            };
            @case(Flag.comptime_addr.ident()) => {
                good = true;
                ::as_ref(FatExpr);
                value := @unwrap(tag.args&.as_ref(), "#comptime_addr requires arg") return;
                ptr := @check(self.immediate_eval_expr(value, i64)) return;
                ptr := i64.assume_cast(ptr&)[];
                func.body = (ComptimeAddr = ptr);
                self.aarch64&.extend_blanks(fid);
                self.aarch64.dispatch[fid.as_index()] = ptr.rawptr_from_int();
            };
            @case(Flag.intrinsic.ident()) => {
                good = true;
                value := @unwrap(tag.args&.as_ref(), "#redirect requires arg") return;
                intrinsic_ty := @unwrap(self.env.intrinsic_type, "used #intrinsic during boot") return;
                op := @check(self.immediate_eval_expr(value, intrinsic_ty)) return;
                op := Intrinsic.assume_cast(op&)[];
                func.body = (Intrinsic = op);
            };
            @case(Flag.redirect.ident()) => {
                good = true;
                value := @unwrap(tag.args&.as_ref(), "#redirect requires arg") return;
                RedirectType :: @struct(arg: Type, ret: Type, os: OverloadSet);
                payload := self.tuple_of(@slice(Type, Type, OverloadSet));
                payload := @check(self.immediate_eval_expr(value, payload)) return;
                payload := RedirectType.assume_cast(payload&)[];
                args := self.arg_types(payload.arg);
                f_ty: FnType = (arg = payload.arg, ret = payload.ret, arity = args.len.trunc());
                target := @check(self.resolve_by_type(payload.os, f_ty, func.loc)) return;
                func.body = (Redirect = target);
                
                // TODO: i dont super understand why this is nessesary but it clearly is
                //       i think if i handled redirects better this could go away. 
                target_func := self.get_function(target);
                if target_func.get_flag(.BodyIsSpecial) {
                    @check(self.emit_special_body(target)) return;
                    // TODO: this breaks deduplicate_functions test somehow. 
                    @if_let(target_func.body) fn Intrinsic(op) => {
                        func.body = (Intrinsic = op);
                    };
                };
            };
            // TODO: remove all the different string based ones and have #asm("llvm") #asm("qbe") FuncImpl::AsmStr(Backend:Symbol, Source:Symbol)
            //       so you can have driver programs add new backends without modifying the core compiler. 
            //       then move backends/qbe.fr to be an external thing in examples.   :io_driver
            @case(Flag.asm.ident()) => {
                // - tuple of string literals -> llvm-ir
                // - tuple of 32-bit int literals -> aarch64 asm ops
                // - anything else, comptime eval expecting Slice(u32) -> aarch64 asm ops
                @debug_assert(func.body&.is(.Normal), "we already checked that #asm has body");
                
                asm := func.body.Normal&;
                
                each func.annotations { tag | 
                    @switch(tag.name) {
                        @case(Flag.aarch64.ident()) => {
                            // TODO: :PushConstFnCtx
                            // TODO: you can't just compile here because then trying to imm_eval hits a not read asm func i think because of ^ callees.
                            //       it recurses and has to emit other asm first but they don't get put in dispatch,
                            //       becuase they don't have a thing in the result stack to do callees first.
                            ops: RsVec(u32) = if asm.expr&.is(.Tuple) {
                                parts := asm.expr.Tuple&;
                                ops: List(u32) = list(parts.len, self.get_alloc());
                                u32_ty := self.intern_type(Int = (bit_count = 32, signed = false));
                                each parts { int |
                                    i := @check(self.immediate_eval_expr(int, u32_ty)) return;
                                    i := u32.assume_cast(i&)[];
                                    ops&.push(i);
                                };
                                ops.rs()
                            } else {
                                // TODO
                                //let ty = self.type_of(asm)?;
                                //if let Some(ty) = ty {
                                //    self.program.finish_layout_deep(ty)?;
                                //    if let TypeInfo::Struct { fields, .. } = &self.program[ty] {
                                //        let is_ints = fields.iter().all(|t| matches!(self.program[t.ty], TypeInfo::Int(_)));
                                //        if is_ints {
                                //            let len = fields.len();
                                //            let val = self.immediate_eval_expr(asm.clone(), ty)?;
                                //            let mut reader = ReadBytes { bytes: val.bytes(), i: 0 };
                                //            let mut ints = vec![];
                                //            for _ in 0..len {
                                //                let op = unwrap!(reader.next_u32(), "");
                                //                ints.push(op);
                                //            }
                                //            assert_eq!(reader.i, val.bytes().len()); // TODO: do this check everywhere.
                                //            break 'o ints;
                                //        }
                                //    }
                                //}
                                // let ops: Vec<u32> = self.immediate_eval_expr_known(asm.clone())?;
                                return(@err("TODO: untested #asm case."))
                            };
                            func.body = (JittedAarch64 = ops);
                            good = true; 
                        };
                        // TODO: an erorr message here gets swollowed because you're probably in the type_of shit. this is really confusing. need to do beter
                        // TODO: if its a string literal just take it
                        // TODO: check if they tried to give you something from the stack
                        @case(Flag.llvm.ident()) => {
                            @err_assert(func.body&.is(.Empty), "found multiple arches for #asm") return;
                            ir := @check(self.eval_str(asm)) return;
                            func.body = (LlvmIr = ir);
                            good = true;
                        };
                        @case(Flag.qbe.ident()) => {
                            @err_assert(func.body&.is(.Empty), "found multiple arches for #asm") return;
                            ir := @check(self.eval_str(asm)) return;
                            func.body = (QbeIr = ir);
                            good = true;
                        };
                        @case(Flag.c.ident()) => {
                            @err_assert(func.body&.is(.Empty), "found multiple arches for #asm") return;
                            ir := @check(self.eval_str(asm)) return;
                            func.body = (CSource = ir);
                            good = true;
                        };
                        @default => ();
                    };
                };
                @err_assert(good, "!asm require arch tag") return;
            };
            @default => ();
        };
    };
    @err_assert(good, "Function has no implementation %", func.log(self.pool)) return;
    .Ok
}

::tagged(ResultType);
fn compile_expr(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) = {
    if expr.done {
        assert(expr.ty != UnknownType, "done but unknown type");
        return(.Ok);
    };
    todo_dont_lose := self.dispatch.enclosing_function;
    old_loc := self.last_loc;
    self.last_loc = expr.loc;
    self.dispatch.active_stack.push(expr = expr, requested = requested);
    //@log_event("compile_expr % %", expr.log(self.pool), self.dispatch.enclosing_function&.tag()) self;
    
    @match(expr.expr&) {
        fn Poison(placeholder) => {
            return(@err("Poison expression %", placeholder));
        }
        fn Value(f) => {
            if(expr.ty == UnknownType, => return(@err("ICE: Value expression must have known type")));
            if !f.coerced {
                @if_let(requested) fn Specific(ty) => {
                    if expr.ty != ty {
                        @check(self.coerce_const_expr(expr, requested)) return;
                    };
                };
            };
            expr.done = true;
        }
        fn Call() => {
            @check(self.compile_call(expr, requested)) return;
        }
        fn Block(f) => {
            if !f.hoisted_constants {
                @check(self.hoist_constants(f.body.items())) return;
                f.hoisted_constants = true;
            };
            done := true;
            each f.body { stmt | 
                new_done := @check(self.compile_stmt(stmt)) return;
                done = new_done && done;
            };
            @check(self.compile_expr(f.result, requested)) return;
            
            expr.ty = f.result.ty;
            
            // HACK. for when you inline something with an early return that ends in a never. :early_return_fallthrough_never ::block_never_unify_early_return_type
            // TODO: seperate out a `unify` operation and use it everywhere you update expr.ty? 
            //       Switch and If already have this so its starting to feel a bit dumb.  -- Aug 19
            if f.result.ty.is_never() {
                if requested.specific() { ty |
                    expr.ty = ty;
                };
            };
            
            expr.done = f.result.done && done;
            if f.body.is_empty() && f.ret_label.is_none() {
                expr[] = f.result[]; // Not required but makes debugging easier cause there's less stuff.
            };
        }
        fn Tuple(parts) => {
            requested_types := @try(self.tuple_types(requested, parts.len)) return;
            types: List(Type) = list(parts.len, temp()); 
            enumerate parts { i, expr | 
                if !expr.done {
                    @check(self.compile_expr(expr, requested_types[i])) return;
                };
                types&.push(expr.ty);
            };
            if expr.ty.is_unknown() {
                expr.ty = self.tuple_of(types.items());
                self.finish_layout_deep(expr.ty);
            };  // TODO: else :type_check
        }
        fn PrefixMacro() => {
            @check(self.compile_prefix_macro(expr)) return;
            @check(self.compile_expr(expr, requested)) return;
        }
        fn GetVar(var) => return(self.compile_get_var(expr, requested));
        fn GetNamed(n) => return(@err("Undeclared Identifier: %", self.pool.get(n[])));
        fn String(i) => {
            // This is only different from a Value node because the 'Str' is not a builtin so the parser is unable to create it.
            byte := self.get_or_create_type(u8);
            str := self.to_values(Str, self.pool.get(i[]));
            expr.set(str, @check(self.create_slice_type(byte, expr.loc)) return);
        }
        fn ConstEval(inner) => {
            // :PushConstFnCtx 
            // We need to track that any callees of this expression are not runtime callees!
            old_func := self.dispatch.enclosing_function;
            self.dispatch.enclosing_function = .None;
            @check(self.compile_expr(inner[], requested)) return;
            self.dispatch.enclosing_function = old_func;
            // TODO: its a bit silly that i have to specifiy the type since the first thing it does is compile it
            value := @check(self.immediate_eval_expr(inner[], inner.ty)) return;
            expr.set(value, inner.ty);
        }
        fn Deref(inner) => @check(self.compile_deref_place(expr, requested, true)) return;
        fn Addr(inner) => {
            // Note: the old version had special handling for GetVar here to avoid loops but this seems fine... - Jul 30
            @check(self.compile_place_expr(inner[], requested, false)) return;
            expr[] = inner[][];
        }
        fn PtrOffset(f) => {
            expr.done = f.ptr.done;
        }
        fn GetParsed() => return(@err("ICE: GetParsed is handled by scope.fr"));
        fn Closure(func) => {
            fid := self.add_function(func[][]);
            fid_value := self.to_values(FuncId, fid);
            expr.set(fid_value, FuncId); // :get_or_create_type
            func := self.get_function(fid);
            @try(self.update_function_metadata(func, .None)) return;
            if func.ret&.is(.Infer) {
                // TODO: this change is sketch if we're just exploring to resolve an overload  -- Aug 5
                @match(requested) {
                    fn Returning(t) => {
                        func.ret = (Finished = t);
                    }
                    fn Specific(f_ty) =>{
                        @if_let(self.get_type(f_ty)) fn Fn(f_ty) => {
                            func.ret = (Finished = f_ty.ret);
                        };
                    }
                    @default => ();
                }
            };
            if !requested&.is(.None) {
                @check(self.coerce_const_expr(expr, requested)) return;
            };
        }
        // :PlaceExpr
        fn FieldAccess(f) => {
            // TODO: this is unfortunate. it means you prewalk instead of letting placeexpr do the recursion
            //       but need to check if its a value that has special fields first.
            @check(self.compile_expr(f.container, .None)) return;

            @switch(f.container.ty) {   // :get_or_create_type
                @case(Type) => {
                    type := @check(self.immediate_eval_expr(f.container, Type)) return;  // :get_or_create_type
                    type := Type.assume_cast(type&)[];
                    @check(self.contextual_field(f.name, expr, type)) return;
                    // TODO: should typecheck against result type be here or elsewhere? 
                };
                @case(ScopeId) => {
                    // TODO: this should probably be removed because its the same as a struct with const fields. 
                    return(@err("TODO: FieldAccess on Scope"));
                };
                @default => {
                    // Otherwise its a normal struct/tagged field.
                    @check(self.compile_place_expr(expr, requested, true)) return;
                };
            };
        }
        fn StructLiteralP() => {
            @check(self.construct_struct_literal(expr, requested)) return;
        }
        fn ContextualField(name) => {
            @err_assert(requested&.is(.Specific), "ContextualField % requires type hint", self.pool.get(name[])) return;
            @check(self.contextual_field(name[], expr, requested.Specific)) return;
        }
        fn Uninitialized() => {
            if expr.ty.is_unknown() {
                @err_assert(requested&.is(.Specific), "Uninitialized requires type hint") return;
                expr.ty = requested.Specific;
            };
            expr.done = true;
        }
        fn Quote(arg) => {
            @check(self.compile_quote(expr, requested)) return;
        }
        fn Slice(arg) => {
            @check(self.compile_expr(arg[], .None)) return;
            types := self.arg_types(arg.ty);
            // TODO: typecheck that all are the same!
            expr.ty = @check(self.create_slice_type(types[0], arg.loc)) return;
            expr.done = arg.done;
        }
        fn As(f) => {
            type := @check(self.immediate_eval_expr(f.type, Type)) return;
            type := Type.assume_cast(type&)[];
            @check(self.compile_expr(f.value, type.want())) return;
            if f.value.ty != type {
                expr.ty = type;
                expr.expr = (Cast = f.value);
            } else {
                expr[] = f.value[];
            };
        }
        fn Cast(arg) => {
            @check(self.compile_expr(arg[], .None)) return;
            expr.done = arg.done;
        }
        fn FnPtr(arg) => {
            @check(self.compile_fn_ptr(expr)) return;
        }
        fn If(f) => {
            @check(self.compile_expr(f.cond, bool.want())) return; // :get_or_create_type

            // TODO: this mostly can't happen anymore because you use the if function and params dont get forwarded like that. 
            //       should allow promoting things to constants. 
            // If its constant, don't even bother emitting the other branch
            if f.cond.expr&.is(.Value) {
                cond := bool.assume_cast(f.cond.expr.Value.bytes&)[];
                ::if(*FatExpr);
                // Now we fully dont emit the branch
                expr[] = if(cond, => f.if_true, => f.if_false)[];
                // need to force the compile again to keep if constant for nested folding.
                return(self.compile_expr(expr, requested));
            };
            
            @check(self.compile_expr(f.if_true, requested)) return;
            true_ty := f.if_true.ty;
            if requested&.is(.None) && !true_ty.is_never() {
                // This is especially helpful for macros that expand to chained ifs (like @switch)
                requested = (Specific = true_ty);
            };
            @check(self.compile_expr(f.if_false, requested)) return;
            if true_ty.is_never() {
                true_ty = f.if_false.ty;
            } else {
                @check(self.can_assign(true_ty, f.if_false.ty)) return;
            };
            expr.ty = true_ty;
            expr.done = f.cond.done && f.if_true.done && f.if_false.done;
        }
        fn Switch(f) => {
            @check(self.compile_expr(f.value, i64.want())) return;
            unify :: fn(expect: *ResultType, new: Type) void = {
                dont_like_this_type := @match(expect) {
                    fn Specific(inner) => inner[].is_never();
                    fn Returning(_) => false;
                    @default => true;
                };
                if dont_like_this_type && !new.is_never() {
                    expect[] = (Specific = new);
                }
            };
            expected_type := requested; 
            @check(self.compile_expr(f.default, expected_type)) return;
            unify(expected_type&, f.default.ty);
            // TODO: ensure the value tags are unique. 
            done := f.default.done;
            each f.cases { it |
                @check(self.compile_expr(it._1&, expected_type)) return;
                unify(expected_type&, it._1.ty);
                done = done && it._1.done;
            };
            ty := @match(expected_type) {
                fn Specific(inner) => inner;
                fn None() => Never;
                @default => return(@err("could not unify switch branch types"));
            };
            expr.ty = ty;
            expr.done = done;
        }
        fn Loop(arg) => {
            @check(self.compile_expr(arg[], void.want())) return;
            expr.done = arg.done;
            expr.ty = Never; // :get_or_create_type
        }
        fn FromBitLiteral(f) => {
            ty := self.intern_type(Int = (bit_count = f.bit_count, signed = false));
            value := self.to_values(i64, f.value);
            @switch(f.bit_count) {
                @case(8) => {
                    value.Small._1 = 1;
                };
                @case(16) => {
                    value.Small._1 = 2;
                };
                @case(32) => {
                    value.Small._1 = 4;
                };
                @default => ();
            };
            expr.set(value, ty);
        }
        @default => @panic("TODO: unhandled node type %: %", expr.expr&.tag(), expr.log(self.pool));
    };
    self.last_loc = old_loc;
    self.dispatch.active_stack.pop();
    self.dispatch.enclosing_function = todo_dont_lose;
    @debug_assert(!expr.ty.is_unknown(), "[compile_expr] Unknown type for %", expr.log(self.pool));
    .Ok
}

fn compile_quote(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) #once = {
    arg := expr.expr.Quote&;

    unquote_placeholders := @unwrap(self.env.unquote_placeholders, "quote during boot") return;
    
    // note: do this before fucking with the expr because it will yield the first time!
    @check(self.infer_arguments(unquote_placeholders)) return;
    @check(self.infer_return(unquote_placeholders)) return;
    if self.aarch64&.get_fn(unquote_placeholders).is_none() {
        return(Suspend = self.wait_for(Jit = unquote_placeholders));
    };
    
    //walk: MarkNotDone = (_hack = 0);
    //walk&.walk_expr(arg[]); // TODO: might not need this :SLOW
    
    walk: Unquote = (compiler = self, placeholders = list(self.get_alloc()));
    @try(walk&.walk_expr(arg[])) return;
    expr_ty := @unwrap(self.env.fat_expr_type, "used quoted ast during bootstrapping") return;
    value := self.to_values(FatExpr, arg[][]);
    expr.set(value, expr_ty);
    @log_event("quote with % placeholders", walk.placeholders.len) self;
        
    if !walk.placeholders.is_empty() {
        walk.placeholders&.push(expr[]);
        arg: FatExpr = (expr = (Tuple = walk.placeholders.rs()), loc = expr.loc, ty = UnknownType, done = false);
        arg := self.box(arg);
        arg: FatExpr = (expr = (Slice = arg), loc = expr.loc, ty = UnknownType, done = false);
        f_value := self.to_values(FuncId, unquote_placeholders); // :get_or_create_type
        f_ty := @unwrap(self.func_type(unquote_placeholders), "ice: unquote_placeholders not typechecked") return;
        f: FatExpr = synthetic_ty((Value = (bytes = f_value, coerced = false)), expr.loc, f_ty);
        expr[] = synthetic_ty((Call = (f = self.box(f), arg = self.box(arg))), expr.loc, expr_ty);
        @check(self.compile_expr(expr, requested)) return;
    };
    .Ok
}

fn compile_fn_ptr(self: *SelfHosted, expr: *FatExpr) Maybe(void) = {
    arg := expr.expr.FnPtr&;
    // TODO: pass through better type hint
    value := @check(self.immediate_eval_expr(arg[], FuncId)) return;
    fid := FuncId.assume_cast(value&)[];
    @check(self.infer_arguments(fid)) return;
    @check(self.infer_return(fid)) return;
    func := self.get_function(fid);
    // TODO: typecheck
    //err!("!fn_ptr expected const fn not {}", self.program.log_type(ty));
    
    @err_assert(!func.get_flag(.AnyConstArgs), "cannot take pointer to function with const args") return;
    
    // Note: else is not `Suspend = self.wait_for(Jit = fid)` because of cycles, we defer to the backend to deal with finializing it. 
    //       a better system would be to generate a shim right now so we'd always have an address? 
    if self.aarch64&.get_fn(fid) { ptr |
        if !func.get_flag(.TookPointerValue) {
            // We already compiled the function but didn't know we'd need to remember its address. (ie. #test fn large_struct_ret_return).
            self.created_jit_fn_ptr_value(fid, ptr.int_from_rawptr())
        };
    };
    @err_assert(!func.get_flag(.Once), "Cannot create a function pointer to something that id #once") return;
    func.set_flag(.TookPointerValue);
    self.add_callee(fid);
    
    // TODO: for now you just need to not make a mistake with calling convention
    // The backend still needs to do something with this, so just leave it
    ty := @unwrap(func.finished_ty(), "!fnptr expected known type") return;
    cc := @unwrap(func.cc, "unknown calling convention") return;
    ty := self.intern_type(FnPtr = (ty = ty, cc = cc));
    arg[].set(value, FuncId);
    expr.ty = ty;
    expr.done = true;
    .Ok
}

fn construct_struct_literal(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) #once = {
    pattern := expr.expr.StructLiteralP&;
    if(!requested&.is(.Specific), => return(@err("struct literal requires type hint"))); // TODO: I'll probably want this to be a new type of yield eventually. 
    requested := requested.Specific;
    raw_container_type := self.raw_type(requested);
    bindings := pattern.bindings&;
    
    @match(self.get_type(raw_container_type)) {
        fn Struct(f) => {
            done := true;
            each bindings { b | 
                name := or b.ident() {
                    return(@err("struct literal requires field names"))
                };
                // TODO: could guess that they did them in order if i cared about not looping twice.
                miscompilation_if_you_inline_this := f.fields&.position(fn(f) => f.name == name);
                field := or miscompilation_if_you_inline_this {
                    return(@err("Tried to assign unknown field %", self.pool.get(name)))
                };
                field := f.fields[field]&;
                value := or b.default&.as_ref() {
                    return(@err("struct literal requires field value (use '=' not ':')"))
                };
                @check(self.compile_expr(value, (Specific = field.ty))) return;
                done = done && value.done;
                self.last_loc = pattern.loc;
                @check(self.can_assign(field.ty, value.ty)) return;
            };

            // TODO: If they're missing some, check for default values.
            runtime_fields := f.fields.len - f.const_field_count.zext();
            if runtime_fields != bindings.len {
                enumerate f.fields { i, field | 
                    continue :: local_return;
                    if(field.kind == .Const, => continue());
                    each bindings { b | 
                        if b.ident() { n | 
                            if(n == field.name, => continue());
                        };
                    };
                    
                    default := @unwrap(field.default, "Missing required field %", self.pool.get(field.name)) return;
                    value, ty := @check(self.find_const(default, field.ty.want())) return;
                    expr := synthetic_ty((Value = (bytes = value, coerced = false)), pattern.loc, field.ty);
                    
                    // TODO: HACK. emit_bc expects them in order
                    bindings.insert(
                        i,
                        (
                            name = (Ident = field.name),
                            ty = (Finished = ty),
                            default = (Some = expr),
                            kind = .Var,
                        ),
                        self.get_alloc()
                    );
                };
                @err_assert(runtime_fields == bindings.len, "ICE: struct field count mismatch but we don't know which is missing") return;
            };
            expr.done = done;
            expr.ty = requested;
            .Ok
        }
        fn Tagged(f) => {
            @err_assert(bindings.len == 1, "% is an enum, value should have one active varient not %", self.log_type(requested), bindings.len) return;
            b := bindings.index(0);
            name := or b.ident() {
                return(@err("struct literal requires field names"))
            };
            each f.cases& { f |
                if f._0 == name {
                    value := @unwrap(b.default&.as_ref(), "struct literal needs value") return;
                    @check(self.compile_expr(value, (Specific = f._1))) return;
                    @err_assert(value.ty == f._1, "TODO: better type checking") return;
                    expr.done = value.done;
                    expr.ty = requested;
                    return(.Ok);
                };
            };
            @err("No field % exists in %", self.pool.get(name), self.log_type(requested))
        }
        @default => @err("found struct literal but expected % = %", requested, self.log_type(requested));
    }
}

fn contextual_field(self: *SelfHosted, name: Symbol, expr_out: *FatExpr, type: Type) Maybe(void) = {
    @match(self.get_type(type)) {
        fn Enum(f) => {
            each f.fields { f |
                if f._0 == name {
                    value := f._1&.deep_clone(self.get_alloc());
                    expr_out.set(value, type);
                    return(.Ok);
                };
            };
            @err("contextual field % not found for %", self.pool.get(name), self.log_type(type))
        }
        fn Struct(f) => {
            enumerate f.fields { i, f | 
                if f.name == name {
                    @err_assert(f.kind == .Const, "struct contextual field must be constant. %", self.pool.get(f.name)) return;
                    default := @unwrap(f.default, "ICE: const field must have value") return;
                    value, ty := @check(self.find_const(default, f.ty.want())) return;
                    expr_out.set(value, ty);
                    return(.Ok);
                };
            };
            @err("const field $% not found for %", self.pool.get(name), self.log_type(type))
        
        }
        fn Tagged(f) => {
            enumerate f.cases { i, f | 
                if f._0 == name {
                    @err_assert(f._1 == void, 
                        "contextual field % of tagged union must be unit found %",
                        self.pool.get(name), self.log_type(f._1)
                    ) return;
                    
                    // We could create a StructLiteralP and let the backend deal with it, but we know the answer right now. 
                    // Note that this forces an extra case for :tagged_prims_hack
                    info := self.get_info(type);
                    size: i64 = info.stride_bytes.zext(); // TODO: allow yield on sizing here. 
                    bytes := 0x00.repeated(size, self.get_alloc());
                    assert(i <= 255, "TODO: giant ass @tagged"); 
                    assert(info.align_bytes <= 8, "TODO: handle large alignment");
                    bytes[0] = i.trunc(); // :endian
                    expr_out.set(bytes.items().to_value(), type);
                    expr_out.ty = type;
                    expr_out.done = true;
                    return(.Ok);
                };
            };
            @err("contextual field % not found for %", self.pool.get(name), self.log_type(type))
        }
        fn Named(f) => self.contextual_field(name, expr_out, f._0);
        @default => @err("no contextual fields for type % (wanted %)", self.log_type(type), self.pool.get(name));
    }
}

::if(ResultType);
fn compile_call(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) #once = {
    @debug_assert(expr.expr&.is(.Call));
    f := expr.expr.Call.f;
    arg := expr.expr.Call.arg;
    req_fn: ResultType = @match(requested) {
        fn Specific(t) => (Returning = t);
        @default => .None;
    };
    
    @check(self.compile_expr(f, req_fn)) return;
    
    if f.ty == OverloadSet {|  // :get_or_create_type
        os := @check(self.immediate_eval_expr(f, OverloadSet)) return;
        os := OverloadSet.assume_cast(os&)[];
        return(Suspend = self.wait_for(ResolveOverload = (os = os, call = (expr = expr, requested = requested), callsite = self.dispatch.enclosing_function)));
    };
    
    if f.ty == FuncId {|  // :get_or_create_type
        return(self.call_direct(expr, requested));
    };
    
    if f.ty == LabelId {|  // :get_or_create_type
        // We're trying to early return but we didn't know the return type yet when the label was created. 
        // You should only get here for .Generic or .Infer. 
        label := @check(self.immediate_eval_expr(f, LabelId)) return;
        label := LabelId.assume_cast(label&)[];
        fid := self.dispatch.return_labels&.nested_index(label.as_index())[];
        func := self.get_function(fid);
        @match(@check(self.infer_type(func.ret&)) return) {
            fn Some(ty) => {
                @check(self.compile_expr(arg, ty.want())) return;
                @check(self.can_assign(ty, arg.ty)) return;
            }  
            fn None() => {
                @check(self.compile_expr(arg, .None)) return;
                // It was .Infer, but we'll save it incase we have multiple returns.
                // TODO: I think this is wrong because you're allowd to have polymorphic closures but I don't clone the func.  
                func.ret = (Finished = arg.ty);
            }
        };
        f.ty = self.intern_type(Label = arg.ty);
        expr.ty = Never; // :get_or_create_type
        expr.done = arg.done;
        return(.Ok);
    };
    
    @match(self.get_type(f.ty)) {
        fn FnPtr(it) => {
            // Feels like a pretty reasonable invarient: if we have a function pointer, we need to know exactly what its types are. 
            @check(self.compile_expr(arg, (Specific = it.ty.arg))) return;
            @check(self.can_assign(arg.ty, it.ty.arg)) return; // TODO: correct varience
        
            expr.ty = it.ty.ret;
        }
        fn Fn(it) => {
            // This happens to be an easy case where we already know the argument type.
            @check(self.compile_expr(arg, (Specific = it.arg))) return;
            return(self.call_direct(expr, requested));
        }
        fn Label(it) => {
            @check(self.compile_expr(arg, (Specific = it[]))) return;
            @check(self.can_assign(it[], arg.ty)) return;
            expr.ty = Never; // :get_or_create_type
            expr.done = arg.done; 
        }
        @default => return(@err("not callable %", f.log(self.pool)));
    };
    
    .Ok
}

// TODO: check function ret type against requested
// Note: when we get here, we might not know the type of the function or the argument. 
fn call_direct(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) = {
    f_expr := expr.expr.Call.f;
    arg_expr := expr.expr.Call.arg;
    @debug_assert(!f_expr.ty.is_unknown(), "call_direct expected fn expr to be compiled");
    fid := @check(self.immediate_eval_expr(f_expr, f_expr.ty)) return;
    fid := FuncId.assume_cast(fid&)[];
    @log_event("compile direct call %", fid) self;
    func := self.get_function(fid);
    
    arg_ty := UnknownType;
    
    @try(self.adjust_named_arguments(fid, arg_expr)) return;
    
    if func.get_flag(.AnyConstArgs) {| 
        // If you don't do this at all, you loop (TODO: why? gets stuck on EvalConstant:i64).
        // But if you @check it, you'll error out on things that need a type hint. 
        // We do a real typecheck after dealing with the const args so its probably fine. 
        // TODO: compiling it at all here (check or not) has to be wrong tho, 
        //       because you don't want things in a const arg expr to be added to runtime callees.
        _ := self.compile_expr(arg_expr, arg_expr.ty.want());
        @check(self.ensure_resolved_sign(fid)) return;
        
        // This creates a new function with only runtime args, and updates the arg_expr accordingly. 
        fid = @check(self.curry_const_args(fid, f_expr, arg_expr)) return;
        func = self.get_function(fid);
        // Since we may have just made a new function, make sure we know its types,
        // and then sanity check that our types still match. 
        if arg_expr.expr&.is(.Tuple) {
            arg_expr.ty = UnknownType;
            arg_expr.done = false;
        };
        arg_ty = @check(self.infer_arguments(fid)) return;
        @check(self.compile_expr(arg_expr, arg_ty.want())) return;
        // It's probably an ICE if this fails on something non-#generic. 
        if arg_ty != arg_expr.ty {
            return(@err("arg type mismatch after removing const args"));
        };
    };
    
    if func.get_flag(.UnsafeNoopCast) {
        @check(self.compile_expr(arg_expr, arg_ty.want())) return;
        //@check(self.can_assign(arg_ty, arg_expr.ty)) return; TODO: type check
        @check(self.infer_return(fid)) return;
        ret_ty := func.finished_ret.unwrap();
        @log_event("UnsafeNoopCast % -> %", self.log_type(arg_ty), self.log_type(ret_ty)) self;
        // TODO
        // assert_eq!(self.program.slot_count(arg_expr.ty), self.program.slot_count(ret_ty));
        expr.expr = (Cast = arg_expr);
        expr.ty = func.finished_ret.unwrap();
        expr.done = arg_expr.done;
        return(.Ok);
    };
    
    capturing   := func.get_flag(.AllowRtCapture).or(func.get_flag(.MayHaveAquiredCaptures));
    will_inline := capturing.or(func.cc.unwrap() == .Inline);
    deny_inline := func.get_flag(.NoInline);
    if(will_inline && deny_inline, => return(@err("must inline a function marked #noinline")));
    
    if will_inline {
        if capturing {
            // We want to allow for polymorphic arguments, but its better if we can infer the annotated ones before duplicating.
            // currently this is just an optimisation.  
            @check(self.infer_arguments_partial(fid)) return;
        };
        
        // If we're just inlining for #inline, compile first so some work on the ast is only done once.
        // note: compile() checks if its ::Inline before actually generating asm so it doesn't waste its time.
        // if its a '=>' function, we can't compile it out of context, and same if it has a const arg of a '=>' function. 
        if !capturing && !func.get_flag(.EnsuredCompiled) {
            self.dispatch.function_in_progress&.set(fid.as_index());
            return(Suspend = self.wait_for(CompileBody = fid));
        };

        // TODO: check that you're calling from the same place as the definition.
        return(self.emit_capturing_call(fid, expr, requested));
    };
    
    arg_ty = @check(self.infer_arguments(fid)) return;
    @check(self.compile_expr(arg_expr, (Specific = arg_ty))) return;
    if arg_ty != arg_expr.ty {
        return(@err("arg type mismatch. TODO: better type checking\n- expected: %\n- found: %", self.log_type(arg_ty), self.log_type(arg_expr.ty)));
    };
    
    ret_ty := @check(self.infer_return(fid))    return;
    is_const_context := self.dispatch.enclosing_function.is_none();
    // TODO: its a bit of a hack to check is_const_context? 
    //       it fixes a problem where you try to compile too soon and then think you're already done even if you make a function for it later.
    expr.done = f_expr.done && arg_expr.done && !is_const_context;
    expr.ty = ret_ty;
    
    if f_expr.ty == FuncId {|  // :get_or_create_type
        f_expr.ty = self.intern_type(Fn = (arg = arg_ty, ret = ret_ty, arity = func.arg.bindings.len.trunc()));
    };
    
    if !f_expr.expr&.is(.Value) {
        _ := @check(self.immediate_eval_expr(f_expr, f_expr.ty)) return;
    };
    allow_fold := self.dispatch.enclosing_function.is_some() && {
        func := self.get_function(self.dispatch.enclosing_function.unwrap());
        !func.get_flag(.SyntheticImmEval)
    };
    if func.get_flag(.TryConstantFold) && allow_fold && arg_expr.is_const() {
        @log_event("TryConstantFold %", expr.log(self.pool)) self;
        value := @check(self.immediate_eval_expr(expr, ret_ty)) return;
        expr.set(value, ret_ty); // TODO: redundant?
    } else {
        // this fixes functions with all const args the reduce to just a value emitting useless calls to like get the number 65 or whatever if you do ascii("A"). 
        if !deny_inline && arg_expr.is_raw_unit() {
            if func.body&.is(.Normal) && func.body.Normal.expr&.is(.Value) {
                expr.set(func.body.Normal.expr.Value.bytes&.deep_clone(self.get_alloc()), ret_ty);
            };
        };
    };
    
    if !expr.expr&.is(.Value) {
        if func.get_flag(.ComptimeOnly) {
            if self.dispatch.enclosing_function { current_f |
                outer := self.get_function(current_f);
                outer.set_flag(.ComptimeOnly);
            };
        };
        self.add_callee(fid);
    };
    
    if func.get_flag(.Once) {
        // TODO: better error message. should show the previous usage. 
        if(func.get_flag(.OnceConsumed), => return(@err("tried to call once function again")));
        func.set_flag(.OnceConsumed);
        assert(expr.done, "ICE: if we applied #once, the expression really needs to be .done");
    };
    
    .Ok
}

fn add_callee(self: *SelfHosted, fid: FuncId) bool = {
    is_const_context := true;
    if self.dispatch.enclosing_function { current_f |
        if(current_f == fid, => return(false)); 
        is_const_context = false;
        new := self.get_function(fid);
        current := self.get_function(current_f);
        if new.callees.items().contains(current_f&) {
            current.mutual_callees&.add_unique(fid, self.get_alloc());
        } else {
            current.callees&.add_unique(fid, self.get_alloc());
        };
        self.aarch64&.extend_blanks(fid);
        @log_event("added % calls %", current_f, fid) self;
        record_function_call(c = self, caller = current_f, callee = fid);
    };
    if is_const_context {
        @log_event("skip adding callee for %", fid) self;
    };
    is_const_context
}

fn quick_guess_type(self: *SelfHosted, expr: *FatExpr) ?Type = {
    if !expr.ty.is_unknown() {
        return(Some = expr.ty);
    };
    @match(expr.expr&) {
        fn Block(f) => self.quick_guess_type(f.result);
        @default => .None;
    }
}

// Replace a call expr with the body of the target function.
fn emit_capturing_call(self: *SelfHosted, f: FuncId, expr_out: *FatExpr, requested: ResultType) Maybe(void) #once = {
    @log_event("emit_capturing_call %", f) self;
    @check(self.ensure_resolved_body(f)) return; // it might not be a closure. it might be an inlined thing.
    @debug_assert(expr_out.expr&.is(.Call));
    arg_expr := expr_out.expr.Call.arg;
    
    // TODO
    //assert!(!self.currently_inlining.contains(&f), "Tried to inline recursive function.");
    //self.currently_inlining.push(f);

    func := self.get_function(f);
    
    // This is complicated to allow `fn() => .a` to stay polymorphic and have different inferred types at different callsites. 
    // Maybe a more robust version of this would be treating the result type like a const arg and duplicating the function? -- Aug 2
    ret_ty := or_else func.finished_ret {
        if func.ret&.is(.Infer) {
            if requested&.is(.Specific) {
                (Some = requested.Specific)
            } else {
                body := func.body.Normal&;
                known := self.quick_guess_type(body);
                known
            }
        } else {
            known := @check(self.infer_return(f)) return;
            //if !requested&.is(.Specific) {
            //    requested = (Specific = known);
            //};
            (Some = known)
        }
    };
    // TODO: does this ever help?
    //       no but it sure hurts... why?
    //if !requested&.is(.Specific) {
    //    if ret_ty { ret_ty |
    //        //@println("I think we want % for %", self.log_type(ret_ty), func.log(self.pool));
    //        requested = (Specific = ret_ty);
    //    };
    //};
    
    label_ty := ret_ty
        .map(fn(ty) => self.intern_type(Label = ty))
        .or(=> LabelId);
    
    // for inlined or things with const args, the body will already have been compiled, but the backend needs to see the whole callgraph.
    for func.callees { callee |
        self.add_callee(callee);
    };
    @err_assert(func.mutual_callees.is_empty(), "TODO: you can't really refer to inlined things so how'd you make it recursive?") return;

    if(!func.body&.is(.Normal), => return(@err("'=>' function must have body expression.")));
    aliased_body := func.body.Normal&;
    may_have_early_return := !aliased_body.expr&.is(.Value);
    pattern := func.arg&.deep_clone(self.get_alloc());
    
    // TODO: you want to be able to share work (across all the call-sites) compiling parts of the body that don't depend on the captured variables
    old_ret_var := func.return_var.unwrap();
    new_ret_var := self.scopes.dup_var(old_ret_var);
    ret_label: LabelId = from_index(self.dispatch.return_labels.len);
    self.dispatch.return_labels&.push(f);
    
    owned_body: FatExpr = if func.get_flag(.Once) {
        // TODO: better error message if they try to call it again. 
        // TODO: decide what #once with const args should mean. 
        temp := aliased_body[];
        aliased_body.expr = (Poison = .OnceUsed);
        temp
    } else {
        aliased_body.deep_clone(self.get_alloc())
    };
    loc := arg_expr.loc;
    // the second case would be sufficient for correctness but this is so common (if(_,!,!), loop(!), etc) that it makes me less sad. 
    if arg_expr.is_raw_unit() {
        // TODO: if !may_have_early_return, should be able to just inline the value but it doesnt work!
        //       similarly i cant have ret_label:None so im clearly wrong. its `not callable` in overloading.rs. trying to call the cond of an if??
        //       -- Jun 16
        expr_out.expr = (Block = (body = empty(), result = self.box(owned_body), ret_label = (Some = ret_label), hoisted_constants = false));
    } else {
        stmts: List(FatStmt) = list(1, self.get_alloc());
        arg_stmt: Stmt = (DeclVarPattern = (binding = pattern, value = arg_expr[]));
        stmts&.push(stmt = arg_stmt, annotations = empty(), loc = loc);
        expr_out.expr = (Block = (body = stmts.rs(), result = self.box(owned_body), ret_label = (Some = ret_label), hoisted_constants = false));
    };
    // TODO: self.currently_inlining.retain(|check| *check != f);
    if ret_ty { ret_ty | 
        expr_out.ty = ret_ty;
    };
    
    if may_have_early_return {
        // Note: not renumbering on the function. didn't need to clone it.
        self.renumber_expr(expr_out, (Some = (old_ret_var, new_ret_var)));
        value := self.to_values(LabelId, ret_label);
        @check(self.save_const_values(new_ret_var, value, label_ty, loc)) return;
    };
    
    @check(self.compile_expr(expr_out, requested)) return;
    //if ret_ty { ret_ty |
    //    @check(self.can_assign(ret_ty, expr_out.ty)) return;
    //};
    .Ok
}

// TODO: this still has the problem of disallowing const args that require type hint of previous const args. 
fn const_args_key(self: *SelfHosted, original_f: FuncId, arg_expr: *FatExpr) Maybe(Values) #once = {
    func := self[original_f]&;
    ::if(Maybe(Values));
    if func.arg.bindings.len == 1 {
        @check(self.compile_expr(arg_expr, func.finished_arg.want())) return;
        value := @check(self.immediate_eval_expr(arg_expr, arg_expr.ty)) return;
        (Ok = value)
    } else {
        check_len :: fn(len: i64) => {
            if func.arg.bindings.len != len {
                return(@err( "TODO: non-trivial pattern matching for call to %", self.pool.get(func.name)));
            };
        };

        types := self.tuple_types(arg_expr.ty);
        if types { types |
            check_len(types.len);
            @if(false) {
                // The rust version did this and i thought it needed but i just typo-ed the test. 
                // TODO: does this ever happen (function are not being a tuple)? or are we strict about arity now? -- Aug 1
                @if_let(arg_expr.expr&) fn Value(f) => {
                    // TODO: this is super dumb but better than what I did before. -- May 3 -- May 24
                    parts: List(FatExpr) = list(types.len, self.get_alloc());
                    reader: ReadBytes = (bytes = f.bytes&.bytes(), i = 0);
                    for types { ty | 
                        taken := or self.chop_prefix(ty, reader&) {| 
                            return(@err("ICE: not enough bytes to destructure value!"))
                        };
                        parts&.push(synthetic_ty((Value = (bytes = taken, coerced = false)), arg_expr.loc, ty));
                    };
                    @assert_eq(reader.bytes.len, reader.i, "ICE: didn't consume all bytes.");
                    arg_expr.expr = (Tuple = parts.rs());
                };
            };
        };
        
        if(!arg_expr.expr&.is(.Tuple), => return(@err("TODO: pattern match on non-tuple but expected % args.\n%", func.arg.bindings.len, arg_expr.log(self.pool))));
        arg_exprs := arg_expr.expr.Tuple;
        check_len(arg_exprs.len);

        all_const_args: List(u8) = list(self.get_alloc());
        i := 0;
        enumerate func.arg.bindings { i, binding |
            continue :: local_return;
            if(binding.kind != .Const, => continue());
            arg_ty := or binding.ty&.ty() {
                // TODO: this isn't really what you want. 
                //       the problem is you want to make the key before duplicating the function and binding const args,
                //       so its faster after the first instantiation, but to do that you need to compile the const args, 
                //       and they might need to get a type hint (like struct/enum literals), 
                //       but also thier type might depend on previous const args which this doesn't handle. 
                @check(self.compile_expr(arg_exprs.index(i), .None)) return;
                arg_exprs[i].ty
            };
            @debug_assert(!arg_ty.is_unknown(), "const_args_key expected arg expr to be compiled");
            value := @check(self.immediate_eval_expr(arg_exprs.index(i), arg_ty)) return;
            
            // TODO: remove? -- Aug 13
            //       You might not need this. I was hoping it would fix deconstruct_values but i think this is only used in the map. 
            self.aligned_append_value(all_const_args&, value, arg_ty);
        };
        (Ok = all_const_args.items().to_value())
    }
}

fn aligned_append_value(self: *SelfHosted, all_values: *List(u8), new_value: Values, arg_ty: Type) void = {
    alignment: i64 = self.get_info(arg_ty)[].align_bytes.zext();
    extra := all_values.len.mod(alignment);
    if extra != 0 {
        padding := alignment - extra;
        range(0, padding) { _ |
            all_values.push(0);
        };
    };
    
    all_values.push_all(new_value&.bytes());
}

fn remove_const_args(self: *SelfHosted, original_f: FuncId, arg_expr: *FatExpr) Maybe(void) = {
    func := self.get_function(original_f);
    if func.arg.bindings.len == 1 {
        arg_expr.set(unit_value, void);
    } else {
        if(!arg_expr.expr&.is(.Tuple), => return(@err("TODO: pattern match on non-tuple")));
        arg_exprs := arg_expr.expr.Tuple&;
        // We need to suspend out before removing anything...
        enumerate func.arg.bindings { i, binding | 
            if binding.ty&.ty() { expected |
                found := arg_exprs[i].ty;
                @check(self.can_assign(expected, found)) return;
            };
        };
        removed := 0;
        enumerate func.arg.bindings { i, binding | 
            if binding.kind == .Const {
                // TODO: this would be better if i was iterating backwards
                arg_exprs.ordered_remove(i - removed);
                removed += 1; // TODO: this sucks
            };
        };
        if arg_exprs.is_empty() {
            // Note: this started being required when I added fn while.
            arg_expr.set(unit_value, void);
        } else {
            if arg_exprs.len() == 1 {
                arg_expr[] = arg_exprs[0];
            } else {
                arg_expr.ty = UnknownType;
                arg_expr.done = false;
            };
        };
    };
    
    .Ok
}

MemoKey :: Ty(FuncId, Values);
// TODO: to allow #generic, this lazyily infers param types on the new function.
//       it would avoid redundant work to do that on the original func for params that don't depend on constants. 
//       that would jsut require compile_expr to be able to yield on a Poison.Argument, and we catch that here and just ignore. 
fn curry_const_args(self: *SelfHosted, original_f: FuncId, f_expr: *FatExpr, arg_expr: *FatExpr) Maybe(FuncId) #once = {
    key: MemoKey = (original_f, @check(self.const_args_key(original_f, arg_expr)) return);
    if self.dispatch.const_bound_memo&.get(key&) { new_f |
        @log_event("reuse baked const args % -> % (%)", original_f, new_f, key._1&) self;
        func := self.get_function(new_f);
        if func.get_flag(.AnyConstArgs) {
            original := self.get_function(original_f);
            if func.arg.bindings.len == original.arg.bindings.len {
                return(self.curry_const_args_inner(original_f, new_f, f_expr, arg_expr, 0));
            } else {
                removed_count := original.arg.bindings.len - func.arg.bindings.len;
                @debug_assert(removed_count > 0);
                return(self.curry_const_args_inner(original_f, new_f, f_expr, arg_expr, removed_count));
                return(@err("TODO: unfinished const args but started replacing some so don't really know what to do anymore. "));
            };
        };
        @check(self.remove_const_args(original_f, arg_expr)) return;
        fid_value := self.to_values(FuncId, new_f);
        f_expr.set(fid_value, FuncId);
        return(Ok = new_f);
    };

    func := self.get_function(original_f);
    @debug_assert(func.get_flag(.AnyConstArgs), "baking const args but none are there");
    @debug_assert_eq(func.get_flag(.AllowRtCapture), func.get_flag(.ResolvedBody));
    // Some part of the argument must be known at comptime.
    new_func := func.deep_clone(self.get_alloc());
    res := self.maybe_renumber_and_dup_scope(new_func&);
    if(res&.is(.Err), => return(Err = self.box(res.Err)));
    new_fid := self.add_function(new_func);
    @log_event("bake const args % -> %", original_f, new_fid) self;
    @check(self.ensure_resolved_sign(new_fid)) return;
    @check(self.ensure_resolved_body(new_fid)) return;
    // TODO: mark func as in progress somehow so nobody can yield on it. 
    //       tho really i feel like you want to make this whole operation yield-able,
    //       currently you could get into a situation with a lot of redundant work i think.  

    // Note: putting it in super early! this ensures that if you try to call the function while compiling it, 
    //       you don't keep spawning new variations that can never be finished. 
    self.dispatch.const_bound_memo&.insert(key, new_fid);
    
    self.curry_const_args_inner(original_f, new_fid, f_expr, arg_expr, 0)
}

fn curry_const_args_inner(self: *SelfHosted, original_f: FuncId, new_fid: FuncId, f_expr: *FatExpr, arg_expr: *FatExpr, initial_removed_count: i64) Maybe(FuncId) = {
    @log_event("work baking const args % -> %", original_f, new_fid) self;
    func := self.get_function(new_fid);
    old_func := self.get_function(original_f);
    original_arg_count := old_func.arg.bindings.len();
    ::if(Maybe(FuncId));
    if original_arg_count == 1 {
        assert(initial_removed_count == 0, "TODO: removed_count single");
        binding := func.arg.bindings[0]&;
        @debug_assert_eq(binding.kind, .Const);
        name := or binding.var() {
            return(@err("arg needs name (unreachable?)"))
        };
        // TODO: if you yield here, you spam clone the function. 
        arg_type := or @check(self.infer_type(binding.ty&)) return {
            @err_assert(func.get_flag(.AllowRtCapture), "only closure may have polymorphic args") return;
            @check(self.compile_expr(arg_expr, .None)) return;
            // It was .Infer, save what we learned for when we try to call get_type_for_arg. 
            // TODO: since there's only one argument you could even save this on the original template? 
            binding.ty = (Finished = arg_expr.ty);
            arg_expr.ty
        };
        value := @check(self.immediate_eval_expr(arg_expr, arg_type)) return;
        @check(self.bind_const_arg(new_fid, name, value, arg_expr.ty, arg_expr.loc)) return;

        func.finished_arg = .None;  // TODO: we know its void because we removed the only argument.
        fid_value := self.to_values(FuncId, new_fid);
        f_expr.set(fid_value, FuncId);
        arg_expr.set(unit_value, void);
        func.unset_flag(.AnyConstArgs);
        func.unset_flag(.Generic);
        (Ok = new_fid)
    } else {
        if(!arg_expr.expr&.is(.Tuple), => return(@err("TODO: pattern match on non-tuple")));
        removed_count := 0;
        range(0, original_arg_count) { i |
            continue :: local_return;
            
            b := func.arg.bindings[i - removed_count]&;
            if removed_count < initial_removed_count {
                if b.kind == .Const {
                    removed_count += 1;
                };
                continue();
                
            };
            
            @log_event("%: check %/%", i, i-removed_count, original_arg_count) self;
            arg_expr := arg_expr.expr.Tuple[i]&;
            if b.kind != .Const {
                if b.ty&.is(.Infer) {
                    // No correctness reason for this requirement but it seems fair to me. -- Aug 2
                    self.last_loc = arg_expr.loc;
                    @err_assert(func.get_flag(.AllowRtCapture), "only closure may have polymorphic args %", func.log(self.pool)) return;
                    @check(self.compile_expr(arg_expr, .None)) return;
                    b.ty = (Finished = arg_expr.ty);
                };
                continue();
            };
            name := or b.var() {
                return(@err("arg needs name (unreachable?)"))
            };
            @log_event("bake arg %: %", i, name&.log(self.pool)) self;
            // TODO: if you yield here, you spam clone the function. 
            
            // We might not be able to know the types expected for each parameter up front (because they can reference previous consts),
            // but once we're binding an argument, we need to be able to get its type. 
            // (TODO: closures are allowed to infer so that's not even true in the long term?)
            xx := @check(self.infer_type(b.ty&)) return;
            arg_type := or xx {
                self.last_loc = func.loc;
                @err_assert(func.get_flag(.AllowRtCapture), "only closure may have polymorphic args") return;
                @check(self.compile_expr(arg_expr, .None)) return;
                // It was .Infer, save what we learned for when we try to call get_type_for_arg. 
                b.ty = (Finished = arg_expr.ty);
                arg_expr.ty
            };
            value := @check(self.immediate_eval_expr(arg_expr, arg_type)) return;
            
            // bind_const_arg handles adding closure captures.
            // since it needs to do a remap, it gives back the new argument names so we can adjust our bindings acordingly. dont have to deal with it above since there's only one.
            @check(self.bind_const_arg(new_fid, name, value, arg_type, arg_expr.loc)) return;
            // No remove from arg here because bind_const_arg calls remove_named.
            removed_count += 1;
        };
        @debug_assert_ne(new_fid, original_f);

        // We're leaving it to the caller to infer the new type and type-check the runtime arguments. 
        fid_value := self.to_values(FuncId, new_fid);
        f_expr.set(fid_value, FuncId);
        func.unset_flag(.AnyConstArgs);
        func.unset_flag(.Generic);
        @check(self.remove_const_args(original_f, arg_expr)) return;
        // Don't need to explicitly force capturing because bind_const_arg added them if any args were closures.
        (Ok = new_fid)
    }
}

// The argument type is evaluated in the function declaration's scope, the argument value is evaluated in the caller's scope.
fn bind_const_arg(self: *SelfHosted, o_f: FuncId, arg_name: Var, arg_value: Values, arg_ty_found: Type, loc: Span) Maybe(void) = {
    // I don't want to renumber, so make sure to do the clone before resolving.
    // TODO: reslove captured constants anyway so dont haveto do the chain lookup redundantly on each speciailization. -- Apr 24
    @log_event("Bind $% = %", arg_name&.log(self.pool), arg_value&) self;
    func := self.get_function(o_f);
    @debug_assert(func.get_flag(.ResolvedBody) && func.get_flag(.ResolvedSign));
    arg_ty := @check(self.get_type_for_arg(func.arg&, arg_name)) return;
    
    //assert(arg_ty_found == arg_ty, "TODO: better type-check");
    //self.type_check_arg(arg_ty_found, arg_ty, "bind arg")?;
    @check(self.can_assign(arg_ty, arg_ty_found)) return;

    is_function := !(!self.get_type(arg_ty).is(.Fn) && arg_ty != FuncId);
    // TODO: not sure if i actually need this but it seems like i should.
    if is_function {
        @err_assert(!func.get_flag(.NoInline), "functions with constant lambda arguments are always inlined") return;
        arg_func := FuncId.assume_cast(arg_value&)[];
        // :ChainedCaptures
        // TODO: HACK: captures aren't tracked properly.
        func.set_flag(.MayHaveAquiredCaptures);
        self[o_f].cc = (Some = .Inline); // just this is enough to fix chained_captures
        self[arg_func].cc = (Some = .Inline); // but this is needed too for others (perhaps just when there's a longer chain than that simple example).
        
        // If we're passing a lambda arg, infer its return type based on the param's hint (not just the callsite). 
        //      f :: fn(x: @Fn() @enum(a, b)) void = { x(); } // callsite doesn't give a hint because statement discards value. 
        //      f(=> .a);  // declaration site doesn't give a hint
        @if_let(self.get_type(arg_ty)) fn Fn(f_ty) => {
            arg_func := self.get_function(arg_func);
            if arg_func.ret&.is(.Infer) {
                arg_func.ret = (Finished = f_ty.ret);
                arg_func.finished_ret = (Some = f_ty.ret);
            };
        };
    };
    @check(self.save_const_values(arg_name, arg_value, arg_ty, loc)) return;
    func.arg&.remove_named(arg_name, self.get_alloc());

    // If it was fully resolved before, we can't leave the wrong answer there.
    // But you might want to call bind_const_arg as part of a resolving a generic signeture so its fine if the type isn't fully known yet.
    func.finished_arg = .None;
    .Ok
}

/// It's fine to call this if the type isn't fully resolved yet.
/// We just need to be able to finish infering for the referenced argument.
fn get_type_for_arg(self: *SelfHosted, arg: *Pattern, arg_name: Var) Maybe(Type) #once = {
    each arg.bindings { arg | 
        if arg.var() { name | 
            if name == arg_name {
                ty := or @check(self.infer_type(arg.ty&)) return {
                    return(@err("called get_type_for_arg on .Infer-ed arg type. expected type annotation."))
                };
                return(Ok = ty);
            };
        };
    };
    @err("missing argument %", arg_name&.log(self.pool))
}
    
fn infer_type(self: *SelfHosted, b: *LazyType) Maybe(?Type) = {
    @match(b) {
        fn PendingEval(e) => {
            ty := @check(self.immediate_eval_expr(e, Type)) return; // :get_or_create_type
            ty := Type.assume_cast(ty&)[]; 
            b[] = (Finished = ty);
            (Ok = (Some = ty))
        }
        fn Finished(ty) => (Ok = (Some = ty[])); // cool, we're done. 
        fn EvilUninit() => panic("ICE: nothing creates this: eviluninit binding"); 
        fn Returning(_) => return(@err("ICE: tried to infer on LazyType.Returning... figure out what to do about that..."));
        fn Infer() => (Ok = .None);
    }
}

fn infer_type(self: *SelfHosted, bindings: *Pattern) Maybe([]Type) = {
    types: List(Type) = list(bindings.bindings.len, temp());
    each bindings.bindings { b |
        ty := or @check(self.infer_type(b.ty&)) return {
            // TODO: really thats not what you want for closures tho... 
            return(@err("function arguments must have type annotation (cannot be inferred)"))
        };
        types&.push(ty);
    };
    (Ok = types.items())
}

fn infer_arguments(self: *SelfHosted, fid: FuncId) Maybe(Type) = {
    func := self.get_function(fid);
    if(func.finished_arg, fn(ty) => return(Ok = ty));
    @check(self.ensure_resolved_sign(fid)) return;
    
    types := @check(self.infer_type(func.arg&)) return;
    ty := self.tuple_of(types);
    func.finished_arg = (Some = ty);
    (Ok = ty)
}

fn get_arg_types_non_blocking(func: *Func, args: *List(ResultType)) void #once = {
    args.clear();
    for func.arg.bindings { b | 
        @match(b.ty&.ty()) {
            fn Some(ty) => args.push(Specific = ty);
            fn None()   => args.push(.None);
        };
    };
}

fn infer_arguments_partial(self: *SelfHosted, fid: FuncId) Maybe(ResultType) = {
    func := self.get_function(fid);
    if(func.finished_arg, fn(ty) => return(Ok = (Specific = ty)));
    @check(self.ensure_resolved_sign(fid)) return;
    
    args: List(ResultType) = list(func.arg.bindings.len, temp());
    all_known := true;
    each func.arg.bindings { b |
        @match(@check(self.infer_type(b.ty&)) return) {
            fn Some(known) => args&.push(Specific = known);
            fn None() => {
                args&.push(.None);
                all_known = false;
            }
        };
    };
    if all_known {
        ty := @check(self.infer_arguments(fid)) return;
        return(Ok = (Specific = ty));
    };
    (Ok = (Tuple = args.items()))
}

fn infer_return(self: *SelfHosted, fid: FuncId) Maybe(Type) = {
    func := self.get_function(fid);
    if(func.finished_ret, fn(ty) => return(Ok = ty));
    @check(self.ensure_resolved_sign(fid)) return;
    
    ty := or @check(self.infer_type(func.ret&)) return {
        // Infer is a valid return type. To deal with that, we just compile the body, and that will set the finished_ret for us. 
        self.dispatch.function_in_progress&.set(fid.as_index());
        return(Suspend = self.wait_for(CompileBody = fid))
    };
    func.finished_ret = (Some = ty);
    (Ok = ty)
}

fn arity(self: *SelfHosted, expr: *FatExpr) i64 = {
    @match(expr.expr&) {
        fn Tuple(parts) => parts.len;
        // I think this isn't really what you want. 
        //fn As(f) => {
        //    value := self.poll_in_place(Values, => self.immediate_eval_expr(f.type, Type));
        //    value := value.unwrap();
        //    type := Type.assume_cast(value&)[];
        //    count := self.arg_types(type).len();
        //    println(count);
        //    count
        //}
        @default => 1;
    }
} 

fn type_of(self: *SelfHosted, expr: *FatExpr) Maybe(Type) = {
    if(!expr.ty.is_unknown(), => return(Ok = expr.ty));
    @match(expr.expr&) {
        fn Block(f) => self.type_of(f.result);
        fn Deref(inner) => {
            ptr := @check(self.type_of(inner[])) return;
            (Ok = self.unptr_ty(ptr).or(=> return(@err("deref non ptr"))))
        }
        fn Addr(inner) => {
            ty := @check(self.type_of(inner[])) return;
            (Ok = self.ptr_ty(ty))
        }
        fn Quote() => (Ok = @unwrap(self.env.fat_expr_type, "quote during boot") return);
        fn As(f) => {
            type := @check(self.immediate_eval_expr(f.type, Type)) return;
            type := Type.assume_cast(type&)[];
            (Ok = type)
        }
        fn GetVar(name) => {
            val_ty := self.scopes.get_var_type(name[]);
            (Ok = val_ty.or(=> return(@err("type_of pending var: %", self.pool.get(name.name)))))
        }
        @default => @err("failed to guess type"); 
    }
}

fn adjust_named_arguments(self: *SelfHosted, fid: FuncId, arg_expr: *FatExpr) Res(void) = {
    @if_let(arg_expr.expr&) fn StructLiteralP(f) => {
        func := self.get_function(fid);
        // If there's one argument, they must be passing a struct, we don't care about that here.
        if func.arg.bindings.len == 1 && f.bindings.len != 1 {
            return(.Ok);
        };
        args: List(FatExpr) = list(func.arg.bindings.len, self.get_alloc());
        enumerate func.arg.bindings { i, want |
            continue :: local_return;
            want_name := @unwrap(want.ident(), "function param must have name") return;
            each f.bindings { found | 
                found_name := @unwrap(found.ident(), "TODO: mixed named and un-named args are not supported yet") return;
                if found_name == want_name {
                    value := @unwrap(found.default, "use '=' not ':' for named arg") return;
                    @err_assert(args.len == i, "TODO: out of order named args are not supported yet") return;
                    args&.push(value);
                    continue();
                };
            };
            return(@err("arg not found for %", self.pool.get(want_name)));
        };
        arg_expr.expr = (Tuple = args.rs());
        arg_expr.done = false;
        arg_expr.ty = UnknownType;
        @log_event("after named %", arg_expr.log(self.pool)) self;
    };
    .Ok
}

// TODO: need to check for conflicts somehow but we can't assume we're able to infer all the options here,
//       because there might be cycles or more might be added later. 
//       do i need to keep a list of all the (os, arg_ty -> fn) and check at the end?
fn resolve_in_overload_set(self: *SelfHosted, arg_expr: *FatExpr, requested_ret: ResultType, i: OverloadSet) Maybe(FuncId) = {
    self.last_loc = arg_expr.loc;
    want_arity := self.arity(arg_expr);
    if want_arity == 1 {
        // There's no way we can get a hint from partial args (since theres only one), so yield early if needed.
        // However, you want `safety_check_enabled(.Bounds)` to work as long as its unambigous,
        // so we don't just compile_expr(arg_expr, .None) here
    };
    
    overloads := self.dispatch.overloads&.nested_index(i.as_index());
    self.compute_new_overloads(overloads);
    
    interesting: List(OverloadOption) = list(temp());
    @log_event("% total options", overloads.ready.len) self;
    each overloads.ready { opt | 
        continue :: local_return;
        @if_let(requested_ret) fn Specific(want) => {
            if opt.ret { have | 
                if self.can_assign(want, have).is_err() {
                    //@println("[%] ret discard % for %", i, self.log_type(have), self.log_type(want));
                    continue();
                };
            };
        };
        
        if opt.args.len != want_arity {
            if !arg_expr.expr&.is(.StructLiteralP) {
                continue();
            };
            // Maybe they're trying to pass named arguments. 
            have_parts := arg_expr.expr.StructLiteralP.bindings&;
            func := self.get_function(opt.func);
            want_parts := func.arg.bindings&;
            if want_parts.len != have_parts.len {| // TODO: allow default args
                continue();
            };
            
            // :SLOW
            each want_parts { want_b | 
                next :: local_return;
                want_name := want_b.ident().or(=> continue()); // idk if this ever happens but it sure can't be named argument
                each have_parts { have_b |
                    have_name := have_b.ident().or(=> continue()); // idk if this ever happens but it sure can't be named argument
                    if want_name == have_name {
                        next();
                    };
                };
                continue();
            };
        };
        
        interesting&.push(opt[]);
    };
    
    // TODO: but what if there are more overloads coming later? 
    if interesting.len == 1 {
        @log_event("chose overload %", interesting[0].func) self;
        func := self.get_function(interesting[0].func);
        @if(DEBUG_SPAM_LOG) self.codemap.show_error_line(func.loc);
        return(Ok = interesting[0].func);
    };
    
    ::if([]FatExpr);
    blocked: List(*Action) = list(temp());
    parts := if(arg_expr.expr&.is(.Tuple), => arg_expr.expr.Tuple.items(), => (ptr = arg_expr, len = 1));
    still_interesting: List(OverloadOption) = list(temp());
    errors: List(*ParseErr) = list(temp());
    each interesting& { opt | 
        continue :: local_return;
        func := self.get_function(opt.func);           
        if !func.get_flag(.Generic) {
            @match(self.infer_arguments(opt.func)) {
                fn Ok() => ();
                fn Err(e) => return(Err = e);
                fn Suspend(f) => {
                    blocked&.push(f); 
                    //still_interesting&.push(opt[]);
                    // TODO: this can't be right... if we suspended we shouldn't assume it won't match!
                    continue(); // we don't like it, we skip it.
                }
            };
        };
        
        if func.arg.bindings.len != want_arity {
            @debug_assert(arg_expr.expr&.is(.StructLiteralP), "expected kwargs");
            
            each func.arg.bindings { want_b | 
                next :: local_return;
                want_name := want_b.ident().or(=> continue()); // idk if this ever happens but it sure can't be named argument
                each arg_expr.expr.StructLiteralP.bindings& { have_b |
                    have_name := have_b.ident().or(=> continue()); // idk if this ever happens but it sure can't be named argument
                    if want_name == have_name {
                        arg_expr := have_b.default&.as_ref().unwrap();
                        if !func.get_flag(.Generic) {
                            @check(self.infer_type(want_b.ty&)) return;
                        };
                        if want_b.ty&.ty() { param | 
                            hint: ResultType = (Specific = param);
                            self.last_loc = arg_expr.loc;
                            @match(self.compile_expr(arg_expr, hint)) {
                                fn Suspend(f) => {
                                    blocked&.push(f); 
                                    //still_interesting&.push(opt[]);
                                    // TODO: this can't be right... if we suspended we shouldn't assume it won't match!
                                    continue(); // we don't like it, we skip it.
                                }
                                fn Err(e) => {
                                    errors&.push(e);
                                    continue();
                                }
                                fn Ok() => {
                                    if !arg_expr.ty.is_unknown() && self.can_assign(param, arg_expr.ty).is_err() {
                                        //@println("kwards discard % for %", self.log_type(arg_expr.ty), self.log_type(param));
                                        continue();
                                    };
                                }
                            };
                        };
                        next();
                    };
                };
                
                // Didn't find the arg
                continue();
            };
            // Found all the args and liked thier types
            still_interesting&.push(opt[]);
            continue();
        };
        
        enumerate func.arg.bindings { i, b | 
            arg_expr := parts.index(i);
            if !func.get_flag(.Generic) {
                @check(self.infer_type(b.ty&)) return;
            };
            if b.ty&.ty() { param | 
                // TODO: this isn't correct because it might make some irriversable choice based on the requested type.
                //       really you want to be able to check all the things with no type hint first, 
                //       then if you need more check with the hint but say its optional or something so it's more conservative. 
                //       like ContextualField`.a` -> Value`A.a` loses information.
                //       or just do it on a clone of the arg expr? -- Aug 2
                //       but you cant just clone here because then you'll never make progress if you yield while compiling it. 
                hint: ResultType = if(i == 0, => .None, => (Specific = param));
                self.last_loc = arg_expr.loc;
                @match(self.compile_expr(arg_expr, hint)) {
                    fn Suspend(f) => {
                        blocked&.push(f); 
                        //still_interesting&.push(opt[]);
                        //arg_expr[] = other;
                        // TODO: this can't be right... if we suspended we shouldn't assume it won't match!
                        continue(); // we don't like it, we skip it.
                    }
                    fn Err(e) => {
                        errors&.push(e);
                        //arg_expr[] = other;
                        continue();
                    }
                    fn Ok() => {
                        if !arg_expr.ty.is_unknown() && self.can_assign(param, arg_expr.ty).is_err() {
                            //@println("[%] discard % for %", i, self.log_type(arg_expr.ty), self.log_type(param));
                            //self.codemap.show_error_line(func.loc);
                            //arg_expr[] = other;
                            continue();
                        };
                        //arg_expr[] = other;
                    }
                };
            };
        };
        still_interesting&.push(opt[]);
    };
    
    swap_interestings :: fn() => {
        temp := still_interesting;
        still_interesting = interesting;
        interesting = temp;
        still_interesting&.clear();
    };
    check_still_interesting :: fn() => {
        if still_interesting.len == 1 {
            fid := still_interesting[0].func;
            @log_event("chose overload %", fid) self;
            func := self.get_function(fid);
            @if(DEBUG_SPAM_LOG) self.codemap.show_error_line(func.loc);
            return(Ok = fid);
        };
        swap_interestings();
    };
    
    check_still_interesting(); 
    //swap_interestings();
    
    @match(requested_ret) {
        fn Specific(want) => {
            each interesting& { opt | 
                continue :: local_return;
                func := self.get_function(opt.func);    
                // TODO: i dont want to check .Generic because i want to remove the need for the annotation eventually. 
                if !func.get_flag(.Generic) {
                    @match(self.infer_return(opt.func)) {
                        fn Ok() => ();
                        fn Err(e) => return(Err = e);
                        fn Suspend(f) => {
                            blocked&.push(f); 
                            //still_interesting&.push(opt[]);
                            // TODO: this can't be right... if we suspended we shouldn't assume it won't match!
                            continue(); // we don't like it, we skip it.
                        }
                    };
                };
                
                if func.finished_ret { found | 
                    if self.can_assign(want, found).is_err()  {
                        //@println("ret discard % for %", self.log_type(found), self.log_type(want));
                        continue();
                    };
                };
                still_interesting&.push(opt[]);
            };
        }
        @default => {
            temp := still_interesting;
            still_interesting = interesting;
            interesting = temp;
        };
    };
    
    check_still_interesting();
    
    if !blocked.is_empty() {
        @log_event("block len = %", blocked.len) self;
        return(Suspend = blocked[0]);  // TODO: return all? don't just pick one. 
    };
    ::?**ParseErr;
    if errors.items().last() { e: **ParseErr | 
        return(Err = e[]); // TODO: show all errors and say it was during overload resolution. 
    };
    
    // TODO: don't spam log since we might discard the error.
    @println("ambigous overload for arg % %", self.log_type(arg_expr.ty), arg_expr.log(self.pool));
    self.last_loc = arg_expr.loc;
    @println("% matching options", interesting.len);
    for interesting { opt |
        func := self.get_function(opt.func);
        @if(DEBUG_SPAM_LOG) self.codemap.show_error_line(func.loc);
        @println("- % -> %", self.log_type(func.finished_arg), self.log_type(func.finished_ret));
    };
    overloads := self.dispatch.overloads&.nested_index(i.as_index());
    @err("TODO: resolve_in_overload_set % %", self.pool.get(overloads.name), interesting.len)
}

fn log_type(self: *SelfHosted, ty: ?Type) Str = {
    @match(ty) {
        fn Some(ty) => self.log_type(ty);
        fn None() => "???";
    }
}

fn compute_new_overloads(self: *SelfHosted, overloads: *OverloadSetData) void  = {
    while => !overloads.pending.is_empty() {
        pending := overloads.pending.items().clone(temp());
        overloads.pending.len = 0;
        for pending { fid | 
            func := self.get_function(fid);
            args: List(ResultType) = list(func.arg.bindings.len, self.get_alloc());
            func.get_arg_types_non_blocking(args&);
            overloads.ready&.push((func = fid, args = args.items(), ret = func.finished_ret), self.get_alloc());
        };
    };
}

// - you want macros to be able to create new constant declarations in macro expansions and const arg functions.
// - for now constants are always stored globally and restricted visibility is just handled by scope resolution.
// So we delay taking constants until you try to compile the expression that contains them.
// Also, to be order independent, we don't actually evaluate or type-check them yet, that's done lazily the first time they're referenced. 
// TODO: the old compiler did #when here, but I think its better to delay until we know we care and can hope more stuff is ready. 
fn hoist_constants(self: *SelfHosted, body: []FatStmt) Maybe(void) #once = {
    each body { stmt |
        @match(stmt.stmt&) {
            fn DeclFunc(func) => {
                @debug_assert(func[].get_flag(.NotEvilUninit));
                // TODO: aren't the `@check`s below a problem because if they suspend you're totally fucked cause the function's gone but you might not know its overload set or whatever? 
                fid := self.add_function(func[][]);
                stmt.stmt = .Noop;
                func := self.get_function(fid);
                overload_out: ?OverloadSet = .None;
                
                // I thought i dont have to add to constants here because we'll find it on the first call when resolving overloads.
                // But it does need to have an empty entry in the overload pool because that allows it to be closed over so later stuff can find it and share if they compile it.
                if func.var_name& { var |
                    // TODO: allow function name to be any expression that resolves to an OverloadSet so you can overload something in a module with dot syntax.
                    // TODO: distinguish between overload sets that you add to and those that you re-export
                    @debug_assert(!func.get_flag(.ResolvedSign));
                    @debug_assert(!func.get_flag(.ResolvedBody));
                    // TODO: assert placeholdervalue
                    if self.is_empty_constant(var[]) {
                        // We're the first to reference this overload set so create it. 
                        i: OverloadSet = from_index(self.dispatch.overloads.len);
                        self.dispatch.overloads&.push(
                            ready = empty(),
                            name = var.name,
                            pending = fid.single(self.get_alloc()).rs(),
                        );
                        os_value := self.to_values(OverloadSet, i);
                        @check(self.save_const_values(var[], os_value, OverloadSet, func.loc)) return;  // :get_or_create_type
                        @log_event("create os % (%) for %", i.as_index(), var.log(self.pool), fid) self;
                        overload_out = (Some = i);
                    } else {
                        overloads := @check(self.find_const(var[], OverloadSet.want())) return;  // :get_or_create_type
                        i := OverloadSet.assume_cast(overloads._0&)[];
                        os := self.dispatch.overloads&.nested_index(i.as_index());
                        os.pending&.push(fid, self.get_alloc());
                        @log_event("add to os % (%) for %", i.as_index(), var.log(self.pool), fid) self;
                        overload_out = (Some = i);
                    };
                };
                
                @try(self.update_function_metadata(func, overload_out)) return;
            }
            fn DeclVar(f) => if f.name.kind == .Const {
                self.scopes.put_constant(f.name, f.value, f.ty);
                stmt.stmt = .Noop;
            };
            @default => ();
        }
    };
    .Ok
}

fn update_function_metadata(self: *SelfHosted, func: *Func, os: ?OverloadSet) Res(void) = {
    any_const_args :: fn(self: *Func) bool = {
        each self.arg.bindings { b |
            if(b.kind == .Const, => return(true));
        };
        false
    };
    if func.any_const_args() {
        func.set_flag(.AnyConstArgs);
    };

    each func.annotations { tag | 
        @switch(tag.name) {
            @case(Flag.fold.ident())     => func.set_flag(.TryConstantFold);
            @case(Flag.macro.ident())    => {
                func.set_flag(.Macro);
                func.set_flag(.ComptimeOnly);
            };
            @case(Flag.noinline.ident()) => func.set_flag(.NoInline);
            // TODO: generic+unsafe_noop_cast+cold are done in scope for old sema but i want to move them here. -- Jul 30
            @case(Flag.generic.ident())  => func.set_flag(.Generic);
            @case(Flag.cold.ident())     => func.set_flag(.Cold);
            @case(Flag.unsafe_noop_cast.ident()) => {
                func.set_flag(.UnsafeNoopCast);
                func.set_flag(.BodyIsSpecial);
            };
            @case(Flag.import.ident())   => func.set_flag(.BodyIsSpecial);
            @case(Flag.libc.ident())     => func.set_flag(.BodyIsSpecial);
            @case(Flag.redirect.ident()) => {
                os := @unwrap(os, "#redirect function only makes sense as part of an overload set") return;
                os := self.to_values(OverloadSet, os);
                expr := @unwrap(tag.args&.as_ref(), "#redirect requires argument") return;
                os := synthetic_ty((Value = (bytes = os, coerced = false)), expr.loc, OverloadSet);
                @err_assert(expr.expr&.is(.Tuple), "#redirect expected tuple") return;
                parts := expr.expr.Tuple&;
                parts.push(os, self.get_alloc());
                func.set_flag(.BodyIsSpecial);
            };
            // TODO: actually im not sure if its better to do this later...
            //       it would be nice to do only one pass over the annotations 
            //       but it would also be nice to do absolutely no work if you never try to call the function. 
            @case(Flag.comptime_addr.ident()) => {
                @err_assert(func.body&.is(.Empty), "#comptime_addr conflicts with body expression") return;
                func.set_flag(.BodyIsSpecial);
                func.set_flag(.ComptimeOnly);
            };
            @case(Flag.intrinsic.ident()) => {
                @err_assert(func.body&.is(.Empty), "#intrinsic conflicts with body expression") return;
                func.set_flag(.BodyIsSpecial);
            };
            @case(Flag.asm.ident()) => {
                @err_assert(!func.body&.is(.Empty), "#asm requires body expression") return;
                func.set_flag(.BodyIsSpecial);
            };
            @case(Flag.inline.ident()) => {
                // TODO: error on conflicting annotations. 
                func.cc = (Some = .Inline);
            };
            @case(Flag.ct.ident()) => {
                // TODO: error on conflicting annotations. 
                func.cc = (Some = .CCallRegCt);
                func.set_flag(.ComptimeOnly);
            };
            @default => ();
        };
    };
    
    if func.cc.is_none() {
        func.cc = (Some = .CCallReg);
    };
    .Ok
}

::if(Maybe(void));
::if_opt(Type, Maybe(void));
fn compile_get_var(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) #once = {
    @debug_assert(expr.expr&.is(.GetVar));
    var := expr.expr.GetVar;
    if var.kind == .Const {
        value, ty := @check(self.find_const(var, requested)) return;
        expr.set(value, ty);
        @check(self.coerce_const_expr(expr, requested)) return;
        .Ok
    } else {
        if self.scopes.get_var_type(var) { ty | 
            expr.ty = ty;
            expr.done = true;
            // Reading a variable. Convert it to `var&[]`. 
            ptr_ty := self.ptr_type(ty);
            expr[] = synthetic_ty((Addr = self.box(expr[])), expr.loc, ptr_ty);
            expr.done = true;
            // Note: not using deref_one, because don't want to just remove the ref, we want raw variable expressions to not exist. kinda HACK
            expr[] = synthetic_ty((Deref = self.box(expr[])), expr.loc, ty);
            expr.done = true;
            .Ok
        } else {
            // For now runtime vars are always declared in order so we always know thier type.
            // This might change to allow peeking into return-ed expressions when infering closure return type? -- Jul 15
            @err("Unknown type for runtime var %", self.pool.get(var.name))
        }
    }
}

// TODO: this is kinda weird. `fn` statements create an overload set or add to an existing one. 
fn is_empty_constant(self: *SelfHosted, name: Var) bool #once = {
    var := self.scopes.get_constant(name);
    var := or(var, => return(true));
    var._0.expr&.is(.Poison)
}

// Passing in the requested type here feels a bit weird, but I think it will make anon-functions less painful. 
fn find_const(self: *SelfHosted, name: Var, requested: ResultType) Maybe(Ty(Values, Type)) = {
    // If someone else is already trying to compile this, we don't want to fight over it. 
    if self.dispatch.const_var_in_progress&.get(name.id.zext()) {
        return(Suspend = self.wait_for(EvalConstant = (name = name, requested = requested)));
    };
    
    var := self.scopes.get_constant(name);
    if var& { var | 
        // If we've compiled this before, great.
        //     We can't coerce_constant here because we don't have a unique expression node to stick changes into if needed. 
        //     (need to change the expression to create function pointers because they might not be compiled yet)
        @if_let(var._0.expr&) fn Value(f) => {
            return(Ok = (f.bytes&.clone(self.get_alloc()), var._0.ty));
        };
    };
    
    self.dispatch.const_var_in_progress&.set(name.id.zext());
    
    // TODO: -- Jul 21
    // its sad to always yield here because _most_ of the time you could just do it now and it would be fine.
    // so an easy optimisation might be just trying now, if it wasn't already const_var_in_progress so we know nobody else is working on it. 
    // but since any _could_ yield, its a bug if we can't compile with _everything_ yielding,
    // so at least keep a flag to toggle this behaviour? 
    
    (Suspend = self.wait_for(EvalConstant = (name = name, requested = requested)))
}

fn find_const_non_blocking(self: *SelfHosted, name: Var) ?Ty(Values, Type) #once = {
    // If someone else is already trying to compile this, we don't want to fight over it. 
    if self.dispatch.const_var_in_progress&.get(name.id.zext()) {
        return(.None);
    };
    var := self.scopes.get_constant(name);
    var := or(var, => return(.None));
    @if_let(var._0.expr&) fn Value(f) => {
        return(Some = (f.bytes&.clone(self.get_alloc()), var._0.ty));
    };
    .None
}

fn handle_declare_constant(self: *SelfHosted, name: Var, ty: *LazyType, value: *FatExpr) Maybe(void) #once = {
    @debug_assert(self.dispatch.enclosing_function.is_none(), "ICE: handle_declare_constant should have no enclosing function");
    
    is_rec := value.expr&.is(.PrefixMacro) && value.expr.PrefixMacro.handler.ident() == (Some = Flag.rec.ident());
    
    want := ResultType.None;
    if @check(self.infer_type(ty)) return { known |
        want = (Specific = known);
        if(is_rec, => @err_assert(known == Type, "@rec expected Type") return);
    };
    
    // TODO: HACK that doesn't respect scoping!
    //       eventually it should just notice when a type tries to reference itself and switch to this path without the explicit @rec. 
    if is_rec {
        invocation := value.expr.PrefixMacro&;
        if invocation.arg.is_raw_unit() {
            invocation.arg[] = invocation.target[];
        };
        real_value_box := invocation.arg;
        hole := self.intern_type(.Placeholder);
        @log_event("% = @rec %", name&.log(self.pool), hole) self;
        val  := self.to_values(Type, hole);
        value.set(val, Type);
        // This can't just fallthrough and call update_placeholder at the end of this function like the old version did,
        // because we might suspend while compiling and then next time around we'll forget this value is special. 
        // (we'll just think its already done because we'll see the placeholder).
        return(Suspend = self.wait_for(FinishRecType = (hole = hole, name = name, value = real_value_box)))
    };
    
    @check(self.compile_expr(value, want)) return;
    
    if value.ty == UnknownType {
        return(@err("TODO: needed type hint for %", self.pool.get(name.name)));
    };
    if !value.expr&.is(.Value) {
        val := @check(self.immediate_eval_expr(value, value.ty)) return;
        value.set(val, value.ty);
    };
    
    @check(self.coerce_const_expr(value, want)) return;
    
    //@if_let(want) fn Specific(ty) => {
    //    @check(self.can_assign(ty, value.ty)) return;
    //};
    
    self.finish_layout_deep(value.ty).unwrap();
    
    .Ok
}

fn handle_finish_rec_type(self: *SelfHosted, hole: Type, name: Var, value: *FatExpr) Maybe(void) = {
    value := @check(self.immediate_eval_expr(value, Type)) return; // :get_or_create_type
    result_type := Type.assume_cast(value&)[];
    assert(result_type != hole, "ICE: @rec resolved to itself");
    self.update_placeholder(hole, result_type, name.name);
    @log_event("update_placeholder @rec % -> %", hole, result_type) self;
    .Ok
}

fn save_const_values(self: *SelfHosted, name: Var, value: Values, final_ty: Type, loc: Span) Maybe(void) = {
    self.save_const(name, (Value = (bytes = value, coerced = false)), final_ty, loc)
}

fn save_const(self: *SelfHosted, name: Var, val_expr: Expr, final_ty: Type, loc: Span) Maybe(void) #once = {
    @debug_assert(name.kind == .Const, "tried to save non-constant");
    // TODO: do i have to check if someone is already working on this constant? -- Jul 30
    val := self.scopes.get_constant(name);
    val := or val {
        // dup_var of return label in emit_capturing_call gets here.
        // eventually should remove the ? so its smaller and just do this there instead. 
        ptr := self.scopes.constants&.nested_index(name.id.zext());
        ptr[] = (Some = ((expr = (Poison = .Unknown), loc = loc, ty = UnknownType, done = false), .Infer));
        ptr.as_ref().unwrap()
    };
    
    if val._1&.is(.Finished) {
        return(@err("tried to re-save constant %", name&.log(self.pool)));
    };
    if !val._0.expr&.is(.Poison) {
        return(@err("tried to stomp constant %", name&.log(self.pool)));
    };
    
    val._0.expr = val_expr;
    val._0.ty = final_ty;
    val._1 = (Finished = final_ty);
    .Ok
}

// TODO: you can never do this to a constant directly in case its aliased once i have const ptrs. 
fn coerce_const_expr(self: *SelfHosted, expr: *FatExpr, req: ResultType) Maybe(void) = {
    if req.specific() { want | 
        found := expr.ty;
        if found != want {
            // can't do this because it mightn ot be a value
            //@assert(!expr.expr.Value.coerced, "const mismatch. % vs % but already coerced", self.log_type(found), self.log_type(want));
            // TODO: set coereced? 
            
            want_info := self.get_type(want);
            found_info := self.get_type(found);
            if found == OverloadSet {
                @if_let(want_info) fn Fn(f_ty) => {
                    os := @check(self.immediate_eval_expr(expr, found)) return;
                    os := OverloadSet.assume_cast(os&)[];
                    fid := @check(self.resolve_by_type(os, f_ty[], expr.loc)) return;
                    fid_value := self.to_values(FuncId, fid);
                    expr.set(fid_value, want);
                    return(.Ok);
                };
                @if_let(want_info) fn FnPtr(f) => {
                    os := @check(self.immediate_eval_expr(expr, found)) return;
                    os := OverloadSet.assume_cast(os&)[];
                    fid := @check(self.resolve_by_type(os, f.ty, expr.loc)) return;
                    fid_value := self.to_values(FuncId, fid);
                    expr.set(fid_value, want);
                    e := self.box(expr[]);  // :fucked segfault if you inline this!!!!!! -- Aug 6
                    expr.expr = (FnPtr = e);
                    expr.ty = want;
                    expr.done = false;
                    return(.Ok);
                }
            };
            if want == FuncId {
                @if_let(found_info) fn Fn() => {
                    expr.ty = FuncId;
                    return(.Ok);
                };
            };
            
            if found == FuncId {
                @if_let(want_info) fn Fn(f_ty) => {
                    expr.ty = want;
                    // TODO: typecheck
                    return(.Ok);
                };
                @if_let(want_info) fn FnPtr(f_ty) => {
                    inner := self.box(expr[]);
                    expr.expr = (FnPtr = inner);
                    expr.done = false;
                    expr.ty = UnknownType;
                    // TODO: typecheck
                    return(self.compile_expr(expr, (Specific = want)));
                };
                if want == rawptr {
                    inner := self.box(expr[]);
                    expr.expr = (FnPtr = inner);
                    expr.done = inner.done;
                    expr.ty = rawptr;
                    // TODO: not calling compile_expr do i have to note that we took a pointer?
                    //       decide and then be consistant with the above. -- Aug 19
                    return(.Ok);
                };
            };
            
            @if_let(found_info) fn FnPtr(f_ty) => {
                if want == rawptr {
                    expr.ty = rawptr;
                    return(.Ok);
                };
            };
        
            @match(found_info) {
                fn Int(have_int) => {
                    @match(want_info) {
                        fn Int(want_int) => {
                            min, max := want_int[].range();
                            @err_assert(expr.expr&.is(.Value), "TODO: imm_eval const int cast") return;
                            value := expr.expr.Value.bytes&;
                            v := @try(value.int_value(have_int[])) return;
                            //@println(" % % %", min, max, v);
                            if v <= max && v >= min {
                                value.adjust_int_length(want_int);
                                expr.ty = want;
                                return(.Ok);
                            };
                        }
                        fn F64() => {
                            max := 1.shift_left(MANTISSA_DIGITS_f64) - 1;
                            min := -max; // TODO: is that true? 
                            @err_assert(expr.expr&.is(.Value), "TODO: imm_eval const int cast") return;
                            value := expr.expr.Value.bytes&;
                            i := @try(value.int_value(have_int[])) return;
                            if i <= max && i >= min {
                                expr.set(self.to_values(f64, i.float()), f64); // :get_or_create_type
                                return(.Ok);
                            };
                        }
                        fn F32() => { // TODO: copy paste
                            max := 1.shift_left(MANTISSA_DIGITS_f32) - 1;
                            min := -max; // TODO: is that true? 
                            @err_assert(expr.expr&.is(.Value), "TODO: imm_eval const int cast") return;
                            value := expr.expr.Value.bytes&;
                            i := @try(value.int_value(have_int[])) return;
                            if i <= max && i >= min {
                                f: f32 = i.float().cast();
                                expr.set(self.to_values(f32, f), f32); // :get_or_create_type
                                return(.Ok);
                            };
                        }
                        @default => ();
                    };
                }
                fn F64() => {
                    @match(want_info) {
                        fn Int(want_int) => {
                            @err_assert(expr.expr&.is(.Value), "TODO: imm_eval const int cast") return;
                            value := expr.expr.Value.bytes&;
                            vf := f64.assume_cast(value)[];
                            v := vf.int();
                            if v.float() == vf {
                                min, max := want_int[].range();
                                if v <= max && v >= min {
                                    value[] = self.to_values(i64, v);
                                    value.adjust_int_length(want_int);
                                    expr.ty = want;
                                    return(.Ok);
                                };
                            };
                        }
                        fn F32() => {
                            // TODO
                        }
                        @default => ();
                    };
                }
                @default => ();
            };
            res := self.can_assign(want, found);
            if res&.is(.Ok) {
                expr.ty = want;
                return(.Ok);
            };
            return(@err("TODO: coerce constant expected % but found %: % (might be an actual type error)", self.log_type(want), self.log_type(found), expr.log(self.pool)));
        };
    };
    .Ok
}

fn can_assign(self: *SelfHosted, want: Type, found: Type) Maybe(void) = {
    if(want == found, => return(.Ok));
    if(found == Never, => return(.Ok));
    want_info  := self.get_type(want);
    found_info := self.get_type(found);
    
    @match(found_info) {
        fn Fn(f) => {
            if want == FuncId {
                // TODO: typecheck!!
                return(.Ok);
            };
        }
        fn Label(f) => {
            if want == LabelId {
                // TODO: typecheck!!
                return(.Ok);
            };
        }
        @default => ();
    };
    @match(want_info) {
        fn Fn(f) => {
            if found == FuncId {
                // TODO: typecheck!!
                return(.Ok);
            };
        }
        fn Label(f) => {
            if found == LabelId {
                // TODO: typecheck!!
                return(.Ok);
            };
        }
        @default => ();
    };
    
    // TODO: dont allocate + fmt here beacause overload resolution spams this. 
    @err("Type Error") // : expected % found %", self.log_type(want), self.log_type(found))
    //@err("Type Error: expected % found %", self.log_type(want), self.log_type(found))
    
}

fn resolve_by_type(self: *SelfHosted, os: OverloadSet, f_ty: FnType, loc: Span) Maybe(FuncId) = {
    // TODO: mega HACK, should probably have a sperate codepath that doesn't want an expression. 
    types := self.arg_types(f_ty.arg);
    fake_args: List(FatExpr) = list(self.get_alloc());
    for types { ty |
        fake_args&.push(synthetic_ty(.Uninitialized, loc, ty));
    };
    fake_expr := synthetic_ty((Tuple = fake_args.rs()), loc, f_ty.arg);
    fid := @check(self.resolve_in_overload_set(self.box(fake_expr), (Specific = f_ty.ret), os)) return;
    (Ok = fid)
}

::?FnType;
fn immediate_eval_expr(self: *SelfHosted, expr: *FatExpr, ret_ty: Type) Maybe(Values) = {
    self.last_loc = expr.loc;
    @log_event("imm_eval %", expr.log(self.pool)) self;
    @debug_assert(!ret_ty.is_unknown(), "immediate_eval_expr unknown");
    old_func := self.dispatch.enclosing_function;
    self.dispatch.enclosing_function = .None;
    ::?Values;
    if self.check_quick_eval(expr, ret_ty) { val |
        self.dispatch.enclosing_function = old_func;
        return(Ok = val);
    };
    
    // Can't just try to compile_expr here!
    // Since were evaluating in const context, any functions that are called in the expression weren't added to anyone's callees. 
    // So we want to say we need to recompile the expression, adding to callees of the lit_fn we're about to make. 

    // If its already a trivial function call, there's nothing else we can do to simplify, 
    // so we have to just yield on the function. 
    @if_let(expr.expr&) fn Call(f) => {
        // TODO: `if self.check_quick_eval(f.arg, f_ty.arg) { arg_value |` 
        //       instead of requiring void so its consistant with the fn_ptr version.
        //       tho also the call_dynamic is kinda sketchy (can only handle simple cases) and 
        //       i could just get rid of it and always generate a function that passes the arguments.    -- Jul 31
        if f.arg.is_raw_unit() && f.f.expr&.is(.Value) && self.get_type(f.f.ty).is(.Fn).or(f.f.ty == FuncId) {
            fid := FuncId.assume_cast(f.f.expr.Value.bytes&)[];
            if self.aarch64&.get_fn(fid) { fn_ptr | 
                hack := self&;
                args: RsVec(i64) = empty();
                func := self.get_function(fid);
                @debug_assert(!func.get_flag(.AnyConstArgs));
                // TODO: it would be nice if this were true... 
                //@if_let(func.body) fn Normal(expr) => {
                //    @debug_assert(expr.done);
                //};
                f_ty := func.finished_ty().expect("known type once compiled");
                if f.arg.ty != f_ty.arg {| // TODO
                    return(@err("TODO: type mismatch"));
                };
                @debug_assert(func.cc.unwrap() == .CCallReg, "expected cc CCallReg");
                self.aarch64&.bump_dirty();
                @log_event("imm_eval direct % %", fid.as_index(), self.pool.get(func.name)) self;
                // SAFETY: we're passing comp_ctx=false so it won't try to use the pointer as a real CompilerRs.
                result := hack&.call_dynamic(fn_ptr.int_from_rawptr(), f_ty&, args&, false);
                self.dispatch.enclosing_function = old_func;
                if result&.is(.Err) {
                    return(Err = self.box(result.Err));
                };
                expr.expr = (Value = (bytes = result.Ok&.deep_clone(self.get_alloc()), coerced = false));
                return(Ok = result.Ok);
            };
            self.dispatch.enclosing_function = old_func;
            return(Suspend = self.wait_for(Jit = fid));
        };
    };
    
    // Different from the version in check_quick_eval because this accepts unfinished ones too. 
    // This is just an optimisation to avoid an intermediate Func on the first use of a given constant. 
    @if_let(expr.expr&) fn GetVar(name) => {
        if name.kind == .Const {
            self.dispatch.enclosing_function = old_func;
            return(Suspend = self.wait_for(EvalConstant = (name = name[], requested = (Specific = ret_ty))));
        };
    };
    
    // The expression is too complex to deal with here. 
    // So box it into a function, compile that normally, and then just call into it with no arguments when we come around again.
    // This operation is make_lit_function from the old compiler. 
    // We know we'll yield to compile the new function, and don't want its body to alias the old expr. 
    
    bindings: List(Binding) = list(self.get_alloc());
    bindings&.if_empty_add_unit();
    arg: Pattern = (bindings = bindings.rs(), loc = expr.loc);
    def: FnDef = (name = .None, arg = arg, ret = (Finished = ret_ty), tags = list(temp()), loc = expr.loc);

    // we might have already tried to compile the expression in a different context,
    // but we need to do it again so we're sure to add callees to the newly created function,
    // so we don't try to call something that isn't compiled yet. 
    walk: MarkNotDone = (_hack = 0);
    walk&.walk_expr(expr);
    
    fake_func := make_func(def, (Some = expr[]), false);
    // We didn't bother setting a scope because we don't need one, the expression will already have been resolved. 
    fake_func&.set_flag(.ResolvedBody);
    fake_func&.set_flag(.ResolvedSign);
    fake_func&.set_flag(.SyntheticImmEval);
    fake_func&.set_flag(.ComptimeOnly);
    // Since we know this function has no args, we'll always fold it. 
    // This makes sure that if we start analyzing the expression without noticing that its actually in const-context,
    // we won't add a callee that becomes unnecessary when the function call gets reduced to an inlined value eventually. 
    // This fixes a bunch of .ComptimeOnly callees that the AOT backends choke on.  -- Aug 21
    // The SyntheticImmEval is used to prevent a loop where we try to fold by calling imm_eval on inner nested expressions? maybe?
    // TODO: i cant quite understand why, but you need something like that even if you don't add this extra TryConstFold. 
    // TODO: this introduces a ICE: Tried to call un-compiled function. for the test `floats`
    //       happens at `assert_eq(5.neg(), 5.7.neg().int());` and only if neg is #fold
    fake_func&.set_flag(.TryConstantFold);
    fake_func.finished_arg = (Some = void);
    fake_func.finished_ret = (Some = ret_ty);
    fake_func.cc = (Some = .CCallReg);    
    fid := self.add_function(fake_func);
    @log_event("imm eval wait for lit %: %", fid, expr.log(self.pool)) self;
    f_value := self.to_values(FuncId, fid);
    f_e: Expr = (Value = (bytes = f_value, coerced = false));
    f_expr := self.box(synthetic_ty(f_e, expr.loc, FuncId));
    expr.expr = (Call = (f = f_expr, arg = self.make_unit_expr(expr.loc)));  // so we try this task again, we get an easy function call.
    expr.done = false;
    self.dispatch.enclosing_function = old_func;
    (Suspend = self.wait_for(Jit = fid))
}

fn check_quick_eval(self: *SelfHosted, expr: *FatExpr, ret_ty: Type) ?Values = {
    @match(expr.expr&) {
        fn Value(f) => (Some = f.bytes&.clone(self.get_alloc()));
        fn GetVar(f) => {
            if f.kind == .Const {
                // This is a super common case because you type `arg: i64` a lot. 
                res := self.find_const_non_blocking(f[]);
                if res { f |
                    // We can't report a type erorr from here so just let the slow path deal with it. 
                    if(ret_ty == f._1, => return(Some = f._0));
                };
            };
            .None
        }
        fn Block(it) => {
            if it.body.is_empty() {
                return(self.check_quick_eval(it.result, ret_ty));
            };
            .None
        }
        fn Tuple(parts) => {
            all: List(u8) = list(self.get_alloc());
            each parts { part |
                // TODO: tuple_types
                val := or self.check_quick_eval(part, part.ty) {
                    return(.None)
                };
                // Required since deconstruct_values (which we use for dyn_call) expects correctly aligned fields. 
                self.aligned_append_value(all&, val, part.ty);
            };
            (Some = (Big = all.rs()))
        }
        fn Call(it) => {
            if it.f.expr&.is(.Value) {
                @if_let(self.get_type(it.f.ty)) fn FnPtr(f) => {
                    if self.check_quick_eval(it.arg, f.ty.arg) { arg_value |
                        if it.arg.ty != f.ty.arg {| // TODO
                            return(.None);
                        };
                        f_ptr := i64.assume_cast(it.f.expr.Value.bytes&)[];
                        // SAFETY: we're passing comp_ctx=false so it won't try to use the pointer as a real CompilerRs.
                        evil_hack := self;
                        evil_hack := self&;
                        self.finish_layout_deep(it.f.ty);
                        res := evil_hack&.call_dynamic_values(f_ptr, f.ty&, arg_value&.bytes(), false);
                        @match(res) {
                            fn Ok(res) => {
                                expr.set(res&.clone(self.get_alloc()), f.ty.ret);
                                return(Some = res);
                            }
                            fn Err(e) => {
                                @println("ERROR: %", e.msg);
                            } // TODO: don't just swollow errors
                        }
                    };
                };
                
                @if_let(self.get_type(it.f.ty)) fn Fn(f) => {
                    if self.check_quick_eval(it.arg, f.arg) { arg_value |
                        if it.arg.ty != f.arg {| // TODO
                            return(.None);
                        };
                        f_id := FuncId.assume_cast(it.f.expr.Value.bytes&)[];
                        if self.aarch64&.get_fn(f_id) { f_ptr |
                            func := self.get_function(f_id);
                            comp_ctx := func.cc.unwrap() == .CCallRegCt;
                            evil_hack := self;
                            evil_hack := self&; 
                            self.finish_layout_deep(it.f.ty);
                            self.aarch64&.bump_dirty();
                            res := evil_hack&.call_dynamic_values(f_ptr.int_from_rawptr(), f, arg_value&.bytes(), comp_ctx);
                            @match(res) {
                                fn Ok(res) => {
                                    expr.set(res&.clone(self.get_alloc()), f.ret);
                                    return(Some = res);
                                }
                                fn Err(e) => {
                                    @println("ERROR: %", e.msg);
                                } // TODO: don't just swollow errors
                            }
                        };
                    };
                };
            };
            .None
        }
        @default => .None;
    }
}

fn create_slice_type(self: *SelfHosted, inner: Type, loc: Span) Maybe(Type) = {
    @log_event("Create slice %", inner) self;
    arg_value := self.to_values(Type, inner);  // :get_or_create_type
    f_value := self.to_values(FuncId, @unwrap(self.env.make_slice_t, "slice type not ready!") return);  // :get_or_create_type
    arg: FatExpr = (expr = (Value = (bytes = arg_value, coerced = false)), loc = loc, ty = Type, done = true);
    f: FatExpr   = (expr = (Value = (bytes = f_value, coerced = false)), loc = loc, ty = FuncId, done = true);
    s_ty := synthetic_ty((Call = (f = self.box(f), arg = self.box(arg))), loc, Type);
    s_ty := self.box(s_ty);
    value := self.poll_in_place(Values, => self.immediate_eval_expr(s_ty, Type));
    value := @try(value) return;  // TODO: miscompilation if you inline this ^ :fucked
    (Ok = Type.assume_cast(value&)[])
}

///////////////////////
/// Macro Expansion ///

fn compile_prefix_macro(self: *SelfHosted, expr: *FatExpr) Maybe(void) #once = {
    // TODO: Bring back tag checks so i don't have to be paranoid!!
    //       this annoys be enough that im tempted to go back to inlining all of these. 
    //       tho maybe #once is reassuring enough. think about it. -- Jul 22
    @debug_assert(expr.expr&.is(.PrefixMacro)); 
    // TODO: you probably want this but constants don't have it (really they shouldn't be compiled without being wrapped in a function?)
    //@err_assert( self.dispatch.enclosing_function.is_some(), "ice: macro expansion must be in function context") return;
    invocation := expr.expr.PrefixMacro&;
    
    // This allows @a E; instead of @a(E);
    if invocation.arg.is_raw_unit() {
        temp := invocation.arg;
        invocation.arg = invocation.target;
        invocation.target = temp;
    };
    
    fat_expr_type := or self.env.fat_expr_type {
        return(self.early_builtin_prefix_macro(expr))
    };
    pair := self.tuple_of(@slice(fat_expr_type, fat_expr_type));
    
    self.finish_layout_deep(fat_expr_type).unwrap();
    
    @log_event("call user macro %", invocation.handler.log(self.pool)) self;
    single := invocation.target.is_raw_unit();
    if single {
        @log_event("macro input: %", invocation.arg.log(self.pool)) self;
    } else {
        @log_event("macro input: (%, %)", invocation.arg.log(self.pool), invocation.target.log(self.pool)) self;
    };
    
    @check(self.compile_expr(invocation.handler, .None)) return;
    if invocation.handler.ty == OverloadSet {
        os := @check(self.immediate_eval_expr(invocation.handler, OverloadSet)) return; // :get_or_create_type
        os := OverloadSet.assume_cast(os&)[];
        ::if(FnType); 
        f_ty: FnType = if single {|  // TODO: wrong! what if they actually passed unit?
            (arg = fat_expr_type, ret = fat_expr_type, arity = 1)
        } else {
            self.finish_layout_deep(pair).unwrap();
            (arg = pair, ret = fat_expr_type, arity = 2)
        };
        fid := @check(self.resolve_by_type(os, f_ty, invocation.handler.loc)) return;
        fid_value := self.to_values(FuncId, fid);
        invocation.handler.set(fid_value, FuncId);
    };
    
    fid := @check(self.immediate_eval_expr(invocation.handler, FuncId)) return; // :get_or_create_type
    fid := FuncId.assume_cast(fid&)[];
    func := self.get_function(fid);
    if !func.get_flag(.Macro) {
        self.codemap.show_error_line(func.loc);
    };
    @err_assert(func.get_flag(.Macro), "Tried to invoke non-macro % (missing #macro or missing overload)", self.pool.get(func.name)) return;
    fn_ptr := or self.aarch64&.get_fn(fid) {| 
        return(Suspend = self.wait_for(Jit = fid))
    };
    
    args: List(i64) = list(2, temp());
    args&.push(FatExpr.int_from_ptr(invocation.arg));
    args&.push(FatExpr.int_from_ptr(invocation.target));
    args := args.rs();
    
    hack := self&;
    needs_ct := func.cc.unwrap() == .CCallRegCt;
    self.last_loc = expr.loc;
    f_ty := func.finished_ty().expect("known type once compiled");
    assert(f_ty.ret == fat_expr_type, "tried to call macro with bad ret type. missing overload? \nresolve_in_overloadset assumes someone later will typecheck so giving a garabge match is fine");
    assert(f_ty.arg.eq(fat_expr_type).or(f_ty.arg == pair), "tried to call macro with bad arg type. missing overload? \nresolve_in_overloadset assumes someone later will typecheck so giving a garabge match is fine");
    self.aarch64&.bump_dirty();
    result := @try(hack&.call_dynamic_inner(fn_ptr.int_from_rawptr(), f_ty&, args&, needs_ct)) return;
    expr[] = FatExpr.assume_cast(result&)[];
    @log_event("macro output: %", expr.log(self.pool)) self;
    //walk: MarkNotDone = (_hack = 0);
    //walk&.walk_expr(expr); // TODO: might not need this :SLOW
    .Ok
}

// If we're early in bootstrapping and haven't compiled the FatExpr type yet, so some special handling.
fn early_builtin_prefix_macro(self: *SelfHosted, expr: *FatExpr) Maybe(void) = {
    invocation := expr.expr.PrefixMacro&;
    if !invocation.handler.expr&.is(.GetVar) {
        return(@err("macro calls must be GetVar while bootstrapping. tried to run something too compilicated too soon: %: %", invocation.handler.expr&.tag(), invocation.handler.log(self.pool)));
    };
    
    name := invocation.handler.expr.GetVar.name;
    @switch(name) {
        @case(Flag.builtin.ident()) => {
            expr[] = @try(self.builtin_macro(invocation.arg[])) return;
        };
        @case(Flag.struct.ident()) => {
            expr[] = @check(self.struct_macro(invocation.arg)) return;
        };
        @case(Flag.enum.ident()) => {
            expr[] = @check(self.enum_macro(invocation.arg, invocation.target)) return;
        };
        @case(Flag.tagged.ident()) => {
            @err_assert(invocation.target.is_raw_unit(), "@tagged expected single arg") return;
            expr[] = @check(self.tagged_macro(invocation.arg)) return;
        };
        @case(Flag.late.ident()) => {
            expr.set(unit_value, void); // :get_or_create_type
        };
        @default => {
            return(@err("tried to call non-builtin macro '%' while bootstrapping.", self.pool.get(name)));
        };
    };
    
    .Ok
}

fn builtin_macro(self: *SelfHosted, arg: FatExpr) Res(FatExpr) = {
    name := @unwrap(arg&.ident(), "@builtin arg must be String literal") return;
    value, type := @try(self.builtin_macro(name)) return;
    arg&.set(value, type);  // :get_or_create_type
    (Ok = arg)
}

fn builtin_macro(self: *SelfHosted, builtin_name: Symbol) Result(Ty(Values, Type), *ParseErr) = {
    builtin_type :: fn(T: Type) void => {
        ptr := T;  // :get_or_create_type
        val := ptr_cast_unchecked(Type, u32, ptr&)[];
        return(Ok = ((Small = (val.zext(), 4)), Type));  // :get_or_create_type
    };
    // These could call :get_or_create_type but it doesn't matter for now because these are hardcoded
    @switch(builtin_name) {
        @case(Flag.i64.ident())         => builtin_type(i64);
        @case(Flag.bool.ident())        => builtin_type(bool);
        @case(Flag.OverloadSet.ident()) => builtin_type(OverloadSet);
        @case(Flag.ScopeId.ident())     => builtin_type(ScopeId);
        @case(Flag.FuncId.ident())      => builtin_type(FuncId);
        @case(Flag.LabelId.ident())     => builtin_type(LabelId);
        @case(Flag.Symbol.ident())      => builtin_type(Symbol);
        @case(Flag.rawptr.ident())      => builtin_type(rawptr);
        @case(Flag.Type.ident())        => builtin_type(Type);
        @case(Flag.void.ident())        => builtin_type(void);
        @case(Flag.Never.ident())       => builtin_type(Never);
        @case(Flag.true.ident())        => return(Ok = (((Small = (1, 1)), bool)));
        @case(Flag.false.ident())       => return(Ok = (((Small = (0, 1)), bool)));
        @case(Flag.f64.ident())         => builtin_type(f64);
        @case(Flag.f32.ident())         => builtin_type(f32);
        @case(Flag.UnknownType.ident()) => builtin_type(UnknownType);
        @case(Flag.compiler_debug_assert_eq_i64.ident()) => {
            my_assert_eq: rawptr : fn(a: i64, b: i64) i64 = {
                assert_eq(a, b);
                a
            };
            ty := self.tuple_of(@slice(i64, i64));
            ty := self.intern_type(FnPtr = (ty = (arg = ty, ret = i64, arity = 2), cc = .CCallReg));
            return(Ok = ((Small = (my_assert_eq.int_from_rawptr(), 8)), ty));
        };
        @default => {
            return(@err("unknown @builtin '%'.", self.pool.get(builtin_name)));
        };
    };
    unreachable()
}

fn struct_type(self: *SelfHosted, pattern: *Pattern) Maybe(Type) #once = {
    fields: List(Field) = list(pattern.bindings.len, self.get_alloc());
    const_field_count := 0;
    each pattern.bindings { b | 
        name := b.ident().expect("field name");
        if b.kind == .Const {
            const_field_count += 1;
            if(b.default.is_none(), => return(@err("constant field % must have a value.", self.pool.get(name))));
        };
        
        ty := or @check(self.infer_type(b.ty&)) return {
            default := @unwrap(b.default&.as_ref(), "@struct field without type requires default value.") return;
            @check(self.compile_expr(default, .None)) return;
            default.ty
        };
        
        default: ?Var = .None;
        if b.default& { expr |
            v := self.unique_const(name);
            self.scopes.put_constant(v, expr[], (Finished = ty));
            default = (Some = v);
            expr.expr = (GetVar = v);  // Save our work because we might yield on a later field. 
        };
        fields&.push(
            name = name,
            ty = ty,
            default = default,
            byte_offset = 99999999999,
            kind = b.kind,
        );
    };
    (Ok = self.intern_type(Struct = (
        fields = fields.rs(),
        layout_done = false,
        is_tuple = false,
        const_field_count = const_field_count.trunc(),
    )))
}

fn struct_macro(self: *SelfHosted, fields: *FatExpr) Maybe(FatExpr) = {
    if(!fields.expr&.is(.StructLiteralP), => return(@err("expected map literal: (name: Type, ... ) for @struct")));
    ty := @check(self.struct_type(fields.expr.StructLiteralP&)) return;
    ty_value := self.to_values(Type, ty);
    fields.set(ty_value, Type); // :get_or_create_type
    (Ok = fields[])
}

fn enum_macro(self: *SelfHosted, arg: *FatExpr, target: *FatExpr) Maybe(FatExpr) = {
    type := @check(self.immediate_eval_expr(arg, Type)) return; // :get_or_create_type
    type := Type.assume_cast(type&)[];

    F :: Ty(Symbol, Values);
    fields: List(F) = list(self.get_alloc());
    as_int: ?IntTypeInfo = @match(self.get_type(type)) {
        fn Int(it) => (Some = it[]);
        @default => .None;
    };
    sequential := as_int.is_some();
    last := -1;
    @match(target.expr&) {
        fn StructLiteralP(pattern) => {
            each pattern.bindings { b | 
                name := @unwrap(b.ident(), "@enum case requires name") return;
                @err_assert(b.default.is_some(), "@enum expected case value") return;
                @err_assert(b.ty&.is(.Infer), "@enum case cannot have type annotation (use '=' instead of ':'") return;

                expr := b.default&.as_ref().unwrap();
                val  := @check(self.immediate_eval_expr(expr, type)) return;
                if sequential {
                    current := @try(val&.int_value(as_int.unwrap())) return;
                    if current == last + 1 {
                        last += 1;
                    } else {
                        sequential = false;
                    };
                };
                fields&.push(@as(F) (name, val));
            };
        }
        fn Tuple(names) => {
            @err_assert(sequential, "@enum on tuple of names must be of int type") return;
            //@err_assert(type == i64, "TODO: @enum(other-int-types)(Tuple)") return;
            enumerate names { i, name |
                name := @unwrap(name.ident(), "@enum expected ident") return;
                value := self.to_values(i64, i); // :get_or_create_type
                fields&.push(@as(F) (name, value));
            };
        }
        @default => return(@error("@enum expected struct literal or tuple of names"));
    };
    unique_ty := self.intern_type(Enum = (raw = type, fields = fields.rs(), sequential = sequential));
    ty_value := self.to_values(Type, unique_ty); // :get_or_create_type
    arg.set(ty_value, Type);
    (Ok = arg[])
}

fn tagged_macro(self: *SelfHosted, cases_expr: *FatExpr) Maybe(FatExpr) = {
    @err_assert(cases_expr.expr&.is(.StructLiteralP), "@tagged expected map literal like `(name: Type, ...)`") return;
    pattern := cases_expr.expr.StructLiteralP&;
    
    F :: Ty(Symbol, Values);
    C :: Ty(Symbol, Type);
    tag_fields: List(F) = list(self.get_alloc());
    cases: List(C) = list(self.get_alloc());
    enumerate pattern.bindings { i, b |
        // TODO: allow as default so you can use .Name like you can with void?
        //       then need to store default in TypeInfo::Tagged as well. -- Jul 5
        @err_assert(b.default.is_none(), "use ':' not '=' with @tagged") return;
        type := @check(self.infer_type(b.ty&)) return;
        type := or type {
            // @tagged(s: i64, n) is valid and infers n as void.
            b.ty = (Finished = void); // :get_or_create_type
            void
        };
        name := @unwrap(b.ident(), "@tagged field requires name") return;
        tag_value := self.to_values(i64, i);
        tag_fields&.push(@as(F) (name, tag_value)); // :tag_enums_are_sequential
        cases&.push(@as(C) (name, type))
    };
    
    tag_type := self.intern_type(Enum = (raw = i64, fields = tag_fields.rs(), sequential = true));
    tagged_type := self.intern_type(Tagged = (cases = cases.rs(), tag = tag_type));
    value := self.to_values(Type, tagged_type); // :get_or_create_type
    cases_expr.set(value, Type);
    (Ok = cases_expr[])
}

// TODO: track if we're in unquote mode or placeholder mode.
Unquote :: @struct(compiler: *SelfHosted, placeholders: List(FatExpr));

// :UnquotePlaceholders
:: WalkAst(Unquote, *ParseErr);

fn handle_expr(self: *Unquote, expr: *FatExpr) Result(DoMore, *ParseErr) #once = {
    @match(expr.expr) {
        fn Unquote(arg) => {
            //expr_ty := self.compiler.env.fat_expr_type.expect("used unquote ast while bootstrapping");
            // Note: take <arg> but replace the whole <expr>
            idx := self.placeholders.len;
            //@log_event("Placeholder(%) <- %", idx, arg.log(self.compiler.pool));
            self.placeholders&.push(arg[]);
            expr[] = (expr = (Placeholder = idx), loc = expr.loc, ty = UnknownType, done = false);
        }
        fn Placeholder(idx) => {
            @err_assert(idx < self.placeholders.len, "ICE: invalid unquote placeholder index %", idx) return;
            value := self.placeholders.index(idx); // TODO: make it more obvious that its only one use and the slot is empty.
            //@log_event("Placeholder(%) -> %", idx, value.log(self.compiler.pool));
            @err_assert(!value.expr&.is(.Poison), "ICE: missing placeholder for unquote") return;
            // This clone fixes a renumbering problem. :double_use_quote
            expr[] = value.deep_clone(self.compiler.get_alloc());
            value.expr = (Poison = .PlaceholderUsed);
            value.done = false;
        }
        fn Quote() => {
            // TODO: add a simpler test case than the derive thing (which is what discovered this problem).
            // Don't go into nested !quote. This allows having macros expand to other macro calls without stomping eachother.
            // TODO: feels like you might still end up with two going on at once so need to have a monotonic id number for each expansion stored in the !placeholder.
            //       but so far this is good enough.
            return(Ok = .Break);
        }
        @default => ();
    };
    (Ok = .Continue)
}
fn handle_stmt(self: *Unquote, stmt: *FatStmt) Result(DoMore, *ParseErr) #once = (Ok = .Continue);
fn handle_func(self: *Unquote, func: *Func)    Result(DoMore, *ParseErr) #once = (Ok = .Continue);
fn handle_type(self: *Unquote, ty: *LazyType)  Result(DoMore, *ParseErr) #once = (Ok = .Continue);
fn handle_pattern(self: *Unquote, p: *Pattern) Result(DoMore, *ParseErr) #once = (Ok = .Continue);
