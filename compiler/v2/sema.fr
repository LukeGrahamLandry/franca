// TODO: have first.fr pass vtable to #test if non-void argument. 

DEBUG_ALWAYS_BE_YIELDING :: false;

ResultType :: @tagged(
    Specific: Type,
    Returning: Type,
    None
);

fn compile_stmt(self: *SelfHosted, stmt: *FatStmt) Maybe(void) = {
    self.last_loc = stmt.loc;
    @match(stmt.stmt&) {
        fn Noop() => return(.Ok);
        fn Eval(expr) => return(self.compile_expr(expr, .None));
        fn DeclFunc(func) => return(@err("TODO: compile DeclFunc stmt"));
        fn DeclVar(f) => {
            assert(f.name.kind != .Const, "hit unhoisted constant");
            return(@err("TODO: compile DeclVar stmt"))
        }
        fn DeclVarPattern(f) => return(@err("TODO: compile DeclVarPattern stmt"));
        fn DeclNamed(f) => return(@err("TODO: compile DeclNamed stmt"));
        fn Set(f) => return(@err("TODO: compile Set stmt"));
        fn ExpandParsedStmts(f) => return(@err("TODO: compile ExpandParsedStmts stmt"));
    };
    unreachable_hack(Maybe(void))
}

fn compile_expr(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) = {
    self.last_loc = expr.loc;
    if(expr.done) {|
        assert(expr.ty != UnknownType, "done but unknown type");
        return(.Ok);
    };
    self.dispatch.active_stack.push(expr = expr, requested = requested);
    @if(DEBUG_ALWAYS_BE_YIELDING) {
        if !expr.debug_been_here_before {|
            expr.debug_been_here_before = true;
            return(Suspend = self.wait_for(CompileExpr = self.dispatch.active_stack));
        };
    };
    
    @match(expr.expr&) {
        fn Poison() => {
            return(@err("Poison expression"));
        }
        fn Value(f) => {
            if(expr.ty == UnknownType, => return(@err("ICE: Value expression must have known type")));
            if !f.coerced {|
                @if_let(requested) fn Specific(ty) => {
                    if expr.ty != ty {|
                        panic("TODO: coerce const");
                    };
                };
            };
            expr.done = true;
        }
        fn _WipFunc() => panic("WipFunc will be removed);
        fn Call() => {
            @check(self.compile_call(expr, requested)) return;
        }
        fn Block(f) => {
            if !f.hoisted_constants {|
                @check(self.hoist_constants(f.body.items())) return;
                f.hoisted_constants = true;
            };
            each f.body { stmt | 
                @check(self.compile_stmt(stmt)) return;
            };
            @check(self.compile_expr(f.result, requested)) return;
        }
        fn Tuple(parts) => {
            each parts { expr | 
                if !expr.done {|
                    req_part := panic("TODO: pass through tuple_types if known requested");
                    @check(self.compile_expr(expr, req_part)) return;
                };
            };
            if expr.ty == UnknownType {|
                expr.ty = panic("TODO: save tuple type");
            };
        }
        fn Closure() => return(@err("TODO: expression"));
        fn _AddToOverloadSet() => panic("AddToOverloadSet will be removed");
        fn SuffixMacro() => return(@err("TODO: expression"));
        fn FieldAccess() => return(@err("TODO: expression"));
        fn StructLiteralP() => return(@err("TODO: expression"));
        fn PrefixMacro() => {
            @check(self.compile_prefix_macro(expr)) return;
        }
        fn GetVar(var) => return(self.compile_get_var(expr, requested));
        fn GetNamed() => return(@err("TODO: expression"));
        fn String() => {
            // This is only different from a Value node because the 'Str' is not a builtin so the parser is unable to create it.
            byte := self.get_or_create_type(u8);
            expr.ty = @check(self.create_slice_type(byte)) return;
            panic("TODO: self.set_literal(expr, self.pool.get(i)");
            expr.done = true;
        }
        fn PtrOffset(_) => return(@err("ICE: PtrOffset should be done=true"));
        fn GetParsed() => return(@err("ICE: GetParsed is handled by scope.fr"));
        fn Cast() => return(@err("TODO: expression"));
    };
    self.dispatch.active_stack.pop();
    .Ok
}

fn compile_call(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) = {
    @debug_assert(expr.expr&.is(.Call));
    f := expr.expr.Call.f;
    arg := expr.expr.Call.arg;
    req_fn: ResultType = @match(requested) {
        fn Specific(t) => (Returning = t);
        @default => .None;
    };
    
    @check(self.compile_expr(f, req_fn)) return;
    
    ::if(ResultType);
    req_arg: ResultType = if(f.ty == UnknownType, => .None, => (Specific = f.ty));
    @check(self.compile_expr(f, req_arg)) return;
    
    .Ok
}

fn compile_prefix_macro(self: *SelfHosted, expr: *FatExpr) Maybe(void) = {
    @debug_assert(expr.expr&.is(.PrefixMacro));
    invocation := expr.expr.PrefixMacro&;
    fat_expr_type := or self.env.fat_expr_type {|
        // If we're early in bootstrapping and haven't compiled the FatExpr type yet, so some special handling.
        if !invocation.handler.expr&.is(.GetVar) {|
            return(@err("macro calls must be GetVar while bootstrapping. tried to run something too compilicated too soon."));
        };
        
        name := invocation.handler.expr.GetVar.name;
        @switch(name) {
            @case(Flag.builtin.ident()) => {
                if !invocation.arg.expr&.is(.String) {|
                    return(@err("@builtin arg must be String literal"));
                };
                builtin_name := invocation.arg.expr.String;
                @println("called builtin %", self.pool.get(builtin_name));
                @switch(builtin_name) {
                    @case(Flag.i64.ident()) => {
                        ptr := i64;
                        val := ptr_cast_unchecked(Type, u32, ptr&)[];
                        expr.set((Small = (val.zext(), 4)), i64);
                    };
                    @case(Flag.compiler_debug_assert_eq_i64.ident()) => {
                        my_assert_eq: rawptr : fn(a: i64, b: i64) i64 = {
                            println("Hello World!");
                            assert_eq(a, b);
                            a
                        };
                        ty := self.tuple_of(@slice(i64, i64));
                        ty := self.intern_type(FnPtr = (ty = (arg = ty, ret = i64, arity = 2), cc = .CCallReg));
                        expr.set((Small = (my_assert_eq.int_from_rawptr(), 8)), ty);
                    };
                    @default => {
                        return(@err("unknown @builtin '%'.", self.pool.get(builtin_name)));
                    };
                };
            };
            @default => {
                return(@err("tried to call non-builtin macro '%' calls while bootstrapping.", self.pool.get(name)));
            };
        };
        
        return(.Ok)
    };
    
    panic("TODO: call user macros");
    .Ok
}

// - you want macros to be able to create new constant declarations in macro expansions and const arg functions.
// - for now constants are always stored globally and restricted visibility is just handled by scope resolution.
// So we delay taking constants until you try to compile the expression that contains them.
// Also, to be order independent, we don't actually evaluate or type-check them yet, that's done lazily the first time they're referenced. 
// TODO: the old compiler did #when here, but I think its better to delay until we know we care and can hope more stuff is ready. 
fn hoist_constants(self: *SelfHosted, body: []FatStmt) Maybe(void) = {
    each body { stmt |
        @match(stmt.stmt&) {
            fn DeclFunc(f) => {
                panic("TODO: hoist_constants DeclFunc");
            }
            fn DeclVar(f) => if f.name.kind == .Const {|
                self.scopes.put_constant(f.name, f.value, f.ty);
                stmt.stmt = .Noop;
            };
            @default => ();
        }
    };
    .Ok
}

::if(Maybe(void));
::if_opt(Type, Maybe(void));
fn compile_get_var(self: *SelfHosted, expr: *FatExpr, requested: ResultType) Maybe(void) = {
    @debug_assert(expr.expr&.is(.GetVar));
    var := expr.expr.GetVar;
    if var.kind == .Const {|
        (value, ty) := @check(self.find_const(var, requested)) return;
        expr.set(value, ty);
        @check(self.coerce_const_expr(expr, requested)) return;
        .Ok
    } else {|
        if self.scopes.get_var_type(var) { ty | 
            expr.ty = ty;
            expr.done = true;
            // Reading a variable. Convert it to `var&[]` so compiling it checks for smaller loads (u8, etc).
            ptr_ty := self.ptr_type(ty);
            expr[] = synthetic_ty((Addr = self.box(expr[])), expr.loc, ptr_ty);
            expr.done = true;
            // Note: not using deref_one, because don't want to just remove the ref, we want raw variable expressions to not exist. kinda HACK
            expr[] = synthetic_ty((Deref = self.box(expr[])), expr.loc, ty);
            expr.done = true;
            .Ok
        } else {|
            // For now runtime vars are always declared in order so we always know thier type.
            // This might change to allow peeking into return-ed expressions when infering closure return type? -- Jul 15
            @err("Unknown type for runtime var %", self.pool.get(var.name))
        }
    }
}

// Passing in the requested type here feels a bit weird, but I think it will make anon-functions less painful. 
fn find_const(self: *SelfHosted, name: Var, requested: ResultType) Maybe(Ty(Values, Type)) = {
    // If someone else is already trying to compile this, we don't want to fight over it. 
    if self.dispatch.const_var_in_progress&.get(name.id.zext()) {|
        return(Suspend = self.wait_for(EvalConstant = (name = name, requested = requested)));
    };
    
    var := self.scopes.get_constant(name);
    var := var.unwrap();
    
    // If we've compiled this before, great.
    //     We can't coerce_constant here because we don't have a unique expression node to stick changes into if needed. 
    //     (need to change the expression to create function pointers because they might not be compiled yet)
    @if_let(var._0.expr&) fn Value(f) => {
        return(Ok = (f.bytes&.clone(self.get_alloc()), var._0.ty));
    };
    
    self.dispatch.const_var_in_progress&.set(name.id.zext());
    
    // TODO: -- Jul 21
    // its sad to always yield here because _most_ of the time you could just do it now and it would be fine.
    // so an easy optimisation might be just trying now, if it wasn't already const_var_in_progress so we know nobody else is working on it. 
    // but since any _could_ yield, its a bug if we can't compile with _everything_ yielding,
    // so at least keep a flag to toggle this behaviour? 
    
    (Suspend = self.wait_for(EvalConstant = (name = name, requested = requested)))
}

fn decl_const(self: *SelfHosted, name: Var, ty: *LazyType, value: *FatExpr) Maybe(void) = {
    // TODO: do the @rec and type checking stuff from the rust version. 
    @check(self.compile_expr(value, .None)) return;
    if value.ty == UnknownType {|
        return(@err("TODO: needed type hint for %", self.pool.get(name.name)));
    };
    if !value.expr&.is(.Value) {|
        val := @check(self.immediate_eval_expr(value, value.ty)) return;
        value.set(val, value.ty);
    };
    .Ok
}

fn coerce_const_expr(self: *SelfHosted, expr: *FatExpr, req: ResultType) Maybe(void) = {
    @debug_assert(expr.expr&.is(.Value), "tried to coerce non-value expr");
    
    if req.specific() { req | 
        if expr.ty != req {|
            @assert(!expr.expr.Value.coerced, "const mismatch. % vs % but already coerced", self.log_type(expr.ty), self.log_type(req));
            
            expr.expr.Value.coerced = true;
            expr.ty = req;
            panic("TODO: coerce constant (might be an actual type error)");
        };
    };
    .Ok
}

fn immediate_eval_expr(self: *SelfHosted, expr: *FatExpr, ret_ty: Type) Maybe(Values) = {
    if self.check_quick_eval(expr, ret_ty) { val |
        return(Ok = val);
    };
    
    // TODO: you need to be on a new stack for this.
    req: ResultType = (Specific = ret_ty);
    @check(self.compile_expr(expr, req)) return;
    if self.check_quick_eval(expr, ret_ty) { val |
        return(Ok = val);
    };
    
    panic("TODO: immediate_eval_expr")
}

fn check_quick_eval(self: *SelfHosted, expr: *FatExpr, ret_ty: Type) ?Values = {
    @match(expr.expr&) {
        fn Value(f) => (Some = f.bytes&.clone(self.get_alloc()));
        fn Block(it) => {
            if it.body.is_empty() {|
                return(self.check_quick_eval(it.result, ret_ty));
            };
            .None
        }
        fn Tuple(parts) => {
            all: List(u8) = list(self.get_alloc());
            each parts { part |
                // TODO: tuple_types
                val := or self.check_quick_eval(part, part.ty) {|
                    return(.None)
                };
                all&.push_all(val&.bytes());
            };
            (Some = (Big = all.rs()))
        }
        fn Call(it) => {
            if it.f.expr&.is(.Value) {|
                @if_let(self.get_type(it.f.ty)) fn FnPtr(f) => {
                    if self.check_quick_eval(it.arg, f.ty.arg) { arg_value |
                        f_ptr := i64.assume_cast(it.f.expr.Value.bytes&)[];
                        // SAFETY: we're passing comp_ctx=false so it won't try to use the pointer as a real CompilerRs.
                        evil_hack := self;
                        evil_hack := self&;
                        self.finish_layout_deep(it.f.ty);
                        res := evil_hack&.call_dynamic_values(f_ptr, f.ty&, arg_value&.bytes(), false);
                        @match(res) {
                            fn Ok(res) => {
                                expr.set(res&.clone(self.get_alloc()), f.ty.ret);
                                return(Some = res);
                            }
                            fn Err(e) => (); // TODO: don't just swollow errors
                        }
                    };
                };
            };
            .None
        }
        @default => .None;
    }
}

fn create_slice_type(self: *SelfHosted, inner: Type) Maybe(Type) = {
    panic("TODO: create_slice_type")
}

fn parse_for_test(c: *SelfHosted, src: Str) FatExpr = {
    span := c.codemap.add_file("name", src);
    id := push_parse(c.parser, src, span);
    c.parser.finish_pending(id).unwrap()
}

fn reach_sema(vtable: *ImportVTable) void = {
    c := {vtable.init_compiler}(.Aarch64);
    c := c.cast()[][];
    src :: """fn() => { 
        builtin :: "this will never be evaluated";
        assert_eq :: @builtin("compiler_debug_assert_eq_i64");
        abc :: 123; 
        assert_eq(123, 123)
        //abc
    }""";
    e := c.parse_for_test(src);
    
    func := e.expr.Closure;
    s := scope_from_index(0);
    r := c.resolve_root(func, s);
    r.unwrap();
    e := func.body.Normal;
    stack: List(ExprAttempt) = list(1, libc_allocator);
    stack&.push(expr = e&, requested = .None);
    
    task: Task = (action = (CompileExpr = stack&), waiting_for = list(libc_allocator));
    c.dispatch.active_tasks&.push(task&);
    
    res := c.poll_tasks();
    ::tagged(@type res);
    if res&.is(.Err) {|
        @panic("Failed %", res.Err.msg);
    };
    
    //res := c.compile_expr(e&, .None);
    //if res&.is(.Err) {|
    //    println("bad");
    //    println(res.Err.msg);
    //    panic(res.Err.msg);
    //};
    //
    @println("%", e.expr.Block.result.log(c.pool));
    
    val := c.immediate_eval_expr(e.expr.Block.result, i64);
    val := val.unwrap();
    val := i64.assume_cast(val&)[];
    assert_eq(val, 123);
}
