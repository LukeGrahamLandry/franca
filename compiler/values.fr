//! Assorted functions work working with the bytes of comptime values.
//! - Emitting relocatable baked constants for AOT (fn bake_relocatable_value).

//////////////////////
/// Bake Constants ///

// This avoids needing to linearly scan all the functions when they try to emit_relocatable_constant of a function pointer. 
// You only need to call it if they created a Values of it, so we might need to emit it as a constant later 
// (like for vtables where you construct the value in memory as with comptime pointers and then we emit relocations). 
// [Jun 30] building the compiler ends up with ~17000 FuncIds created and 21 calls to this function. So thats pretty good. 
// TODO: tho that means we wont find it if someone cheats somehow and gets the pointer in a way i didn't think of. 
//       it relies on them only being created through '!fn_ptr'/const_coerce expressions. 
fn created_jit_fn_ptr_value(self: *SelfHosted, f: FuncId, ptr: i64) void #compiler = {
    self.baked.functions&.insert(ptr, f);
}

// TODO: call this from rust. 
fn save_bake_callback(self: *SelfHosted, ty: Type, f: BakeHandler) PRes #compiler = {
    prev := self.baked.custom_bake_constant&.insert(ty, f);
    if prev.is_some() {|
        // TODO: show the two locations and the type. :ERROR_QUALITY
        msg :: "conflicting overload for bake AOT constant";
        return (Err = (span = self.last_loc, msg = msg));
    };
    .Ok
}

fn get_baked(c: *SelfHosted, id: BakedVarId) *Ty(rawptr, BakedVar) #compiler = {
    c.baked.values&.nested_index(@as(i64) id.id.zext())
}

fn put_baked(c: *SelfHosted, v: BakedVar, jit_ptr: ?i64) BakedVarId #compiler = {
    i := c.baked.values.len;
    j := jit_ptr.or(=> 0).rawptr_from_int();
    c.baked.values&.push(@as(Ty(rawptr, BakedVar)) (j, v)); // TODO: this shouldn't need type hint.
    id: BakedVarId = (id = i.trunc());
    if jit_ptr { ptr | 
        c.baked.lookup&.insert(ptr, id); // TODO: check unique? 
    };
    id
}

fn emit_relocatable_constant_body(c: CompilerRs, bytes: Slice(u8), ty: Type, force_default_handling: bool) Res(Slice(BakedEntry)) #compiler = {
    out: List(BakedEntry) = list(c.get_alloc());
    value := bytes.to_value();
    @try(c.emit_relocatable_constant_body(ty, value&, out&, force_default_handling)) return;
    (Ok = out.items())
}

// BakedVar :: @tagged(Zeros: i64, Bytes: RsVec(u8), VoidPtrArray: RsVec(BakedEntry));
// BakedEntry :: @tagged(Num: @struct(value: i64, ty: Prim), FnPtr: FuncId, AddrOf: BakedVarId);
Baked :: @struct(
    values: BucketArray(Ty(rawptr, BakedVar)),
    // TODO: defend against the same memory being aliased as different types that would want to emit the constant differently? -- Jun 30
    // TODO: this doesn't help for small strings because they're stored inline in the Values. 
    // deduplicate values by thier jit address. 
    lookup: HashMap(i64, BakedVarId),
    // avoid iterating all function pointers when you try to have one as a constant. 
    functions: HashMap(i64, FuncId),
    // Some types need special handling (Slice, CStr, etc). This are called at comptime and might call back into the auto dynamic versions to handle thier fields. 
    custom_bake_constant: HashMap(Type, BakeHandler),
);
BakeHandler :: @FnPtr(self: rawptr) Slice(BakedEntry);

// TODO: i should have constant pointers as a concept in my language.
//       right now i could check if its in the constant data arena for a hint that should catch a few of them.
fn emit_relocatable_constant(c: CompilerRs, ty: Type, value: *Values) Res(BakedVarId) #compiler = {
    jit_ptr := value.jit_addr();
    // TODO: this barely does anything! cause like cstr and slice don't go through this function. they call dyn_bake_relocatable_value. -- Jun 30
    //       this is the right idea, they just need to check thier pointers against the cache first. 
    if c.baked.lookup&.get(jit_ptr) { v | 
        // TODO: be careful about aliasing as different types with different custom_bake_constant? -- Jun 30 
        return(Ok = v);
    };
    
    // TODO: is it really that helpful to tell the backend to use zeroinitilizer? could at least have a faster memcmp. 
    (fn() => {
        break :: local_return;
        for value.bytes() { b |
            if(b != 0, => break());
        };
        return(Ok = c[][].put_baked((Zeros = value.bytes().len()), (Some = jit_ptr)));
    })();
    
    // Eventually we'll recurse to something with no pointers. ie Str -> [u8; n]
    info := c.get_info(ty);
    if (!info.contains_pointers) {|
        v := value.bytes().clone(c.get_alloc()); // TODO: do i have to clone? 
        return(Ok = c[][].put_baked((Bytes = v.rs()), (Some = jit_ptr)));
    };

    out: List(BakedEntry) = list(c.get_alloc());
    @try(c.emit_relocatable_constant_body(ty, value, out&, false)) return;
    (Ok = c[][].put_baked((VoidPtrArray = out.rs()), (Some = jit_ptr)))
}

// TODO: deduplicate small constant strings. they get stored in Values inline so can't be fixed by baked.lookup
// TODO: make sure baked.lookup actually ever helps. might need to add checks in more places.
fn emit_relocatable_constant_body(
    c: CompilerRs,
    ty: Type,
    value: *Values,
    out: *List(BakedEntry),
    force_default_handling: bool,
) PRes = {
    info := c.get_info(ty);
    if value.len() != info.stride_bytes.zext() {|
        msg := @format("ICE: Tried to emit constant value of wrong size. Expected % bytes but found %.", @as(i64) info.stride_bytes.zext(), value.len()) temp();
        return(Err = (span = c.last_loc, msg = msg.items()));
    };
    // TODO: alignment check? 
    
    // :bake_relocatable_value
    if (!force_default_handling) {|
        if c.baked.custom_bake_constant&.get(ty) { f |
            values := f(value.jit_addr().rawptr_from_int());
            out.push_all(values);
            return(.Ok);
        };
    };

    // Eventually we'll recurse to something with no pointers. ie Str -> [u8; n]
    if (!info.contains_pointers) {|
        assert_eq(value.len().mod(8), 0); // TODO. but rust version doesn't handle this either -- Jun 30
        
        bytes := value.bytes();
        ptr := ptr_cast_unchecked(u8, i64, bytes.ptr);
        ints: Slice(i64) = (ptr = ptr, len = bytes.len / 8);
        for ints { i | 
            // TODO: small prims
            out.push((Num = (i, .I64)));
        };
        return(.Ok);
    };

    // The rust version skipped to raw type at the top but that's kinda wrong cause there might be an overload for just some intermediate? 
    @match(c.get_type(ty)) {
        (fn FnPtr(_) => {
            ptr := i64.assume_cast(value)[];
            if c.baked.functions&.get(ptr) { fid |
                // assert_eq!(*f_ty, program[f].finished_ty().unwrap()); // TODO?
                out.push((FnPtr = fid));
                return (.Ok);
            };
            msg :: "function not found for constant. (might be ICE created_jit_fn_ptr_value)";
            return (Err = (span = c.last_loc, msg = msg));
        });
        (fn Ptr(inner) => {
            // TODO: allow zero?
            inner_info := c.get_info(inner[]);
            // load the pointer and recurse.
            addr := i64.assume_cast(value)[];
            
            // emit_relocatable_constant only does it by the address of the value but pointers are small so stored inline. 
            if c.baked.lookup&.get(addr) { v | 
                out.push((AddrOf = v));
                return(.Ok);
            };
            
            ptr := u8.ptr_from_int(addr);
            data := slice(ptr, inner_info.stride_bytes.zext());
            inner_value := data.to_value(); // TODO: do i have to clone? 
            id := @try(c.emit_relocatable_constant(inner[], inner_value&)) return;
            c.baked.lookup&.insert(addr, id);
            out.push((AddrOf = id));
        });
        (fn Struct(f) => {
            // Just do all the fields.
            each f.fields.items() { f | 
                info := c.get_info(f.ty);
                @assert_eq(info.stride_bytes.zext().mod(8), 0, "TODO: non-8-aligned fields");
                v := value.bytes().slice(f.byte_offset, f.byte_offset + info.stride_bytes.zext());
                v := v.to_value(); // TODO: do i have to clone? 
                @try(c.emit_relocatable_constant_body(f.ty, v&, out, false)) return;
            };
        });
        (fn Tagged(f) => {
            tag := i64.unchecked_cast(value)[]; // just read the tag
            assert(f.cases.len >= tag, "invalid constant tagged union");
            
            name := c.pool.get(f.cases.items()[tag]._0);
            println(name);
            
            inner := f.cases.items()[tag]._1;
            case_info := c.get_info(inner);
            out.push((Num = (tag, .I64)));
            payload_size: i64 = case_info.stride_bytes.zext();
            if payload_size > 0 {|
                b := value.bytes();
                tag_size := 8;
                payload := b.slice(tag_size, tag_size + payload_size).to_value();
                
                for payload&.bytes() { b |
                    print(@as(i64) b.zext());
                    print(", ");
                };
                println("]");
                
                @try(c.emit_relocatable_constant_body(inner, payload&, out, false)) return;
            };
        });
        (fn Enum(f) => {
            return(c.emit_relocatable_constant_body(f.raw, value, out, force_default_handling));
        });
        (fn Named(f) => {
            return(c.emit_relocatable_constant_body(f._0, value, out, force_default_handling));
        });
        (fn VoidPtr() => {
            ptr := i64.assume_cast(value)[];
            if ptr == 0 {|
                // You're allowed to have a constant null pointer (like for global allocator interface instances).
                out.push((Num = (0, .P64)));
                return(.Ok);
            };
            
            if c.baked.functions&.get(ptr) { fid |
                // Maybe you wanted to store a bunch of type erased functions (like i have to for export_ffi). 
                out.push((FnPtr = fid));
                return(.Ok);
            };
            
            if c.baked.lookup&.get(ptr) { v | 
                // I'm not sure why you'd get here but I guess its fine.
                out.push((AddrOf = v));
                return(.Ok);
            };
            
            msg :: "You can't have a void pointer as a constant. The compiler can't tell how many bytes to put in the final executable.";
            return (Err = (span = c.last_loc, msg = msg));
        });
        @default => {
            return (Err = (span = c.last_loc, msg = "ICE: bad constant"));
        };
    };
    .Ok
}

fn Res($T: Type) Type = Result(T, ParseErr);

fn jit_addr(v: *Values) i64 = {
    s := v.bytes();
    u8.int_from_ptr(s.ptr)
}

fn bytes(self: *Values) Slice(u8) = {
    @match(self) {
        (fn Small(v) Slice(u8) => (ptr = ptr_cast_unchecked(i64, u8, v._0&), len = v._1.zext()));
        (fn Big(v) Slice(u8) => v.items());
    }
}

fn len(self: *Values) i64 = {
    @match(self) {
        (fn Small(v) i64 => { v._1.zext() });
        (fn Big(v) i64 => { v.len });
    }
}

fn assume_cast($T: Type, self: *Values) *T #generic = {
    b := self.bytes();
    assert_eq(b.len, T.size_of());  // TODO: check alignment
    ptr_cast_unchecked(u8, T, b.ptr)
}

fn unchecked_cast($T: Type, self: *Values) *T #generic = {
    b := self.bytes();
    ptr_cast_unchecked(u8, T, b.ptr)
}

fn get_type(c: CompilerRs, ty: Type) *TypeInfo = {
    {c.vtable.get_type}(c.cast(), ty)
}

fn get_info(c: CompilerRs, ty: Type) TypeMeta = {
    {c.vtable.get_type_meta}(c.cast(), ty)
}

fn to_value(bytes: Slice(u8)) Values = {
    ::if(Values);
    if bytes.len <= 8 {|
        v := 0;
        shift := 0;
        for bytes { b |
            v = v.bit_or((@as(i64) b.zext()).shift_left(shift));
            shift += 8;
        };
        (Small = (v, bytes.len.trunc()))
    } else {|
        (Big = (cap = bytes.len, ptr = bytes.ptr, len = bytes.len))
    }
}

fn log_type(c: CompilerRs, ty: Type) Str = {
    {c.vtable.log_type}(c.cast(), ty)
}
