/*
(i assume you need this thing for static link)
ar rvs qbe_merged.o util.o parse.o abi.o cfg.o mem.o ssa.o alias.o load.o copy.o fold.o simpl.o live.o spill.o rega.o emit.o amd64/targ.o amd64/sysv.o amd64/isel.o amd64/emit.o arm64/targ.o arm64/abi.o arm64/isel.o arm64/emit.o rv64/targ.o rv64/abi.o rv64/isel.o rv64/emit.o
(for comptime dynamic link this works, you need main for the symbols _T/_debug)
clang -dynamiclib -o qbe_merged.dylib main.o util.o parse.o abi.o cfg.o mem.o ssa.o alias.o load.o copy.o fold.o simpl.o live.o spill.o rega.o emit.o amd64/targ.o amd64/sysv.o amd64/isel.o amd64/emit.o arm64/targ.o arm64/abi.o arm64/isel.o arm64/emit.o rv64/targ.o rv64/abi.o rv64/isel.o rv64/emit.o
*/
#include_std("bindings/qbe.fr");
#include_std("backend2/builder.fr");
:: {
    c := current_compiler_context();
    handle := dlopen("./bindings/qbe/qbe_merged.dylib".sym().c_str(), DlFlag.Lazy);
    assert(!handle.lib.is_null(), "failed to open qbe dylib");
    c.add_comptime_library(@symbol "qbe", handle);
};

// TODO: this has to change when i do static aot.
qbe_globals :: @static(Qbe.Globals) {  
    g: Qbe.Globals = (
        types = get_qbe_dylib_variable(InsaneVec(Qbe.Typ), "typ"),
        insb = get_qbe_dylib_variable(Array(Qbe.Ins, 1.shift_left(20)), "insb"),
        curi = get_qbe_dylib_variable(*Qbe.Ins, "curi"),
        target = get_qbe_dylib_variable(Qbe.Target, "T"),
    );
    g.target[] = get_qbe_dylib_variable(Qbe.Target, "T_arm64_apple")[]; // TODO: choose arch!
    g
};

// TODO: this changes for aot!!
outf :: @static(*FILE) {    
    out_fd := open_temp_file();
    outf := fdopen(out_fd.fd, "a".sym().c_str());
    assert(!outf.is_null(), "failed to open temp file");
    @println("Output asm to %", out_fd&.s_name());
    aaaa_out[] = out_fd;
    outf
};
aaaa_out :: @static(TmpFile);
debugf :: @static(*FILE) {    
    name :: "target/franca_debug.txt";
    outf := fopen(name.sym().c_str(), "w".sym().c_str());
    assert(!outf.is_null(), "failed to open debug file");
    @println("Output debug logging to %", name);
    outf
};

run_qbe_passes :: fn(fnn: *Qbe.Fn) void = {
    //printfn(fnn, debugf[]);
    {qbe_globals[].target.abi0}(fnn);
    fillrpo(fnn);
    fillpreds(fnn);
    filluse(fnn);
    promote(fnn);
    filluse(fnn);
    ssa(fnn);
    filluse(fnn);
    ssacheck(fnn);
    fillalias(fnn);
    loadopt(fnn);
    filluse(fnn);
    fillalias(fnn);
    coalesce(fnn);
    filluse(fnn);
    ssacheck(fnn);
    copy(fnn);
    filluse(fnn);
    fold(fnn);
    {qbe_globals[].target.abi1}(fnn);
    simpl(fnn);
    fillpreds(fnn);
    filluse(fnn);
    {qbe_globals[].target.isel}(fnn);
    fillrpo(fnn);
    filllive(fnn);
    fillloop(fnn);
    fillcost(fnn);
    spill(fnn);
    rega(fnn);
    fillrpo(fnn);
    simpljmp(fnn);
    fillpreds(fnn);
    fillrpo(fnn);
    
    assert_eq(Qbe.Blk.int_from_ptr(fnn.rpo[]), Qbe.Blk.int_from_ptr(fnn.start));
    
    ::ptr_utils(*Qbe.Blk);
    // We have a linear array but want a linked list for some reason. 
    range(0, fnn.nblk.zext() - 1) { n |
        fnn.rpo.offset(n)[].link = fnn.rpo.offset(n + 1)[];
    };
    fnn.rpo.offset(fnn.nblk.zext() - 1)[].link = Qbe.Blk.ptr_from_int(0);
    
    {qbe_globals[].target.emitfn}(fnn, outf[]);
    freeall();
};


fn finished(self: *EmitQbe2, fid: FuncId) void = {
    name: List(u8) = list(temp()); 
    self.fmt_fn_name(fid, name&);
    fnn := self.b&.build(name.items());
    printfn(fnn&, debugf[]);
}; 

#include_std("compiler/backend/walk_bc.fr");

fn fdopen(fd: Fd, mode: CStr) *FILE #libc;
fn fopen(filename: CStr, mode: CStr) *FILE #libc;
fn fwrite(ptr: rawptr, size: i64, nmemb: i64, stream: *FILE) i64 #libc;
fn fclose(stream: *FILE) voidResult #libc;

fn write(stream: *FILE, bytes: []u8) voidResult = {
    written := fwrite(u8.raw_from_ptr(bytes.ptr), 1, bytes.len, stream);
    if written < bytes.len {
        return(value = -1);
    };
    (value = 0)
}

// this returns asm text
emit_qbe_included :: fn(comp: CompCtx, fns: [] FuncId, entry: ProgramEntry, target: *TargetEnv) BucketArray(u8) = {
    ir_text := {CodeGen(EmitQbe2).emit}(comp, fns, entry, target);
    inline_asm_functions := ir_text&.pop_current_bucket().unwrap();
    
    ir_out := open_temp_file();
    for ir_text& { bucket |
        ir_out.fd&.write(bucket).unwrap();
    };
    ir_out.fd.close();
    
    ir_file := fopen(ir_out&.c_name(), "r".sym().c_str());
    ::ptr_utils(FILE);
    assert(!ir_file.is_null(), "failed to open ir_file");
    
    emitdbgfile :: fn(fnn: CStr) void = ();
    data :: fn(d: *Qbe.Dat) void = {
        emitdat(d, outf[]);
        //if (d->type == DEnd) {
        //  fputs("/* end data */\n\n", outf);
        //  freeall();
        //} 
    };
    parse(ir_file, "-".sym().c_str(), emitdbgfile, data, run_qbe_passes);
    write(outf[], inline_asm_functions.items()).unwrap();
    fclose(outf[]).unwrap();
    asm := temp().read_to_string(aaaa_out.s_name());
    aaa: BucketArray(u8) = init(0, temp());
    aaa&.push_bucket(asm);
    aaa
};


EmitQbe2 :: @struct(
    comp: CompCtx,
    b: QbeBuilder,
    block_args: List(Qbe.Ref),
    indirect_return_slot := Qbe.Ref.zeroed(),
    out: BucketArray(u8),
    current: BbId,
    next_var: i64 = 0,
    return_value_type_sizes: BitSet,
    inline_asm: List(u8),
    current_has_indirect_return := false,
    os: Os,
    $Val := Qbe.Ref, // TODO: const can't be first (doesn't parse).  -- Jun 14
);

fn get_qbe_dylib_variable($T: Type, $name: Str) *T #generic = {
    lib := dlopen("./bindings/qbe/qbe_merged.dylib".sym().c_str(), DlFlag.Lazy);
    assert(!lib.lib.is_null(), "failed to open qbe dylib");
    ref := dlsym(lib, name.sym().c_str());
    if(ref.is_null(), => @panic("failed to get '%'", name));
    T.ptr_from_raw(ref)
}

// TODO: dependency problem so can't call this `init`
fn new(comp: CompCtx, alloc: Alloc, arch: Arch, os: Os) EmitQbe2 #inline = {
    s: EmitQbe2 = (comp = comp, b = init(temp(), qbe_globals), block_args = list(temp()), out = init(12, alloc), current = BbId.zeroed(), return_value_type_sizes = empty(), inline_asm = list(alloc), os = os);
    s.return_value_type_sizes&.set(16, temp());
    
    if arch == .x86_64 {
        s.inline_asm&.push_all(".intel_syntax noprefix\n");
    };
    s
}

fn emit_function_husk(self: *EmitQbe2, fid: FuncId, signeture: PrimSig, $emit_body: @Fn() void) void = {
    @println("Emitting F% %", fid.to_index(), self.comp.get_string(self.comp.get_function(fid)[].name));
    emit_body();
}

fn emit_entry_points_and_debug_info(gen: *CodeGen(EmitQbe2), comp: CompCtx, fns: []FuncId, entry: ProgramEntry) void = {
    @match(entry) {
        fn TestRunnerMain() => {
            gen.backend.out&.push_all("export function w $main() {\n@start\n");
            
            i := 1;
            // TODO: warn if fns has duplicates
            for (fns) {f|
                gen.backend.out&.reserve(100);
                //f = gen.program.follow_redirects(f);
                func := {comp.vtable.get_function}(comp.data, f);
                // note: this only works because void has a fixed typeid value
                if func.finished_arg.unwrap() == void {
                    @fmt(gen.backend.out&.current(), "   call $%()\n", (gen.backend&, f));
                } else {
                    @fmt(gen.backend.out&.current(), "   %v% =l call $%(l 0)\n", "%", i, (gen.backend&, f));
                    i += 1;
                };
            };
            gen.backend.out&.push_all("ret 0\n}\n");
        };
        fn GiveMeTheCodeAndGiveItToMeRaw() => ();
        fn ExportWithNames() => {
            // TODO: warn if fns has duplicates
            for fns { fid |
                gen.backend&.write_export_bounce(fid);
            };
        };
    };
    
    // "They have file scope, but types must be defined before being referenced."
    out: List(u8) = list(gen.backend.out.buckets.gpa);
    range(0, gen.backend.return_value_type_sizes&.capacity()) { i |
        if gen.backend.return_value_type_sizes&.get(i) {
            @fmt(out&, "   type :Ret% = align 8 { % }\n", i, i);
        };
    };
    // Note: not the same as Ret16! we need this be be passed in registers if i want to call between backends. 
    @fmt(out&, "   type :RetPair = { l, l }\n");
    
    gen.backend.out.buckets&.insert(0, out);
    gen.backend.out.i += 1;

    // HACK we rely on this being called at the very end for our secret returning inline asm
    // TODO: clean this up and just return a struct
    gen.backend.out&.push_bucket(gen.backend.inline_asm);
    gen.backend.inline_asm = List(u8).zeroed();
}

fn emit_bounce_fn(self: *EmitQbe2, impl_name_callee: Str, fake_decl_name: Str, signeture: PrimSig, private: bool) void = {
    panic("TODO: emit_bounce_fn");
    //if !private {
    //    self.out&.push_all("export ");
    //};
    //self.out&.push_all("function ");
    //values: List(Qbe.Ref) = list(temp());
    //self.next_var = 0;
    //self.write_header(signeture, fake_decl_name) {arg_index|
    //    ::if(Prim);
    //    // TODO: format this better. 
    //    ty: Prim = if(signeture.first_arg_is_indirect_return){
    //        // TODO: only sokol tests this 
    //        if arg_index.eq(0) {
    //            Prim.P64
    //        }{
    //            signeture.args[arg_index.sub(1)]
    //        }
    //    }{
    //        signeture.args[arg_index]
    //    };
    //    values&.push(var(ty = ty, id = arg_index));
    //    s := @format("%v%", "%", arg_index) temp();
    //    self.next_var += 1;
    //    s.items()
    //};
    //self.out&.reserve(50);
    //self.out&.current().push_all("{\n@start\n");
    
    //self.current_has_indirect_return = signeture.first_arg_is_indirect_return;
    //if signeture.first_arg_is_indirect_return {
    //    @fmt(self.out&.current(), "   %ret =l alloc8 %\n", "%", signeture.return_value_bytes);
    //    @fmt(self.out&.current(), "   %v0 =l alloc8 %\n", "%", signeture.return_value_bytes);
    //};
    //if signeture.ret2.is_some() {
    //    @fmt(self.out&.current(), "   %ret =l alloc8 16\n", "%");
    //};
    
    //ret := self.inst_call(values.items(), signeture) {
    //    @fmt(self.out&.current(), "$%", impl_name_callee);
    //};
    
    //if signeture.first_arg_is_indirect_return {
    //    size: i64 = signeture.return_value_bytes.zext();
    //    // backwards from memcpy!!
    //    @fmt(self.out&.current(), "   blit %v0, %ret, %\n", "%", "%", size);
    //};
    //self.inst_return(ret);
    //self.out&.current().push_all("}\n");
}

// TODO: copy-paste from DynamicImport but reversed so its a pain. 
fn write_export_bounce(self: *EmitQbe2, fid: FuncId) void = {
    func := self.comp.get_function(fid);
    export_name := self.comp.get_string(func.name);
    internal_name: List(u8) = list(temp()); 
    self.fmt_fn_name(fid, internal_name&);
    
    sig := {self.comp.vtable.prim_sig}(self.comp.data, func).unwrap();
    self.emit_bounce_fn(internal_name.items(), export_name, sig, false);
}

fn emit_constant(self: *EmitQbe2, id: BakedVarId) void = {
    panic("TODO: emit_constant");
    //self.out&.reserve(100);
    //value := {self.comp.vtable.get_baked}(self.comp.data, id)[]._1;
    //idx: i64 = id.id.zext();
    
    //@match(value&) {
    //    (fn Zeros(len) => {
    //        @fmt(self.out&.current(), "data $g% = { z % }\n", idx, len[]);
    //    });
    //    (fn Bytes(bytes) => {
    //        // TODO: emit string as characters if they're in a sane range. 
    //        @fmt(self.out&.current(), "data $g% = { b ", idx);
    //        for(bytes[].items()) {b|
    //            @fmt(self.out&.current(), "% ", @as(i64) b.zext());
    //        };
    //        // self.pop_trailing_comma(); // add back when remove below
    //        self.out&.push_all("0 }\n"); // TODO: hack cause im to lazy to ask for debug names as cstr
    //    });
    //    (fn VoidPtrArray(parts) => {
    //        // it feels like this should be ok cause it works for bytes 
    //        // data $g9 = { l $arena_alloc__2375 $arena_free__2771  }
    //        // but no i get two frees, so do it this way. idk if qbe bug or im just failing at reading the docs
    //        // data $g9 = { l $arena_alloc__2375, l $arena_free__2771  }
    //        @fmt(self.out&.current(), "data $g% = { ", idx);
    //        for(parts[].items()){inner|
    //            self.out&.reserve(20);
    //            @match(inner) {
    //                (fn FnPtr(f) => {
    //                    // TODO: hack because of new deduplication
    //                    func := self.comp.get_function(f);
    //                    @if_let(func.body&) fn Redirect(inner) => {
    //                        f = inner[];
    //                    };
                        
    //                    @fmt(self.out&.current(), " l $%, ", (self, f));
    //                    // TODO: make sure we emitted the function. 
    //                });
    //                (fn AddrOf(id) => {
    //                    @fmt(self.out&.current(), " l $g%, ", @as(i64) id.id.zext());
    //                });
    //                (fn Num(v) => {
    //                    // TODO: small prims
    //                    @fmt(self.out&.current(), " l %, ", v.value);
    //                });
    //            };
    //        };
    //        self.pop_trailing_comma();
    //        self.out&.push_all(" }\n");
    //    });
    //}
}

fn emit_special(self: *EmitQbe2, f_id: FuncId, body: *FuncImpl, func: *Func, bc: *FnBody, pending: *List(FuncId)) bool = {
    panic("TODO: emit_special");
    //comp := self.comp;
    //@match(body) {
    //    fn Normal(_) => { panic("ICE: empty body but expr"); };
    //    fn Redirect(f) => {
    //        // TODO: assert that 'f' is flagged for being emitted?
    //        //       currently just trusting that emit_bc replaced all actual uses. 
    //        //       could also just have the front end check if body is redirect before adding to callees list. -- Jun 27
            
    //        pending.push(f[]);
            
    //        // :sema_regression :ExtraRedirectShim
    //        assert(f[] != f_id, "redirect to yourself");
    //        new_name := @format("%", (self, f[])) temp();
    //        old_name := @format("%", (self, f_id)) temp();
    //        self.emit_bounce_fn(new_name.items(), old_name.items(), bc.signeture, true);
    //        return(true);
    //    }
    //    fn Merged(parts) => { 
    //        each(parts[].items()) {check: *FuncImpl| 
    //            if(self.emit_special(f_id, check, func, bc, pending), => return(true));
    //        };
    //    }
    //    fn DynamicImport(name) => { 
    //        // TODO: do i need to hackily do the same for ComptimeAddr and hope for the best? ideally the forntend would handle that instead. 
    //        import_name := comp.get_string(name[]);
    //        self.forward_declare(bc.signeture, false, import_name);
    //        name := @format("%", (self, bc.func)) temp();
    //        self.emit_bounce_fn(import_name, name.items(), bc.signeture, true);
    //        return(true);
    //    }
    //    fn QbeIr(code) => { 
    //        self.next_var = 0;
    //        ir := comp.get_string(code[]);
    //        self.out&.push_all("function ");
    //        name := @format("%", (self, bc.func)) temp();
    //        self.write_header(bc.signeture, name.items()) {arg_index|
    //            args := func.arg.bindings.items();
    //            arg := args[arg_index].name.Var.name;
    //            arg := comp.get_string(arg);
    //            arg := @format("%%", "%", arg) temp();
    //            self.next_var += 1;
    //            arg.items()
    //        };
    //        @fmt(self.out&.current(), "{\n@start\n%}\n", ir);
    //        return(true);
    //    }
    //    fn TargetOsSplit(it) => {
    //        if it.os == self.os {
    //            // TODO: :copy-paste from emit_special:redirect
    //            pending.push(it.fid);
    //            assert(it.fid != f_id, "redirect to yourself");
    //            new_name := @format("%", (self, it.fid)) temp();
    //            old_name := @format("%", (self, f_id)) temp();
    //            self.emit_bounce_fn(new_name.items(), old_name.items(), bc.signeture, true);
    //            return(true);
    //        };
    //    }
    //    @default fn() void => return(false);
    //};
    //false
}

fn forward_declare(self: *EmitQbe2, sig: PrimSig, private: bool, name: Str) void = {
    // Qbe doesn't need external functions to be declared. The call instruction has the type information. 
}

fn emit_special_asm(self: *EmitQbe2, body: *FuncImpl, func: *Func, bc: *FnBody, target: *TargetEnv) bool = {
    arch := target.arch;
    comp := self.comp;
    @match(body) {
        (fn Merged(parts) => { 
            each(parts[].items()) {check: *FuncImpl| 
                if(self.emit_special_asm(check, func, bc, target), => return(true));
            };
        });
        (fn JittedAarch64(code) => { 
            if(arch.ne(Arch.aarch64), => { return(false); });
            // qbe spits out asm so we need to add this to that somehow
            name := @format("%", (self, bc.func)) temp();
            @fmt(self.inline_asm&, ".text\n.balign 4\n_%:", name.items());
            
            for code { inst |
                v := @as(i64) inst.zext();
                @fmt(self.inline_asm&, "   .word %\n", v);
            };
            
            return(true);
        });
        fn X86AsmText(code) => {
            if target.arch != .x86_64 { 
                return(false); 
            };
            name := @format("%", (self, bc.func)) temp();
            self.forward_declare(bc.signeture, false, name.items());
            
            prefix := if(self.os == .linux, => "", => "_");
            @fmt(self.inline_asm&, "%%:\n", prefix, (self, bc.func));
            code := self.comp.get_string(code[]);
            code := code.split_lines(temp());
            for code { inst |
                @fmt(self.inline_asm&, "%\n", inst);
            };
            return(true);
        }
        fn X86AsmBytes(code) => { // :copy-paste
            if target.arch != .x86_64 { 
                return(false); 
            };
            name := @format("%", (self, bc.func)) temp();
            self.forward_declare(bc.signeture, false, name.items());
            
            prefix := if(self.os == .linux, => "", => "_");
            @fmt(self.inline_asm&, "%%:", prefix, (self, bc.func));
            for code { inst |
                v := @as(i64) inst.zext();
                @fmt(self.inline_asm&, ".byte %\n", v);
            };
            
            return(true);
        }
        @default fn() void => return(false);
    };
    false
}

fn write_header(self: *EmitQbe2, sig: PrimSig, name: Str, $get_arg_name: @Fn(idx: i64) Str) []Qbe.Ref = {
    panic("TODO: write_header");
    //self.out&.reserve(50);
    //if(sig.ret1) {fst: Prim|
    //    if(sig.ret2) {snd: Prim| // two
    //        @fmt(self.out&.current(), " :RetPair");
    //    }{| // one
    //        @fmt(self.out&.current(), "%", fst.type_char_var());
    //    };
    //}{
    //    if sig.return_value_bytes != 0 {| // indirect
    //        @debug_assert(sig.first_arg_is_indirect_return);
    //        @fmt(self.out&.current(), ":Ret%", sig.return_value_bytes);
    //        self.return_value_type_sizes&.set(sig.return_value_bytes.zext(), temp());
    //    }
    //    // else: void
    //};
    //@fmt(self.out&.current(), " $%(", name);
    
    //// TODO: don't have two callsites for get_arg_name
    //// TODO: one of the verions of get_arg_name relies on it getting called the right number of times but mayeb thats fine cause it is in fact important that you have all the names
    //indirect_arg_name := "";  // TODO: use this somewhere? 
    //shift := if(sig.first_arg_is_indirect_return) {
    //    indirect_arg_name = get_arg_name(0);
    //    1
    //}{| 0 };
    
    //enumerate(sig.args) {i, ty|
    //    self.out&.reserve(20);
    //    i := i.add(shift);
    //    @fmt(self.out&.current(), "% %,", ty[].type_char_var(), get_arg_name(i)); 
    //};
    //self.pop_trailing_comma();
    //self.out&.current().push_all(")");
}

fn setup(self: *EmitQbe2, body: *FnBody, vars_out: *List(Qbe.Ref)) void = {
    entry := self.b&.push_block();
    
    params: List(Qbe.Ref) = list(temp());
    for body.signeture.args { prim | 
        params&.push(self.b&.push_parameter(qbe_real_class(prim)));
    };
    
    // TODO: waste for ssa vars, they just get set to the value. -- Jun 14
    enumerate body.vars.items() { i, ty |
        op := Qbe.O.alloc4;
        align := 4;
        if(ty.align > align.trunc(), => { align = 8; op = .alloc8; });
        if(ty.align > align.trunc(), => { align = 16; op = .alloc16; });
        
        size := self.b&.push_literal(@as(i64) ty.size.zext());
        v := self.b&.push_inst(entry, op, .Kl, size, QbeUndef);
        vars_out.push(v);
    };
    // TODO: use phi nodes cause this is stupid but that's such a pain in the ass. 
    // TODO: actually qbe vars are mutable so could just use those. 
    // I use these for block arguments. 
    max_args := 0;
    each body.blocks.items() { b |
        max_args = max_args.max(b.arg_prims.len);
    };
    self.block_args&.reserve(max_args);
    range(0, max_args) {i|
        v := self.b&.push_inst(entry, .alloc8, .Kl, self.b&.push_literal(8), QbeUndef);
        self.block_args&.push(v);
    };
    
    self.current_has_indirect_return = body.signeture.first_arg_is_indirect_return;
    shift := if body.signeture.first_arg_is_indirect_return {
        size := self.b&.push_literal(@as(i64) body.signeture.return_value_bytes.zext());
        self.indirect_return_slot = self.b&.push_inst(entry, .alloc8, .Kl, size, QbeUndef);
        self.b&.push_inst0(entry, .storel, .Kl, self.indirect_return_slot, self.block_args[0]);
        1
    }{| 0 };
    
    if body.signeture.ret2.is_some() {
        self.indirect_return_slot = self.b&.push_inst(entry, .alloc8, .Kl, self.b&.push_literal(16), QbeUndef);
    };
    
    enumerate body.signeture.args {i, ty|
        self.out&.reserve(20);
        i := i.add(shift);
        self.b&.push_inst0(entry, qbe_store(ty[]), qbe_fake_class(ty[]), params[i], self.block_args[i]);
        // TODO: ty.qbe_type() error says it wants the raw type but found enum ptr when it should say wants the enum type
        @fmt(self.out&.current(), "   store% %arg%, %a%\n", ty[].qbe_type(), "%", i, "%", i); 
    };
    
    // It's crimes to jump to the start block so don't use that as our entry block. 
    self.b&.end_block(entry, (type = .Jjmp, target1 = (id = 1)));
}

fn fmt_fn_name(self: *EmitQbe2, f: FuncId, out: *List(u8)) void = {
    opts := self.comp.get_build_options();
    if opts.retain_function_names {
        func := self.comp.get_function(f);
        real_name := self.comp.get_string(func.name);
        @fmt(out, "%__%", real_name, f.to_index());
    } else {
        @fmt(out, "F%", f.to_index());
    }
}

fn fn_name_cstr(self: *EmitQbe2, f: FuncId) CStr = {
    name: List(u8) = list(libc_allocator /*TODO :LEAK*/); 
    self.fmt_fn_name(f, name&);
    name&.push(0);
    (ptr = name.maybe_uninit.ptr)
}

fn display(self: Ty(*EmitQbe2, FuncId), out: *List(u8)) void = {
    self._0.fmt_fn_name(self._1, out);
}

// TODO: are the float cmp ordered or unordered? 
fn inst_intrinsic(self: *EmitQbe2, args: []Qbe.Ref, op: Intrinsic) []Qbe.Ref = {
    panic("TODO: inst_intrinsic")
    //bin :: fn(self: *EmitQbe2, args: [] Qbe.Ref, op: Str) [] Qbe.Ref = {
    //    out := self.get_var(args[0].ty);
    //    @fmt(self.out&.current(), "   % =% % %, %\n", out, out.ty.type_char_var(), op, args[0], args[1]);
    //    a := temp().alloc(EmitQbe2.Val, 1);
    //    a.ptr[] = out;
    //    a
    //};
    //bin_cmp :: fn(self: *EmitQbe2, args: []Qbe.Ref, op: Str) []Qbe.Ref = {
    //    out := self.get_var(.I8);
    //    @fmt(self.out&.current(), "   % =% % %, %\n", out, Prim.I8.type_char_var(), op, args[0], args[1]);
    //    a := temp().alloc(EmitQbe2.Val, 1);
    //    a.ptr[] = out;
    //    a
    //};    
    //cast :: fn(self: *EmitQbe2, args: []Qbe.Ref, ty: Prim, op: Str) []Qbe.Ref = {
    //    out := self.get_var(ty);
    //    @fmt(self.out&.current(), "   % =% % %\n", out, ty.type_char_var(), op, args[0]);
    //    a := temp().alloc(EmitQbe2.Val, 1);
    //    a.ptr[] = out;
    //    a
    //};

    //@match(op) {
    //    fn Add() => self.bin(args, "add");
    //    fn Sub() => self.bin(args, "sub");
    //    fn Mul() => self.bin(args, "mul");
    //    fn Div() => self.bin(args, "div");
    //    fn Eq() => self.bin_cmp(args, "ceql");
    //    fn Ne() => self.bin_cmp(args, "cnel");
    //    fn Ge() => self.bin_cmp(args, "csgel");
    //    fn Le() => self.bin_cmp(args, "cslel");
    //    fn Gt() => self.bin_cmp(args, "csgtl");
    //    fn Lt() => self.bin_cmp(args, "csltl");
    //    // sketch aliasing because walk_bc is gonna copy the slice back onto itself but it seems to be fine. -- Jul 24  
    //    fn IntToPtr() => args.slice(0, 1); // no-op 
    //    fn PtrToInt() => args.slice(0, 1); // no-op
    //    fn ShiftLeft()            => self.bin(args, "shl");
    //    fn ShiftRightLogical()    => self.bin(args, "shr");
    //    fn ShiftRightArithmetic() => self.bin(args, "sar");
    //    fn BitOr()  => self.bin(args, "or");
    //    fn BitAnd() => self.bin(args, "and");
    //    fn BitXor() => self.bin(args, "xor");
    //    fn FAdd() => self.bin(args, "add");
    //    fn FSub() => self.bin(args, "sub");
    //    fn FMul() => self.bin(args, "mul");
    //    fn FDiv() => self.bin(args, "div");
    //    fn FEq() => self.bin_cmp(args, "ceqd");
    //    fn FNe() => self.bin_cmp(args, "cned");
    //    fn FGe() => self.bin_cmp(args, "cged");
    //    fn FLe() => self.bin_cmp(args, "cled");
    //    fn FGt() => self.bin_cmp(args, "cgtd");
    //    fn FLt() => self.bin_cmp(args, "cltd");
        
    //    // TODO: trunc shouldn't be a noop! it should and off the top bits! but this is what the old inline asm did.
    //    //       MAKE A TEST THAT FAILS BECAUSE OF THIS! -- Jul 25 :FUCKED
    //    //       also im not chaning the prim type of the value so test that makes that fail also would be good. 
    //    fn Trunc64To32() => args.slice(0, 1); // no-op
    //    fn Trunc64To16() => args.slice(0, 1); // no-op
    //    fn Trunc64To8()  => args.slice(0, 1); // no-op
    //    fn Trunc32To16() => args.slice(0, 1); // no-op
    //    fn Trunc32To8()  => args.slice(0, 1); // no-op
    //    fn Trunc16To8()  => args.slice(0, 1); // no-op 
        
    //    fn SignExtend32To64() => self.cast(args, .I64, "extsw");
    //    fn ZeroExtend32To64() => self.cast(args, .I64, "extuw");
    //    fn ZeroExtend16To64() => self.cast(args, .I64, "extuw");
    //    fn ZeroExtend8To64()  => self.cast(args, .I64, "extuw");
    //    // TODO: im not changing prim type properly. if it doesn't matter don't track it!! -- Jul 25
    //    fn ZeroExtend16To32() => args.slice(0, 1); // no-op 
    //    fn ZeroExtend8To32()  => args.slice(0, 1); // no-op 
    //    fn ZeroExtend8To16()  => args.slice(0, 1); // no-op 
        
    //    fn IntToFloatValue() => self.cast(args, .F64, "sltof"); 
    //    fn FloatToIntValue() => self.cast(args, .I64, "dtosi"); 
    //    fn IntToFloatBits()  => self.cast(args, .F64, "cast"); 
    //    fn FloatToIntBits()  => self.cast(args, .I64, "cast"); 
    //    fn ShrinkFloat()     => self.cast(args, .F32, "truncd"); 
    //    fn GrowFloat()       => self.cast(args, .F64, "exts"); 
    //    fn BitNot() => {
    //        out := self.get_var(args[0].ty);
    //        @fmt(self.out&.current(), "   % =% xor %, -1\n", out, out.ty.type_char_var(), args[0]);
    //        a := temp().alloc(EmitQbe2.Val, 1);
    //        a.ptr[] = out;
    //        a
    //    }
    //    @default => @panic("ICE: unhandled qbe inst_intrinsic %", op);
    //}
}

fn inst_call(self: *EmitQbe2, args: Slice(Qbe.Ref), sig: PrimSig, f: FuncId, tail: bool, _loc: ?Span) Slice(EmitQbe2.Val) = {
    callee := self.b&.push_symbol(self.fn_name_cstr(f));
    self.inst_call(args, sig, callee)
}

fn inst_call(self: *EmitQbe2, args: Slice(Qbe.Ref), sig: PrimSig, callee: Qbe.Ref) Slice(EmitQbe2.Val) = {
    self.b.leaf = false;
    out_vals: List(Qbe.Ref) = list(temp());
    return_value := Qbe.Ref.zeroed();
    return_type := Qbe.Cls.zeroed();
    maybe_struct_return_type := Qbe.Ref.zeroed();
    if sig.ret1 { fst: Prim |
        if sig.ret2 { snd: Prim | // two
            @panic("TODO: return pair % %", fst, snd);
            //out_vals&.push(self.get_var(fst));
            //out_vals&.push(self.get_var(snd));
            //indirect_return_slot := self.get_var(that struct type somehow)
            //@fmt(self.out&.current(), "   %v% =:RetPair call ", "%", self.next_var);
        } else { // one
            return_value = self.get_var(fst);
            out_vals&.push(return_value);
            return_type = qbe_real_class(fst);
            //@fmt(self.out&.current(), "   % =% call ", v, fst.type_char_var());
        };
    } else { // void or indirect
        if sig.first_arg_is_indirect_return {
            panic("TODO: return indirect");
            //temp_for_indirect := self.get_var(.P64);
            //size: i64 = sig.return_value_bytes.zext();
            //@fmt(self.out&.current(), "% =:Ret% ", temp_for_indirect, size);
            //self.return_value_type_sizes&.set(sig.return_value_bytes.zext(), temp());
        };
        // TODO: push call
    };
    //maybe_struct_out := self.next_var.sub(1);
    
    shift := if(sig.first_arg_is_indirect_return, => 1, => 0);
    @debug_assert_eq(args.len, sig.args.len.add(shift));
    
    range(0, sig.args.len) {i|
        ty := sig.args[i];
        v := args[i.add(shift)];
        self.b&.push_argument(self.current, qbe_real_class(ty), v);
    };
    
    self.b&.push_inst(self.current, .call, return_type, return_value, callee, maybe_struct_return_type);
    if(sig.ret2) {_| // two
        @panic("TODO: return pair");
    //    v1 := out_vals[0];
    //    v2 := out_vals[1];
    //    self.out&.reserve(30);
    //    @fmt(self.out&.current(), "   % =% load% %v%\n", v1, type_char_var(v1.ty), type_char_sign(v1.ty), "%", maybe_struct_out);
        
    //    offset_to_second_field := 8;
    //    struct_out_2 := self.get_var(.P64);
    //    @fmt(self.out&.current(), "   % =l add %v%, %\n", struct_out_2, "%", maybe_struct_out, offset_to_second_field); 
    //    @fmt(self.out&.current(), "   % =% load% %\n", v2, type_char_var(v2.ty), type_char_sign(v2.ty), struct_out_2);
    };
    if sig.first_arg_is_indirect_return {
        panic("TODO: return indirect");
    //    size: i64 = sig.return_value_bytes.zext();
    //    // backwards from memcpy!!
    //    @fmt(self.out&.current(), "   blit %v%, %, %\n", "%", maybe_struct_out, args[0], size);
    };
    
    out_vals.items()
}

fn inst_trap(self: *EmitQbe2) void = {
    panic("TODO: inst_trap")
    //self.out&.push_all("   hlt\n");
}

fn inst_call_ptr(self: *EmitQbe2, args: Slice(Qbe.Ref), sig: PrimSig, ptr: EmitQbe2.Val, _loc: ?Span) Slice(EmitQbe2.Val) = {
    self.inst_call(args, sig, ptr)
}

fn inst_offset(self: *EmitQbe2, ptr: EmitQbe2.Val, bytes: i64) EmitQbe2.Val = {
    bytes := self.b&.push_literal(bytes);
    self.b&.push_inst(self.current, .add, .Kl, ptr, bytes)
}

fn inst_literal(self: *EmitQbe2, value: i64, ty: Prim) EmitQbe2.Val = {
    @match(ty) {    
        fn F64() => self.b&.push_literal(@as(f64) value.bitcast());
        fn F32() => self.b&.push_literal(@as(f32) value.trunc().bitcast());
        @default => self.b&.push_literal(value);
    }
}

fn inst_store(self: *EmitQbe2, addr: EmitQbe2.Val, value: EmitQbe2.Val, ty: Prim) void = {
    panic("TODO: inst_store")
    //self.out&.reserve(30);
    //@fmt(self.out&.current(), "   store% %, %\n", ty.qbe_type(), value, addr); 
}

fn inst_copy(self: *EmitQbe2, from: EmitQbe2.Val, to: EmitQbe2.Val, bytes: u16) void = {
    panic("TODO: inst_copy")
    //self.out&.reserve(30);
    //// note: args are swapped from memcpy because we hate ourselves apparently!
    //@fmt(self.out&.current(), "   blit %, %, %\n", from, to, @as(i64) bytes.zext()); 
}

fn inst_func_ref(self: *EmitQbe2, fid: FuncId) EmitQbe2.Val = {
    panic("TODO: inst_func_ref")
    //v := self.get_var(.P64);
    //self.out&.reserve(30);
    //@fmt(self.out&.current(), "   % =l copy $%\n", v, (self, fid));
    //v
}

fn inst_jump_if(self: *EmitQbe2, cond: EmitQbe2.Val, true: BbId, false: BbId, args: Slice(EmitQbe2.Val)) void = {
    panic("TODO: inst_jump_if")
    //assert(args.len.eq(0), "i dont use this yet");
    //self.out&.reserve(40);
    //@fmt(self.out&.current(), "   jnz %, @b%, @b%\n", cond, @as(i64) true.id.zext(), @as(i64) false.id.zext()); 
}

fn inst_jump(self: *EmitQbe2, always: BbId, args: Slice(EmitQbe2.Val)) void = {
    panic("TODO: inst_jump")
    //enumerate(args){i, arg|
    //    self.out&.reserve(50);
    //    @fmt(self.out&.current(), "   store% %, %a%\n", arg.ty.qbe_type(), arg[], "%", i); 
    //};
    //self.out&.reserve(20);
    //@fmt(self.out&.current(), "   jmp @b%\n", @as(i64) always.id.zext()); 
}

fn inst_switch(self: *EmitQbe2, info: *RsVec(SwitchPayload), inspected: Qbe.Ref, uid: i64) void = {
    panic("TODO: inst_switch")
    //normal_branches, default := info.decode_switch();
    //next_block := 0;
    //for normal_branches { case | 
    //    cond := self.get_var(.I8);
    //    @fmt(self.out&.current(), "   % =% ceql %, %\n", cond, Prim.I8.type_char_var(), inspected, case.value);
    //    @fmt(self.out&.current(), "   jnz %, @b%, @b%_%\n", cond, @as(i64) case.block.id.zext(), uid, next_block); 
    //    @fmt(self.out&.current(), "@b%_%\n", uid, next_block); 
    //    next_block += 1;
    //};
    //if default { default |
    //    @fmt(self.out&.current(), "   jmp @b%\n", @as(i64) default.id.zext()); 
    //};
}

fn inst_return(self: *EmitQbe2, args: Slice(EmitQbe2.Val)) void = {
    @switch(args.len){
        @case(0) => {
            if self.current_has_indirect_return {
                panic("TODO: inst_return indirect");
                //self.out&.current().push_all("   ret %ret\n");
            } else {
                self.b&.end_block(self.current, (type = .Jret0));
            };
        };
        @case(1) => {
            //@fmt(self.out&.current(), "   ret %\n", args[0]); 
            panic("TODO: inst_return 1");
        };
        @case(2) => {
            panic("TODO: inst_return 2");
            //offset_to_second_field := 8; // TODO
            //@fmt(self.out&.current(), "   store% %, %ret\n", args[0].ty.qbe_type(), args[0], "%"); 
            //@fmt(self.out&.current(), "   %ret2 =l add %ret, %\n", "%", "%", offset_to_second_field); 
            //@fmt(self.out&.current(), "   store% %, %ret2\n", args[1].ty.qbe_type(), args[1], "%"); 
            //@fmt(self.out&.current(), "   ret %ret\n", "%"); 
        };
        @default fn() => unreachable();
    };
}

fn move_to_block(self: *EmitQbe2, block: *BasicBlock, ip: BbId) Slice(EmitQbe2.Val) = {
    // The backend might not go to blocks in order but we want BbIds to match. 
    while => self.b.blocks.len <= ip.id.zext() + 1 {
        self.b&.push_block();
    };
    self.current = (id = ip.id + 1); // off by one for entry block
    args: List(EmitQbe2.Val) = list(block.arg_prims.len, temp());
    
    enumerate block.arg_prims { i, ty |
        v := self.b&.push_inst(self.current, qbe_load(ty[]), qbe_fake_class(ty[]), self.block_args[i], QbeUndef);
        args&.push(v);
    };
    
    args.items()
}

fn var(ty: Prim, id: i64) Qbe.Ref = {
    (ty = ty, data = (Var = id))
}

// TODO: need to sign extend sometimes. 
fn inst_load(self: *EmitQbe2, addr: EmitQbe2.Val, ty: Prim) EmitQbe2.Val = {
    panic("TODO: inst_load")
    //value := self.get_var(ty);
    
    //// Prim :: @enum(I8, I16, I32, F64, F32, P64);
    //inst := @switch(ty) {
    //    @case(.I8) => "loadub";
    //    @case(.I16) => "loaduh";
    //    @case(.I32) => "loaduw";
    //    @case(.I64) => "loadl";
    //    @case(.F64) => "loadd";
    //    @case(.F32) => "loads";
    //    @case(.P64) => "loadl";
    //};
    
    //self.out&.reserve(30);
    //@fmt(self.out&.current(), "   % =% % %\n", value, ty.type_char_var(), inst, addr); 
    //value
}

fn inst_global(self: *EmitQbe2, id: BakedVarId) EmitQbe2.Val = {
    name := @format("g%", @as(i64) id.id.zext()) libc_allocator /* TODO :LEAK */;
    name&.push(0);
    self.b&.push_symbol(ptr = name.maybe_uninit.ptr)
}

fn get_var(self: *EmitQbe2, ty: Prim) Qbe.Ref = {
    self.b&.push_temp(qbe_real_class(ty))
}

fn qbe_real_class(ty: Prim) Qbe.Cls = {
    @match(ty) {
        fn P64() => .Kl;
        fn I64() => .Kl;
        fn I32() => .Kw;
        fn I16() => .Kw;
        fn I8() =>  .Kw;
        fn F64() => .Kd;
        fn F32() => .Ks;
    }
}

fn qbe_fake_class(ty: Prim) Qbe.Cls = {
    @match(ty) {
        fn P64() => .Kl;
        fn I64() => .Kl;
        fn I32() => .Kw;
        fn I16() => .Kuh;
        fn I8() =>  .Kub;
        fn F64() => .Kd;
        fn F32() => .Ks;
    }
}

fn qbe_store(ty: Prim) Qbe.O = {
    @match(ty) {
        fn P64() => .storel;
        fn I64() => .storel;
        fn I32() => .storew;
        fn I16() => .storeh;
        fn I8() =>  .storeb;
        fn F64() => .stored;
        fn F32() => .stores;
    }
}

// TODO: wrong becuase sometimes you want sign extend
fn qbe_load(ty: Prim) Qbe.O = {
    @match(ty) {
        fn P64() => .load;
        fn I64() => .load;
        fn I32() => .loaduw;
        fn I16() => .loaduh;
        fn I8() =>  .loadub;
        fn F64() => .load;
        fn F32() => .load;
    }
}


fn display(self: Qbe.Ref, out: *List(u8)) void = {
    out.push_all("TODO:Qbe.Ref");
}
