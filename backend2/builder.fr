// TODO: preallocate the arrays since qbe sets maximum sizes for things (and other places in the backend use those numbers). 
// it doesnt have to be fast it just has to work
// it doesnt have to be fast it just has to work
// for now... 

QbeBuilder :: @struct(
    globals: *Qbe.Globals,
    temporaries: List(Qbe.Tmp),
    constants: List(Qbe.Con),
    memory: List(Qbe.Addr),
    blocks: List(WipBlock),
    lnk := Qbe.Lnk.zeroed(),
    leaf := true,
    aggragate_return_index: ?i64,
);

QbeTerminator :: @struct(
    arg := QbeUndef,
    target1 := BbId.zeroed(),
    target2 := BbId.zeroed(),
    type: Qbe.J,
);

WipBlock :: @struct(
    insts: List(Qbe.Ins),
    jmp: QbeTerminator,
);

fn init(gpa: Alloc, globals: *Qbe.Globals) QbeBuilder = {
    b: QbeBuilder = (
        globals = globals,
        temporaries = list(gpa),
        constants = list(gpa),
        memory = list(gpa),
        blocks = list(gpa),
        aggragate_return_index = .None,
    );
    b&.clear();
    b
}

fn clear(b: *QbeBuilder) void = {
    // :ClearOkBecauseCopied
    b.constants&.clear();
    b.temporaries&.clear(); 
    b.memory&.clear();
    b.blocks&.clear();
    b.aggragate_return_index = .None;
    
    b.constants&.push(type = .CBits, bits = (i = 0xdeaddead)); // :Undef
    b.constants&.push(type = .CBits, bits = (i = 0));
    
    // Add temporaries representing physical registers.
    // TODO: is it required to pad out fake ones up to 64? maybe they're ignored and its just to make the indices work out. -- Sep 25
    range(0, Qbe.Tmp0) { i |
        is_float := b.globals.target.fpr0 <= i.intcast() && i.intcast() < (b.globals.target.fpr0 + b.globals.target.nfpr);
		if is_float {
		    b.push_temp(.Kd);
		} else {
		    b.push_temp(.Kl);
		};
    };
}

// TODO: I'm not setting width.
fn push_temp(b: *QbeBuilder, k: Qbe.Cls) Qbe.Ref = {
    temp := Qbe.Tmp.zeroed();
    if b.temporaries.len >= Qbe.Tmp0 {
        // TODO: don't be fucking with strings, only do this in debug mode.
        name: List(u8) = (maybe_uninit = temp.name&.items(), len = 0, gpa = panicking_allocator);
        @fmt(name&, "v%", b.temporaries.len - Qbe.Tmp0);
    };
    temp.cls = k;
    temp.slot = -1;
    temp.nuse = 1;
    temp.ndef = 1;
    b.temporaries&.push(temp);
    ref(.RTmp, b.temporaries.len - 1)
}

// TODO: fix load/store union in emit_bc so you can just pass `get_field_type(Qbe.Con, @symbol bits)`
fn push_literal(b: *QbeBuilder, i: i64) Qbe.Ref = {
    con: Qbe.Con = (type = .CBits, bits = (i = i));
    b.constants&.push(con);
    ref(.RCon, b.constants.len - 1)
}

fn push_literal(b: *QbeBuilder, i: f64) Qbe.Ref = {
    con: Qbe.Con = (type = .CBits, bits = (d = i));
    b.constants&.push(con);
    ref(.RCon, b.constants.len - 1)
}

fn push_literal(b: *QbeBuilder, i: f32) Qbe.Ref = {
    con: Qbe.Con = (type = .CBits, bits = (s = i));
    b.constants&.push(con);
    ref(.RCon, b.constants.len - 1)
}

fn push_symbol(b: *QbeBuilder, name: CStr) Qbe.Ref = {
    con: Qbe.Con = (type = .CAddr, bits = (i = 0));
    con.sym.id = intern(name); // TODO: why can't do this inline :FUCKED
    b.constants&.push(con);
    ref(.RCon, b.constants.len - 1)
}

fn push_inst(b: *QbeBuilder, block: BbId, op: Qbe.O, k: Qbe.Cls, out: Qbe.Ref, in1: Qbe.Ref, in2: Qbe.Ref) void = {
    // TODO: why bother
    // if k > .Ksb {| k = .Kw; };
    @debug_assert(k == .Kl || k == .Kw || k == .Ks || k == .Kd, "size must be w/l/s/d");
    // TODO: should be able to init array from tuple
    inst: Qbe.Ins = (op30_cls2 = pack_op_cls(op, k), arg = init(@slice(in1, in2)), to = out);
    b.blocks[block.id.zext()].insts&.push(inst);
}

fn push_inst(b: *QbeBuilder, block: BbId, op: Qbe.O, k: Qbe.Cls, in1: Qbe.Ref, in2: Qbe.Ref) Qbe.Ref = {
    out := b.push_temp(k);
    b.push_inst(block, op, k, out, in1, in2);
    out
}

fn push_inst0(b: *QbeBuilder, block: BbId, op: Qbe.O,  k: Qbe.Cls, in1: Qbe.Ref, in2: Qbe.Ref) void = {
    b.push_inst(block, op, k, QbeUndef, in1, in2);
}

fn push_blit(b: *QbeBuilder, block: BbId, dest: Qbe.Ref, src: Qbe.Ref, size: i64) void = {
    if size < 0 || size >= 0x10000000 {
        err("invalid blit size".sym().c_str());
    };
    // TODO: why not just put the size in the out slot? 
    //       maybe its about avoiding a branchy special case to check that its actually a register. 
    b.push_inst(block, .blit0, .Kw, QbeUndef, src, dest); // note: flipped from memcpy
    b.push_inst(block, .blit1, .Kw, QbeUndef, small_int_for_blit(size), QbeUndef);
}
        
// Parameters are represented as instructions at the beginning of the @start block. 
fn push_parameter(b: *QbeBuilder, arg_type: Qbe.Cls) Qbe.Ref = {
    @debug_assert(b.blocks.len == 1, "push args at the beginning of the start block");
    // TODO: check that only args pushed so far just to be helpful. 
    @debug_assert(arg_type != .Kc, "TODO: I don't support struct typed args yet because emit_bc throws away the info (but that needs to be fixed to implement the abi correctly)");
    // if (arg_type == .Kc) *curi = (Ins){Oparc, Kl, r, {TYPE(ty)}};
    
    is_small_for_abi := arg_type >= Qbe.Cls.Ksb;
    base_type := if(is_small_for_abi, => Qbe.Cls.Kw, => arg_type);
    op := if(is_small_for_abi, => offset_by_class(Qbe.O.parsb, arg_type), => Qbe.O.par);
    value_out := b.push_temp(base_type);
    block: BbId = (id = 0);
    b.push_inst(block, op, base_type, value_out, QbeUndef, QbeUndef);
    value_out
}

// Each argument to a call is represented by an instruction. Don't forget to `push_inst(call)` at the end. 
fn push_argument(b: *QbeBuilder, block: BbId, arg_type: Qbe.Cls, value: Qbe.Ref) void = {
    @debug_assert(arg_type != .Kc, "TODO: I don't support struct typed args yet because emit_bc throws away the info (but that needs to be fixed to implement the abi correctly)");
    is_small_for_abi := arg_type >= Qbe.Cls.Ksb;
    base_type := if(is_small_for_abi, => Qbe.Cls.Kw, => arg_type);
    op := if(is_small_for_abi, => offset_by_class(Qbe.O.argsb, arg_type), => Qbe.O.arg);
    b.push_inst(block, op, base_type, QbeUndef, value, QbeUndef);
}

fn offset_by_class(op: Qbe.O, k: Qbe.Cls) Qbe.O = {
    // TODO: make this not painful
    a: i64 = k.raw().zext();
    b: i64 = Qbe.Cls.Ksb.raw().zext();
    c: i64 = op.raw().zext();
    d := c + a - b;
    @as(Qbe.O) @as(i32) d.intcast()
}

// TODO: type for typeid
// TODO: the front end should cache these since it has to track types anyway. and then we wouldn't need to do this scan. 
//       they probably don't have to be uniqued anyway, i think we just care about the structure for the abi. 
fn opaque_type_slow(b: *QbeBuilder, size: i64, align_log2: i64) i64 = {
    // :SLOW
    n := b.globals.number_of_types;
    enumerate b.globals.types[].slice(0, n) { i, type | 
        if type.is_dark && type.size == size && type.align_log2.zext() == align_log2 {
            return(i);
        };
    };
    b.globals.types.grow(n + 1);
    type := b.globals.types[n]&;
    type[] = Qbe.Typ.zeroed();
    type.is_dark = true;
    type.align_log2 = align_log2.intcast();
    type.size = size;
    type.nunion = 1; // don't forget this or life is ass 
    b.globals.number_of_types += 1;
    // TODO: don't be fucking with strings, only do this in debug mode.
    name: List(u8) = (maybe_uninit = type.name&.items(), len = 0, gpa = panicking_allocator);
    @fmt(name&, "t%s%a%", n, size, align_log2);
    n
}

// TODO: could do the size+align calc here but my front end already does it for now.  that means you have to put FPad in too!!!
//       but i barely use this for now. TODO: ill need to improve that when i want to follow the abi better. 
fn struct_type(b: *QbeBuilder, fields: []Qbe.Field, size: i64, align_log2: i64) i64 = {
    n := b.globals.number_of_types;
    b.globals.types.grow(n + 1);
    type := b.globals.types[n]&;
    type[] = Qbe.Typ.zeroed();
    type.fields = new(fields.len + 1, .PHeap);
    type.align_log2 = align_log2.intcast();
    type.size = size;
    enumerate fields { i, f | 
        type.fields[i] = f[];
    };
    type.nunion = 1;// don't forget this or life is ass (it caused a 0 op, `no match for (null)(w)`)
    type.fields[fields.len] = (type = .FEnd, len = 0);
    b.globals.number_of_types += 1;
    name: List(u8) = (maybe_uninit = type.name&.items(), len = 0, gpa = panicking_allocator);
    @fmt(name&, "t%", n);
    n
}

fn ge(a: Qbe.Cls, b: Qbe.Cls) bool #redirect(Ty(i64, i64), bool);
fn gt(a: Qbe.Cls, b: Qbe.Cls) bool #redirect(Ty(i64, i64), bool);
fn add(a: i16, b: i16) i16 #redirect(Ty(i64, i64), i64);
fn sub(a: i16, b: i16) i16 #redirect(Ty(i64, i64), i64);

fn push_block(b: *QbeBuilder) BbId = {
    // zero init terminator is Qbe.J.Jxxx
    b.blocks&.push(insts = list(b.blocks.gpa), jmp = QbeTerminator.zeroed());
    // TODO: set name for debug
    (id = b.blocks.len.sub(1).trunc())
}

fn end_block(b: *QbeBuilder, bb: BbId, jmp: QbeTerminator) void = {
    block := b.blocks[bb.id.zext()]&;
    @debug_assert(block.jmp.type == .Jxxx, "tried to close block % twice", bb.id);
    block.jmp = jmp;
}

fn build(b: *QbeBuilder, name: Str, /*TODO: link_type: Qbe.Lnk,*/) Qbe.Fn = {
    curf := Qbe.Fn.zeroed();
	// curf.rpo = 0; filled in by later pass
	// curf.vararg = false; // TODO
    
    // :ClearOkBecauseCopied
    curf.ntmp = b.temporaries.len.intcast();
    curf.tmp = new_copy(b.temporaries.items(), .PFn);
    curf.ncon = b.constants.len.intcast();
    curf.con = new_copy(b.constants.items(), .PFn);
    curf.nmem = b.memory.len.intcast();
    curf.mem = new_copy(b.memory.items(), .PFn);
    //@println("% temps. % blocks.", curf.ntmp.zext() - Qbe.Tmp0, b.blocks.len);
    
	curf.leaf = b.leaf;
    curf.lnk = b.lnk;
	curf.retty = (b.aggragate_return_index || @as(i64) -1).intcast();
	
    if b.blocks.len == 0 {
        err("empty function".sym().c_str());
    };
    if name.len > 80 {
        err("TODO: function name cannot be longer than 80 characters".sym().c_str());
    };
    name_dest := curf.name&.items().slice(0, name.len);
    name_dest.copy_from(name);
    
    qbe_blocks: List(Qbe.Blk) = list(b.blocks.len, b.blocks.gpa); // stable!
	curf.nblk = b.blocks.len.trunc();
	
    curf.start = qbe_blocks.index_unchecked(0);
    enumerate b.blocks { i, wip |
        if wip.jmp.type == .Jxxx {
            wip.jmp.type = .Jhlt;  // TODO: report error and force the front end to be precise and not have empty blocks. 
        };
        qbe_blocks&.push(Qbe.Blk.zeroed());
        block := qbe_blocks[i]&;
        block.nins = wip.insts.len.trunc();
        block.ins = wip.insts.maybe_uninit.ptr;
        if i == b.blocks.len - 1 {
            block.link = Qbe.Blk.ptr_from_int(0);
        } else {
            block.link = qbe_blocks.index_unchecked(i + 1);
        };
        block.jmp.type = wip.jmp.type;
        block.jmp.arg = wip.jmp.arg;
        if wip.jmp.target1.id != 0 {
            block.s1 = qbe_blocks.index_unchecked(wip.jmp.target1.id.zext());
        };
        if wip.jmp.target2.id != 0 {
            block.s2 = qbe_blocks.index_unchecked(wip.jmp.target2.id.zext());
        };
        
        // TODO: don't be fucking with strings, only do this in debug mode.
        name: List(u8) = (maybe_uninit = block.name&.items(), len = 0, gpa = panicking_allocator);
        @fmt(name&, "b%", i);
    };
	
	// TODO: make sure nothing requires the extra call to fillpreds and then disable this in release mode. 
	//       if the frontend generates valid code it will always type check. 
	//       but always have to option to run this to make peoples lives easier! (ie if a user wants to use #bc)
    typecheck(curf&); 
    b.clear();
    
    curf.globals = b.globals;
    curf
}

//////////////////////////////////////////////
// These are used in the optimisation passes. 
// Note: we're always iterating backwards so `emit` inserts into the block buffer backwards!
// For now we use the buffer in Qbe.Globals but that will move out eventually. 
//////////////////////////////////////////////

fn for_blocks(f: *Qbe.Fn, $body: @Fn(b: *Qbe.Blk) void) void = {
    b := f.start;
    while => !b.is_null() {
        body(b);
        b = b.link;
    };
}

// Not the same as just `for_rev(b.ins.slice(0, b.nins)`
// because the body is allowed to consume multiple instructions by offsetting the pointer. 
// This is needed because the ir uses a vairable length encoding (for blit, call, args).
fn for_insts_rev(b: *Qbe.Blk, $body: @Fn(i: **Qbe.Ins) void) void = {
    i := b.ins.offset(b.nins.zext());
    while => !i.identical(b.ins) {
        i = i.offset(-1);
        body(i&);
        // TODO: @debug_assert() `i` is still in range
    };
}

fn copy_instructions_from_scratch(f: *Qbe.Fn, b: *Qbe.Blk) void = {
    b.nins = f.scratch_next().ptr_diff(f.scratch_start()).trunc();
	idup(b.ins&, f.scratch_next(), b.nins.zext());
	f.globals.curi[] = f.scratch_start(); // TODO: make sure this is right. qbe didn't do it where i'd expect in simpl
}

fn scratch_start(f: *Qbe.Fn) *Qbe.Ins #inline =
    f.globals.insb.index_unchecked(Qbe.MaxInstructions);

fn scratch_next(f: *Qbe.Fn) *Qbe.Ins #inline =
    f.globals.curi[];

fn emit(f: *Qbe.Fn, op: Qbe.O, k: Qbe.Cls, to: Qbe.Ref, arg0: Qbe.Ref, arg1: Qbe.Ref) void = {
    i := f.globals.curi;
    if i[].identical(f.globals.insb.as_ptr()) {
        die("emit, too many instructions".sym().c_str());
    };
    i[] = i[].offset(-1);
    i[][] = (op30_cls2 = pack_op_cls(op, k), to = to, arg = init(@slice(arg0, arg1)));
}

fn emit(f: *Qbe.Fn, i: Qbe.Ins) void #inline = {
    f.emit(i&.op(), i&.cls(), i.to, i.arg&[0], i.arg&[1]);
}

// :TodoPort
fn newtmp(f: *Qbe.Fn, $debug_hint: Str, k: Qbe.Cls) Qbe.Ref #inline = {
    newtmp(debug_hint.sym().c_str(), k, f)
}

// :TodoPort
fn getcon(f: *Qbe.Fn, val: i64) Qbe.Ref #inline = {
    getcon(val, f)
}

//////////////////////////////////////

fn pack_op_cls(op: Qbe.O, k: Qbe.Cls) u32 #inline = {
    (@as(i64) k.raw().zext()).shift_left(30).bit_or(op.raw().zext()).trunc()
}

// TODO: ugh. garbage setter, i need to add real bit fields to my language!
fn set_op(i: *Qbe.Ins, op: Qbe.O) void #inline = {
    i.op30_cls2 = pack_op_cls(op, i.cls());
}

fn op(i: *Qbe.Ins) Qbe.O #inline = {
    @as(Qbe.O) @as(i32) @as(u32) i.op30_cls2.bit_and(1.shift_left(30) - 1)
}

fn cls(i: *Qbe.Ins) Qbe.Cls #inline = {
    x := i.op30_cls2.shift_right_logical(30).bit_and(1.shift_left(2) - 1);
    @as(Qbe.Cls) @as(i16) x.trunc()
}

fn KBASE(k: Qbe.Cls) i64 #inline = {
    k.raw().shift_right_logical(1).zext()
}

fn req(a: Qbe.Ref, b: Qbe.Ref) bool #inline = {
    a.type3_val29 == b.type3_val29
}

fn rtype(r: Qbe.Ref) Qbe.RegKind #inline = {
    if r.type3_val29 == 0 {
        return(.Undef);
    };
    @as(Qbe.RegKind) @as(u32) r.type3_val29.bit_and(1.shift_left(3) - 1)
}

fn get_constant(f: *Qbe.Fn, r: Qbe.Ref) *Qbe.Con #inline = {
    @debug_assert(rtype(r) == .RCon, "tried to get constant of non constant");
    i: i64 = r.val().zext();
    @safety(.Bounds) i < f.ncon.zext();
    f.con.index(i)
}

fn trunc(x: u32) i16 #redirect(u32, u16); // TODO
fn shift_right_logical(v: i16, shift_amount: i64) i16 #redirect(Ty(i64, i64), i64); // TODO: trunc

fn ref(cls: Qbe.RegKind, id: i64) Qbe.Ref #inline = {
    (type3_val29 = cls.raw().bitcast().bit_or(id.shift_left(3).trunc()))
}

fn val(r: Qbe.Ref) u32 #inline = {
   @as(u32) r.type3_val29.shift_right_logical(3).bit_and(1.shift_left(29) - 1)
}

fn rsval(r: Qbe.Ref) i32 #inline = {    
   intcast(r.val().zext().bit_xor(0x10000000) - 0x10000000)
}

// TODO: can we use this instead of making a constant for small integer literals? 
//       qbe only uses this for blit but CBits for all constants.
fn small_int_for_blit(x: i64) Qbe.Ref #inline = 
    ref(.RInt, x.bit_and(0x1fffffff));

//////////////////////////////////////

::enum(Qbe.ConType);
fn sub(a: u64, b: u64) u64 #redirect(Ty(i64, i64), i64); // TODO: wrong because of llvm UB

::enum(Qbe.Cls);
::enum(Qbe.J);
::enum(Qbe.RegKind);
::if(Qbe.Cls);
::if(Qbe.O);
::enum(Qbe.O);
::ptr_utils(Qbe.Blk);

fn bitcast(x: i32) u32 #unsafe_noop_cast;

::if(i32);
fn sub(a: i32, b: i32) i32 #redirect(Ty(i64, i64), i64);
